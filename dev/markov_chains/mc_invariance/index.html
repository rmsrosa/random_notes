<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Invariant distributions · Random notes</title><meta name="title" content="Invariant distributions · Random notes"/><meta property="og:title" content="Invariant distributions · Random notes"/><meta property="twitter:title" content="Invariant distributions · Random notes"/><meta name="description" content="Documentation for Random notes."/><meta property="og:description" content="Documentation for Random notes."/><meta property="twitter:description" content="Documentation for Random notes."/><meta property="og:url" content="https://github.com/rmsrosa/random_notes/markov_chains/mc_invariance/"/><meta property="twitter:url" content="https://github.com/rmsrosa/random_notes/markov_chains/mc_invariance/"/><link rel="canonical" href="https://github.com/rmsrosa/random_notes/markov_chains/mc_invariance/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Random notes logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Random notes</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Random Notes</a></li><li><span class="tocitem">Probability Essentials</span><ul><li><a class="tocitem" href="../../probability/kernel_density_estimation/">Kernel Density Estimation</a></li><li><a class="tocitem" href="../../probability/convergence_notions/">Convergence notions</a></li></ul></li><li><span class="tocitem">Discrete-time Markov chains</span><ul><li><a class="tocitem" href="../mc_definitions/">Essential definitions</a></li><li class="is-active"><a class="tocitem" href>Invariant distributions</a><ul class="internal"><li><a class="tocitem" href="#Definition"><span>Definition</span></a></li><li><a class="tocitem" href="#Examples"><span>Examples</span></a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Countable-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../mc_countableX_recurrence/">Recurrence in the countable-space case</a></li><li><a class="tocitem" href="../mc_countableX_connections/">Connected states, irreducibility and uniqueness of invariant measures</a></li><li><a class="tocitem" href="../mc_countableX_convergencia/">Aperiodicidade e convergência para a distribuição estacionária</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Continuous-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../mc_irreducibility_and_recurrence/">Irreducibility and recurrence in the continuous-space case</a></li></ul></li></ul></li><li><span class="tocitem">Sampling methods</span><ul><li><a class="tocitem" href="../../sampling/overview/">Overview</a></li><li><a class="tocitem" href="../../sampling/prng/">Random number generators</a></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Transform methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/invFtransform/">Probability integral transform</a></li><li><a class="tocitem" href="../../sampling/box_muller/">Box-Muller transform</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Accept-Reject methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/rejection_sampling/">Rejection sampling</a></li><li><a class="tocitem" href="../../sampling/empiricalsup_rejection/">Empirical supremum rejection sampling</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Markov Chain Monte Carlo (MCMC)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/mcmc/">Overview</a></li><li><a class="tocitem" href="../../sampling/metropolis/">Metropolis and Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/convergence_metropolis/">Convergence of Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/gibbs/">Gibbs sampling</a></li><li><a class="tocitem" href="../../sampling/hmc/">Hamiltonian Monte Carlo (HMC)</a></li></ul></li><li><a class="tocitem" href="../../sampling/langevin_sampling/">Langevin sampling</a></li></ul></li><li><span class="tocitem">Bayesian inference</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Bayes Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/bayes/">Bayes Theorem</a></li><li><a class="tocitem" href="../../bayesian/bayes_inference/">Bayesian inference</a></li><li><a class="tocitem" href="../../bayesian/bernstein_vonmises/">Bernstein–von Mises theorem</a></li></ul></li><li><a class="tocitem" href="../../bayesian/bayesian_probprog/">Bayesian probabilistic programming</a></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/find_pi/">Estimating π via frequentist and Bayesian methods</a></li><li><a class="tocitem" href="../../bayesian/linear_regression/">Many Ways to Linear Regression</a></li><li><a class="tocitem" href="../../bayesian/tilapia_alometry/">Alometry law for the Nile Tilapia</a></li><li><a class="tocitem" href="../../bayesian/mortality_tables/">Modeling mortality tables</a></li></ul></li></ul></li><li><span class="tocitem">Generative models</span><ul><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox"/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Score matching</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../generative/overview/">Overview</a></li><li><a class="tocitem" href="../../generative/stein_score/">Stein score function</a></li><li><a class="tocitem" href="../../generative/score_matching_aapo/">Score matching of Aapo Hyvärinen</a></li><li><a class="tocitem" href="../../generative/score_matching_neural_network/">Score matching a neural network</a></li><li><a class="tocitem" href="../../generative/parzen_estimation_score_matching/">Score matching with Parzen estimation</a></li><li><a class="tocitem" href="../../generative/denoising_score_matching/">Denoising score matching of Pascal Vincent</a></li><li><a class="tocitem" href="../../generative/sliced_score_matching/">Sliced score matching</a></li><li><a class="tocitem" href="../../generative/1d_FD_score_matching/">1D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/2d_FD_score_matching/">2D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/ddpm/">Denoising diffusion probabilistic models</a></li><li><a class="tocitem" href="../../generative/mdsm/">Multiple denoising score matching</a></li><li><a class="tocitem" href="../../generative/probability_flow/">Probability flow</a></li><li><a class="tocitem" href="../../generative/reverse_flow/">Reverse probability flow</a></li><li><a class="tocitem" href="../../generative/score_based_sde/">Score-based SDE model</a></li></ul></li></ul></li><li><span class="tocitem">Sensitivity analysis</span><ul><li><a class="tocitem" href="../../sensitivity/overview/">Overview</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Discrete-time Markov chains</a></li><li class="is-active"><a href>Invariant distributions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Invariant distributions</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes/blob/main/docs/src/markov_chains/mc_invariance.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Invariant-distributions"><a class="docs-heading-anchor" href="#Invariant-distributions">Invariant distributions</a><a id="Invariant-distributions-1"></a><a class="docs-heading-anchor-permalink" href="#Invariant-distributions" title="Permalink"></a></h1><p>Of particular interest, for time-homogeneous Markov chains, are the stationary distributions, i.e. such that <span>$X_n$</span> have the same law as <span>$X_0,$</span> for all <span>$n=0, 1, 2, \ldots.$</span> This is the same as saying that they all have the same distribution <span>$P,$</span> which is invariant by the Markov operator.</p><h2 id="Definition"><a class="docs-heading-anchor" href="#Definition">Definition</a><a id="Definition-1"></a><a class="docs-heading-anchor-permalink" href="#Definition" title="Permalink"></a></h2><p>More precisely, a probability distribution <span>$P$</span> on <span>$\mathcal{X}$</span> is <strong>(time-)invariant</strong> or <strong>stationary</strong> for a time-homogenous discrete-time Markov chain <span>$(X_n)_n$</span> when <span>$P = PK,$</span> i.e.</p><p class="math-container">\[    P(E) = \int_{\mathcal{X}} K(x, E)\;\mathrm{d}P(x),\]</p><p>where <span>$K(x, E) = K_1(x, E) = K_{n,n+1}(x, E)$</span> is the one-step transition probability of the Markov chain and the <span>$K$</span> in the equation <span>$P = PK$</span> is the associated Markov operator on the space <span>$\mathcal{P}(\mathcal{X})$</span> of probability distributions on <span>$\mathcal{X}.$</span></p><p>Sometimes it might be useful to consider measures with are not necessarily probability distributions. They may be finite or infinite, and <span>$\sigma$</span>-finite or not. In any case, we call a measure <span>$\rho$</span> <strong>(time-)invariant</strong> or <strong>stationary</strong> for the Markov chain if <span>$\rho = \rho K,$</span> i.e.</p><p class="math-container">\[    \rho(E) = \int_{\mathcal{X}} K(x, E)\;\mathrm{d}\rho(x).\]</p><p>When the transition probability has a kernel <span>$k(x, y)$</span> with respect to a measure <span>$\mu(x),$</span> this can be written as</p><p class="math-container">\[    \rho(E) = \int_E \int_{\mathcal{X}} k(x, y)\;\mathrm{d}\rho(x) \;\mathrm{d}\mu(y).\]</p><p>In the case of the Lebesgue measure, we simply have</p><p class="math-container">\[    \rho(E) = \int_E \int_{\mathcal{X}} k(x, y)\;\mathrm{d}\rho(x) \;\mathrm{d}y.\]</p><p>If, moreover, <span>$\rho$</span> has a density <span>$f$</span> with respect to the Lebesgue measure, this is equivalent to</p><p class="math-container">\[    f(y) = \int_{\mathcal{X}} k(x, y)f(y)\;\mathrm{d}x.\]</p><p>In case the space <span>$\mathcal{X}$</span> is countable, with the discrete topology, the invariance may be expressed pointwise:</p><p class="math-container">\[    \rho(y) = \sum_{y\in\mathcal{X}} K(x, y)\rho(x), \quad \forall y\in\mathcal{X}.\]</p><h2 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h2><p>A Markov chain may or may not have an invariant distribution and it may have a unique invariant distribution or several ones. This is a main topic of interest in the theory of Markov chains. Below, we give a few examples with these cases of uniqueness, non-uniqueness, and non-existence of invariant probability measures, also called stationary distributions.</p><h3 id="A-two-state-Markov-chain"><a class="docs-heading-anchor" href="#A-two-state-Markov-chain">A two-state Markov chain</a><a id="A-two-state-Markov-chain-1"></a><a class="docs-heading-anchor-permalink" href="#A-two-state-Markov-chain" title="Permalink"></a></h3><p>Let <span>$\mathcal{X} = \{1, 2\}$</span> and consider the Markov chain characterized by the one-step transition distribution</p><p class="math-container">\[    K = (K(i, j))_{i,j=1}^2 = \begin{bmatrix}
        1 - \alpha &amp; \alpha \\
        \beta &amp; 1 - \beta
    \end{bmatrix},\]</p><p>where <span>$0 &lt; \alpha, \beta &lt; 1.$</span> We can look for an invariant state by solving <span>$P = PK,$</span> with <span>$P = (p, 1-p).$</span> We have</p><p class="math-container">\[    \begin{cases}
        p = p(1-\alpha) + (1-p)\beta, \\
        1 - p = p\alpha + (1-p)(1-\beta)
    \end{cases}.\]</p><p>This can be simplified to</p><p class="math-container">\[    p(\alpha + \beta) = \beta,\]</p><p>hence</p><p class="math-container">\[    p = \frac{\beta}{\alpha + \beta}.\]</p><p>Thus, there is a unique invariant distribution, which is given by</p><p class="math-container">\[    P = \left(\frac{\beta}{\alpha + \beta}, \frac{\alpha}{\alpha + \beta}\right).\]</p><p>If <span>$\alpha &gt; \beta,$</span> then state <span>$1$</span> is more likely to go to state <span>$2$</span> than the other way around. And this also means that, in the stationary state, state <span>$2$</span> is more likely than state <span>$1$</span>. Similarly for <span>$\beta &gt; \alpha.$</span> If both are equal, then the stationary state is uniform in the state variables. In any case, we will see further on that any initial distribution converges to this unique stationary distribution.</p><p>When either or both parameters <span>$\alpha$</span> and <span>$\beta$</span> assume one of the extreme values <span>$0$</span> and <span>$1,$</span> then we may or may not have a unique invariant measure.</p><p>Indeed, if only <span>$\alpha = 0,$</span> with <span>$0 &lt; \beta \leq 1,$</span> then <span>$p=1$</span> and there is only one stationary distribution, concentrated at state <span>$x=1.$</span> If only <span>$\beta = 0,$</span> with <span>$0 &lt; \alpha \leq 1,$</span> then <span>$p=0$</span> and there is, again, only one stationary distribution, which this time is concentrated at state <span>$x=2.$</span></p><p>If both <span>$\alpha = \beta = 0,$</span> then <span>$0\leq p \leq 1$</span> is arbitrary, and there are an infinite number of stationary distributions, one concentrated at <span>$x=1,$</span> another concentrated at <span>$x=2,$</span> and many others as convex combinations of both. Effectivaly, in this case of both <span>$\alpha=\beta=0,$</span> the Markov chain can be decoupled into two separate chains, one restricted to state <span>$x=1$</span> and the other restricted to state <span>$x=2.$</span> Each has its own unique invariant measure, with the whole system having any convex combination of both as invariant measure.</p><p>Finally, if both <span>$\alpha = \beta = 1,$</span> then <span>$p=1/2$</span> and we have again a unique invariant measure, with uniform probability in both states. The peculiarity of this example is that it has some periodic solutions in time. Indeed, if we start with <span>$X_0 = 1$</span> or <span>$X_0 = 2,$</span> then it oscillates between both states. They do not converge to the stationary distribution.</p><h3 id="Random-walk-running-to-infinity"><a class="docs-heading-anchor" href="#Random-walk-running-to-infinity">Random walk running to infinity</a><a id="Random-walk-running-to-infinity-1"></a><a class="docs-heading-anchor-permalink" href="#Random-walk-running-to-infinity" title="Permalink"></a></h3><p>In the finite-state case, we always have at least one invariant probability distribution. For a case with no invariant distribution, we need to go to an infinite-state case, either discrete or continuous. Here we consider an infinite but discrete example. Similary continuous-state examples can be easily constructed.</p><p>Consider a random walk</p><p class="math-container">\[    X_n = X_n + B_n, \quad n=0, 1, 2, \ldots,\]</p><p>on <span>$\mathcal{X} = \mathbb{N},$</span> where the <span>$B_n$</span> are i.i.d. Bernoulli-type random variables with equal probabilities of being <span>$0$</span> or <span>$+1,$</span> </p><p class="math-container">\[    B_n \sim \operatorname{Bernoulli}(\{0, 1\}, 1/2).\]</p><p>This means the one-step transition probability is</p><p class="math-container">\[    K(i, j) = \frac{1}{2}\delta_{i, j} + \frac{1}{2}\delta_{i,j-1},\]</p><p>where <span>$\delta_{i,j}$</span> is the Kroenecker delta, equal to <span>$1,$</span> when <span>$i=j,$</span> and to <span>$0,$</span> otherwise. Thus any sample path has <span>$1/2$</span> probability of staying at <span>$j=1$</span> and <span>$1/2$</span> probability to move from <span>$i$</span> up to <span>$j=i+1.$</span> In (infinite-)matrix form, it has both the diagonal and the superdiagonal with entries <span>$1/2$</span> and all the other entries equal to zero.</p><p>If there were an equilibrium probability distribution <span>$p = (p_1, p_2, \cdots),$</span> where <span>$p_n \geq 0$</span> and <span>$\sum_{n\in\mathbb{N}} p_n = 1,$</span> we would have the equations</p><p class="math-container">\[    p_n = \frac{p_n + p_{n+1}}{2}, \quad n\in\mathbb{Z}.\]</p><p>This means</p><p class="math-container">\[    p_{n+1} = p_n = p_1,\]</p><p>so that</p><p class="math-container">\[    \sum_{n\in\mathbb{N}} p_n = \sum_{n\in\mathbb{N}} p_1 = \infty,\]</p><p>which makes it impossible to be a probability distribution, with <span>$\sum_{n\in\mathbb{N}} p_n = 1.$</span> This means the chain admits no invariant probability distribution. The problem here is the fact that we ask the probability to be finite. In fact, the counting measure, or any multiple of it, is an invariant measure, which is not finite. (See the next example, which is similar).</p><h3 id="A-symmetric-random-walk-on-the-integers"><a class="docs-heading-anchor" href="#A-symmetric-random-walk-on-the-integers">A symmetric random walk on the integers</a><a id="A-symmetric-random-walk-on-the-integers-1"></a><a class="docs-heading-anchor-permalink" href="#A-symmetric-random-walk-on-the-integers" title="Permalink"></a></h3><p>Even if we are allowed to move up or down, we may not have an invariant probability distribution. Consider, for instance, the random walk</p><p class="math-container">\[    X_{n+1} = X_n + B_n, \quad n = 0, 1, 2, \ldots,\]</p><p>on <span>$\mathcal{X} = \mathbb{Z},$</span> where the <span>$B_n$</span> are i.i.d. Bernoulli-type random variables with equal probabilities of being <span>$+1$</span> or <span>$-1,$</span></p><p class="math-container">\[    B_n \sim \operatorname{Bernoulli}(\{-1, +1\}, 1/2).\]</p><p>This means the one-step transition probability is</p><p class="math-container">\[    K(i, j) = \frac{1}{2}\delta_{i, j-1} + \frac{1}{2}\delta_{i,j+1},\]</p><p>where <span>$\delta_{i,j}$</span> is the Kroenecker delta, equal to <span>$1,$</span> when <span>$i=j,$</span> and to <span>$0,$</span> otherwise, so it has <span>$1/2$</span> probability to move from <span>$i$</span> to <span>$j=i+1$</span> and <span>$1/2$</span> probability to move from <span>$i$</span> to <span>$j=i-1.$</span> In (infinite-)matrix form, it has both the subdiagonal and superdiagonal with entries <span>$1/2$</span> and all the other entries equal to zero.</p><p>If there were an equilibrium probability distribution <span>$p = (\cdots, p_{-2}, p_{-1}, p_0, p_1, p_2, \cdots),$</span> where <span>$p_n \geq 0$</span> and <span>$\sum_{n\in\mathbb{Z}} p_n = 1,$</span> we would have the equations</p><p class="math-container">\[    p_n = \frac{p_{n-1} + p_{n+1}}{2}, \quad n\in\mathbb{Z}.\]</p><p>But this equation contradicts the conditions <span>$p_n \geq 0$</span> and <span>$\sum_n p_n = 1.$</span> Indeed, the finite summation implies that <span>$\liminf_{|n|\rightarrow \infty} p_n = 0.$</span> If some <span>$p_n &gt; 0,$</span> then we would have <span>$n_- &lt; n$</span> and <span>$n_+ &gt; n$</span> such that <span>$p_{n_-}, p_{n_+} &lt; p_n.$</span> This means that the maximum of <span>$p_j$</span> for <span>$n_- \leq j \leq n_+$</span> occurs somewhere within the extreme values and also that there must be a point <span>$m$</span> with <span>$p_{m-1}, p_{m+1} \leq p_m$</span> and <span>$\min\{p_{m-1}, p_{m+1}\} &lt; p_m$</span>. In this case,</p><p class="math-container">\[    p_m &gt; \frac{p_{m-1} + p_{m+1}}{2},\]</p><p>contradicting the inequality above for the stationary distribution. Thus, one cannot have an invariant probability distribution for this Markov chain.</p><p>If we look for an invariant measure which is not necessarily finite, then we find out that the <em>counting distribution</em> is invariant. In fact, the counting distribution can be written as</p><p class="math-container">\[    P(E) = \sum_{n\in \mathbb{Z}} \delta_n(E),\]</p><p>where <span>$\delta_n$</span> is the Dirac distribution at <span>$n,$</span> i.e. <span>$\delta_n(E) = 1,$</span> if <span>$n\in E, and $= 0,$</span> otherwise. Then,</p><p class="math-container">\[    \begin{align*}
        (PK)(E) &amp; = \sum_{n\in \mathbb{Z}} \frac{1}{2}\left(\delta_{n-1}(E) + \delta_{n+1}(E)\right) = \frac{1}{2}\sum_{n\in \mathbb{N}} \delta_{n-1}(E) + \frac{1}{2}\sum_{n\in\mathbb{N}}\delta_n(E) \\
        &amp; = \frac{1}{2}\sum_{i\in \mathbb{N}} \delta_{i}(E) + \frac{1}{2}\sum_{i\in\mathbb{N}}\delta_i(E) = \frac{1}{2}P(E) + \frac{1}{2}P(E) = P(E),
    \end{align*}\]</p><p>showing that <span>$P$</span> is invariant (or any constant multiple of <span>$P$</span>).</p><h3 id="Gaussian-random-walk-on-the-real-line"><a class="docs-heading-anchor" href="#Gaussian-random-walk-on-the-real-line">Gaussian random walk on the real line</a><a id="Gaussian-random-walk-on-the-real-line-1"></a><a class="docs-heading-anchor-permalink" href="#Gaussian-random-walk-on-the-real-line" title="Permalink"></a></h3><p>The last example is the random walk</p><p class="math-container">\[    X_{n+1} = X_n + W_n, \quad n = 0, 1, 2, \ldots,\]</p><p>on the real line <span>$\mathcal{X} = \mathbb{R},$</span> where</p><p class="math-container">\[    W_n \sim \mathcal{N}(0, 1)\]</p><p>are independent normal random variables. In this case, the kernel of the transition distribution is the Gaussian kernel</p><p class="math-container">\[    k(x, y) = \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}(y - x)^2}.\]</p><p>We may easily check that the Lebesgue measure <span>$\lambda$</span> is invariant for this random walk:</p><p class="math-container">\[    \begin{align*}
        (\lambda K)(E) &amp; = \int_E \int_{\mathbb{R}}k(x, y)\;\mathrm{d}x\;\mathrm{d}y \\
        &amp; = \frac{1}{\sqrt{2\pi}} \int_E \int_{\mathbb{R}} e^{-\frac{1}{2}(y - x)^2} \;\mathrm{d}x\;\mathrm{d}y \\
        &amp; = \int_E \;\mathrm{d}y \\
        &amp; = \lambda(E).
    \end{align*}\]</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../mc_definitions/">« Essential definitions</a><a class="docs-footer-nextpage" href="../mc_countableX_recurrence/">Recurrence in the countable-space case »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.13.0 on <span class="colophon-date" title="Thursday 26 June 2025 15:36">Thursday 26 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
