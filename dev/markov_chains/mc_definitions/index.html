<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Essential definitions · Random notes</title><meta name="title" content="Essential definitions · Random notes"/><meta property="og:title" content="Essential definitions · Random notes"/><meta property="twitter:title" content="Essential definitions · Random notes"/><meta name="description" content="Documentation for Random notes."/><meta property="og:description" content="Documentation for Random notes."/><meta property="twitter:description" content="Documentation for Random notes."/><meta property="og:url" content="https://github.com/rmsrosa/random_notes/markov_chains/mc_definitions/"/><meta property="twitter:url" content="https://github.com/rmsrosa/random_notes/markov_chains/mc_definitions/"/><link rel="canonical" href="https://github.com/rmsrosa/random_notes/markov_chains/mc_definitions/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Random notes logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Random notes</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Random Notes</a></li><li><span class="tocitem">Probability Essentials</span><ul><li><a class="tocitem" href="../../probability/kernel_density_estimation/">Kernel Density Estimation</a></li><li><a class="tocitem" href="../../probability/convergence_notions/">Convergence notions</a></li></ul></li><li><span class="tocitem">Discrete-time Markov chains</span><ul><li class="is-active"><a class="tocitem" href>Essential definitions</a><ul class="internal"><li><a class="tocitem" href="#Definition"><span>Definition</span></a></li><li><a class="tocitem" href="#Transition-probabilities"><span>Transition probabilities</span></a></li><li><a class="tocitem" href="#The-Markov-operator"><span>The Markov operator</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../mc_invariance/">Invariant distributions</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Countable-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../mc_countableX_recurrence/">Recurrence in the countable-space case</a></li><li><a class="tocitem" href="../mc_countableX_connections/">Connected states, irreducibility and uniqueness of invariant measures</a></li><li><a class="tocitem" href="../mc_countableX_convergencia/">Aperiodicidade e convergência para a distribuição estacionária</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Continuous-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../mc_irreducibility_and_recurrence/">Irreducibility and recurrence in the continuous-space case</a></li></ul></li></ul></li><li><span class="tocitem">Sampling methods</span><ul><li><a class="tocitem" href="../../sampling/overview/">Overview</a></li><li><a class="tocitem" href="../../sampling/prng/">Random number generators</a></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Transform methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/invFtransform/">Probability integral transform</a></li><li><a class="tocitem" href="../../sampling/box_muller/">Box-Muller transform</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Accept-Reject methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/rejection_sampling/">Rejection sampling</a></li><li><a class="tocitem" href="../../sampling/empiricalsup_rejection/">Empirical supremum rejection sampling</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Markov Chain Monte Carlo (MCMC)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/mcmc/">Overview</a></li><li><a class="tocitem" href="../../sampling/metropolis/">Metropolis and Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/convergence_metropolis/">Convergence of Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/gibbs/">Gibbs sampling</a></li><li><a class="tocitem" href="../../sampling/hmc/">Hamiltonian Monte Carlo (HMC)</a></li></ul></li><li><a class="tocitem" href="../../sampling/langevin_sampling/">Langevin sampling</a></li></ul></li><li><span class="tocitem">Bayesian inference</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Bayes Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/bayes/">Bayes Theorem</a></li><li><a class="tocitem" href="../../bayesian/bayes_inference/">Bayesian inference</a></li><li><a class="tocitem" href="../../bayesian/bernstein_vonmises/">Bernstein–von Mises theorem</a></li></ul></li><li><a class="tocitem" href="../../bayesian/bayesian_probprog/">Bayesian probabilistic programming</a></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/find_pi/">Estimating π via frequentist and Bayesian methods</a></li><li><a class="tocitem" href="../../bayesian/linear_regression/">Many Ways to Linear Regression</a></li><li><a class="tocitem" href="../../bayesian/tilapia_alometry/">Alometry law for the Nile Tilapia</a></li><li><a class="tocitem" href="../../bayesian/mortality_tables/">Modeling mortality tables</a></li></ul></li></ul></li><li><span class="tocitem">Generative models</span><ul><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox"/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Score matching</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../generative/overview/">Overview</a></li><li><a class="tocitem" href="../../generative/stein_score/">Stein score function</a></li><li><a class="tocitem" href="../../generative/score_matching_aapo/">Score matching of Aapo Hyvärinen</a></li><li><a class="tocitem" href="../../generative/score_matching_neural_network/">Score matching a neural network</a></li><li><a class="tocitem" href="../../generative/parzen_estimation_score_matching/">Score matching with Parzen estimation</a></li><li><a class="tocitem" href="../../generative/denoising_score_matching/">Denoising score matching of Pascal Vincent</a></li><li><a class="tocitem" href="../../generative/sliced_score_matching/">Sliced score matching</a></li><li><a class="tocitem" href="../../generative/1d_FD_score_matching/">1D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/2d_FD_score_matching/">2D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/ddpm/">Denoising diffusion probabilistic models</a></li><li><a class="tocitem" href="../../generative/mdsm/">Multiple denoising score matching</a></li><li><a class="tocitem" href="../../generative/probability_flow/">Probability flow</a></li><li><a class="tocitem" href="../../generative/reverse_flow/">Reverse probability flow</a></li><li><a class="tocitem" href="../../generative/score_based_sde/">Score-based SDE model</a></li></ul></li></ul></li><li><span class="tocitem">Sensitivity analysis</span><ul><li><a class="tocitem" href="../../sensitivity/overview/">Overview</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Discrete-time Markov chains</a></li><li class="is-active"><a href>Essential definitions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Essential definitions</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes/blob/main/docs/src/markov_chains/mc_definitions.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Discrete-time-Markov-chains"><a class="docs-heading-anchor" href="#Discrete-time-Markov-chains">Discrete-time Markov chains</a><a id="Discrete-time-Markov-chains-1"></a><a class="docs-heading-anchor-permalink" href="#Discrete-time-Markov-chains" title="Permalink"></a></h1><p>Many important probabilistic models fit the framework of a Markov chain, including the Markov Chain Monte Carlo (MCMC) methods, as the name says it. Here we explore some of its concepts and properties. Markov chains can be indexed with either discrete or continous &quot;time&quot; variables, but here we only consider the discrete-time case.</p><h2 id="Definition"><a class="docs-heading-anchor" href="#Definition">Definition</a><a id="Definition-1"></a><a class="docs-heading-anchor-permalink" href="#Definition" title="Permalink"></a></h2><p>Markov chains are families of random variables <span>$(X_n)_{n\in I},$</span> over an index set <span>$I,$</span> such that, essentially, only the most recent known state determines the future of the chain. The index set <span>$I$</span> can be continuous or discrete, but here we are only interested on the discrete case <span>$I = \mathbb{Z}_{\geq 0} = \{0, 1, 2, \ldots, \}.$</span> The index set is usually referred to as the <em>time</em> variable, while the values of the random variables live on a space <span>$\mathcal{X}$</span> called the <em>state</em> or <em>event</em> space.</p><p>The event space <span>$\mathcal{X}$</span> can be either countable (finite or infinite, with the discrete topology) or continuous (e.g. <span>$\mathcal{X} = \mathbb{R}^d,$</span> <span>$d\in\mathbb{N},$</span> or some infinite dimensional Hilbert or Banach space). We are mostly interested in the continuous case <span>$\mathcal{X} = \mathbb{R}^d,$</span> <span>$d\in\mathbb{N},$</span> but some examples are given with <span>$\mathcal{X} = \{1, \ldots, n\},$</span> <span>$n\in\mathbb{N},$</span> or <span>$\mathcal{X}=\mathbb{Z},$</span> for illustrative purposes and intuitive assessment. In any case, we always assume it is a topological space.</p><p>The random variables are functions <span>$X_n:\Omega \rightarrow \mathcal{X}$</span> which are assumed to be measurable from a probability space <span>$(\Omega, \mathcal{F}, \mathbb{P}),$</span> with <span>$\sigma$</span>-algebra <span>$\mathcal{F}$</span> and probability distribution <span>$\mathbb{P},$</span> to a measurable space, which we take here to be <span>$(\mathcal{X}, \mathcal{B}(\mathcal{X})),$</span> where <span>$\mathcal{B}(\mathcal{X})$</span> denotes the Borel <span>$\sigma$</span>-algebra of the topological space <span>$\mathcal{X}.$</span></p><p>In the discrete-time case, the Markov property for the discrete-time process <span>$(X_n)_n$</span> to be a Markov chain can be written as</p><p class="math-container">\[    \mathbb{P}(X_{n+1}|X_0\in E_0, X_1 \in E_1, \ldots, X_n\in E_n) = \mathbb{P}(X_{n+1}|X_n\in E_n),\]</p><p>for all Borel sets <span>$E_0, \ldots, E_n.$</span> The continuos-time version has a similar condition, based on the notion of filtration of a <span>$\sigma$</span>-algebra, but we do not need to worry about this in the time-discrete case.</p><h2 id="Transition-probabilities"><a class="docs-heading-anchor" href="#Transition-probabilities">Transition probabilities</a><a id="Transition-probabilities-1"></a><a class="docs-heading-anchor-permalink" href="#Transition-probabilities" title="Permalink"></a></h2><p>Markov chains can be described by transition probabilities. We will define them in both non-homogeneous and homogeneous cases in time, but after that we will only consider the homogeneous case.</p><h3 id="The-non-homogeneous-time-discrete-case"><a class="docs-heading-anchor" href="#The-non-homogeneous-time-discrete-case">The non-homogeneous time-discrete case</a><a id="The-non-homogeneous-time-discrete-case-1"></a><a class="docs-heading-anchor-permalink" href="#The-non-homogeneous-time-discrete-case" title="Permalink"></a></h3><p>A Markov chain can be fully characterized by the <strong>transition probabilities</strong></p><p class="math-container">\[    K_{n, m}(E, F) = \mathbb{P}(X_m\in F|X_n\in E),\]</p><p>for any pair <span>$E, F\subset \mathcal{X}$</span> of Borel sets, where <span>$n, m = 0, 1, \ldots.$</span> In particular, we denote</p><p class="math-container">\[    K_{n, m}(x, F) = \mathbb{P}(X_{n+1}\in F|X_n = x),\]</p><p>for any Borel set <span>$E\subset \mathcal{X}$</span> and any point <span>$x\in\mathcal{X}.$</span> Notice that </p><ul><li>The set map <span>$K_{n, m}(x, \cdot)$</span> is a probability measure on <span>$\mathcal{X},$</span> for each <span>$x\in\mathcal{X}.$</span></li><li>The map <span>$K_{n, m}(\cdot, F)$</span> is a measurable function from <span>$\mathcal{X}$</span> to <span>$[0, 1],$</span> for each Borel set <span>$F\subset \mathcal{X}.$</span></li></ul><p>When <span>$\mathcal{X} = \mathbb{R}^d,$</span> <span>$d\in \mathbb{N},$</span> we say that the transition probability <span>$K_{n, m}$</span> has a <strong>transition kernel</strong> or <strong>transition density</strong> <span>$k_{n, m} = k_{n, m}(x, y)$</span> when <span>$K_{n, m}(x, \cdot)$</span> is absolutely continous with respect to the Lebesgue measure, so that</p><p class="math-container">\[    K_{n, m}(x, F) = \int_F k_{n, m}(x, y) \;\mathrm{d}y,\]</p><p>and</p><p class="math-container">\[    K_{n, m}(E, F) = \int_E \int_F k_{n, m}(x, y) \;\mathrm{d}y\;\mathrm{d}x.\]</p><p>Since <span>$K_{n, m}(x, \cdot)$</span> is a probability distribution, we have</p><p class="math-container">\[    \int_{\mathcal{X}} k_{n,m}(x, y) \;\mathrm{d}y = K_n(x, \mathcal{X}) = 1.\]</p><p>But <span>$K_{n,m}(E, F)$</span> is contined on <span>$X_n\in E,$</span> so <span>$K_{n, m}(\cdot, y)$</span> need not be a probability distribution.</p><h3 id="The-time-homogeneous-case"><a class="docs-heading-anchor" href="#The-time-homogeneous-case">The time-homogeneous case</a><a id="The-time-homogeneous-case-1"></a><a class="docs-heading-anchor-permalink" href="#The-time-homogeneous-case" title="Permalink"></a></h3><p>Very often, as in most examples we are interested in, here, the transition probabilities only depend on the &quot;time difference&quot; <span>$m-n,$</span> i.e. it is <em>time homogeneous,</em> or <em>autonomous.</em> More precisely, the Markov chain is called <strong>time homogeneous</strong> when</p><p class="math-container">\[    K_{k, k + n}(E, F) = K_{0, n}(E, F), \quad \forall n, k = 0, 1, 2, \ldots, \;\forall E, F\in\mathcal{B}(\mathcal{X}).\]</p><p>In this case, we define the <strong><span>$n$</span>th-step transition probability</strong> by</p><p class="math-container">\[    K_n(E, F) = K_{0, n}(E, F) = K_{k, k+n}(E, F),\]</p><p>The corresponding density <span>$k_n(x, y)$</span> is called the <strong><span>$n$</span>th-step transition density.</strong></p><p>The one-step transition probability and density are simply denoted without any subscript,</p><p class="math-container">\[    \begin{align*}
        K(E, F) &amp; = K_1(E, F) = \mathbb{P}(X_{n+1} \in F | X_n\in E), \\
        K(x, F) &amp; = K_1(x, F) = \mathbb{P}(X_{n+1} \in F | X_n = x), \\
        k(x, y) = k_1(x, y).
    \end{align*}\]</p><h3 id="The-evolution-of-distributions"><a class="docs-heading-anchor" href="#The-evolution-of-distributions">The evolution of distributions</a><a id="The-evolution-of-distributions-1"></a><a class="docs-heading-anchor-permalink" href="#The-evolution-of-distributions" title="Permalink"></a></h3><p>We denote by <span>$P_n$</span> the probability distribution of the random variable <span>$X_n,$</span> i.e.</p><p class="math-container">\[    P_n(E) = \mathbb{P}(X_n\in E), \quad \forall E\in\mathcal{B}(\mathcal{X}).\]</p><p>Due to the nature of a Markov process, the distribution of <span>$P_{n+1}$</span> only depends on the distribution of <span>$P_n$</span> and on the transition distribution. More generally, <span>$P_{k+n}$</span> depends on <span>$P_{k}$</span> and, in particular, the distribution <span>$P_n$</span> of <span>$X_n$</span> depends on the distribution <span>$P_0$</span> of <span>$X_0.$</span></p><p>More precisely, we can express this dependence via the Chapman-Kolmogorov equation, which, in the case the transition probabilities admit a density, reads</p><p class="math-container">\[    K_{m+n}(x, F) = \int_{\mathcal{X}} K_n(y, F)k_m(x, y)\;\mathrm{d}y,\]</p><p>for any Borel set <span>$F\subset\mathcal{X}.$</span></p><h2 id="The-Markov-operator"><a class="docs-heading-anchor" href="#The-Markov-operator">The Markov operator</a><a id="The-Markov-operator-1"></a><a class="docs-heading-anchor-permalink" href="#The-Markov-operator" title="Permalink"></a></h2><p>Given the one-step transition probability <span>$K(\cdot, \cdot),$</span> in the time-homogeneous case, on defines the associated <strong>Markov operator</strong> <span>$K:\mathcal{P}(\mathcal{X})\rightarrow \mathcal{P}(\mathcal{X})$</span> that takes a distribution <span>$P\in \mathcal{P}(\mathcal{X})$</span> on <span>$\mathcal{X}$</span> to the &quot;next step&quot; distribution <span>$PK\in\mathcal{P}(\mathcal{X}),$</span> defined by</p><p class="math-container">\[    (PK)(E) = \int_{\mathcal{X}} K(x, E);\mathrm{d}P(x).\]</p><p>In particular, if <span>$P_n$</span> is the distribution of <span>$X_n,$</span> then the distribution of <span>$X_{n+1}$</span> is <span>$KP_n,$</span> i.e.</p><p class="math-container">\[    P_{n+1} = P_nK, \quad \textrm{for } X_j \sim P_j.\]</p><p><strong>Rmk:</strong> Another common notation in the integration is with <span>$P(\mathrm{d}x)$</span> instead of <span>$\mathrm{d}P(x).$</span> </p><p><strong>Rmk:</strong> We use the same <span>$K$</span> to denote the Markov operator on <span>$\mathcal{P}(\mathcal{X})$</span> and the one-step probability distribution <span>$K(\cdot, \cdot)$</span> on <span>$\mathcal{X}\times\mathcal{X}.$</span></p><h3 id="Finite-state-case"><a class="docs-heading-anchor" href="#Finite-state-case">Finite-state case</a><a id="Finite-state-case-1"></a><a class="docs-heading-anchor-permalink" href="#Finite-state-case" title="Permalink"></a></h3><p>When the state is finite, say <span>$\mathcal{X} = \{1, 2, \ldots, n\},$</span> the transition operator can be characterized by the transitions <span>$K(i, j)$</span> of going from state <span>$i$</span> to state <span>$j$</span>. This defines a matrix,</p><p class="math-container">\[    K = \left(K_1(i, j)\right)_{i,j=1}^n = \begin{bmatrix}
        k_{1,1} &amp; k_{1,2} &amp; \cdots &amp; k_{1,n} \\
        k_{2,1} &amp; k_{2,2} &amp; \ddots &amp; \vdots \\
        \vdots &amp; \ddots &amp; \ddots &amp; k_{n-1,n} \\
        k_{n,1} &amp; \cdots &amp; k_{n,n-1} &amp; k_{n,n}
    \end{bmatrix},\]</p><p>where <span>$k_{i, j} = K(i, j).$</span> Each row sums up to one:</p><p class="math-container">\[    \sum_{j=1}^n k_{i,j} = \sum_{j=1}^n K_1(i, j) = K_1(i, \mathcal{X}) = 1.\]</p><p>The <span>$n$</span>-step transition operator is obtained by simply composing the <span>$1$</span>-step transition operator,</p><p class="math-container">\[    \begin{align*}
        \left(K_n(i, j)\right)_{i,j} &amp; = \left(K_{0,n}(i, j)\right)_{i,j} = \left(K_{n-1, n}(i, j)\right)_{i,j}\left(K_{n-2, n-1}(i, j)\right)_{i,j}\cdots \left(K_{0, 1}(i, j)\right)_{i,j} \\
        &amp; = \left(K(i, j)\right)_{i,j}^n = K^n.
    \end{align*}\]</p><p>If we denote the distribution of a given state <span>$X_n$</span> by a row vector</p><p class="math-container">\[    P_n = [p_1, \ldots, p_n], \quad p_i = \mathbb{P}(X_n = i),\]</p><p>then</p><p class="math-container">\[    \begin{align*}
        P_{n+1} &amp; = [\mathbb{P}(X_{n+1} = j)]_{j=1, \ldots, n} = \left[\sum_{i=1}^n \mathbb{P}(X_{n+1} = j | X_n = i) \mathbb{P}(X_n = 1)\right]_{j=1, \ldots, n} \\ 
        &amp; = \left[\sum_{i=1}^n K_{i, j} p_i\right]_{j=1, \ldots, n} = \begin{bmatrix} p_1 &amp; p_2 &amp; \cdots &amp; p_n\end{bmatrix} \begin{bmatrix}
            k_{1,1} &amp; k_{1,2} &amp; \cdots &amp; k_{1,n} \\
            k_{2,1} &amp; k_{2,2} &amp; \ddots &amp; \vdots \\
            \vdots &amp; \ddots &amp; \ddots &amp; k_{n-1,n} \\
            k_{n,1} &amp; \cdots &amp; k_{n,n-1} &amp; k_{n,n}
        \end{bmatrix} = P_n K,
    \end{align*}\]</p><p>where the product <span>$P_n K$</span> is to be understood as the matrix product of a row vector <span>$[p_1, \ldots, p_n]$</span> of the distribution of <span>$X_n$</span> with the transition matrix <span>$K,$</span> to yield another row vector with the distributions for the next state. Thus, <span>$K$</span> is also a representation of the Markov operator.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ol><li><a href="https://doi.org/10.1007/978-1-4757-4145-2">C. P. Robert, G. Casella (2004), &quot;Monte Carlo Statistical Methods&quot;, Second Edition, Springer Texts in Statistics, Springer New York, NY</a></li><li><a href="https://doi.org/10.1201/9781315273600">G. F. Lawler (2006), &quot;Introduction to Stochastic Processes&quot;, 2nd Edition. Chapman and Hall/CRC, New York.</a></li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../probability/convergence_notions/">« Convergence notions</a><a class="docs-footer-nextpage" href="../mc_invariance/">Invariant distributions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.13.0 on <span class="colophon-date" title="Thursday 26 June 2025 15:36">Thursday 26 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
