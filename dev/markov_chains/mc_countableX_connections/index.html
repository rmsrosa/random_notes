<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Connected states, irreducibility and uniqueness of invariant measures · Random notes</title><meta name="title" content="Connected states, irreducibility and uniqueness of invariant measures · Random notes"/><meta property="og:title" content="Connected states, irreducibility and uniqueness of invariant measures · Random notes"/><meta property="twitter:title" content="Connected states, irreducibility and uniqueness of invariant measures · Random notes"/><meta name="description" content="Documentation for Random notes."/><meta property="og:description" content="Documentation for Random notes."/><meta property="twitter:description" content="Documentation for Random notes."/><meta property="og:url" content="https://github.com/rmsrosa/random_notes/markov_chains/mc_countableX_connections/"/><meta property="twitter:url" content="https://github.com/rmsrosa/random_notes/markov_chains/mc_countableX_connections/"/><link rel="canonical" href="https://github.com/rmsrosa/random_notes/markov_chains/mc_countableX_connections/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Random notes logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Random notes</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Random Notes</a></li><li><span class="tocitem">Probability Essentials</span><ul><li><a class="tocitem" href="../../probability/kernel_density_estimation/">Kernel Density Estimation</a></li><li><a class="tocitem" href="../../probability/convergence_notions/">Convergence notions</a></li></ul></li><li><span class="tocitem">Discrete-time Markov chains</span><ul><li><a class="tocitem" href="../mc_definitions/">Essential definitions</a></li><li><a class="tocitem" href="../mc_invariance/">Invariant distributions</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Countable-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../mc_countableX_recurrence/">Recurrence in the countable-space case</a></li><li class="is-active"><a class="tocitem" href>Connected states, irreducibility and uniqueness of invariant measures</a><ul class="internal"><li><a class="tocitem" href="#Setting"><span>Setting</span></a></li><li><a class="tocitem" href="#Definitions"><span>Definitions</span></a></li><li><a class="tocitem" href="#Local-uniqueness-of-invariant-measures"><span>Local uniqueness of invariant measures</span></a></li></ul></li><li><a class="tocitem" href="../mc_countableX_convergencia/">Aperiodicidade e convergência para a distribuição estacionária</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Continuous-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../mc_irreducibility_and_recurrence/">Irreducibility and recurrence in the continuous-space case</a></li></ul></li></ul></li><li><span class="tocitem">Sampling methods</span><ul><li><a class="tocitem" href="../../sampling/overview/">Overview</a></li><li><a class="tocitem" href="../../sampling/prng/">Random number generators</a></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Transform methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/invFtransform/">Probability integral transform</a></li><li><a class="tocitem" href="../../sampling/box_muller/">Box-Muller transform</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Accept-Reject methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/rejection_sampling/">Rejection sampling</a></li><li><a class="tocitem" href="../../sampling/empiricalsup_rejection/">Empirical supremum rejection sampling</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Markov Chain Monte Carlo (MCMC)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/mcmc/">Overview</a></li><li><a class="tocitem" href="../../sampling/metropolis/">Metropolis and Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/convergence_metropolis/">Convergence of Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/gibbs/">Gibbs sampling</a></li><li><a class="tocitem" href="../../sampling/hmc/">Hamiltonian Monte Carlo (HMC)</a></li></ul></li><li><a class="tocitem" href="../../sampling/langevin_sampling/">Langevin sampling</a></li></ul></li><li><span class="tocitem">Bayesian inference</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Bayes Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/bayes/">Bayes Theorem</a></li><li><a class="tocitem" href="../../bayesian/bayes_inference/">Bayesian inference</a></li><li><a class="tocitem" href="../../bayesian/bernstein_vonmises/">Bernstein–von Mises theorem</a></li></ul></li><li><a class="tocitem" href="../../bayesian/bayesian_probprog/">Bayesian probabilistic programming</a></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/find_pi/">Estimating π via frequentist and Bayesian methods</a></li><li><a class="tocitem" href="../../bayesian/linear_regression/">Many Ways to Linear Regression</a></li><li><a class="tocitem" href="../../bayesian/tilapia_alometry/">Alometry law for the Nile Tilapia</a></li><li><a class="tocitem" href="../../bayesian/mortality_tables/">Modeling mortality tables</a></li></ul></li></ul></li><li><span class="tocitem">Generative models</span><ul><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox"/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Score matching</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../generative/overview/">Overview</a></li><li><a class="tocitem" href="../../generative/stein_score/">Stein score function</a></li><li><a class="tocitem" href="../../generative/score_matching_aapo/">Score matching of Aapo Hyvärinen</a></li><li><a class="tocitem" href="../../generative/score_matching_neural_network/">Score matching a neural network</a></li><li><a class="tocitem" href="../../generative/parzen_estimation_score_matching/">Score matching with Parzen estimation</a></li><li><a class="tocitem" href="../../generative/denoising_score_matching/">Denoising score matching of Pascal Vincent</a></li><li><a class="tocitem" href="../../generative/sliced_score_matching/">Sliced score matching</a></li><li><a class="tocitem" href="../../generative/1d_FD_score_matching/">1D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/2d_FD_score_matching/">2D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/ddpm/">Denoising diffusion probabilistic models</a></li><li><a class="tocitem" href="../../generative/mdsm/">Multiple denoising score matching</a></li><li><a class="tocitem" href="../../generative/probability_flow/">Probability flow</a></li><li><a class="tocitem" href="../../generative/reverse_flow/">Reverse probability flow</a></li><li><a class="tocitem" href="../../generative/score_based_sde/">Score-based SDE model</a></li></ul></li></ul></li><li><span class="tocitem">Sensitivity analysis</span><ul><li><a class="tocitem" href="../../sensitivity/overview/">Overview</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Discrete-time Markov chains</a></li><li><a class="is-disabled">Countable-space Markov chains</a></li><li class="is-active"><a href>Connected states, irreducibility and uniqueness of invariant measures</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Connected states, irreducibility and uniqueness of invariant measures</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes/blob/main/docs/src/markov_chains/mc_countableX_connections.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Connected-states,-irreducibility-and-uniqueness-of-invariant-measures"><a class="docs-heading-anchor" href="#Connected-states,-irreducibility-and-uniqueness-of-invariant-measures">Connected states, irreducibility and uniqueness of invariant measures</a><a id="Connected-states,-irreducibility-and-uniqueness-of-invariant-measures-1"></a><a class="docs-heading-anchor-permalink" href="#Connected-states,-irreducibility-and-uniqueness-of-invariant-measures" title="Permalink"></a></h1><p>The notion of communicating states is a fundamental concept related to the uniqueness of an invariant measure, at least in a local scope. When every pair of states communicate with each other, then we have the notion of irreducibility, which extends the uniquenesse to a global scope.</p><h2 id="Setting"><a class="docs-heading-anchor" href="#Setting">Setting</a><a id="Setting-1"></a><a class="docs-heading-anchor-permalink" href="#Setting" title="Permalink"></a></h2><p>As before, we assume that <span>$(X_n)_n$</span> is a time-homogeneous, discrete-time Markov chain with a countable state space. More precisely, we assume the indices are <span>$n=0, 1, 2, \ldots,$</span> and that the space <span>$\mathcal{X}$</span> is finite or countably infinite. The sample space is the probability space <span>$(\Omega, \mathcal{F}, \mathbb{P}),$</span> where <span>$\mathcal{F}$</span> is the <span>$\sigma$</span>-algebra on the set <span>$\Omega$</span> and <span>$\mathbb{P}$</span> is the probability distribution. The one-step transition distribution is denoted by <span>$K(x, y) = \mathbb{P}(X_{n+1} = y | X_n = x),$</span> and is independent of <span>$n=0, 1, \ldots,$</span> thanks to the time-homogeneous assumption. Similary, the <span>$n$</span>-step transition distribution is denoted <span>$K_n(x, y) = \mathbb{P}(X_{k+n} = y | X_k = x),$</span> for <span>$n=1, 2, \ldots,$</span> independently of <span>$k=0, 1, \ldots.$</span></p><h2 id="Definitions"><a class="docs-heading-anchor" href="#Definitions">Definitions</a><a id="Definitions-1"></a><a class="docs-heading-anchor-permalink" href="#Definitions" title="Permalink"></a></h2><p>We start with some fundamental definitions.</p><h3 id="Communicating-points"><a class="docs-heading-anchor" href="#Communicating-points">Communicating points</a><a id="Communicating-points-1"></a><a class="docs-heading-anchor-permalink" href="#Communicating-points" title="Permalink"></a></h3><p>Markov chains are about the probability of states changing with time. If starting at some state, some of the other states might be more likely to be observed in the future than others, and some might never be observed. We distinguish them by the notion of communication.</p><div class="admonition is-info" id="Definition-(communicating-points)-52b21e9843e34df9"><header class="admonition-header">Definition (communicating points)<a class="admonition-anchor" href="#Definition-(communicating-points)-52b21e9843e34df9" title="Permalink"></a></header><div class="admonition-body"><p>We say that <strong><span>$x$</span> leads to <span>$y$</span></strong> when there exists a nonnegative integer <span>$n=n(x, y)$</span> such that <span>$K_n(x, y) &gt; 0.$</span> When <span>$x$</span> leads to <span>$y$</span>, we write <span>$x \rightarrow y.$</span> If <span>$x$</span> does not lead to <span>$y,$</span> we write <span>$x \not\rightarrow y.$</span> When <span>$x$</span> leads to <span>$y$</span> and <span>$y$</span> leads to <span>$x,$</span> we say that these states <strong>communicate</strong> with each other, and we write <span>$x \leftrightarrow y.$</span></p></div></div><p><strong>Remark.</strong> Notice that this definition automatically gives that <span>$x \leftrightarrow x,$</span> for every state <span>$x,$</span> even if <span>$x$</span> is transient and the chain that starts at <span>$x$</span> never returns to <span>$x.$</span> Because of this, some authors defines <span>$x\rightarrow y$</span> restricting <span>$n(x, y)$</span> to be a <em>positive</em> integer. As a side effect, the communication property looses the reflexivity property which has to be enforced in the definition of an equivalence relation, so we can properly decompose the space into equivalence classes of communicating states.</p><h3 id="Equivalence-class-of-communicating-states"><a class="docs-heading-anchor" href="#Equivalence-class-of-communicating-states">Equivalence class of communicating states</a><a id="Equivalence-class-of-communicating-states-1"></a><a class="docs-heading-anchor-permalink" href="#Equivalence-class-of-communicating-states" title="Permalink"></a></h3><p>The relation of mutual communication <span>$x \leftrightarrow y$</span> is an equivalence class.</p><div class="admonition is-info" id="Fact-(communication-is-an-equivalence-relation)-764efc3072f2a5dd"><header class="admonition-header">Fact (communication is an equivalence relation)<a class="admonition-anchor" href="#Fact-(communication-is-an-equivalence-relation)-764efc3072f2a5dd" title="Permalink"></a></header><div class="admonition-body"><p>The relation <span>$x \leftrightarrow y$</span> is an equivalence relation which we term <strong>communication relation.</strong> The <strong>communication class</strong> of a state <span>$x$</span> is denoted <span>$[x].$</span></p></div></div><h3 id="Closed-communication-class"><a class="docs-heading-anchor" href="#Closed-communication-class">Closed communication class</a><a id="Closed-communication-class-1"></a><a class="docs-heading-anchor-permalink" href="#Closed-communication-class" title="Permalink"></a></h3><p>In particular, the state space can be decomposed into one or more communication classes. But a communication class may not carry an invariant measure. The chain may &quot;leak&quot; to other classes. More precisely, we may have one state in one class leading to another state in a different class. It is important to distinguish when this happens or not. For that, we have the following definition.</p><div class="admonition is-info" id="Definition-(Closed-communication-class)-51d0522c4eda93d4"><header class="admonition-header">Definition (Closed communication class)<a class="admonition-anchor" href="#Definition-(Closed-communication-class)-51d0522c4eda93d4" title="Permalink"></a></header><div class="admonition-body"><p>A communication class <span>$C$</span> is called <strong>closed</strong> when for every <span>$x\in C$</span> and every <span>$z\in\mathcal{X}$</span> such that <span>$x\rightarrow z,$</span> we also have <span>$z\in C.$</span> In other words, if <span>$x\in C$</span> and <span>$z\in \mathcal{X}\setminus C,$</span> then <span>$x \not\rightarrow z.$</span></p></div></div><h2 id="Local-uniqueness-of-invariant-measures"><a class="docs-heading-anchor" href="#Local-uniqueness-of-invariant-measures">Local uniqueness of invariant measures</a><a id="Local-uniqueness-of-invariant-measures-1"></a><a class="docs-heading-anchor-permalink" href="#Local-uniqueness-of-invariant-measures" title="Permalink"></a></h2><p>First we have the following result, without any special assumption, but which will be key, for the uniqueness, when the state <span>$x$</span> is assumed to be recurrent and with positive probability for the assumed invariant measure.</p><div class="admonition is-info" id="Lemma-(lower-bound-on-an-invariant-measure)-ca7527c7bd154def"><header class="admonition-header">Lemma (lower bound on an invariant measure)<a class="admonition-anchor" href="#Lemma-(lower-bound-on-an-invariant-measure)-ca7527c7bd154def" title="Permalink"></a></header><div class="admonition-body"><p>Suppose <span>${\tilde P}$</span> is an invariant measure for the Markov chain. Then, for any two states <span>$x, z\in\mathcal{X},$</span></p><p class="math-container">\[    {\tilde P}(z) \geq {\tilde P}_x(z){\tilde P}(x),\]</p><p>where</p><p class="math-container">\[    {\tilde P}_x(z) = \sum_{n=1}^\infty \mathbb{P}(X_n = z, n \leq \tau_{x} | X_0 = x).\]</p></div></div><p><strong>Proof.</strong> If <span>${\tilde P}$</span> is a given invariant measure, then, using this invariance,</p><p class="math-container">\[    {\tilde P}(z) = \sum_{y_1} K(y_1, z){\tilde P}(y_1).\]</p><p>Splitting the summation into <span>$y_1=x$</span> and <span>$y_1\neq x,$</span> we have</p><p class="math-container">\[    {\tilde P}(z) = K(x, z){\tilde P}(x) + \sum_{y_1\neq x} K(y_1, z){\tilde P}(y).\]</p><p>Using again the invariance for the term <span>${\tilde P}(y)$</span> inside the summation and spliting again the summation, we have</p><p class="math-container">\[    \begin{align*}
        {\tilde P}(z) &amp; = K(x, z){\tilde P}(x) + \sum_{y_1\neq x} K(y_1, z)\left( \sum_{y_2} K(y_2, y_1){\tilde P}(y_2) \right) \\
        &amp; = K(x, z){\tilde P}(x) + \sum_{y_1\neq x} K(x, y_1)K(y_1, z){\tilde P}(x) + \sum_{y_1\neq x}\sum_{y_2\neq x} K(y_2, y_1)K(y_1, z){\tilde P}(y_2).
    \end{align*}\]</p><p>By induction, we obtain</p><p class="math-container">\[    \begin{align*}
        {\tilde P}(z) &amp; = K(x, z){\tilde P}(x) \\
        &amp; \quad + \sum_{y_1\neq x} K(x, y_1)K(y_1, z){\tilde P}(x) \\
        &amp; \quad + \sum_{y_1\neq x}\sum_{y_2\neq x} K(x, y_1)K(y_1, z){\tilde P}(x) \\
        &amp; \quad + \cdots \\
        &amp; \quad + \sum_{y_1\neq x}\cdots \sum_{y_{k-1}\neq x} K(x, y_{k-1})K(y_{k-2}, y_{k-1})\cdots K(y_1, z){\tilde P}(x) \\
        &amp; \quad + \sum_{y_1\neq x}\cdots \sum_{y_k\neq x} K(y_k, y_{k-1})K(y_{k-1}, y_{k-2})\cdots K(y_1, z){\tilde P}(x),
    \end{align*}\]</p><p>for every <span>$k\in\mathbb{N}.$</span> Negleting the last term at each iteration <span>$k,$</span> we find that</p><p class="math-container">\[    \begin{align*}
        {\tilde P}(z) &amp; \geq \bigg(K(x, z) + \sum_{y_1\neq x} K(x, y_1)K(y_1, z) + \cdots \\
        &amp; \qquad + \sum_{y_1\neq x}\cdots \sum_{y_{k-1}\neq x} K(x, y_{k-1})K(y_{k-2}, y_{k-1})\cdots K(y_1, z)\bigg){\tilde P}(x).
    \end{align*}\]</p><p>Now notice that, for <span>$k=1,$</span></p><p class="math-container">\[    K(x, z) = \mathbb{P}(X_1 = z | X_0 = x) = \mathbb{P}(X_1 = z, \tau_x \geq 1 | X_0 = x),\]</p><p>for <span>$k=2,$</span></p><p class="math-container">\[    \sum_{y_1\neq x} K(x, y_1)K(y_1, z) = \mathbb{P}(X_2 = z, X_1 \neq x | X_0 = x) = \mathbb{P}(X_2 = z, \tau_x \geq 2 | X_0 = x),\]</p><p>and, more generally, for any <span>$k\in\mathbb{N},$</span></p><p class="math-container">\[    \begin{align*}
        \sum_{y_1\neq x}\cdots \sum_{y_{k-1}\neq x} K(x, y_{k-1})K(y_{k-2}, y_{k-1})\cdots K(y_1, z) &amp; = \mathbb{P}(X_k = z, X_{k-1}\neq x, \ldots, X_1 \neq x | X_0 = x) \\
        &amp; = \mathbb{P}(X_k = z, \tau_x \geq k | X_0 = x).
    \end{align*}\]</p><p>The summation of all such <span>$k\in\mathbb{N}$</span> terms is precisely <span>${\tilde P}_x(z),$</span> and we find</p><p class="math-container">\[    {\tilde P}(z) \geq {\tilde P}_x(z){\tilde P}(x).\]</p><p>This concludes the proof. □</p><p>In the result above, we do not need to assume that <span>$x$</span> is recurrent. If it is not, then both terms on the right hand side may vanish and the inequality is vacuous. However, if <span>$x$</span> is recurrent and has positive measure <span>${\tilde P}(x) &gt; 0$</span> with respect to the invariant measure, then we deduce that <span>${\tilde P}$</span> must be a multiple of <span>${\tilde P}_x,$</span> meaning uniqueness up to a multiplicative constant, at least locally among all communicating states to <span>$x.$</span></p><p>In order to establish such result, let us first show that, if a state <span>$x$</span> is recurrent, then the associated invariant measure <span>${\tilde P}_x$</span> is positive over the communication class <span>$[x]$</span> and vanishes on the complement of <span>$[x].$</span></p><div class="admonition is-info" id="Proposition-e8fd1776b95a6ade"><header class="admonition-header">Proposition<a class="admonition-anchor" href="#Proposition-e8fd1776b95a6ade" title="Permalink"></a></header><div class="admonition-body"><p>Suppose <span>$x$</span> is a recurrent state and that <span>$[x]$</span> is a closed communication class. Then</p><p class="math-container">\[    {\tilde P}_x(z) &gt; 0 \quad \Longleftrightarrow z \in [x].\]</p></div></div><p><strong>Proof.</strong> If <span>$z = x,$</span> then the result is immediate since <span>${\tilde P}_x(x) = 1.$</span> If <span>$z\neq x$</span> but <span>$z\in [x],$</span> then there exists <span>$n\in\mathbb{N}$</span> such that <span>$K_n(x, z) &gt; 0.$</span> Since <span>${\tilde P}_x$</span> is invariant, we have</p><p class="math-container">\[    {\tilde P}_x(z) = \sum_{y\in\mathcal{X}} K_n(y, z) {\tilde P}_x(y) \geq K(x, z){\tilde P}_x(x)\]</p><p>Estimating from below the summation over <span>$y\in\mathcal{x}$</span> by the summand at <span>$y=x$</span> and using that <span>$K_n(x, z) &gt; 0$</span> and <span>${\tilde P}_x(x) = 1,$</span></p><p class="math-container">\[    {\tilde P}_x(z) = \sum_{y\in\mathcal{X}} K_n(y, z) {\tilde P}_x(y) \geq K_n(x, z){\tilde P}_x(x) = K_n(x, z) &gt; 0,\]</p><p>which proves that <span>$z\in [x]$</span> implies <span>${\tilde P}_x(z).$</span> Now for the converse. Suppose <span>${\tilde P}_x(z) &gt; 0.$</span> If <span>$z = x,$</span> then <span>$z\in [x]$</span> and we are done. If <span>$z\neq x,$</span> we have, by the definition of this measure as</p><p class="math-container">\[    {\tilde P}_x(z) = \sum_{n=1}^\infty \mathbb{P}(X_n = z, n \leq \tau_{x} | X_0 = x),\]</p><p>that, for some <span>$n\in\mathbb{N},$</span></p><p class="math-container">\[    \mathbb{P}(X_n = z, n \leq \tau_{x} | X_0 = x) &gt; 0.\]</p><p>In particular,</p><p class="math-container">\[    K_n(x, z) = \mathbb{P}(X_n = z | X_0 = x) \geq \mathbb{P}(X_n = z, n \leq \tau_{x} | X_0 = x) &gt; 0,\]</p><p>which means that <span>$x \rightarrow z.$</span> Now, since <span>$[x]$</span> is closed, this means that <span>$z\in [x].$</span> This completes the characterization of <span>$z\in [x]$</span> as <span>${\tilde P}_x(z) &gt; 0$</span>.  □</p><div class="admonition is-info" id="Theorem-(local-uniqueness-up-to-a-multiplicative-constant)-7593e42e18f56e8e"><header class="admonition-header">Theorem (local uniqueness up to a multiplicative constant)<a class="admonition-anchor" href="#Theorem-(local-uniqueness-up-to-a-multiplicative-constant)-7593e42e18f56e8e" title="Permalink"></a></header><div class="admonition-body"><p>Assume that <span>$x$</span> is a recurrent state with closed communication class <span>$[x].$</span> Suppose that <span>${\tilde P}$</span> is an invariant measure for the Markov chain which is carried by <span>$[x]$</span> and with <span>${\tilde P}(x) &gt; 0.$</span> Then, for any state <span>$z \in [x],$</span> both</p><p class="math-container">\[    {\tilde P}_x(z), {\tilde P}(z) &gt; 0\]</p><p>and</p><p class="math-container">\[    \frac{{\tilde P}(z)}{{\tilde P}_x(z)} \geq \frac{{\tilde P}(x)}{{\tilde P}_x(x)},\]</p><p>which implies that <span>${\tilde P}$</span> and <span>${\tilde P}_x$</span> are proportional i.e. there exists <span>$C &gt; 0$</span> such that</p><p class="math-container">\[    \frac{{\tilde P}(z)}{{\tilde P}_x(z)} = C, \quad \forall z\in [x].\]</p></div></div><p><strong>Proof.</strong> It follows from the lemma on the lower bound on an invariant measure that</p><p class="math-container">\[    {\tilde P}(z) \geq {\tilde P}_x(z){\tilde P}(x),\]</p><p>for all <span>$z\in\mathcal{X}.$</span> Since <span>$x$</span> is a recurrent state, it follows that <span>${\tilde P}_x$</span> is also an invariant measure and, as seen in the previous proposition, since <span>$[x]$</span> is closed,</p><p class="math-container">\[    {\tilde P}_x(z) &gt; 0, \quad \forall z\in [x].\]</p><p>We also know that</p><p class="math-container">\[    {\tilde P}_x(x) = \mathbb{P}(\tau_{x} &lt; \infty | X_0 = x) = 1.\]</p><p>Thus, we obtain the inequality</p><p class="math-container">\[    \frac{{\tilde P}(z)}{{\tilde P}_x(z)} \geq \frac{{\tilde P}(x)}{{\tilde P}_x(x)}, \quad \forall z\in [x].\]</p><p>Since <span>${\tilde P}(x) &gt; 0,$</span> this implies that</p><p class="math-container">\[    {\tilde P}(z) &gt; 0, \quad \forall z\in [x].\]</p><p>This proves the first claim that <span>${\tilde P}$</span> is also positive on the communication class <span>$[x].$</span></p><p>Now, using that <span>${\tilde P}$</span> is invariant and is carried by <span>$[x],$</span> we have</p><p class="math-container">\[    {\tilde P}(x) = \sum_z K_n(z, x){\tilde P}(z) = \sum_{z\in [x]} K_n(z, x){\tilde P}(z).\]</p><p>Using the previous inequality and the fact that <span>${\tilde P}_x$</span> is also invariant and carried by <span>$[x],$</span> we have, for any <span>$n\in\mathbb{N},$</span></p><p class="math-container">\[    \begin{align*}
        {\tilde P}(x) &amp; = \sum_{z\in [x]} K_n(z, x){\tilde P}(z) \\
            &amp; \geq \frac{{\tilde P}(x)}{{\tilde P}_x(x)} \sum_{z\in [x]} K_n(z, x){\tilde P}_x(z) \\
            &amp; = \frac{{\tilde P}(x)}{{\tilde P}_x(x)} {\tilde P}_x(x) \\
            &amp; = {\tilde P}(x).
    \end{align*}\]</p><p>This means that the inequality in the middle is actually an equality, i.e.</p><p class="math-container">\[    \sum_{z\in [x]} K_n(z, x){\tilde P}(z) = \frac{{\tilde P}(x)}{{\tilde P}_x(x)} \sum_{z\in [x]} K_n(z, x){\tilde P}_x(z).\]</p><p>Since for each <span>$z \in [x]$</span> we have</p><p class="math-container">\[    {\tilde P}(z) \geq \frac{{\tilde P}(x)}{{\tilde P}_x(x)} {\tilde P}_x(z)\]</p><p>and the summation of these terms is equal, this means that each summand must be equal, i.e.</p><p class="math-container">\[    {\tilde P}(z) = \frac{{\tilde P}(x)}{{\tilde P}_x(x)} {\tilde P}_x(z), \quad \forall z\in [x].\]</p><p>Dividing by <span>${\tilde P}_x(z),$</span> which we know is positive over <span>$[x],$</span> yields the second claim.</p><p>Finally, considering the constant</p><p class="math-container">\[    C = \frac{{\tilde P}(x)}{{\tilde P}_x(x)},\]</p><p>yields the claim that <span>${\tilde P}$</span> is proportional to <span>${\tilde P}_x,$</span> completing the proof. □</p><div class="admonition is-info" id="Corollary-12c6d9a3e7e8fd15"><header class="admonition-header">Corollary<a class="admonition-anchor" href="#Corollary-12c6d9a3e7e8fd15" title="Permalink"></a></header><div class="admonition-body"><p>Suppose the chain is recurrent and irreducible. Then there is only one invariant measure, up to a multiplicative constant.</p></div></div><p><strong>Proof.</strong> Since the chain is assumed to be recurrent, any <span>$x\in\mathcal{X}$</span> is recurrent, which means <span>${\tilde P}_x$</span> is a nontrivial invariant measure, for any <span>$x\in\mathcal{X}.$</span> Since the chain is irreducible, the whole space is a single communication class and is also closed because the chain has nowhere else to go. Thus, any invariant measure is a multiple of any of the <span>${\tilde P}_x,$</span> <span>$x\in\mathcal{X},$</span> and any pair <span>${\tilde P}_{x}$</span> and <span>${\tilde P}_y$</span> is one a constant multiple of the other.</p><div class="admonition is-info" id="Corollary-(Kac&#39;s-Theorem)-754cbddcf3636252"><header class="admonition-header">Corollary (Kac&#39;s Theorem)<a class="admonition-anchor" href="#Corollary-(Kac&#39;s-Theorem)-754cbddcf3636252" title="Permalink"></a></header><div class="admonition-body"><p>Suppose the chain is irreducible and has a stationary probability distribution <span>${\tilde P}.$</span> Then</p><p class="math-container">\[    {\tilde P}(x) = \frac{1}{\mathbb{E}[\tau_x | X_n = x]}.\]</p></div></div><p><strong>Proof.</strong> ...</p><p><strong>Remark.</strong> If we consider the chain</p><p class="math-container">\[    X_{n+1} = \begin{cases} 
        X_n + 1, &amp; n \neq -1, 0, \\
        X_n + 2, &amp; n = -1, \\
        X_n, &amp; n = 0.
    \end{cases}\]</p><p>Then, the only recurrent state is <span>$X_n = 0.$</span> The associated stationary probability distribution is the Dirac Delta at <span>$X=0.$</span> On the other hand, the counting measure is also invariant and has measure 1 at any point, including the recurrent point <span>$X=0,$</span> but this measure is not proportional to the Dirac Delta, so it does not suffice to assume that <span>${\tilde P}$</span> is an invariant measure with <span>${\tilde P}(x) &gt; 0$</span> at a recurrent point <span>$x.$</span> One must assume that <span>${\tilde P}$</span> is carried by the equivalence class of <span>$x.$</span></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../mc_countableX_recurrence/">« Recurrence in the countable-space case</a><a class="docs-footer-nextpage" href="../mc_countableX_convergencia/">Aperiodicidade e convergência para a distribuição estacionária »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.13.0 on <span class="colophon-date" title="Thursday 26 June 2025 15:36">Thursday 26 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
