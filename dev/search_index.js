var documenterSearchIndex = {"docs":
[{"location":"generative/stein_score/#Stein-score-function","page":"Stein score function","title":"Stein score function","text":"","category":"section"},{"location":"generative/stein_score/#Aim","page":"Stein score function","title":"Aim","text":"","category":"section"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"Revisit the origin of the Stein score function, which is the basis of score-based generative models.","category":"page"},{"location":"generative/stein_score/#The-Stein-score-function","page":"Stein score function","title":"The Stein score function","text":"","category":"section"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"Given a random variable mathbfX in mathbbR^d, dinmathbbN we denote its pdf by p_mathbfX(mathbfx), while its (Stein) score function, also known as gradlogpdf, is defined by","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    boldsymbolpsi_mathbfX(mathbfx) = boldsymbolnabla_mathbfx log p_mathbfX(mathbfx) = fracboldsymbolpartiallog p_mathbfX(mathbfx)boldsymbolpartialmathbfx = left( fracpartialpartial x_j log p_mathbfX(mathbfx)right)_j=1 ldots d","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"where we may use either notation boldsymbolnabla_mathbfx or boldsymbolpartialboldsymbolpartialmathbfx for the gradient of a scalar function. (For the differential of a vector-valued function, we will use either mathrmD_mathbfx or boldsymbolpartialboldsymbolpartialmathbfx.)","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"For a parametrized model with pdf denoted by p(mathbfx boldsymboltheta), or p(mathbfx  boldsymboltheta), and parameters boldsymboltheta = (theta_1 ldots theta_m) min mathbbN, the score function becomes","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    boldsymbolpsi(mathbfx boldsymboltheta) = boldsymbolnabla_mathbfx log p(mathbfx boldsymboltheta) = left( fracpartialpartial x_j log p(mathbfx boldsymboltheta)right)_j=1 ldots d","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"In the univariate case, the score function is also univariate and is given by the derivative of the log of the pdf. For example, for a univariate Normal distribution mathcalN(mu sigma^2), muinmathbbR, sigma  0, the pdf, logpdf and gradlogpdf are","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    beginalign*\n        p_X(x)  = frac1sqrt2pisigmae^-frac12left(fracx - musigmaright)^2 \n        log p_X(x)  = -frac12left(fracx - musigmaright)^2 - log(sqrt2pisigma) \n        psi_X(x)  = - fracx - musigma^2\n    endalign*","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"Notice the score function in this case is just a linear function vanishing at the mean of the distribution and with the slope being minus the multiplicative inverse of its variance.","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"plot(plt1, plt2, plt3, layout=(3, 1), legend=false, size=(600, 400)) # hide","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"In the multivariate case, the score function is a vector field in the event space mathbbR^d.","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"plot(plt1a, plt1b, plt2a, plt2b, size=(600, 400)) # hide","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"This notion of score function used in generative models in machine learning is different from the more classical notion of score in Statistics. The classical score function is defined for a parametrized model and refers to the gradient of the log-likelihood","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    ell(boldsymbolthetamathbfx) = logmathcalL(boldsymbolthetamathbfx) = log p(mathbfxboldsymboltheta)","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"of a parametrized model, with respect to the parameters, i.e.","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    s(boldsymboltheta mathbfx) = boldsymbolnabla_boldsymbolthetalog mathcalL(boldsymbolthetamathbfx) = fracboldsymbolpartiallog mathcalL(boldsymbolthetamathbfx)boldsymbolpartialboldsymboltheta","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"This notion measures the sensitivity of the model with respect to changes in the parameters and is useful, for instance, in the maximization of the likelihood function when fitting a parametrized distribution to data.","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"The score function given by the gradlogpdf of a distribution is, on the other hand, useful for drawing samples via Langevin dynamics.","category":"page"},{"location":"generative/stein_score/#Stein-divergence","page":"Stein score function","title":"Stein divergence","text":"","category":"section"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"Stein (1972) addressed a more general framework to estimate distances between distributions with the aim of approximating the sum of dependent random variables by a normal distribution, in a generalization of the Central Limit Theorem. In a particular case, as described in Liu, Lee, and Jordan (2016), this distance involves the Stein score function and reads as follows.","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"If p=p(mathbfx) is a probability density function on mathbfxinmathbbR^d, then, for any smooth scalar function f(mathbfx) decaying sufficiently fast relative to p(mathbfx),","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    beginalign*\n        int_mathbbR^d p(mathbfx)left( boldsymbolnabla_mathbfx log p(mathbfx)f(mathbfx) + boldsymbolnabla_mathbfx f(mathbfx) right)mathrmdmathbfx  = int_mathbbR^d p(mathbfx)left( fracboldsymbolnabla_mathbfx p(mathbfx)p(mathbfx) f(mathbfx) + boldsymbolnabla_mathbfx f(mathbfx) right)mathrmdmathbfx \n         = int_mathbbR^d left(boldsymbolnabla_mathbfx p(mathbfx) f(mathbfx) + p(mathbfx)boldsymbolnabla_mathbfx f(mathbfx) right)mathrmdmathbfx \n         = int_mathbbR^d boldsymbolnabla_mathbfx left(p(mathbfx) f(mathbfx)right)mathrmdmathbfx \n         = 0\n    endalign*","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"This is a particular case of the Stein identity. Now if q=q(mathbfx) is another probability density function, then","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    beginalign*\n        int_mathbbR^d p(mathbfx)left( boldsymbolnabla_mathbfx log q(mathbfx)f(mathbfx) + boldsymbolnabla_mathbfx f(mathbfx) right)mathrmdmathbfx  = int_mathbbR^d p(mathbfx)boldsymbolnabla_mathbfx log left(q(mathbfx) - p(mathbfx) right)f(mathbfx) mathrmdmathbfx\n    endalign*","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"and we see that ","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    int_mathbbR^d p(mathbfx)left( boldsymbolnabla_mathbfx log q(mathbfx)f(mathbfx) + boldsymbolnabla_mathbfx f(mathbfx) right)mathrmdmathbfx = 0 forall finmathcalF quad textrmif and only if quad q = p textrmae","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"where mathcalF is taken to be the class of function f=f(mathbfx) which are smooth and decay relatively fast with respect to p=p(mathbfx) (or, more generally, a subset of that which is relatively large in a suitable sense). Based on that, the Stein discrepancy measure is defined originally as","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    mathbbS_mathcalF^1(p q) = max_finmathcalFmathbbE_pleftboldsymbolnabla_mathbfx log q(mathbfx)f(mathbfx) + boldsymbolnabla_mathbfx f(mathbfx)right","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"but in other works such as Liu, Lee, and Jordan (2016) the Stein discrepancy measure is taken with the square of the expectation:","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    mathbbS_mathcalF^2(p q) = max_finmathcalFmathbbE_pleftboldsymbolnabla_mathbfx log q(mathbfx)f(mathbfx) + boldsymbolnabla_mathbfx f(mathbfx)right^2","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"This is not usually computationally tractable and is not often used in practice, when mathcalF is such a large class of functions. Liu, Lee, and Jordan (2016), however, proposed working with a particular subset mathcalF, defined by a ball in a reproducing kernel Hilbert space, for which the discrepancy can be computed via","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    mathbbS_mathcalF^2(p q) = mathbbE_mathbfx mathbfx sim pleftu_q(mathbfx mathbfx)right","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"where mathbfx mathbfx are independently draw from p, and u_q is a function involving the (Stein) score of q and a suitable (Stein) kernel.","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"We do not get into more details here since this moves away from our objective. The aim here was just to mention the context in which the (Stein) score function was brought to relevance, before starting to be used for generative methods.","category":"page"},{"location":"generative/stein_score/#Score-function-in-the-Julia-language","page":"Stein score function","title":"Score function in the Julia language","text":"","category":"section"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"The distributions and their pdf are obtained from the JuliaStats/Distributions.jl package. The score function is also implemented in JuliaStats/Distributions.jl as gradlogpdf, but only for some distributions. Since we are interested on Gaussian mixtures, we did some pirating and extended Distributions.gradlogpdf to MixtureModels, both univariate and multivariate.","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"Consider a mixture model with pdf given by","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    p(mathbfx) = alpha_1 p_1(mathbfx) + cdots + alpha_k p_k(mathbfx)","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"where 0 leq alpha_i leq 1, sum_i alpha_i = 1, and each p_i(mathbfx) is a PDF of a distribution. If each p(mathbfx) is supported on the whole space mathbbR^d, then","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    beginalign*\n        boldsymbolnabla_mathbfx log p(mathbfx)  = frac1p(mathbfx)boldsymbolnabla_mathbfx p(mathbfx) \n         = frac1p(mathbfx)boldsymbolnabla_mathbfx left( alpha_1 p_1(mathbfx) + cdots + alpha_k p_k(mathbfx) right) \n         = frac1p(mathbfx)boldsymbolnabla_mathbfx left( alpha_1 boldsymbolnabla_mathbfx p_1(mathbfx) + cdots + alpha_kboldsymbolnabla_mathbfx p_k(mathbfx) right)\n    endalign*","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"This would be sufficient if each gradpdf were implemented for the distributions in JuliaStats/Distributions.jl. But unfortunately it is not. What we can do then is to assume that each distribution p_i(mathbfx) is also supported on the whole mathbbR^d and use that","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    boldsymbolnabla_mathbfx p_i(mathbfx) = p_i(mathbfx)boldsymbolnabla_mathbfx log p_i(mathbfx)","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"In this case, we have the identity","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    boldsymbolnabla_mathbfx log p(mathbfx) = frac1p(mathbfx)boldsymbolnabla_mathbfx left( alpha_1 p_1(mathbfx)boldsymbolnabla_mathbfx log p_1(mathbfx) + cdots + alpha_k p_k(mathbfx)boldsymbolnabla_mathbfx log p_k(mathbfx) right)","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"Assuming the Stein score function is implemented for each distribution, we write the score s_p(mathbfx) of the mixture model in terms of the score s_p_i(mathbfx) of each distribution as","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"    s_p(mathbfx) = frac1p(mathbfx)left(alpha_1 p_1(mathbfx)s_1(mathbfx) + cdots + alpha_k p_k(mathbfx)s_k(mathbfx)right)","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"These are the codes for that.","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"function Distributions.gradlogpdf(d::UnivariateMixture, x::Real)\n    ps = probs(d)\n    cs = components(d)\n    ps1 = first(ps)\n    cs1 = first(cs)\n    pdfx1 = pdf(cs1, x)\n    pdfx = ps1 * pdfx1\n    glp = pdfx * gradlogpdf(cs1, x)\n    if iszero(ps1)\n        glp = zero(glp)\n    end\n    @inbounds for (psi, csi) in Iterators.drop(zip(ps, cs), 1)\n        if !iszero(psi)\n            pdfxi = pdf(csi, x)\n            if !iszero(pdfxi)\n                pipdfxi = psi * pdfxi\n                pdfx += pipdfxi\n                glp += pipdfxi * gradlogpdf(csi, x)\n            end\n        end\n    end\n    if !iszero(pdfx) # else glp is already zero\n        glp /= pdfx\n    end \n    return glp\nend","category":"page"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"function Distributions.gradlogpdf(d::MultivariateMixture, x::AbstractVector{<:Real})\n    ps = probs(d)\n    cs = components(d)\n\n    # `d` is expected to have at least one distribution, otherwise this will just error\n    psi, idxps = iterate(ps)\n    csi, idxcs = iterate(cs)\n    pdfx1 = pdf(csi, x)\n    pdfx = psi * pdfx1\n    glp = pdfx * gradlogpdf(csi, x)\n    if iszero(psi)\n        fill!(glp, zero(eltype(glp)))\n    end\n    \n    while (iterps = iterate(ps, idxps)) !== nothing && (itercs = iterate(cs, idxcs)) !== nothing\n        psi, idxps = iterps\n        csi, idxcs = itercs\n        if !iszero(psi)\n            pdfxi = pdf(csi, x)\n            if !iszero(pdfxi)\n                pipdfxi = psi * pdfxi\n                pdfx += pipdfxi\n                glp .+= pipdfxi .* gradlogpdf(csi, x)\n            end\n        end\n    end\n    if !iszero(pdfx) # else glp is already zero\n        glp ./= pdfx\n    end \n    return glp\nend","category":"page"},{"location":"generative/stein_score/#References","page":"Stein score function","title":"References","text":"","category":"section"},{"location":"generative/stein_score/","page":"Stein score function","title":"Stein score function","text":"C. Stein (1972), \"A bound for the error in the Normal approximation to the distribution of a sum of dependent random variables\", Proceedings of the Sixth Berkeley Symposium on Mathematical Statistics and Probability, 583-602\nQ. Liu, J. Lee, M. Jordan (2016), \"A kernelized Stein discrepancy for goodness-of-fit tests\", Proceedings of The 33rd International Conference on Machine Learning, PMLR 48, 276-284","category":"page"},{"location":"probability/kernel_density_estimation/#Kernel-density-estimation","page":"Kernel Density Estimation","title":"Kernel density estimation","text":"","category":"section"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"We consider a univariate real-valued random variable X, for simplicity, but the same idea applies to multivariate random variables.","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"Let us say we have a sample x_n_n=1^N of X, where NinmathbbN.","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"scatter(sample, one.(sample), xlims=extrema(xrange), ylims=(0, 2), axis=false, legend=false, grid=false, size=(600, 80)) # hide","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"Which statistical informations one can draw from it?","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"Certainly we can compute the sample mean, and the sample standard deviation, directly from the data, and so on. They give us some reasonable estimates on the true values, depending on the number of sample points and on the independence of the sample.","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"scatter(sample, one.(sample), xlims=extrema(xrange), ylims=(0, 2), axis=false, legend=false, grid=false, size=(600, 80)) # hide\nvline!([mean(sample)]) # hide\nvspan!([mean(sample) - std(sample), mean(sample) + std(sample)], alpha=0.2) # hide","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"We can also draw its histogram, to have a more visual information of the underlying distribution.","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"histogram(xrange, sample, bins=30, legend=false) # hide","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"That histogram resembles a PDF. It is not a PDF in the sense that its mass is not one, but it can be normalized to resemble a PDF.","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"In view of that, one natural question is how well can we approximate the PDF from the data?","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"There are parametric ways to do that, which means we can assume a parametrized model, say a Beta distribution B(alpha beta) with shape parameters alpha and beta, and fit the model to the data, say using maximum likelyhood estimation, and use the pdf of the fitted model. That's all good. Depending on the random variable, though, your model can become quite complex.","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"There are also nonparametric ways of obtaining an approximate PDF for the distribution. One popular choice is the kernel density estimation, also known as Parzen window estimation, developed by Murray Rosenblatt (1956), Peter Whittle (1958), and Emanuel Parzen (1962).","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"One way we can view the kernel density estimation is as a spin-off of the histogram. The PDF is likely to be larger where there are more sample points nearby. The closer they are to a point, the higher the chances around that. We can measure this with a kernel density around each sample point, like a region of influence. One can use different types of kernels, but a common one is a Gaussian kernel.","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"In the case of a histogram, if the interval I_j represents a bin, then the corresponding height h_j of the histogram on this bin is the sample count within the bin, which can be written as","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    h_j = sum_n=1^N chi_I_j(x_n)","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"We can normalize this with","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    p_j = frac1NI_jsum_n=1^N chi_I_j(x_n)","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"where I_j is the width (or length) of the interval I_j. ","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"In this case, if we set hat p_mathcalI(x) = p_j for xin I_i, then","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    int_mathbbR hat p_mathcalI(x) mathrmdx = sum_j=1^M p_j I_j","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"where M denotes the total number of bins, containing all the sample points and the partition mathcalI = I_j_j=1^M is the collection of bins. Then,","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    int_mathbbR hat p_mathcalI(x) mathrmdx = sum_j=1^M frac1NI_jsum_n=1^N chi_I_j(x_n)I_j = frac1N sum_j=1^M sum_n=1^N chi_I_j(x_n)","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"Switching the order of summation, we obtain","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    int_mathbbR hat p_mathcalI(x) mathrmdx = frac1N sum_n=1^N sum_j=1^M chi_I_j(x_n)","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"Since each sample point is in one and only one bin, we have that","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    sum_j=1^M chi_I_j(x_n) = 1","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"Thus,","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    int_mathbbR hat p_mathcalI(x) mathrmdx = frac1N sum_n=1^N 1  = fracNN = 1","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"showing that hat p_mathcalI(cdot) is normalized to have total mass 1. So, this is a genuine PDF of some distribution that somehow approximates the true distribution. But it is not smooth.","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"stephist(xrange, sample, bins=30, legend=false, normalized=true, seriestype = :stephist) # hide","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"The kernel window estimation can be seen as a variation of this, which regularizes the PDF, provided the kernel is smooth. In this estimation, instead of summing up characteristic functions of the bins, we sum up the kernel around each sample point:","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    hat p_h(x) = frac1h Nsum_n=1^N Kleft(fracx - x_nhright)","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"where h is a scale parameter that plays the role of the width of the bin, for a nondimensional kernel.","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"If the kernel has mass 1, so does hat p_h(x). Indeed, using the change of variables y = (x - x_n)  h,","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    beginalign*\n        int_mathbbR hat p_h(x) mathrmdx  = frac1h Nsum_n=1^N int_mathbbR Kleft(fracx - x_nhright) mathrmdx \n         = frac1h Nsum_n=1^N int_mathbbR K(y) h mathrmdy \n         = frac1N sum_n=1^N int_mathbbR K(y) mathrmdy \n         = frac1N sum_n=1^N 1 = fracNN = 1\n    endalign*","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"If the kernel is flat, say the characteristic function of the interval -12 12), ","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    K(x) = chi_-12 12)(x)","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"then the kernel window estimation hat p_h(x) is constant by parts, resembling a histogram, but not quite like a histogram since the characteristic function is not attached to bins, but are centered on each sample point.","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"plts = [] # hide\nfor h in (0.01, 0.05, 0.1, 0.5) # hide\n    plti = plot(xrange, x -> kerneldensityestimation(x, x -> (-1/2 ≤ x < 1/2), h, sample), xlims=extrema(xrange), title=\"characteristic function kernel with h=$h\", titlefont=8, legend=false) # hide\n    push!(plts, plti) # hide\nend # hide\nplot(plts..., plot_title=\"kernel density estimations\", plot_titlevspan=0.1, plot_titlefont=10) # hide","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"When the kernel is smooth, so is hat p_h(x). In fact, hat p_h(x) is as regular as the kernel. One popular choice is the Gaussian kernel","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    K(x) = frac1sqrt2pi e^-fracx^22","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"This yields the estimation","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"    hat p_h(x) = frac1h Nsum_n=1^N Kleft(fracx - x_nhright) = frac1Nsum_n=1^N frac1sqrt2pi h e^-frac12left(fracx - x_nhright)^2","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"plts = [] # hide\nfor h in (0.01, 0.05, 0.1, 0.5) # hide\n    plti = plot(xrange, x -> kerneldensityestimation(x, x -> exp(-x^2/2)/sqrt(2pi), h, sample), xlims=extrema(xrange), title=\"Gaussian kernel with h=$h\", titlefont=8, legend=false) # hide\n    push!(plts, plti) # hide\nend # hide\nplot(plts..., plot_title=\"kernel density estimations\", plot_titlevspan=0.1, plot_titlefont=10) # hide","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"The sample in this example was drawn from a mixture model combining a Beta distribution, a Gamma distribution, and a normal distribution. Here is the actual PDF compared with Gaussian kernel estimation with a specific value of h.","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"h = 0.1 # hide\nplot(title=\"Sample, histogram, actual PDF and kernel density estimation\", titlefont=10, xlims=extrema(xrange)) # hide\nscatter!(sample, zero(sample) .+ 0.02 , label=\"sample\", color=1) # hide\nhistogram!(sample, alpha=0.3, bins=30, normalized=true, label=\"histogram\", color=1) # hide\nplot!(xrange, x -> pdf(prob, x), label=\"actual PDF\", color=2) # hide\nplot!(xrange, x -> kerneldensityestimation(x, x -> exp(-x^2/2)/sqrt(2pi), h, sample), xlims=extrema(xrange), label=\"Gaussian kernel estimation with h=$h\", color=3) # hide","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"The choice of a suitable value for h is a delicate problem, though, as one can see from the estimations above, which is akin to the problem of choosing how many bins to view the histogram. And how can we be sure that this is really a good approximation for some \"reasonable\" choices of h?","category":"page"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"Indeed, these are fundamental questions, and the works of Rosenblatt, Whittle, and Parzen are deeper than simply proposing the estimation bar p_h for some kernel function and some value h. They also discuss further conditions on the kernel such that the estimate is not biased, and discuss asymptotic properties of the estimation, as the number of sample points grows to infinity. One of the results is that the choice of h should depend on n and decay to zero as n increases. They are worth reading, but we will not dwelve into further details at this moment.","category":"page"},{"location":"probability/kernel_density_estimation/#References","page":"Kernel Density Estimation","title":"References","text":"","category":"section"},{"location":"probability/kernel_density_estimation/","page":"Kernel Density Estimation","title":"Kernel Density Estimation","text":"M. Rosenblatt (1956), Remarks on Some Nonparametric Estimates of a Density Function. The Annals of Mathematical Statistics 27, no. 3, 832–837, doi:10.1214/aoms/1177728190\nP. Whittle (1958), On the Smoothing of Probability Density Functions, Journal of the Royal Statistical Society. Series B (Methodological), Vol. 20, No. 2, pp. 334-343\nE. Parzen (1962), On Estimation of a Probability Density Function and Mode. The Annals of Mathematical Statistics 33, no. 3, 1065–1076, doi:10.1214/aoms/1177704472","category":"page"},{"location":"bayesian/bernstein_vonmises/#Bernstein–von-Mises-theorem","page":"Bernstein–von Mises theorem","title":"Bernstein–von Mises theorem","text":"","category":"section"},{"location":"bayesian/find_pi/#Estimating-the-value-of-π-via-frequentist-and-Bayesian-methods","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating the value of π via frequentist and Bayesian methods","text":"","category":"section"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"In the frequentist approach, we draw a number of samples uniformly distributed in the unit square and compute how many of them fall into the quarter circle. This yields an estimate for the area of the quarter circle along with confidence intervals. ","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"In the Bayesian approach, we start with a prior estimating the value of pi and update our prior to refine the estimate and the confidence levels, according to the posterior.","category":"page"},{"location":"bayesian/find_pi/#The-Julia-packages","page":"Estimating π via frequentist and Bayesian methods","title":"The Julia packages","text":"","category":"section"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"For the numerical implementation, we need some packages.","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"We use Distributions.jl for the common distributions, such as Uniform, Beta, Bernoulli, Normal, etc.","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"using Distributions","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"For reproducibility, we set the seed for the pseudo random number generators.","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"using Random\nRandom.seed!(12)","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"For plotting, we use StatsPlots.jl","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"using StatsPlots","category":"page"},{"location":"bayesian/find_pi/#The-frequentist-approach","page":"Estimating π via frequentist and Bayesian methods","title":"The frequentist approach","text":"","category":"section"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"This is a classical example illustrating the Monte Carlo method. We generate a bunch of samples (x_i y_i) from two independent uniform distributions on the interval 0 1 and check whether they belong to the unit circle (quarter circle, more precisely) or not, i.e. whether x_i^2 + y_i^2 leq 1 The distribution uniformly fills up the unit square, which has area one, and some of them will be in the quarter circle. The proportion of those in the circle approximates the area of the quarter circle over that of the unit square, i.e. pi4. Multiplying it by four, yields an estimate for pi. The more samples we use, the closer we expect the mean to approximate this value.","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"We start choosing a maximum number N of samples. We will analyse the estimate for each i up to N, to have an idea how the value and our confidence on it improves with the number of samples.","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"N = 10_000","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"Now we sample N pairs of numbers uniformly on the unit square","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"positions_f = rand(N, 2)","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"With the sample at hand, we compute their distance to the origin and check whether they belong to the unit circle or not, giving a sequence x_f of random variables with values 1 or 0, with the respective indication.","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"distance_f = sum(abs2, positions_f, dims=2)\nx_f = vec(distance_f) .≤ 1","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"For each n between 1 and N, we compute the sample mean q_f[n] of x_f[1], …, x_f[n], and the sample standard error s_f[n].","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"q_f = cumsum(x_f) ./ (1:N)\ns_f = [1.0; [√(var(view(x_f, 1:n), mean=q_f[n])/n) for n in 2:N]]","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"The sample means approximate the value of pi4, so we multiply it by 4 to have an estimate of pi. Accordingly, we multipy the standard error by 4. The 95% confidence interval is estimated by twice the standard error around the mean. This is illustrated in the following plots. Of course, for small samples, we should use the t-Student distribution, but we concentrate on not-so-small samples and just use the normal distribution, relying on the Central Limit Theorem.","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"plot(10:N, 4q_f[10:N], ribbon = 8s_f[10:N], label=\"estimate\")\nhline!(10:N, [π], label=\"true value\")","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"A close up of the 10% first samples","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"Nrange = 10:min(N, div(N, 10))\nplot(Nrange, 4q_f[Nrange], ribbon = 8s_f[Nrange], label=\"estimate\")\nhline!(Nrange, [π], label=\"true value\")","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"The probability distribution for the estimate of pi after N samples is illustrated below in a few cases.","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"pp = 0.0:0.001:1.0\n\nplt = plot(title=\"Evolution of our belief in the value of π\\nwith respect to the sample size n\", titlefont=10, xlims=(0.5, 1.0))\n    \nfor n in (div(N, 1000), div(N, 100), div(N, 10), N)\n    plot!(plt, pp, pdf.(Normal(q_f[n], s_f[n]), pp), label=\"n=$n\", fill=true, alpha=0.5)\nend\nvline!(plt, [π/4], color=:black, label=\"π/4\")","category":"page"},{"location":"bayesian/find_pi/#The-Bayesian-approach","page":"Estimating π via frequentist and Bayesian methods","title":"The Bayesian approach","text":"","category":"section"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"In the Bayesian approach, we start guessing the area of the quarter circle, or, more precisely, the probability that it be a certain value within a certain range. It is reasonable to assume it is a little over half the area of the unit circle and not too close to 1, with higher probability of being closer to the middle of these two values. We could use a normal distribution, but a better choice is a Beta distribution since it is conjugate to the likelihood, which is expected to be a Beta distribution B(alpha beta) with density x^alpha (1 - x)^beta, where alpha counts as the number of success draws (within the quarter circle) and beta as the number of failures (outside the quarter circle). ","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"So we choose as prior the distribution Beta(alpha beta) with something like alpha = 24 and beta = 8, in which case the mean is alpha  (alpha + beta) = 2432 = 34 = 075 and the variance is αβ((α + β)^2(α + β + 1)) = 19233792  000568. These are our hyperparameters. Let us visualize this prior distribution","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"prior_distribution = Beta(24,8)\n\nplt = plot(pp, pdf.(prior_distribution, pp), label=nothing, title=\"Density of the (prior) distribution $prior_distribution\\nmean = $(round(mean(prior_distribution), sigdigits=4)); standard deviation = $(round(std(prior_distribution), sigdigits=5))\", titlefont=10, fill=true, alpha=0.5, legend=:topleft)\n\nvline!(plt, [mean(prior_distribution)], label=\"mean $(round(mean(prior_distribution), sigdigits=4))\")\n\nvline!(plt, mean(prior_distribution) .+ [-std(prior_distribution), +std(prior_distribution)], label=\"mean +/- std: $(round(mean(prior_distribution), sigdigits=4)) +/- $(round(std(prior_distribution), sigdigits=5))\")","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"Just for the sake of illustration, we draw some sample from the prior","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"priordata = rand(prior_distribution, N)","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"Now we generate some \"real\" data. Since we know pi with high precision, we use that to generate the data, which are Bernoulli trials with probability pi4, and check the mean, which should be close to p_true.","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"p_true = π/4","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"data = rand(Bernoulli(p_true), N)\n\nmean(data)","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"We update our prior in closed form, since the prior is a Beta distribution, which is a conjugate prior to the Bernoulli distribution. It is updated by simply counting the number of sucesses and the number of failures to the shape parameters alpha and beta, respectively.","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"function update_belief(prior_distribution::Beta, data::AbstractArray{Bool})\n    # Count the number of successes and failures.\n    successes = sum(data)\n    failures = length(data) - successes\n\n    # Update our prior belief using the fact that Beta is conjugate distribution.\n    return Beta(prior_distribution.α + successes, prior_distribution.β + failures)\nend","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"In order to see the evolution of the posterior with respect to the added evidence, we first we update the prior with a small part of the data","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"Ns = div.(N, (1000, 100, 10, 1))\nposterior_distributions = Dict(n => update_belief(prior_distribution, view(data, 1:n)) for n in Ns)","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"Now we visualize the posterior, which is the updated distribution.","category":"page"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"plt = plot(title=\"Density of the posterior distributions Beta(α', β')\", titlefont=10, legend=:topleft, xlims=(0.5, 1.0))\nfor n in Ns\n    distr = posterior_distributions[n]\n    plot!(plt, pp, pdf.(distr, pp), label=\"N=$n; α'=$(distr.α), β'=$(distr.β), mean=$(round(mean(distr), sigdigits=4))\", fill=true, alpha=0.5)\nend\nvline!(plt, [π/4], label=nothing, color=:black)","category":"page"},{"location":"bayesian/find_pi/#Performance-of-the-two-methods","page":"Estimating π via frequentist and Bayesian methods","title":"Performance of the two methods","text":"","category":"section"},{"location":"bayesian/find_pi/","page":"Estimating π via frequentist and Bayesian methods","title":"Estimating π via frequentist and Bayesian methods","text":"It is not so relevant to compare the performance of the two methods above since this is a toy problem and not representative of the variety of situations that can be handled by either frequentist or Bayesian approaches. Drawing pseudo random numbers is pretty cheap and the frequentist approach above is much faster, even with the code not optimized for performance. The use of the Bayesian approach is more relevant in more complex cases and where sampling is more expensive. But more important than that is the perspective of the Bayesian approach of treating parameters as random variables and of their distributions as uncertainties, or quantifiers of our belief on their values.","category":"page"},{"location":"generative/mdsm/#Multiple-denoising-score-matching-with-annealed-Langevin-dynamics","page":"Multiple denoising score matching","title":"Multiple denoising score matching with annealed Langevin dynamics","text":"","category":"section"},{"location":"generative/mdsm/#Introduction","page":"Multiple denoising score matching","title":"Introduction","text":"","category":"section"},{"location":"generative/mdsm/#Aim","page":"Multiple denoising score matching","title":"Aim","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Review the (multiple denoising) score matching with Langevin dynamics (SMLD), which fits a noise conditional score network (NCSN), as introduced by Song and Ermon (2019), which together with DDPM was one step closer to the score-based SDE model.","category":"page"},{"location":"generative/mdsm/#Background","page":"Multiple denoising score matching","title":"Background","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"After Aapo Hyvärinen (2005) suggested fitting the score function of a distribution, several directions were undertaken to improve the quality of the method and make it more practical.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"One of the approaches was the denoising score matching of Pascal Vincent (2011), in which the data is corrupted by a Gaussian noise and the model was trained to correctly denoise the corrupted data. The model itself would either be of the pdf itself or of an energy potential for the pdf. In any case, one would have a model for the pdf and could draw samples directly using that.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Song and Ermon (2019) came with two ideas tied together. The first idea was to model directly the score function and use the Langevin equation to draw samples from it. One difficulty with Langevin sampling, however, is in correctly estimating the weights of multimodal distributions, either superestimating or subestimating some modal regions, depending on where the initial distribution of points is located relative to the model regions. It may take a long time to reach the desired distribution.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"In order to overcome that, Song and Ermon (2019) also proposed using an annealed version of Langevin dynamics, based on a scale of denoising score matching models, with different levels of noise, instead of a single denoising. Lower noises are closer to the target distribution but are challenging to the Langevin sampling, while higher noises are better for Langevin sampling but depart from the target distributions. Combining different levels of noise and gradually sampling between different denoising models improve the modeling and sampling of a distribution. That is the idea of their proposed noise conditional score network (NCSN) framework, in a method that was later denominated denosing score matching with Langevin dynamics (SMLD), and for which a more precise description would be (multiple denosing) score matching with (annealed) Langevin dynamics.","category":"page"},{"location":"generative/mdsm/#Multiple-denoising-score-matching","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"The idea is to consider a sequence of denoising score matching models, starting with a relatively large noise level sigma_1, to avoid the difficulties with Langevin sampling described earlier, and end up with a relatively small noise level sigma_L, to minimize the noisy effect on the data.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"For training, one trains directly a score model according to a weighted loss involving all noise levels.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Then, for sampling, a corresponding sequence of Langevin dynamics, with decreasing levels of noise, driving new samples closer and closer to the target distribution.","category":"page"},{"location":"generative/mdsm/#The-model","page":"Multiple denoising score matching","title":"The model","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"More precisely, one starts with a positive geometric sequence of noise levels sigma_1 ldots sigma_L satisfying","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    fracsigma_1sigma_2 = cdots = fracsigma_L-1sigma_L  1","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"which is the same as","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    sigma_i = theta^i-1 sigma_1 quad i = 1 ldots L","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"for a starting sigma_1  0 and a rate 0  theta  1 given by theta = sigma_2sigma_1 = ldots = sigma_Lsigma_L-1.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"For each sigma=sigma_i, i=1 ldots L, one considers the perturbed distribution","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    p_sigma(tildemathbfx) = int_mathbbR^d p(mathbfx)p_sigma(tildemathbfxmathbfx)mathrmdmathbfx","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"with a perturbation kernel","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    p_sigma(tildemathbfxmathbfx) = mathcalNleft(tildemathbfx mathbfx sigma^2 mathbfIright)","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"This yields a sequence of perturbed distributions","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    p_sigma_i_i=1^L","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"We model the corresponding family of score functions s_boldsymboltheta(tildemathbfx sigma_i), i.e. such that s_boldsymboltheta(tildemathbfx sigma_i) approximates the score function of p_sigma_i, i.e.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    s_boldsymboltheta(tildemathbfx sigma_i) approx boldsymbolnabla_tildemathbfx log p_sigma_i(tildemathbfx)","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"The noise conditional score network (NCSN) is precisely ","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    s_boldsymboltheta(tildemathbfx sigma)","category":"page"},{"location":"generative/mdsm/#The-loss-function","page":"Multiple denoising score matching","title":"The loss function","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"One wants to train the noise conditional score network s_boldsymboltheta(tildemathbfx sigma) by weighting together the denosing loss function of each perturbation, i.e.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    J_textrmSMLD(boldsymboltheta) = frac12Lsum_i=1^L lambda(sigma_i) mathbbE_p(mathbfx)p_sigma_i(tildemathbfxmathbfx)left left s_boldsymboltheta(tildemathbfx sigma_i) - fracmathbfx - tildemathbfxsigma_i^2 right^2 right","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"where lambda = lambda(sigma_i) is a weighting factor.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"In practice, we use the empirical distribution and a single corrupted data for each sample data, i.e.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    tilde J_textrmSMLD(boldsymboltheta) = frac12LN sum_n=1^N sum_i=1^L lambda(sigma_i)left s_boldsymboltheta(tildemathbfx_n i sigma_i) - fracmathbfx_n - tildemathbfx_n isigma_i^2 right^2 quad tildemathbfx_n i sim mathcalNleft(mathbfx_n sigma^2 mathbfIright)","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"This can also be written with a reparametrization,","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    tilde J_textrmSMLD(boldsymboltheta) = frac12LN sum_n=1^N sum_i=1^L lambda(sigma_i) left s_boldsymboltheta(mathbfx_n + boldsymbolepsilon_n i sigma_i) + fracboldsymbolepsilon_n isigma_i right^2 quad boldsymbolepsilon_n i sim mathcalNleft(mathbf0_n mathbfIright)","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"As for the choice of lambda(sigma), Song and Ermon (2019) suggested choosing","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    lambda(sigma) = sigma^2","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"This comes from the observation that,","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    s_boldsymboltheta(tildemathbfx_n sigma_i)^2 sim frac1sigma_i","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"hence","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    lambda(sigma_i)left s_boldsymboltheta(mathbfx_n + boldsymbolepsilon_n i sigma_i) + fracboldsymbolepsilon_n isigma_i right^2 sim 1","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"is independent of i=1 ldots L. Choosing such weighting, the loss function becomes","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    tilde J_textrmSMLD(boldsymboltheta) = frac12LN sum_n=1^N sum_i=1^L left sigma_i s_boldsymboltheta(tildemathbfx_n i sigma_i) - (mathbfx_n - tildemathbfx_n i)right^2 quad tildemathbfx_n i sim mathcalNleft(mathbfx_n sigma^2 mathbfIright)","category":"page"},{"location":"generative/mdsm/#Sampling","page":"Multiple denoising score matching","title":"Sampling","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"For each i=1 ldots L, the dynamics of the overdamped Langevin equation","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    mathrmdX_t = boldsymbolnabla_tildemathbfx log p_sigma_i(tildemathbfX_t)mathrmdt + sqrt2mathrmdW_t","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"drives any initial sample towards the distribution defined by p_sigma_i. With s_boldsymboltheta(tildemathbfx sigma_i) being an approximation of boldsymbolnabla_tildemathbfx log p_sigma_i(tildemathbfx) and with p_sigma_i(tildemathbfx) being closer to the target p(mathbfx) the smaller the sigma_i, the idea is to run batches of Langevin dynamics for decreasing values of noise, i.e. for sigma_1 down to sigma_L.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"More precisely, given KinmathbbN, we run the Langevin equation for K steps, for each i=1 ldots L:","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"1. Start with a M sample points mathbfy_m, m=1 ldots M, MinmathbbN, of a multivariate Normal distribution, or a uniform distribution, or any other known distribution.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"2. Then for each i=1 ldots L, run the discretized overdamped Langevin equation for K steps","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    mathbfy^i_m k = mathbfy^i_m k-1 + s_boldsymboltheta(tildemathbfy^i-1_m k-1 sigma_i) tau_i + sqrt2tau_imathbfz^i_m k","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"where tau_i  0 is a given time step (which may or may not vary with i); the mathbfz^i_m k sim mathcalN(mathbf0 mathbfI) are independent; and the initial conditions are given by","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    mathbfy^1_m 0 = mathbfy_m","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"for i=1, and","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"    mathbfy^i_m 0 = mathbfy^i-1_m K","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"for i = 2 ldots L, i.e. the final Kth-step of the solution of the Langevin equation with a given i = 1 ldots K-1 is the initial step of the Langevin equation for i+1.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"3. The final points mathbfy^L_m K, m=1 ldots M, are the M desired new generated samples of the distribution approximating the data distribution.","category":"page"},{"location":"generative/mdsm/#Numerical-example","page":"Multiple denoising score matching","title":"Numerical example","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"We illustrate, numerically, the use of multiple denoising score matching to model a synthetic univariate Gaussian mixture distribution.","category":"page"},{"location":"generative/mdsm/#Julia-language-setup","page":"Multiple denoising score matching","title":"Julia language setup","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"We use the Julia programming language for the numerical simulations, with suitable packages.","category":"page"},{"location":"generative/mdsm/#Packages","page":"Multiple denoising score matching","title":"Packages","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"using StatsPlots\nusing Random\nusing Distributions\nusing Lux # artificial neural networks explicitly parametrized\nusing Optimisers\nusing Zygote # automatic differentiation\nusing Markdown\n\nnothing # hide","category":"page"},{"location":"generative/mdsm/#Reproducibility","page":"Multiple denoising score matching","title":"Reproducibility","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"We set the random seed for reproducibility purposes.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"rng = Xoshiro(12345)\nnothing # hide","category":"page"},{"location":"generative/mdsm/#Data","page":"Multiple denoising score matching","title":"Data","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"We build the usual target model and draw samples from it.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Visualizing the sample data drawn from the distribution and the PDF.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"plt # hide","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Visualizing the score function.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"plt # hide","category":"page"},{"location":"generative/mdsm/#Parameters","page":"Multiple denoising score matching","title":"Parameters","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Here we set some parameters for the model and prepare any necessary data.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"L = 16\nsigma_1 = 2.0\nsigma_L = 0.5\ntheta = ( sigma_L / sigma_1 )^(1/(L-1))\nsigmas = [sigma_1 * theta ^ (i-1) for i in 1:L]","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"data = (sample_points, sigmas)","category":"page"},{"location":"generative/mdsm/#The-neural-network-model","page":"Multiple denoising score matching","title":"The neural network model","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"The neural network we consider is a simple feed-forward neural network made of a single hidden layer, obtained as a chain of a couple of dense layers. This is implemented with the LuxDL/Lux.jl package.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"We will see that we don't need a big neural network in this simple example. We go as low as it works.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"model = Chain(Dense(2 => 64, relu), Dense(64 => 1))","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"The LuxDL/Lux.jl package uses explicit parameters, that are initialized (or obtained) with the Lux.setup function, giving us the parameters and the state of the model.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model","category":"page"},{"location":"generative/mdsm/#Loss-function","page":"Multiple denoising score matching","title":"Loss function","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"function loss_function_mdsm(model, ps, st, data)\n        sample_points, sigmas = data\n\n    noisy_sample_points = sample_points .+ sigmas .* randn(rng, size(sample_points))\n    scores = ( sample_points .- noisy_sample_points ) ./ sigmas .^ 2\n\n    flattened_noisy_sample_points = reshape(noisy_sample_points, 1, :)\n    flattened_sigmas = repeat(sigmas', 1, length(sample_points))\n    model_input = [flattened_noisy_sample_points; flattened_sigmas]\n\n    y_score_pred, st = Lux.apply(model, model_input, ps, st)\n    \n    flattened_scores = reshape(scores, 1, :)\n\n    loss = mean(abs2, flattened_sigmas .* (y_score_pred .- flattened_scores)) / 2\n    \n    return loss, st, ()\nend","category":"page"},{"location":"generative/mdsm/#Optimization-setup","page":"Multiple denoising score matching","title":"Optimization setup","text":"","category":"section"},{"location":"generative/mdsm/#Optimization-method","page":"Multiple denoising score matching","title":"Optimization method","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"We use the Adam optimiser.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"opt = Adam(0.01)\n\ntstate_org = Lux.Training.TrainState(model, ps, st, opt)","category":"page"},{"location":"generative/mdsm/#Automatic-differentiation-in-the-optimization","page":"Multiple denoising score matching","title":"Automatic differentiation in the optimization","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"As mentioned, we setup differentiation in LuxDL/Lux.jl with the FluxML/Zygote.jl library.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"vjp_rule = Lux.Training.AutoZygote()","category":"page"},{"location":"generative/mdsm/#Processor","page":"Multiple denoising score matching","title":"Processor","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"We use the CPU instead of the GPU.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"dev_cpu = cpu_device()\n## dev_gpu = gpu_device()","category":"page"},{"location":"generative/mdsm/#Check-differentiation","page":"Multiple denoising score matching","title":"Check differentiation","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Check if Zygote via Lux is working fine to differentiate the loss functions for training.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Lux.Training.compute_gradients(vjp_rule, loss_function_mdsm, data, tstate_org)","category":"page"},{"location":"generative/mdsm/#Training-loop","page":"Multiple denoising score matching","title":"Training loop","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Here is the typical main training loop suggest in the LuxDL/Lux.jl tutorials, but sligthly modified to save the history of losses per iteration.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"function train(tstate, vjp, data, loss_function, epochs, numshowepochs=20, numsavestates=0)\n    losses = zeros(epochs)\n    tstates = [(0, tstate)]\n    for epoch in 1:epochs\n        grads, loss, stats, tstate = Lux.Training.compute_gradients(vjp,\n            loss_function, data, tstate)\n        if ( epochs ≥ numshowepochs > 0 ) && rem(epoch, div(epochs, numshowepochs)) == 0\n            println(\"Epoch: $(epoch) || Loss: $(loss)\")\n        end\n        if ( epochs ≥ numsavestates > 0 ) && rem(epoch, div(epochs, numsavestates)) == 0\n            push!(tstates, (epoch, tstate))\n        end\n        losses[epoch] = loss\n        tstate = Lux.Training.apply_gradients(tstate, grads)\n    end\n    return tstate, losses, tstates\nend","category":"page"},{"location":"generative/mdsm/#Training","page":"Multiple denoising score matching","title":"Training","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Now we train the model with the objective function tilde J_mathrmESMtilde p_sigmatilde p_0(boldsymboltheta).","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_mdsm, 1000, 20, 125)\nnothing # hide","category":"page"},{"location":"generative/mdsm/#Results","page":"Multiple denoising score matching","title":"Results","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Checking out the trained model.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"plt # hide","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Visualizing the result with the smallest noise.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"plt # hide","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"plt # hide","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"With the smallest noise.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"plt # hide","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Just for the fun of it, let us see an animation of the optimization process.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"gif(anim, fps = 20) # hide","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"And the animation of the evolution of the PDF.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"gif(anim, fps = 10) # hide","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"We also visualize the evolution of the losses.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false) # hide","category":"page"},{"location":"generative/mdsm/#Sampling-with-annealed-Langevin","page":"Multiple denoising score matching","title":"Sampling with annealed Langevin","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Now we sample the modeled distribution with the annealed Langevin method described earlier.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Here are the trajectories.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"plot(title=\"$(length(x0)) annealed Langevin trajectories with \\$M=$M\\$ and \\$\\\\mathrm{dt}=$(round(dt, sigdigits=2))\\$\", titlefont=10, legend=false) # hide\nplot!(tt, xt, xlabel=\"\\$t\\$\", ylabel=\"\\$x\\$\") # hide","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"The sample histogram obtained at the end of the trajectories.","category":"page"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"plot(title=\"Histogram at the end of sampling\", titlefont=10) # hide\nhistogram(xt[end, :], bins=40, normalize=:pdf, label=\"sample\") # hide\nplot!(range(-6, 6, length=200), x -> pdf(target_prob, x), label=\"target PDF\", xlabel=\"\\$x\\$\") # hide","category":"page"},{"location":"generative/mdsm/#References","page":"Multiple denoising score matching","title":"References","text":"","category":"section"},{"location":"generative/mdsm/","page":"Multiple denoising score matching","title":"Multiple denoising score matching","text":"Aapo Hyvärinen (2005), \"Estimation of non-normalized statistical models by score matching\", Journal of Machine Learning Research 6, 695-709\nPascal Vincent (2011), \"A connection between score matching and denoising autoencoders,\" Neural Computation, 23 (7), 1661-1674, doi:10.1162/NECOa00142\nY. Song and S. Ermon (2019), \"Generative modeling by estimating gradients of the data distribution\", NIPS'19: Proceedings of the 33rd International Conference on Neural Information Processing Systems, no. 1067, 11918-11930","category":"page"},{"location":"generative/1d_FD_score_matching/#Finite-difference-score-matching-of-a-one-dimensional-Gaussian-mixture-model","page":"1D finite-difference score matching","title":"Finite-difference score-matching of a one-dimensional Gaussian mixture model","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/#Introduction","page":"1D finite-difference score matching","title":"Introduction","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/#Aim","page":"1D finite-difference score matching","title":"Aim","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"The aim, this time, is to fit a neural network via finite-difference score matching, following the pioneering work of Aapo Hyvärinen (2005) about score-matching, combined with the work of Pang, Xu, Li, Song, Ermon, and Zhu (2020), which uses finite differences to efficiently approximate the gradient in the loss function proposed by Aapo Hyvärinen (2005), and the idea of 1. Song and Ermon (2019) of modeling directly the score function instead of the pdf or an energy potential of the pdf.","category":"page"},{"location":"generative/1d_FD_score_matching/#Background","page":"1D finite-difference score matching","title":"Background","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Generative score-matching diffusion methods use Langevin dynamics to draw samples from a modeled score function. It rests on the idea of Aapo Hyvärinen (2005) that one can directly fit the score function, from the sample data, using a suitable loss function (associated with the Fisher divergence) not depending on the unknown score function of the random variable. This is obtained by a simple integration by parts on the expected square distance between the model score function and the actual score function. The integration by parts separates the dependence on the actual score function from the parameters of the model, so the fitting process (minimization over the parameters of the model) does not depend on the unknown score function.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"The obtained loss function, however, depends on the gradient of the model, which is computationally expensive. Pang, Xu, Li, Song, Ermon, and Zhu (2020) proposed to use finite differences to approximate the derivative of the model to significantly reduce the computational cost of training the model.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"The differentiation for the optimization is with respect to the parameters, while the differentiation of the modeled score function is on the variate, but still this is a great computational challenge and not all AD are fit for that. For this reason, we resort to centered finite differences to approximate the derivative of the modeled score function.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"For a python version of a similar pedagogical example, see Eric J. Ma (2021). There, they use AD on top of AD, via the google/jax library, which apparently handles this double-AD not so badly.","category":"page"},{"location":"generative/1d_FD_score_matching/#Take-away","page":"1D finite-difference score matching","title":"Take away","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We'll see that, in this simple example at least, we don't need a large or deep neural network. It is much more important to have enough sample points to capture the transition region in the mixture of Gaussians.","category":"page"},{"location":"generative/1d_FD_score_matching/#The-finite-difference-implicit-score-matching-method","page":"1D finite-difference score matching","title":"The finite-difference implicit score matching method","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"The score-matching method from Aapo Hyvärinen (2005) rests on the following ideas:","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"1. Fit the model by minimizing the expected square distance between the model score function psi(x boldsymboltheta) and the score function psi_X(x) of the random variable X, via the explicit score matching (ESM) objective","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"    J_mathrmESM(boldsymboltheta) = frac12int_mathbbR^d p_mathbfX(mathbfx) leftboldsymbolpsi(mathbfx boldsymboltheta) - boldsymbolpsi_mathbfX(mathbfx)right^2mathrmdmathbfx","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"2. Use integration by parts in the expectation to write that","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"    J_mathrmESM(boldsymboltheta) = J_mathrmISM(boldsymboltheta) + C","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"where C is constant with respect to the parameters, so we only need to minimize the implicit score matching (ISM) objective tilde J_mathrmISM, given by","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"    J_mathrmISM(boldsymboltheta) = int_mathbbR p_mathbfX(mathbfx) left( frac12leftboldsymbolpsi(mathbfx boldsymboltheta)right^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx boldsymboltheta) right)mathrmdmathbfx","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"which does not involve the unknown score function of mathbfX. It does, however, involve the gradient of the modeled score function, which is expensive to compute.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"3. In practice, the implicit score-matching loss function, which depends on the unknown p_mathbfX(mathbfx), is estimated via the empirical distribution, obtained from the sample data (mathbfx_n)_n. Thus, we minimize the empirical implicit score matching objective","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"    tilde J_mathrmISMtilde p_0 =  frac1Nsum_n=1^N left( frac12boldsymbolpsi(mathbfx_n boldsymboltheta)^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx_n boldsymboltheta) right)","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"where the empirical distribution is given by tilde p_0 = (1N)sum_n=1^N delta_mathbfx_n","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"On top of that, we add one more step.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"4. As mentioned before, computing a derivative to form the loss function becomes expensive when combined with the usual optimization methods to fit a neural network, as they require the gradient of the loss function itself, i.e. the optimization process involves the gradient of the gradient of something. Because of that, one alternative is to approximate the derivative of the model score function by centered finite differences, i.e.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"    fracpartialpartial x psi(x_n boldsymboltheta) approx fracpsi(x_n + delta boldsymboltheta) - psi(x_n - delta boldsymboltheta)2delta","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"for a suitably small delta  0.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"In this case, since we need compute psi(x_n + delta boldsymboltheta) and psi(x_n - delta boldsymboltheta), we avoid computing also psi(x_n boldsymboltheta) and approximate it with the average","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"    psi(x_n boldsymboltheta) approx fracpsi(x_n + delta boldsymboltheta) + psi(x_n - delta boldsymboltheta)2","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Hence, we approximate the implicit score matching tilde J_mathrmISMtilde p_0 by the finite-difference (implicit) score matching","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"    tilde J_mathrmFDSM(boldsymboltheta) = int_mathbbR p_X(x) Bigg( frac12left(fracpsi(x + delta boldsymboltheta) + psi(x - delta boldsymboltheta)2right)^2 + fracpsi(x + delta boldsymboltheta) - psi(x - delta boldsymboltheta)2delta Bigg)mathrmdx","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"And the empirical implicit score matching tilde J_mathrmISMtilde p_0 is approximated by","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"    tilde J_mathrmFDSMtilde p_0 =  frac1Nsum_n=1^N Bigg( frac12left(fracpsi(x + delta boldsymboltheta) + psi(x - delta boldsymboltheta)2right)^2 + fracpsi(x + delta boldsymboltheta) - psi(x - delta boldsymboltheta)2delta Bigg)","category":"page"},{"location":"generative/1d_FD_score_matching/#Numerical-example","page":"1D finite-difference score matching","title":"Numerical example","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We illustrate the above method by fitting a neural network to a univariate Gaussian mixture distribution.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We played with different target distributions and settled here with a bimodal distribution used in Eric J. Ma (2021).","category":"page"},{"location":"generative/1d_FD_score_matching/#Julia-language-setup","page":"1D finite-difference score matching","title":"Julia language setup","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We use the Julia programming language with suitable packages.","category":"page"},{"location":"generative/1d_FD_score_matching/#Packages","page":"1D finite-difference score matching","title":"Packages","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"using StatsPlots\nusing Random\nusing Distributions\nusing Lux # artificial neural networks explicitly parametrized\nusing Optimisers\nusing Zygote # automatic differentiation\n\nnothing # hide","category":"page"},{"location":"generative/1d_FD_score_matching/#Reproducibility","page":"1D finite-difference score matching","title":"Reproducibility","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We set the random seed for reproducibility purposes.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"rng = Xoshiro(12345)\nnothing # hide","category":"page"},{"location":"generative/1d_FD_score_matching/#Code-introspection","page":"1D finite-difference score matching","title":"Code introspection","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We do not attempt to overly optimize the code here since this is a simple one-dimensional problem. Nevertheless, it is always healthy to check the type stability of the critical parts (like the loss functions) with @code_warntype. One should also check for any unusual time and allocation with BenchmarkTools.@btime or BenchmarkTools.@benchmark. We performed these analysis and everything seems good. We found it unnecessary to clutter the notebook with their outputs here, though.","category":"page"},{"location":"generative/1d_FD_score_matching/#Data","page":"1D finite-difference score matching","title":"Data","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We build the target model and draw samples from it. We need enough sample points to capture the transition region in the mixture of Gaussians.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"xrange = range(-10, 10, 200)\ndx = Float64(xrange.step)\nx = permutedims(collect(xrange))\n\ntarget_prob = MixtureModel([Normal(-3, 1), Normal(3, 1)], [0.1, 0.9])\n\ntarget_pdf = pdf.(target_prob, x)\ntarget_score = gradlogpdf.(target_prob, x)\n\ny = target_score # just to simplify the notation\nsample_points = permutedims(rand(rng, target_prob, 1024))\ndata = (x, y, target_pdf, sample_points)","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Notice the data x and sample_points are defined as row vectors so we can apply the model in batch to all of their values at once. The values y are also row vectors for easy comparison with the predicted values. When, plotting, though, we need to revert them to vectors.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Visualizing the sample data drawn from the distribution and the PDF.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(title=\"PDF and histogram of sample data from the distribution\", titlefont=10)\nhistogram!(sample_points', normalize=:pdf, nbins=80, label=\"sample histogram\")\nplot!(x', target_pdf', linewidth=4, label=\"pdf\")\nscatter!(sample_points', s -> pdf(target_prob, s), linewidth=4, label=\"sample\")","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Visualizing the score function.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(title=\"The score function and the sample\", titlefont=10)\n\nplot!(x', target_score', label=\"score function\", markersize=2)\nscatter!(sample_points', s -> gradlogpdf(target_prob, s), label=\"data\", markersize=2)","category":"page"},{"location":"generative/1d_FD_score_matching/#The-neural-network-model","page":"1D finite-difference score matching","title":"The neural network model","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"The neural network we consider is a simple feed-forward neural network made of a single hidden layer, obtained as a chain of a couple of dense layers. This is implemented with the LuxDL/Lux.jl package.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We will see, again, that we don't need a big neural network in this simple example. We go as low as it works.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"model = Chain(Dense(1 => 8, relu), Dense(8 => 1))","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"The LuxDL/Lux.jl package uses explicit parameters, that are initialized (or obtained) with the Lux.setup function, giving us the parameters and the state of the model.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model","category":"page"},{"location":"generative/1d_FD_score_matching/#Explicit-score-matching-loss-function-J_{\\mathrm{ESM}}({\\boldsymbol{\\theta}})","page":"1D finite-difference score matching","title":"Explicit score matching loss function J_mathrmESM(boldsymboltheta)","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"For educational purposes, since we have the pdf and the score function, one of the ways we may train the model is directly with J_mathrmESM(boldsymboltheta). This is also useful to make sure that our network is able to model the desired score function.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Here is how we implement it.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"function loss_function_esm(model, ps, st, data)\n    x, y, target_pdf, sample_points = data\n    y_pred, st = Lux.apply(model, x, ps, st)\n    loss = mean(target_pdf .* (y_pred .- y) .^2)\n    return loss, st, ()\nend","category":"page"},{"location":"generative/1d_FD_score_matching/#Plain-square-error-loss-function","page":"1D finite-difference score matching","title":"Plain square error loss function","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Still for educational purposes, we modify J_mathrmESM(boldsymboltheta) for training, without weighting on the distribution of the random variable itself, as in J_mathrmESM(boldsymboltheta). This has the benefit of giving more weight to the transition region. Here is how we implement it.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"function loss_function_esm_plain(model, ps, st, data)\n    x, y, target_pdf, sample_points = data\n    y_pred, st = Lux.apply(model, x, ps, st)\n    loss = mean(abs2, y_pred .- y)\n    return loss, st, ()\nend","category":"page"},{"location":"generative/1d_FD_score_matching/#Finite-difference-score-matching-{\\tilde-J}_{\\mathrm{FDSM}}","page":"1D finite-difference score matching","title":"Finite-difference score matching tilde J_mathrmFDSM","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Again, for educational purposes, we may implement tilde J_mathrmFDSM(boldsymboltheta), as follows.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"function loss_function_FDSM(model, ps, st, data)\n    x, y, target_pdf, sample_points = data\n    xmin, xmax = extrema(x)\n    delta = (xmax - xmin) / 2length(x)\n    y_pred_fwd, = Lux.apply(model, x .+ delta, ps, st)\n    y_pred_bwd, = Lux.apply(model, x .- delta, ps, st)\n    y_pred = ( y_pred_bwd .+ y_pred_fwd ) ./ 2\n    dy_pred = (y_pred_fwd .- y_pred_bwd ) ./ 2delta\n    loss = mean(target_pdf .* (dy_pred + y_pred .^ 2 / 2))\n    return loss, st, ()\nend","category":"page"},{"location":"generative/1d_FD_score_matching/#Empirical-finite-difference-score-matching-loss-function-{\\tilde-J}_{\\mathrm{FDSM}{\\tilde-p}_0}","page":"1D finite-difference score matching","title":"Empirical finite-difference score matching loss function tilde J_mathrmFDSMtilde p_0","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"In practice we would use the sample data, not the supposedly unknown score function and PDF themselves. Here would be one implementation using finite differences, along with Monte-Carlo.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"function loss_function_FDSM_over_sample(model, ps, st, data)\n    x, y, target_pdf, sample_points = data\n    xmin, xmax = extrema(sample_points)\n    delta = (xmax - xmin) / 2length(sample_points)\n    y_pred_fwd, = Lux.apply(model, sample_points .+ delta, ps, st)\n    y_pred_bwd, = Lux.apply(model, sample_points .- delta, ps, st)\n    y_pred = ( y_pred_bwd .+ y_pred_fwd ) ./ 2\n    dy_pred = (y_pred_fwd .- y_pred_bwd ) ./ 2delta\n    loss = mean(dy_pred + y_pred .^ 2 / 2)\n    return loss, st, ()\nend","category":"page"},{"location":"generative/1d_FD_score_matching/#Optimization-setup","page":"1D finite-difference score matching","title":"Optimization setup","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/#Optimization-method","page":"1D finite-difference score matching","title":"Optimization method","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We use the classical Adam optimiser (see Kingma and Ba (2015)), which is a stochastic gradient-based optimization method.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"opt = Adam(0.03)\n\ntstate_org = Lux.Training.TrainState(model, ps, st, opt)","category":"page"},{"location":"generative/1d_FD_score_matching/#Automatic-differentiation-in-the-optimization","page":"1D finite-difference score matching","title":"Automatic differentiation in the optimization","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"As mentioned, we setup differentiation in LuxDL/Lux.jl with the FluxML/Zygote.jl library, which is currently the only one implemented (there are pre-defined methods for AutoForwardDiff(), AutoReverseDiff(), AutoFiniteDifferences(), etc., but not implemented yet).","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"vjp_rule = Lux.Training.AutoZygote()","category":"page"},{"location":"generative/1d_FD_score_matching/#Processor","page":"1D finite-difference score matching","title":"Processor","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We use the CPU instead of the GPU.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"dev_cpu = cpu_device()\n## dev_gpu = gpu_device()","category":"page"},{"location":"generative/1d_FD_score_matching/#Check-differentiation","page":"1D finite-difference score matching","title":"Check differentiation","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Check if Zygote via Lux is working fine to differentiate the loss functions for training.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Lux.Training.compute_gradients(vjp_rule, loss_function_esm, data, tstate_org)","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Lux.Training.compute_gradients(vjp_rule, loss_function_esm_plain, data, tstate_org)","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Lux.Training.compute_gradients(vjp_rule, loss_function_FDSM, data, tstate_org)","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Lux.Training.compute_gradients(vjp_rule, loss_function_FDSM_over_sample, data, tstate_org)","category":"page"},{"location":"generative/1d_FD_score_matching/#Training-loop","page":"1D finite-difference score matching","title":"Training loop","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Here is the typical main training loop suggest in the LuxDL/Lux.jl tutorials, but sligthly modified to save the history of losses per iteration.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"function train(tstate, vjp, data, loss_function, epochs, numshowepochs=20, numsavestates=0)\n    losses = zeros(epochs)\n    tstates = [(0, tstate)]\n    for epoch in 1:epochs\n        grads, loss, stats, tstate = Lux.Training.compute_gradients(vjp,\n            loss_function, data, tstate)\n        if ( epochs ≥ numshowepochs > 0 ) && rem(epoch, div(epochs, numshowepochs)) == 0\n            println(\"Epoch: $(epoch) || Loss: $(loss)\")\n        end\n        if ( epochs ≥ numsavestates > 0 ) && rem(epoch, div(epochs, numsavestates)) == 0\n            push!(tstates, (epoch, tstate))\n        end\n        losses[epoch] = loss\n        tstate = Lux.Training.apply_gradients(tstate, grads)\n    end\n    return tstate, losses, tstates\nend","category":"page"},{"location":"generative/1d_FD_score_matching/#Training","page":"1D finite-difference score matching","title":"Training","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/#Training-with-J_{\\mathrm{ESM}}({\\boldsymbol{\\theta}})","page":"1D finite-difference score matching","title":"Training with J_mathrmESM(boldsymboltheta)","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Now we attempt to train the model, starting with J_mathrmESM(boldsymboltheta).","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_esm, 500, 20, 125)\nnothing # hide","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Testing out the trained model.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"y_pred = Lux.apply(tstate.model, dev_cpu(x), tstate.parameters, tstate.states)[1]","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Visualizing the result.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(title=\"Fitting\", titlefont=10)\n\nplot!(x', y', linewidth=4, label=\"score function\")\n\nscatter!(sample_points', s -> gradlogpdf(target_prob, s), label=\"data\", markersize=2)\n\nplot!(x', y_pred', linewidth=2, label=\"predicted MLP\")","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Just for the fun of it, let us see an animation of the optimization process.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"gif(anim, fps = 20) # hide","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We also visualize the evolution of the losses.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false)","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"paux = exp.(accumulate(+, y_pred) .* dx)\npdf_pred = paux ./ sum(paux) ./ dx\nplot(title=\"Original PDF and PDF from predicted score function\", titlefont=10)\nplot!(x', target_pdf', label=\"original\")\nplot!(x', pdf_pred', label=\"recoverd\")","category":"page"},{"location":"generative/1d_FD_score_matching/#Training-with-plain-square-error-loss","page":"1D finite-difference score matching","title":"Training with plain square error loss","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Now we attempt to train it with the plain square error loss function. We do not reuse the state from the previous optimization. We start over at the initial state, for the sake of comparison of the different loss functions.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"@time tstate, losses, = train(tstate_org, vjp_rule, data, loss_function_esm_plain, 500)\nnothing # hide","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Testing out the trained model.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"y_pred = Lux.apply(tstate.model, dev_cpu(x), tstate.parameters, tstate.states)[1]","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Visualizing the result.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(title=\"Fitting\", titlefont=10)\n\nplot!(x', y', linewidth=4, label=\"score function\")\n\nscatter!(sample_points', s -> gradlogpdf(target_prob, s), label=\"data\", markersize=2)\n\nplot!(x', y_pred', linewidth=2, label=\"predicted MLP\")","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"And evolution of the losses.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false)","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"paux = exp.(accumulate(+, y_pred) * dx)\npdf_pred = paux ./ sum(paux) ./ dx\nplot(title=\"Original PDF and PDF from predicted score function\", titlefont=10)\nplot!(x', target_pdf', label=\"original\")\nplot!(x', pdf_pred', label=\"recoverd\")","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"That is an almost perfect matching.","category":"page"},{"location":"generative/1d_FD_score_matching/#Training-with-{\\tilde-J}_{\\mathrm{FDSM}}({\\boldsymbol{\\theta}})","page":"1D finite-difference score matching","title":"Training with tilde J_mathrmFDSM(boldsymboltheta)","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Now we attempt to train it with tilde J_mathrmFDSM. Again we start over with the untrained state of the model.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"@time tstate, losses, = train(tstate_org, vjp_rule, data, loss_function_FDSM, 500)\nnothing # hide","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"We may try a little longer from this state on.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"@time tstate, losses_more, = train(tstate, vjp_rule, data, loss_function_FDSM, 500)\nappend!(losses, losses_more)\nnothing # hide","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Testing out the trained model.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"y_pred = Lux.apply(tstate.model, dev_cpu(x), tstate.parameters, tstate.states)[1]","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Visualizing the result.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(title=\"Fitting\", titlefont=10)\n\nplot!(x', y', linewidth=4, label=\"score function\")\n\nscatter!(sample_points', s -> gradlogpdf(target_prob, s), label=\"data\", markersize=2)\n\nplot!(x', y_pred', linewidth=2, label=\"predicted MLP\")","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"And evolution of the losses.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false)","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"paux = exp.(accumulate(+, y_pred) * dx)\npdf_pred = paux ./ sum(paux) ./ dx\nplot(title=\"Original PDF and PDF from predicted score function\", titlefont=10)\nplot!(x', target_pdf', label=\"original\")\nplot!(x', pdf_pred', label=\"recoverd\")","category":"page"},{"location":"generative/1d_FD_score_matching/#Training-with-{\\tilde-J}_{\\mathrm{FDSM}{\\tilde-p}_0}({\\boldsymbol{\\theta}})","page":"1D finite-difference score matching","title":"Training with tilde J_mathrmFDSMtilde p_0(boldsymboltheta)","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Finally we attemp to train with the sample data. This is the real thing, without anything from the supposedly unknown target distribution other than the sample data.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_FDSM_over_sample, 500, 20, 125)\nnothing # hide","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Testing out the trained model.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"y_pred = Lux.apply(tstate.model, dev_cpu(x), tstate.parameters, tstate.states)[1]","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Visualizing the result.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(title=\"Fitting\", titlefont=10)\n\nplot!(x', y', linewidth=4, label=\"score function\")\n\nscatter!(sample_points', s -> gradlogpdf(target_prob, s), label=\"data\", markersize=2)\n\nplot!(x', y_pred', linewidth=2, label=\"predicted MLP\")","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Let us see an animation of the optimization process in this case, as well, since it is the one of interest.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"gif(anim, fps = 20) # hide","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Here is the evolution of the losses.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false)","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"paux = exp.(accumulate(+, y_pred) * dx)\npdf_pred = paux ./ sum(paux) ./ dx\nplot(title=\"Original PDF and PDF from predicted score function\", titlefont=10)\nplot!(x', target_pdf', label=\"original\")\nplot!(x', pdf_pred', label=\"recoverd\")","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"And the evolution of the PDF.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"gif(anim, fps = 10) # hide","category":"page"},{"location":"generative/1d_FD_score_matching/#Pre-training-{\\tilde-J}_{\\mathrm{FDSM}{\\tilde-p}_0}{\\tilde-J}_{\\mathrm{FDSM}{\\tilde-p}_0}({\\boldsymbol{\\theta}})-with-J_{\\mathrm{ESM}}({\\boldsymbol{\\theta}})","page":"1D finite-difference score matching","title":"Pre-training tilde J_mathrmFDSMtilde p_0tilde J_mathrmFDSMtilde p_0(boldsymboltheta) with J_mathrmESM(boldsymboltheta)","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Let us now pre-train the model with the J_mathrmESM(boldsymboltheta) and see if tilde J_mathrmFDSMtilde p_0(boldsymboltheta) improves.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"tstate, = train(tstate_org, vjp_rule, data, loss_function_esm, 500)\nnothing # hide","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"tstate, losses, = train(tstate, vjp_rule, data, loss_function_FDSM_over_sample, 500)\nnothing # hide","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Testing out the trained model.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"y_pred = Lux.apply(tstate.model, dev_cpu(x), tstate.parameters, tstate.states)[1]","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Visualizing the result.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(title=\"Fitting\", titlefont=10)\n\nplot!(x', y', linewidth=4, label=\"score function\")\n\nscatter!(sample_points', s -> gradlogpdf(target_prob, s), label=\"data\", markersize=2)\n\nplot!(x', y_pred', linewidth=2, label=\"predicted MLP\")","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"paux = exp.(accumulate(+, y_pred) * dx)\npdf_pred = paux ./ sum(paux) ./ dx\nplot(title=\"Original PDF and PDF from predicted score function\", titlefont=10)\nplot!(x', target_pdf', label=\"original\")\nplot!(x', pdf_pred', label=\"recoverd\")","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"And evolution of the losses.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false)","category":"page"},{"location":"generative/1d_FD_score_matching/#The-need-for-enough-sample-points","page":"1D finite-difference score matching","title":"The need for enough sample points","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"One interesting thing is that enough sample points in the low-probability transition region is required for a proper fit, as the following example with few samples illustrates.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"y = target_score # just to simplify the notation\nsample_points = permutedims(rand(rng, target_prob, 128))\ndata = (x, y, target_pdf, sample_points)","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"tstate, losses, = train(tstate_org, vjp_rule, data, loss_function_FDSM_over_sample, 500)\nnothing # hide","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Testing out the trained model.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"y_pred = Lux.apply(tstate.model, dev_cpu(x), tstate.parameters, tstate.states)[1]","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Visualizing the result.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(title=\"Fitting\", titlefont=10)\n\nplot!(x', y', linewidth=4, label=\"score function\")\n\nscatter!(sample_points', s -> gradlogpdf(target_prob, s)', label=\"data\", markersize=2)\n\nplot!(x', y_pred', linewidth=2, label=\"predicted MLP\")","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"paux = exp.(accumulate(+, y_pred) * dx)\npdf_pred = paux ./ sum(paux) ./ dx\nplot(title=\"Original PDF and PDF from predicted score function\", titlefont=10)\nplot!(x', target_pdf', label=\"original\")\nplot!(x', pdf_pred', label=\"recoverd\")","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"And evolution of the losses.","category":"page"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false)","category":"page"},{"location":"generative/1d_FD_score_matching/#References","page":"1D finite-difference score matching","title":"References","text":"","category":"section"},{"location":"generative/1d_FD_score_matching/","page":"1D finite-difference score matching","title":"1D finite-difference score matching","text":"Aapo Hyvärinen (2005), \"Estimation of non-normalized statistical models by score matching\", Journal of Machine Learning Research 6, 695-709\nT. Pang, K. Xu, C. Li, Y. Song, S. Ermon, J. Zhu (2020), Efficient Learning of Generative Models via Finite-Difference Score Matching, NeurIPS - see also the arxiv version\nEric J. Ma, A Pedagogical Introduction to Score Models, webpage, April 21, 2021 - with the associated github repo\nD. P. Kingma, J. Ba (2015), Adam: A Method for Stochastic Optimization, In International Conference on Learning Representations (ICLR) – see also the arxiv version\nY. Song and S. Ermon (2019), \"Generative modeling by estimating gradients of the data distribution\", NIPS'19: Proceedings of the 33rd International Conference on Neural Information Processing Systems, no. 1067, 11918-11930","category":"page"},{"location":"bayesian/bayes_inference/#Bayesian-inference","page":"Bayesian inference","title":"Bayesian inference","text":"","category":"section"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"In many situations, we expect some random variable to follow a given distribution but it is not certain what parameters actually define the distribution. For instance, we may have a coin that might be biased but we are unsure about how biased it is. Or we may expect some feature of a population to follow a normal distribution but it is not clear what are its mean and/or standard deviation. In those cases, it is useful to treat those parameters as random variables themselves, leading to what is known as a compound distribution.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"Then, given a certain feature and a model, we may attempt to fit the model to the available data, which is refereed to a statistical inference problem. We are particularly interested here in Bayesian inference, which amounts to using Bayes' formula in the inference process, by updating a prior knowledge of the distribution according to the evidence given by the data.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"In loose terms, suppose a compound distribution model has a parameter theta, and we initially believe in a certain prior distribution p(theta) for this parameter. We then observe some data, or evidence, E, and update our belief according to Bayes' formula,","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"    p(theta  E) = fracp(E  theta) p(theta)p(E)","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"After updating, the posterior p(theta  E) may indicate better the most likely values for the parameter theta.","category":"page"},{"location":"bayesian/bayes_inference/#Bayesian-inference-on-defect-item","page":"Bayesian inference","title":"Bayesian inference on defect item","text":"","category":"section"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"The Bayesian inference on defect item is an example of Bayesian inference. One wants to infer which die was picked by their friend, based on the results of throwing the die a few times. In this case, we have a compound distributions, starting with a categorial distribution with the three categories D_4, D_5, D_6, representing each type of die, with probabilities 14, 14, and 12, respectively, and then, for each category D_i, we have the probabilities p(jD_i) of obtaining each number j=1 ldots 6, with each die type D_i, i = 4 5 6.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"After a number of throws resulting in a sequence E = (3 1 4 5 1 5 2 5) of events, we want to know the posterior p(D_iE), revealing the most likely die picked in the beginning of the problem.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"The following animation illustrates the evolution of our belief on the picked die as the die is thrown, along the sequence of events E.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"gif(anim, fps = 0.5) # hide","category":"page"},{"location":"bayesian/bayes_inference/#A-biased-coin","page":"Bayesian inference","title":"A biased coin","text":"","category":"section"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"The previous example illustrates the case of a finite number of choices for the parameter, namely D_5, D_5, D_6. More often than not, the parameter belongs to a continuum, in either a finite- or infinite-dimensional space.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"Indeed, let's suppose we are told a coin is biased but we don't know its bias and don't even know whether it is biased towards heads or tails. We let X be the random variable with the result of tossing the coin, which follows a Bernoulli distribution with say probability theta of assuming the value 1, representing heads, and 1-theta of assuming the value 0, representing tails. Thus,","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"    X sim mathrmBernoulli(theta)","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"The bias theta may assume any value between 0 and 1, so we consider it as a random variable denoted Theta. We could assume an uninformative prior, with Theta uniformly distributed between 0 and 1, or an informative prior, assuming, more likely, just a slight bias, near 1/2. In the first case, we take Theta sim mathrmBeta(1 1) = mathrmUniform(0 1), while in the second case, we may assume Theta to be distributed like mathrmBeta(n m), with n m gg 1. In any case, we suppose","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"    Theta sim mathrmBeta(alpha beta)","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"for alpha beta  0. Recall the probability distribution function for Theta is","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"    f_Theta(theta) = f_Theta(theta alpha beta) = fracGamma(alpha + beta)Gamma(alpha)Gamma(beta)theta^alpha - 1(1 - theta)^beta - 1","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"where Gamma = Gamma(z) is the gamma function.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"Now, suppose we toss the coin a number of times and it lands heads k times and tails m times. So this is our evidence E. The random variable X is discrete, while Theta is continuous. The posterior becomes","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"    f_Theta(theta  E) = fracp(E  theta) f_Theta(theta)p(E)","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"Since E is heads k times and tails m times, we have p(E  theta) propto theta^k (1 - theta)^m. Computing p(E) is usually not a trivial task but in this case can be computed via","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"    beginalign*\n        p(E)  = int_0^1 p(Etheta)f_Theta(theta)mathrmdtheta = left(beginmatrix k + m  k endmatrix right)fracGamma(alpha + beta)Gamma(alpha)Gamma(beta)int_0^1 theta^k (1 - theta)^m theta^alpha -1(1-theta)^beta - 1 mathrmdtheta \n         = left(beginmatrix k + m  k endmatrix right)fracGamma(alpha + beta)Gamma(alpha)Gamma(beta)fracGamma(alpha + k)Gamma(beta + m)Gamma(alpha + k + beta + m)\n    endalign*","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"But we do not need to compute it in this case. Indeed, up to a constant, we have","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"    p(theta  E) propto theta^k (1 - theta)^m theta^alpha - 1(1 - theta)^beta - 1 = theta^k + alpha - 1(1 - theta)^m + beta - 1 sim mathrmBeta(alpha + k beta + m)","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"Hence, updating the prior in this case simply amounts to adding the number of heads and the number of tails to the parameters of the beta distribution.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"As more and more coins are tossed, we get the expected value of the posterior converging to the actual bias of the coin, with the credible interval narrowing down the uncertainty.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"The code below (adapted from Introduction to Turing) exemplifies the increased belief we get with more and more data collected.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"We first generate the data drawing from a Bernoulli distribution using the true bias.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"using Distributions, StatsPlots\nusing Random # hide\nRandom.seed!(321) # set the seed for reproducibility # hide\n\np_true = 0.6\nN = 2_000\ndata = rand(Bernoulli(p_true), N)\nnothing # hide","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"Next we define an uniformative prior and create a function to update the prior with a given set of data.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"prior = Beta(1, 1)\n\nfunction update_prior(prior::Beta, data::AbstractVector{Bool})\n    heads = sum(data)\n    tails = length(data) - heads\n\n    posterior = Beta(prior.α + heads, prior.β + tails)\n    return posterior\nend\nnothing # hide","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"Now we visualize the effect of the size of the data on the posterior.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"plt = []\n\nfor n in (0, 10, 100, N)\n    push!(\n        plt,\n        plot(\n            update_prior(prior, view(data, 1:n)),\n            title = n == 0 ? \"Uninformative prior\" : \"Posterior with $n observations\",\n            titlefont = 10, # hide\n            legend=nothing, # hide\n            xlim=(0, 1), # hide\n            fill=0, # hide\n            α=0.3, # hide\n            w=3, # hide\n        )\n    )\nend\n\nplot(plt..., size=(700, 400)) # hide","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"To complement that, we show two animations with the posterior being updated as more data is used.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"gif(anim, fps = 1) # hide","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"gif(anim, fps = 24) # hide","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"Here is a static view of the evolution of the posterior mean and 95% credible interval.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"posterior_means = [mean(update_prior(prior, data[1:n])) for n in 0:N] # hide\nposterior_quantiles = [[quantile(update_prior(prior, data[1:n]), 0.025) for n in 0:N] [quantile(update_prior(prior, data[1:n]), 0.975) for n in 0:N]] # hide\n\nplt = plot(title = \"Evolution of the posterior mean and credible interval\", titlefont=10, xaxis=\"number of observations\", yaxis=\"p\") # hide\nplot!(plt, posterior_quantiles[:,1], fillrange=posterior_quantiles[:,2], alpha=0.0, fillalpha=0.3, label=\"95% credible interval\", color=1) # hide\nhline!(plt, [p_true], label=\"true p = $p_true\", color=2) # hide\nplot!(plt, posterior_means, label=\"posterior mean\", color=1) # hide","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"For the sake of comparison, here is the evolution of the sample mean and the associated 95% confidence intervals, according to the frequentist approach.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"sample_means = [mean(data[1:n]) for n in 2:N] # hide\nstd_error = [sqrt(var(data[1:n])/n) for n in 2:N] # hide\n\nplot(title = \"Evolution of the sample mean and confidence interval\", titlefont=10, xaxis=\"number of observations\", yaxis=\"p\") # hide\nplot!(sample_means, ribbon = 2*std_error, fillalpha=0.3, label=\"sample mean\") # hide\nhline!([p_true], label=\"true p = $p_true\") # hide","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"The data above has been seeded for reproducibility reasons. For the sake of illustration, here is another set of data, where the 95% intervals fall sometimes a little bit short.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"Random.seed!(123) # set the seed for reproducibility # hide\ndata = rand(Bernoulli(p_true), N) # hide\n\nposterior_means = [mean(update_prior(prior, data[1:n])) for n in 0:N] # hide\nposterior_quantiles = [[quantile(update_prior(prior, data[1:n]), 0.025) for n in 0:N] [quantile(update_prior(prior, data[1:n]), 0.975) for n in 0:N]] # hide\n\nplot(title = \"Evolution of the posterior mean and credible interval\", titlefont=10, xaxis=\"number of observations\", yaxis=\"p\") # hide\nplot!(posterior_quantiles[:,1], fillrange=posterior_quantiles[:,2], alpha=0.0, fillalpha=0.3, label=\"95% credible interval\", color=1) # hide\nhline!([p_true], label=\"true p = $p_true\", color=2) # hide\nplot!(posterior_means, label=\"posterior mean\", color=1) # hide","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"sample_means = [mean(data[1:n]) for n in 2:N] # hide\nstd_error = [sqrt(var(data[1:n])/n) for n in 2:N] # hide\n\nplot(title = \"Evolution of the sample mean and confidence interval\", titlefont=10, xaxis=\"number of observations\", yaxis=\"p\") # hide\nplot!(sample_means, ribbon = 2*std_error, fillalpha=0.3, label=\"sample mean\") # hide\nhline!([p_true], label=\"true p = $p_true\") # hide","category":"page"},{"location":"bayesian/bayes_inference/#Conjugate-distributions","page":"Bayesian inference","title":"Conjugate distributions","text":"","category":"section"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"This property that multipling a Bernoulli distribution by a Beta prior yields a Beta posterior is an example of conjugate distributions. Conjugate distributions greatly facilitate the updating process in Bayesian statistics. There are a number of other conjugate prior distributions, as can be seen on this table of conjugate distributions.","category":"page"},{"location":"bayesian/bayes_inference/","page":"Bayesian inference","title":"Bayesian inference","text":"But, in general, without conjugate distributions, common in \"real-world\" problems, updating a prior is a much harder process and requires some fancy computational techniques.","category":"page"},{"location":"generative/overview/#Overview-of-the-main-results-pertaining-to-score-based-generative-methods","page":"Overview","title":"Overview of the main results pertaining to score-based generative methods","text":"","category":"section"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"Here we review the main results associated with score-based generative methods.","category":"page"},{"location":"generative/overview/#Main-results","page":"Overview","title":"Main results","text":"","category":"section"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"The Langevin equation dates back to the beginning of the 20th Century, as proposed by Langevin (1908), in relation to the Brownian motion.","category":"page"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"The use of the Langevin equation (and especially of the overdamped Langevin equation) to draw samples of a known distribution from its score function was proposed by Roberts and Tweedie (1996). Rates of convergence were also given and are still an important area of research.","category":"page"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"The idea of fitting a distribution via the score function was then proposed by Hyvärinen (2005), via implicit score matching. The implicit score matching is obtained via integration by parts on the explicit score matching objective, which requires the unknown target score function. The implicit score objective function eliminates the unknown score of the target distribution, but requires computing the divergence of the score of the model pdf, which means the trace of the hessian of the model pdf. This works fine for some specific models for which the derivatives can be readily computed, as considered by Hyvärinen (2005) (and subsequently by Köster and Hyvärinen (2010)), but which otherwise might be computationally intensive.","category":"page"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"Kingma and LeCun (2010) used an energy based framework to write the pdf in terms of the exponential of an energy function, modeled as a neural network, and used automatic differentiation to compute the hessian of the log of the pdf via the hessian of the energy function. In doing so, they also proposed a regularized implicit score matching objective, by adding a penalization in terms of the hessian, for stability purposes. This penalization does not add much to the complexity of the method, but the underlying method is already computationally demanding since it is based on the implicit score matching and needs the gradient of the score function. This computational cost also increases dramatically with the dimension of the problem.","category":"page"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"Vincent (2011) proposed the denoising score matching method, by working with the explicit score matching and using Parzen kernel density estimation to approximate the gradient of the desired score function, avoiding the need to differentiate the score of the model pdf. One can directly compute the score of the Parzen estimation, which involves computing the logarithm of a sum of kernels, and this can be computed explicitly beforehand, so the optimization process is relatively straightforward. Pascal went further, though, writing the objective function as a double integral with a conditional distribution, so the score that needs to be computed is that of a single kernel, simplifying the computation. This is also interpreted in connection with the denoising auto-encoder methods, where one uses the original sample and a corrupted sample, associated with the conditional distribution over a single kernel of the Parzen estimation. The double integral is not a burden in computations since it turns out a single corrupted sample for each clean sample is sufficient, rendering it effectively as a single integral, which becomes a simple sum over the sample data.","category":"page"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"Song, Garg, Shi, and Ermon (2020) addressed again the implicit score matching approach and proposed a sliced (implicit) score matching method to reduce the computational cost of the implicit score matching for high-dimensional problems. The trick is to take derivatives only at certain random directions, at each sample point.","category":"page"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"A few months later, Pang, Xu, Li, Song, Ermon, and Zhu (2020) proposed the finite-difference (implicit) score matching method, using finite differences to approximate whatever derivatives appear in the loss function. The authors suggest using finite-differences not only for implicit score matching, but also sliced score matching, denoising score matching, sliced score matching with variance reduction, and so on. The use of finite-differences greatly reduces the computational cost of the optimization process.","category":"page"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"A few years earlier, Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015) introduced denoising diffusion probabilistic models (DDPM), which was further improved in Ho, Jain, and Abbeel (2020). The idea is to embed the target distribution into a Markov chain and model the reverse process of the Markov chain. The Markov chain gradually adds noise to the process and drives it to a tractable noisy distribution. The model then starts from the tractable distribution and reverts back to an approximation of the target distribution. In other words, the model denoises a noisy sample towards a sample of the desired distribution. This is a much more complex task which greatly increases the dimension of the problem, but which yields more stability to both training and generative processes. The original work of Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015) had a more complex model and an expensive loss function. Ho, Jain, and Abbeel (2020) simplified the model and the loss function, turning it into a practical and efficient model. Further on, Nichol and Dhariwal (2021) showed improvements with a nonlinear variance schedule for the forward process and a partial training of the variance of the model reverse process. It is worth mentioning that, in principle, this is a maximum likelihood estimation, not a score matching, but it turns out that the actual term modeled in the reverse Markov chain is somewhat a discretized approximation of the score function.","category":"page"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"Song and Ermon (2019) finally proposed modeling directly the score function as a neural network (instead of the pdf or the energy potential) and proposed a noise conditional score network (NSCN) model, with a sequence of perturbations of the data with different noise levels, similar to denoising score matching, and a cooresponding denoising scheme based on annealed Langevin dynamics.","category":"page"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"In a subsequent work, Song, Meng, Ermon (2021) improved the DDPM model and introduced denoising diffusion implicit models (DDIM), which is based on non-Markovian processes but amounts to the same training strategy and model. The advantage, then, is that sampling is greatly expedited with a non-Markovian reverse process that can sample directly from the tractable distribution. We do not detail this method here, though.","category":"page"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"Then came Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020), with the score-based denoising diffusion SDE models, unifying the ideas of DDPM and NCSN methods, in a time-continuum model, adding noise to the data via a stochastic differential equation (SDE), with a corresponding reverse SDE.","category":"page"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"Finally, we have the paper from the NVIDIA team, Karras, Aittala, Aila, Laine (2022) with the aim of \"elucidating the design space of diffusion-based generative models\", as the title says.","category":"page"},{"location":"generative/overview/#References","page":"Overview","title":"References","text":"","category":"section"},{"location":"generative/overview/","page":"Overview","title":"Overview","text":"P. Langevin (1908), \"Sur la théorie du mouvement brownien [On the Theory of Brownian Motion]\". C. R. Acad. Sci. Paris. 146: 530–533\nG. O. Roberts, R. L. Tweedie (1996), \"Exponential Convergence of Langevin Distributions and Their Discrete Approximations\", Bernoulli, Vol. 2, No. 4, 341-363, doi:10.2307/3318418\nAapo Hyvärinen (2005), \"Estimation of non-normalized statistical models by score matching\", Journal of Machine Learning Research 6, 695-709\nU. Köster, A. Hyvärinen (2010), \"A two-layer model of natural stimuli estimated with score matching\", Neural. Comput. 22 (no. 9), 2308-33, doi: 10.1162/NECOa00010\nDurk P. Kingma, Yann Cun (2010), \"Regularized estimation of image statistics by Score Matching\", Advances in Neural Information Processing Systems 23 (NIPS 2010)\nPascal Vincent (2011), \"A connection between score matching and denoising autoencoders,\" Neural Computation, 23 (7), 1661-1674, doi:10.1162/NECOa00142\nY. Song, S. Garg, J. Shi, S. Ermon (2020), Sliced Score Matching: A Scalable Approach to Density and Score Estimation, Proceedings of The 35th Uncertainty in Artificial Intelligence Conference, PMLR 115:574-584 – see also the arxiv version\nT. Pang, K. Xu, C. Li, Y. Song, S. Ermon, J. Zhu (2020), Efficient Learning of Generative Models via Finite-Difference Score Matching, NeurIPS - see also the arxiv version\nJ. Sohl-Dickstein, E. A. Weiss, N. Maheswaranathan, S. Ganguli (2015), \"Deep unsupervised learning using nonequilibrium thermodynamics\", ICML'15: Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, 2256-2265\nY. Song and S. Ermon (2019), \"Generative modeling by estimating gradients of the data distribution\", NIPS'19: Proceedings of the 33rd International Conference on Neural Information Processing Systems, no. 1067, 11918-11930\nJ. Ho, A. Jain, P. Abbeel (2020), \"Denoising diffusion probabilistic models\", in Advances in Neural Information Processing Systems 33, NeurIPS2020\nA. Q. Nichol and P. Dhariwal (2021), \"Improved denoising diffusion probabilistic models\", ICLR 2021 Conference\nJ. Song, C. Meng, S. Ermon (2021), \"Denoising diffusion implicit models\", ICLR 2021 Conference\nY. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, B. Poole (2020), \"Score-based generative modeling through stochastic differential equations\", arXiv:2011.13456\nT. Karras, M. Aittala, T. Aila, S. Laine (2022), Elucidating the design space of diffusion-based generative models, Advances in Neural Information Processing Systems 35 (NeurIPS 2022)","category":"page"},{"location":"bayesian/bayes/#Bayes-theorem-and-applications","page":"Bayes Theorem","title":"Bayes theorem and applications","text":"","category":"section"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"In this section, we state Bayes' theorem and discuss some of its applications.","category":"page"},{"location":"bayesian/bayes/#Bayes'-Theorem","page":"Bayes Theorem","title":"Bayes' Theorem","text":"","category":"section"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Bayes' Theorem concerns the probability of a given event, conditioned to another event, and can be stated as follows.","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"note: Bayes' Theorem\nLet p be a probability distribution on a given sample space and let A and B be two events with p(B)  0. Then    p(AB) = fracp(BA)p(A)p(B)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"In other words, Bayes' Theorem says that the posterior conditional probability p(AB) of an event A, given the occurrence of another event B, equals the likelihood p(BA) of the second event B given the first event A times the prior p(A) divided by the marginal p(B). The prior here refers to the probability p(A) of A before observing the event B, while the posterior p(AB) refers to the probability of A after the observation of the event B.","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Bayes' theorem has many useful consequences (see e.g. ), but first let us sketch its proof.","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Proof of Bayes's Theorem.When P(A) = 0, then P(AB) = 0 and the result is trivial. When p(A)  0, the result can be obtained from the conditional probability relations    p(AB) = fracp(Acap B)p(B) qquad p(BA) = fracp(Bcap A)p(A)which imply    p(AB)p(B) = p(Acap B) = p(Bcap A) = p(BA)p(A)Solving for p(AB) yields the desired result. ■","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Very often, we are not given p(B) directly, but we can use the law of total probability to find p(B), according to a decomposition of the sample space Omega, such as Omega = A cup neg A, where neg A = Omega setminus A denotes the event complementary to A. This law has two forms, one in terms of joint probabilities and one in terms of conditional probabilities:","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    beginalign*\n        p(B)  = p(Bcap A) + p(B cap neg A) \n             = p(BA)p(A) + p(Bneg A)p(neg A)\n    endalign*","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"This law also applies to decompositions of the sample space in terms of several disjoint events, i.e. Omega = cup_i A_i, with disjoint p(A_i cap A_j) = 0, for ineq j.","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Using this decomposition, we can write the Bayes' formula as","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"note: Extended version of Bayes' formula\nLet p be a probability distribution on a given sample space and let A and B be two events with p(B)  0. Then    p(AB) = fracp(BA)p(A)p(BA)p(A) + p(Bneg A)p(neg A)","category":"page"},{"location":"bayesian/bayes/#Screening-test","page":"Bayes Theorem","title":"Screening test","text":"","category":"section"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"There are many applications of Bayes' Theorem in Biomedicine. Let's say, for example, a certain test for a given endemic disease (or illegal drug use, etc.) has a 4% chance of false negative and 0.1% chance of false positive, and suppose that the disease occurs in 1% of the population.","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"If a certain person tests positive, what are their chances of really carrying the disease? This means we want to know the conditional probability of having the disease, given that it tested positive. Let's use the following notation for the relevant events:","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"D denotes the event of having the disease;\nneg D denotes the event of not having the disease;\nP denotes the event of testing positive;\nN denotes the event of testing negative.","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"The chances of a person who tested positive to have the disease can be expressed as the conditional probability p(DP). Using Bayes' theorem, this can be expressed as","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(DP) = fracp(PD)p(D)p(P)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"According to the given information, the probability p(PD) of testing positive while having the disease is 96%, since the false negatives p(ND) amount to 4%. The probability p(D) of having the disease among the general population is 1%. Finally, the probability of testing positive can be obtained from the law of total probability:","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(P) = p(PD)p(D) + p(Pneg D)p(neg D) = 96 times 1 + 01 times 99 = 1059","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Thus, according to Bayes' Theorem,","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(DP) = fracp(PD)p(D)p(P) = frac96 times 11059 approx 906","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Hence, the chances a person who tested positive has indeed this disease are of about 90%, which is reasonably high.","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"If, however, the false negatives were of the order of 5% and the false positives were of the order of 1%, then the chances p(DP) of a person who tested positive to indeed have the disease would be only of the order of 49%! Pretty low, right? Not quite reliable. PSA tests are one example where this conditional probability is low, of the order of 25%.","category":"page"},{"location":"bayesian/bayes/#Bayesian-inference-on-defect-item","page":"Bayes Theorem","title":"Bayesian inference on defect item","text":"","category":"section"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Suppose we have a collection of four six-faced dice, with two normal ones with faces numbered one to six, but one with two faces numbered five and none numbered six and one with three faces numbered four and none numbered five nor six. Let's call them dice types D_6, D_5 and D_4, respectively. A friend picks one of the dice at random and throws it repeatedly to find the numbers 3, 1, 4, 5, 1, 5, 2, 5, reading them aloud. What is the most likely type of die your friend picked?","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Your prior is that a normal die is selected with probability 1/2,","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(D_6) = frac12","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"while the other two, with probability 1/4:","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(D_5) = p(D_4) = frac14","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Now, after learning about the evidence E = (3 1 4 5 1 5 2 5) of the numbers thrown by your friend, you update your prior with this evidence to find the posteriors","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(D_i  E) = fracp(ED_i)p(D_i)p(E)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"For each die, the likelyhood p(ED_i) is","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(ED_i) = p(3D_i)p(1D_i)p(4D_i)p(5D_i)p(1D_i)p(5D_i)p(2D_i)p(5D_i)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Since p(5D_4) = 0, p(5D_5) = 13 and all remaining odds are 16, we find","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    beginalign*\n        p(ED_4)  = 0 \n        p(ED_5)  = left(frac16right)^5left(frac13right)^3 = 8 left(frac16right)^8 \n        p(ED_6)  = left(frac16right)^8\n    endalign*","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"The probability of seeing this evidence is given by the law of total probability","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(E) = p(ED_4)p(D_4) + p(ED_5)p(D_5) + p(ED_6)p(D_6) = 0 times frac14 + 8 left(frac16right)^8frac14 + left(frac16right)^8frac12","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Hence,","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(E) = frac52 left(frac16right)^8","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Therefore, the posteriors are","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    beginalign*\n        p(D_4E)  = 0 \n        p(D_5E)  = frac8 times 1452 = 45 \n        p(D_6E)  = frac1 times 1252 = 15\n    endalign*","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Therefore, it is four times more likely that your friend picked the defective D_5-type die than the normal die, and, of course, the D_4-type die was surely not picked.","category":"page"},{"location":"bayesian/bayes/#Monty-Hall-problem","page":"Bayes Theorem","title":"Monty Hall problem","text":"","category":"section"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"The Monty Hall problem is a classic probability puzzle. In a television show, a contender has to choose between three doors, with only one of them giving you a reward. You choose one at random and you have 1/3 chance of choosing the right one. But after you choose this one, the host of the show reveals one of the doors which do not have any reward and asks if you want to choose a different door or keep the same. It turns out that if you switch to the remaining door, your chances rise to 2/3.","category":"page"},{"location":"bayesian/bayes/#Solution-via-probability-tree","page":"Bayes Theorem","title":"Solution via probability tree","text":"","category":"section"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"At first, you have 1/3 chance of choosing the right one and 2/3 chances of choosing a door without the reward. If you choose the right door and changes it after the host reveals an empty door, then you necessarily change to an empty door. This with a 1/3 chance. If you choose a door without reward and changes it after the host reveals an empty door, then you necessarily change it to the right door. This with a 2/3 chance. Hence, you have a 2/3 chance of success!","category":"page"},{"location":"bayesian/bayes/#Solving-it-via-the-law-of-total-probability","page":"Bayes Theorem","title":"Solving it via the law of total probability","text":"","category":"section"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Let us do this more formally. Suppose R denotes the door with the reward. Let X be the random variable denoting the player's choice. With a single choice, p(X=R) = 13.","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Now suppose we make two choices, denoted by the random variables X_1 and X_2. In the first strategy, that the player doesn't change his choice, we have X_2 = X_1. In this case, we work with a probability conditioned to X_2 = X_1, and we simplify the notation to p_1(E) = p(EX_2 = X_1), for any possible event E. Then, by the law of total probability,","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p_1(X_2 = R) = p_1(X_2 = RX_1 = R)p_1(X_1 = R) + p_1(X_2 = RX_1 neq R)p_1(X_1 neq R)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"If the player doesn't change his choice, then p_1(X_2 = RX_1 = R) = 1 and p_1(X_1 = R) = 13, while p_1(X_2 = RX_1 neq R) = 0, so that p(X_2 = RX_2 = X_1) = p_1(X_2 = R) = 13.","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Now, if the player changes his choice, then we work with the probability p_2(E) = p(EX_2 neq X_1). In this case, p_2(X_2 = RX_1 = R) = 0, while p_2(X_2 = RX_1 neq R) = 1 and p_2(X_1 neq R) = 23, so that p_2(X_2 = R) = 23.","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"In this derivation, we did not make explicit the dependence on the choice of the host. We leave this as an exercise.","category":"page"},{"location":"bayesian/bayes/#Solving-it-via-Bayes'-rule","page":"Bayes Theorem","title":"Solving it via Bayes' rule","text":"","category":"section"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Suppose now you first pick door X_1, then the host picks door H, and next you choose door X_2. This means we have a random vector (X_1 H X_2) in a sample space with cardinality 27, meaning each choice can be any of the three doors. We are interested in the chances that X_2 is the door with the car, given that all chosen doors are different and that the host does not choose the door with the car. This corresponds to the strategy that the player changes the door. This can be written as the following conditional probability, where R denotes the \"right\" door, with the car:","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(X_2 = R  X_2 notin X_1 H H neq R H neq X_1)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Well, the condition of the show is that the host picks a different door than the first one chosen by the player, that that door is not the right one, and that the second door picked by the player is not the door chosen by the host. Under this rule, the player is free to stick we the first door, i.e. X_2 = X_1, or choose a different one, i.e. X_2 neq X_1. In order to simplify the notation, we write the probability conditioned to the rules of the game as","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    tilde p(E) = p(E  X_2 neq H H neq X_1 H neq R)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"for any possible event E. Using Bayes' rule,","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    tilde p(X_2 = R  X_2 neq X_1) = fractilde p(X_2 neq X_1  X_2 = R)tilde p(X_2 = R)tilde p(X_2 neq X_1)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Under the rules of the game,","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    beginalign*\n        tilde p(X_2 neq X_1  X_2 = R)  = 23 \n        tilde p(X_2 = R)  = 12 \n        tilde p(X_2 neq X_1)  = 12\n    endalign*","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Hence,","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    tilde p(X_2 = R  X_2 neq X_1) = frac23 times 1212 = frac23","category":"page"},{"location":"bayesian/bayes/#Solving-it-via-Bayes'-rule-by-updating-the-prior","page":"Bayes Theorem","title":"Solving it via Bayes' rule by updating the prior","text":"","category":"section"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"We can also use the classic interpretation of Bayes' rule as updating a prior distribution describing your chances of winning, according to new evidence revealed by the host. We'll do this in two ways, the first one, as it is usually presented, of updating the prior of having chosen correctly the first door X_1, and in a more natural way, of updating the prior of choosing correctly the last door opened X_2.","category":"page"},{"location":"bayesian/bayes/#Updating-the-prior-for-X_1-R","page":"Bayes Theorem","title":"Updating the prior for X_1 = R","text":"","category":"section"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"In this case, the player has, initially, one-third chance of choosing the right door:","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(X_1 = R) = frac13","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"This is the player's prior. After that, the host reveals a door, showing it does not have a car, which we state as H neq R. Now we want to update our prior to have a posterior probability","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(X_1 = R  H neq R)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"According to Bayes' rule,","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(X_1 = R  H neq R) = fracp(H neq R  X_1 = R) p(X_1 = R)p(H neq R)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Well, the host always picks the door without the car, so both p(H neq R  X_1 = R) and p(H neq R) are equal to 1. Meanwhile, your prior is p(X_1 = R) = 13. Thus,","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(X_1 = R  H neq R) = frac1 times 131 = frac13","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"This means your chances of having chosen the right door at first do not change after the evidence. On the other hand, after the host reveals their choice of door, you only have two alternatives: stick with X_1 or change to the only remaining door. This means","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(X_1 = R  H neq R) + p(X_1 neq R  H neq R) = 1","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"i.e.","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(X_1 neq R  H neq R) = 1 - frac13 = frac23","category":"page"},{"location":"bayesian/bayes/#Updating-the-prior-for-X_2-R.","page":"Bayes Theorem","title":"Updating the prior for X_2 = R.","text":"","category":"section"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"A different way of solving this is to update directly the prior probability of selecting the right door X_2 = R, when switching your choice. Without the host opening a door, your chances are still one-third. This conditioned to the rules of the game, H neq X_1, H neq R, and of the strategy X_2 neq X_1. In this case, despite the fact that the host chooses the door without the car, the prior does not use this knowledge and the player does not know which door was chosen by the host and, at first, can choose either one of the remaining two, with still a one-third chance of getting it right:","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    p(X_2 = R  X_2 neq X_1 H neq X_1 H neq R) = frac13","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"As before, in order to simplify the notation, we consider the probability conditioned to the rules of the game and the strategy but without including yet X_2 neq H since we will start with a prior that lacks this knowledge. Hence, we consider the conditional probability","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    tilde p(E) = p(E  X_2 neq X_1 H neq X_1 H neq R)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Thus, the prior reads","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    tilde p(X_2 = R) = frac13","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"Now, once the door H is revealed, you choose X_2 neq H upon this new evidence. Hence, by Bayes' theorem,","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    tilde p(X_2 = R  X_2 neq H) = fractilde p(X_2 neq H  X_2 = R) tilde p(X_2 = R)tilde p(X_2 neq H)","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"The likelihood tilde p(X_2 neq H  X_2 = R) = 1 because surely X_2neq H when conditioned to X_2 = R and H neq R. The marginal tilde p(X_2 neq H) = 12 because when conditioned to X_2 neq X_1 and H neq X_1, there are two doors left for X_2, one equals to H and the other different than H, hence one out of two possibilities of X_2 neq H. Therefore,","category":"page"},{"location":"bayesian/bayes/","page":"Bayes Theorem","title":"Bayes Theorem","text":"    tilde p(X_2 = R  X_2 neq H) = frac1 times 1312 = frac23","category":"page"},{"location":"bayesian/tilapia_alometry/#Alometry-law-for-the-Nile-Tilapia","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"","category":"section"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"(Image: nile tilapia)","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"(image from Fishsource)","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"We use the alometry law y = A x^B to correlate the length x of the fish tilapia with its mass y. The following table for the length-weight relationship of growing-finishing cage-farmed Nile tilapia (Oreocromis niloticus)is provided in the article T. S. de Castro Silva, L. D. dos Santos, L. C. R. da Silva, M. Michelato, V. R. B. Furuya, W. M. Furuya, Length-weight relationship and prediction equations of body composition for growing-finishing cage-farmed Nile tilapia, R. Bras. Zootec. vol.44 no.4 Viçosa Apr. 2015):","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"Days of culture 1 20 40 60 80 100\nMass (g) 28.6 ± 4.2 88.6 ± 1.4 177.6 ± 3.6 313.8 ± 12.8 423.7 ± 12.7 774.4 ± 23.6\nLength (cm) 10.9±0.4 15.3±0.4 19.1±0.2 22.8±0.5 26.3±0.6 31.3±0.4","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"We use Turing.jl with the compound model","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"    beginalign*\n        A  sim mathrmInverseGamma(alpha_A beta_A) \n        B  sim mathrmInverseGamma(alpha_B beta_B) \n        sigma^2  sim mathrmInverseGamma(2 1) \n        y  sim mathrmNormal(A x^B sigma^2)\n    endalign*","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"with suitable hyperparameters (alpha_A beta_A) and (alpha_B beta_B) to be chosen shortly.","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"We start by loading the necessary packages:","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"using Distributions, Turing, StatsPlots","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"Then we collect the adimensionalized data in vector form and plot it for the fun of it:","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"xx = [10.9, 15.3, 19.1, 22.8, 26.3, 31.3]\nyy = [28.6, 88.6, 177.6, 313.8, 423.7, 774.4]\n\nscatter(xx, yy, xlabel=\"Body length (cm)\", ylabel=\"Body weight (g)\", xlims=(0.0, 35.0), ylims=(0.0, 1000.0), title=\"Length-weight relationship of growing-finishing cage-farmed Nile tilapia\", titlefont=10, legend=nothing)","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"We define the Turing.jl model with parameters A and B as Inverse Gamma functions with hyperparameters Ah = (Ah.α, Ah.β) and Bh=(Bh.α, Bh.β).","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"@model function alometry(x, q; Ah, Bh)\n    A ~ InverseGamma(Ah.α, Ah.β)\n    B ~ InverseGamma(Bh.α, Bh.β)\n    σ² ~ InverseGamma(2, 1)\n    σ = sqrt(σ²)\n\n    for i in eachindex(x)\n        y = A * x[i] ^ B\n        q[i] ~ Normal(y, σ)\n    end\nend","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"As in any nonlinear optimization problem, the starting point is crucial. Here, the starting point is our prior. The following prior does not work properly, as we can see.","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"model = alometry(xx, yy; Ah=(α=1,β=1), Bh=(α=1,β=1))\nchain = sample(model, NUTS(0.65), 1_000)","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"plt = scatter(xx, yy, xlabel=\"Body length (cm)\", ylabel=\"Body weight (g)\", xlims=(0.0, 35.0), ylims=(0.0, 1000.0), title=\"Length-weight relationship of growing-finishing cage-farmed Nile tilapia\", titlefont=10, legend=nothing)\nxxx = range(0.9*first(xx), 1.1*last(xx), length=200)\nyyy = mean(chain, :A) * xxx .^ mean(chain, :B)\nplot!(plt, xxx, yyy)","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"If we start with a more informative prior, we get a suitable result. If we pick two data points (x_1 y_1) and (x_2 y_2), assuming y approx Ax^B, we have y_2y_1 = (x_2x_1)^B, so that","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"    B = fracln(y_2y_1)ln(x_2x_1)","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"If we choose the second and third points, we get","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"    B = log(yy[3]/yy[2])/log(xx[3]/xx[2])","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"From that, we can also estimate A from A = yx^B, so that, choosing the second point","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"    A = yy[2]/xx[2]^B","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"With that in mind, we choose the hyperparameters for the prior as (alpha_A beta_A) = (57 1), with mean 1(57+1) approx 0017, and (alpha_B beta_B) = (1 6), with mean 6(1+1) = 30.","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"model = alometry(xx, yy; Ah=(α=57,β=1), Bh=(α=1,β=6))","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"With this prior, we attempt again to fit the model.","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"# chain = sample(model, HMC(0.05, 10), 4_000) # HMC seems quite unstable here\nchain = sample(model, NUTS(0.65), MCMCSerial(), 1000, 3; progress=false)","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"Here is the result of the chain.","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"plot(chain)","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"Taking the mean of the parameters A and B we plot the fitted curve.","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"plt = scatter(xx, yy, xlabel=\"Body length (cm)\", ylabel=\"Body weight (g)\", xlims=(0.0, 35.0), ylims=(0.0, 1000.0), title=\"Length-weight relationship of growing-finishing cage-farmed Nile tilapia\", titlefont=10, legend=nothing)\nxxx = range(0.9*first(xx), 1.1*last(xx), length=200)\nyyy = mean(chain, :A) * xxx .^ mean(chain, :B)\nplot!(plt, xxx, yyy)","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"This seems successful. Now we compute the 95% credible interval","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"quantiles = reduce(\n    hcat,\n    quantile(\n        [\n            A * x^B for (A, B) in eachrow(view(chain.value.data, :, 1:2, 1))\n        ],\n        [0.025, 0.975]\n        )\n    for x in xxx\n)","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"and plot it along the data:","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"plt = plot(xlabel=\"Body length (cm)\", ylabel=\"Body weight (g)\", xlims=(0.0, 35.0), ylims=(0.0, 1000.0), title=\"Length-weight relationship of growing-finishing cage-farmed Nile tilapia\", titlefont=10, legend=nothing)\nplot!(plt, xxx, yyy, ribbon=(yyy .- view(quantiles, 1, :), view(quantiles, 2, :) .- yyy), label=\"Bayesian fitted line\", color=2)\nscatter!(plt, xx, yy, color=1)","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"We end this section plotting an ensemble of lines generated with the chain.","category":"page"},{"location":"bayesian/tilapia_alometry/","page":"Alometry law for the Nile Tilapia","title":"Alometry law for the Nile Tilapia","text":"plt = plot(xlabel=\"Body length (cm)\", ylabel=\"Body weight (g)\", xlims=(0.0, 35.0), ylims=(0.0, 1000.0), title=\"Length-weight relationship of growing-finishing cage-farmed Nile tilapia\", titlefont=10, legend=nothing)\nplot!(plt, xxx, yyy, label=\"Bayesian fitted line\", color=2)\nfor (a, b) in eachrow(view(chain.value.data, :, 1:2, 1))\n    plot!(plt, xxx, a .* xxx .^b, alpha=0.01, color=2, label=false)\nend\nscatter!(plt, xx, yy, color=1)","category":"page"},{"location":"generative/probability_flow/#Probability-flow-ODEs-for-Itô-diffusions","page":"Probability flow","title":"Probability flow ODEs for Itô diffusions","text":"","category":"section"},{"location":"generative/probability_flow/#Aim","page":"Probability flow","title":"Aim","text":"","category":"section"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"The aim is to review the probability flow introduced by Maoutsa, Reich, Opper (2020) and generalized by Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020) and Karras, Aittala, Aila, Laine (2022).","category":"page"},{"location":"generative/probability_flow/#Background","page":"Probability flow","title":"Background","text":"","category":"section"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020) extended the denoising diffusion probabilistic models (DDPM) of Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015) and Ho, Jain, and Abbeel (2020) and the (multiple denoising) score matching with (annealed) Langevin dynamics (SMLD) of Song and Ermon (2019) to the continuous case. This lead to a noising schedule based on a stochastic differential equation of the form","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    mathrmdX_t = f(t X_t)mathrmdt + G(t X_t)mathrmdW_t","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"for suitable choices of f=f(t x) and G=G(t x) (usually with f(t x) = -a(t)x linear in x and with G(t x) = g(t)mathbfI diagonal and only time dependent).","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020) then showed that the probability density p(t x) of X_t can also be obtained with the (random) ODE","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracmathrmdY_tmathrmdt = f(t Y_t) - frac12 nabla_y cdot ( G(t Y_t)G(t Y_t)^mathrmtr ) - frac12 G(t Y_t)G(t Y_t)^mathrmtrnabla_y log p(t Y_t)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"This probability flow ODE, as so they termed, was based on the work by Maoutsa, Reich, Opper (2020), who derived this equation in the particular case of a time-independent drift term and a constant diagonal noise factor, i.e. with","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    f(t x) = f(x) qquad G(t x) = sigma mathbfI","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Both the SDE for X_t_t and the random ODE for Y_t_t have a reverse-time counterpart, which is then used for sampling, provided the Stein score nabla log p(t x) has been properly modeled by a suitable neural network.","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"In theory, both formulations are equivalent to each other, in the sense of yielding the same probability density p(t x) In practice, however, their numerical implementations and their Monte Carlo approximations differ considerably. Sampling via the reverse probability flow ODE has some advantages such as the fact that the sample trajectories are smoother and easier to integrate numerically, allowing for higher order schemes with lower computational cost, and that there are less parameters to fiddle with. It is also easier to go back and forth with the ODE. Meanwhile, in some situations and with well chosen parameters, sampling with the reverse SDE seems to somehow generate better sample distributions.","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Notice that we denoted the probability flow ODE with Y_t_t to stress the fact that this is a different process from X_t_t but with the remarkable fact that they have same probability density function p(t x)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Later, Karras, Aittala, Aila, Laine (2022) considered a particular type of SDE and obtained a sort of probability flow SDE with two main characteristics: a desired specific variance schedule and a mixture of the original SDE and the probability flow ODE. In essence, the desired variance is simply a reparametrization of the terms of the equation, while the mixture of the SDE and the ODE is just a split-up of the way the diffusion term is handled. More precisely, for the passage from the SDE to the flow ODE, the whole diffusion term is rewritten as a flux. For the mixture, just part of it is rewritten.","category":"page"},{"location":"generative/probability_flow/#Probability-flow-(random)-ODEs","page":"Probability flow","title":"Probability flow (random) ODEs","text":"","category":"section"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"The probability flow ODEs are actually ordinary differential equations with random initial conditions, which is a special form of a Random ODE (RODE). The main point is that they have the same probability distributions as their original stochastic versions. In what follows, we will build that up in different context.","category":"page"},{"location":"generative/probability_flow/#With-a-constant-scalar-diagonal-noise-amplitude","page":"Probability flow","title":"With a constant scalar diagonal noise amplitude","text":"","category":"section"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"This is the original result given by Maoutsa, Reich, Opper (2020). The SDE is the Itô diffusion with a constant scalar diagonal noise term","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    mathrmdX_t = f(X_t)mathrmdt + sigmamathrmdW_t","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"where the unknown X_t_t is a vector valued process with values in mathbbR^d dinmathbbR W_t_t is a vector valued process in the same event space mathbbR^d with components made of independent Wiener processes; the drift term is a vector field fmathbbR^d rightarrow mathbbR^d and sigma  0 is a constant noise amplitude factor.","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"In this case, given a initial probability distribution p_0 for the initial random variable X_0 the probability distribution p(t x) for X_t is the solution of the Fokker-Planck (Kolmogorov forward) equation","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot (f(x) p(t x)) = fracsigma^22Delta_x p(t x)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"The idea is that the diffusion term can also be expressed as a divergence, namely","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracsigma^22Delta_x p(t x) = fracsigma^22nabla_x cdot nabla_x p(t x) = nabla_x cdot left(fracsigma^22nabla_x p(t x)right)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Another key point is that the gradient above can be written as a multiple of the probability density, with the help of the Stein score function nabla_xlog p(t x) Indeed, in the region where p(t x)  0","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    nabla_x p(t x) = p(t x) fracnabla_x p(t x)p(t x) = p(t x) nabla_x log p(t x)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Then, with the understanding that slog s vanishes for s = 0, which extends this function continuously to the region sgeq 0 we can assume this relation holds everywhere. Thus, the Fokker-Planck equation takes the form","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot (f(x) p(t x)) = nabla_x cdot (fracsigma^22p(t x) nabla_x log p(t x))","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"We now rewrite this equation as","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot left(f(x) p(t x) - fracsigma^22p(t x) nabla_x log p(t x) right) = 0","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Defining","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    tilde f(t x) = f(x) - fracsigma^22 nabla_x log p(t x)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"the Fokker-Planck equation becomes","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot left(tilde f(x) p(t x) right) = 0","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"which can be viewed as the Liouville equation associated with the evolution of a distribution governed by the ODE, with no diffusion,","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    mathrmdY_t = tilde f(t Y_t)mathrmdt","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"i.e. just a Random ODE (more specifically an ODE with random initial data) of the form","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracmathrmdY_tmathrmdt = f(t Y_t) - fracsigma^22 nabla_y log p(t Y_t)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"This equation did not receive any special name in the original work Maoutsa, Reich, Opper (2020), but got the name probability flow ODE in the work Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020), which we discuss next.","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Before that, we remark that one difficulty with the probability flow ODE is that it requires knownledge of the Stein score function nabla_x log p(t x) of the supposedly unknown distribution. This is circumvented in Maoutsa, Reich, Opper (2020) by using a gradient log density estimator obtained from samples of the forward diffusion process, i.e. from a maximum likelihood estimation based on the evolution of the empiral distribution of X_0","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"On the other hand, Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020) models the score function directly as a (trained) neural network.","category":"page"},{"location":"generative/probability_flow/#With-a-nonlinear-scalar-diagonal-noise-amplitude","page":"Probability flow","title":"With a nonlinear scalar diagonal noise amplitude","text":"","category":"section"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"In Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020), the authors consider the more general SDE","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    mathrmdX_t = f(t X_t)mathrmdt + G(t X_t)mathrmdW_t","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"where the diffusion factor is not a scalar diagonal anymore but is a  matrix-valued, time-dependent function GItimes mathbbR^d rightarrow mathbbR^dtimes d and with the drift term also time dependent, fItimes mathbbR^d rightarrow mathbbR^d on an interval of interest I=0 T","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Just for clarity, let us consider first the case in which G=G(t x) is still diagonal but not a constant anymore, i.e.","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    G(t x) = g(t x)mathbfI","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"so that","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    mathrmdX_t = f(t X_t)mathrmdt + g(t X_t)mathrmdW_t","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"In this case, the Fokker-Planck equation takes the form","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot (f(x) p(t x)) = frac12Delta_x (g(t x)^2 p(t x))","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"As before, the diffusion term can be written as","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    beginalign*\n        frac12Delta_x (g(t x)^2 p(t x))  = frac12nabla_x cdot nabla_x (g(t x)^2 p(t x)) \n         = frac12nabla_x cdot left( nabla_x g(t x)^2 p(t x) + g(t x)^2 nabla_x p(t x) right) \n         = frac12nabla_x cdot left( nabla_x g(t x)^2 p(t x) + g(t x)^2 p(t x) nabla_x log p(t x) right)\n    endalign*","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Thus, the Fokker-Planck equation becomes","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot left( f(x) p(t x) - frac12 nabla_x g(t x)^2 p(t x) - g(t x)^2 p(t x) nabla_x log p(t x) right) = 0","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"which can also be viewed as the Fokker-Planck equation for the SDE with no diffusion","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    mathrmdY_t = tilde f(t Y_t)mathrmdt","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"with","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    tilde f(t x) = f(t x) - frac12 nabla_x g(t x)^2 - g(t x)^2nabla_x log p(t x)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"which is actually a random ODE (more specifically an ODE with random initial condition),","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracmathrmdY_tmathrmdt = f(t Y_t) - frac12 nabla_y g(t Y_t)^2 - g(t Y_t)^2nabla_y log p(t Y_t)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"with the equation for p(t x) being the associated Liouville equation.","category":"page"},{"location":"generative/probability_flow/#With-arbitrary-drift-and-diffusion","page":"Probability flow","title":"With arbitrary drift and diffusion","text":"","category":"section"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Now we address the more general case considered in Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020), with an SDE of the form","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    mathrmdX_t = f(t X_t)mathrmdt + G(t X_t)mathrmdW_t","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"where the diffusion factor is now a matrix-valued, time-dependent function GItimes mathbbR^d rightarrow mathbbR^dtimes d","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"In this case, the Fokker-Planck equation takes the form","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot (f(t x) p(t x)) = frac12nabla_x^2  left( (G(t x)G(t x)^mathrmtr) p(t x)right)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Notice that the term within the parentheses, on the right hand side, is a tensor field which at each point (t x) yields a certain matrix A(t x) = (A_ij(t x))_ij=1^d The differential operation nabla_x^2  acting on such a tensor field is given by","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    nabla_x^2  A(t x) = sum_i=1^dsum_j=1^d fracpartial^2partial x_ipartial x_j A_ij(t x)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"We may write everything in coordinates, starting with","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    X_t = (X_t^i)_i=1^d quad W_t = (W_t^i)_i=1^d quad f(t x) = (f_i(t x))_i=1^d quad G(t X_t) = (G_ij(t X_t))_i j=1^d","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"so that the SDE reads","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    mathrmdX_t^i = f_i(t X_t^1 ldots X_t^d)mathrmdt + sum_j=1^d G_ij(t X_t^1 ldots X_t^d)mathrmdW_t^j","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"and the Fokker-Planck equation reads","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + sum_i=1^d fracpartialpartial x_i (f(t x) p(t x)) = frac12sum_i=1^d sum_j=1^d fracpartial^2partial x_i partial x_j (G_ik(t x)G_jk(t x) p(t x))","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Writing the divergence of a tensor field A(t x) = (A_ij(x))_ij=1^d as the vector","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    nabla_x cdot A(t x) = left( nabla_x cdot A_icdot(t x)right)_i=1^d = left( sum_j=1^d fracpartialpartial x_j A_ij(t x)right)_i=1^d","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"we can write the Fokker-Planck equation in divergence form,","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot (f(t x) p(t x)) = frac12nabla_x cdot left(nabla_x cdot (G(t x)G(t x)^mathrmtr p(t x))right)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"As before, the diffusion term can be written as","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    beginalign*\n        frac12nabla_x cdot  left( nabla_x cdot (G(t x)G(t x)^mathrmtr p(t x)) right) \n         = frac12nabla_x cdot bigg( nabla_x cdot ( G(t x)G(t x)^mathrmtr) p(t x) + G(t x)G(t x)^mathrmtrnabla_x p(t x) bigg) \n         = frac12nabla_x cdot bigg( nabla_x cdot ( G(t x)G(t x)^mathrmtr) p(t x) + G(t x)G(t x)^mathrmtrp(t x)nabla_x log p(t x) bigg)\n    endalign*","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"With that, the Fokker-Planck equation reads","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    beginalign*\n        fracpartial ppartial t +  nabla_x cdot (f(t x) p(t x)) \n         = frac12nabla_x cdot left( nabla_x cdot ( G(t x)G(t x)^mathrmtr) p(t x) + G(t x)G(t x)^mathrmtrp(t x)nabla_x log p(t x) right)\n    endalign*","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Rearranging it, we obtain the following equation","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot left( left( f(t x) - frac12 nabla_x cdot ( G(t x)G(t x)^mathrmtr ) - frac12 G(t x)G(t x)^mathrmtrnabla_x log p(t x) right) p(t x) right) = 0","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"which can be viewed as the Liouville equation for the random ODE","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracmathrmdY_tmathrmdt = f(t Y_t) - frac12 nabla_y cdot ( G(t Y_t)G(t Y_t)^mathrmtr ) - frac12 G(t Y_t)G(t Y_t)^mathrmtrnabla_y log p(t Y_t)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"This is the probability flow (random) ODE of Karras, Aittala, Aila, Laine (2022) (except for the symbol Y_t_t instead of X_t_t).","category":"page"},{"location":"generative/probability_flow/#Splitted-up-probability-flow-SDE","page":"Probability flow","title":"Splitted-up probability flow SDE","text":"","category":"section"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"The change from the Fokker-Planck equation","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot (f(t x) p(t x)) = frac12nabla_x^2  left( (G(t x)G(t x)^mathrmtr) p(t x) right)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"for the SDE","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    mathrmdX_t = f(t X_t)mathrmdt + G(t X_t)mathrmdW_t","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"to the Liouville equation","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot left( left( f(t x) - frac12 nabla_x cdot ( G(t x)G(t x)^mathrmtr ) - frac12 G(t x)G(t x)^mathrmtrnabla_x log p(t x) right) p(t x) right) = 0","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"for the random ODE","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracmathrmdY_tmathrmdt = f(t Y_t) - frac12 nabla_y cdot ( G(t Y_t)G(t Y_t)^mathrmtr ) - frac12 G(t Y_t)G(t Y_t)^mathrmtrnabla_y log p(t Y_t)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"boils down to expressing the diffusion term completely as a flux term:","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    beginalign*\n        frac12nabla_x^2   left( (G(t x)G(t x)^mathrmtr) p(t x) right) \n         = frac12nabla_x cdot left( left( nabla_x cdot ( G(t x)G(t x)^mathrmtr ) + G(t x)G(t x)^mathrmtrnabla_x log p(t x) right) p(t x) right)\n    endalign*","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"As discussed in the Introduction, both formulations seem to have their advantages. So one idea is to split up the diffusion term and handle one part as the ODE flow and leave the other part as the SDE diffusion, in an attempt to leverage the advantages of both formulations. This is what we do next.","category":"page"},{"location":"generative/probability_flow/#For-a-general-Itô-diffusion","page":"Probability flow","title":"For a general Itô diffusion","text":"","category":"section"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"We may introduce a weight parameter, say theta(t) which can even be time dependent, and split up the diffusion term of the Fokker-Planck equation into","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"   beginalign*\n        frac12nabla_x^2   left( (G(t x)G(t x)^mathrmtr) p(t x) right) \n         = frac1 - theta(t)2nabla_x^2  left( (G(t x)G(t x)^mathrmtr) p(t x) right) + fractheta(t)2nabla_x^2  left( (G(t x)G(t x)^mathrmtr) p(t x) right)\n    endalign*","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Rewriting only the first term as a flux we obtain","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    beginalign*\n        frac12nabla_x^2   left( (G(t x)G(t x)^mathrmtr) p(t x) right) \n         = frac1 - theta(t)2nabla_x cdot left( left( nabla_x cdot ( G(t x)G(t x)^mathrmtr ) + G(t x)G(t x)^mathrmtrnabla_x log p(t x) right) p(t x) right) \n         qquad +  fractheta(t)2nabla_x^2  left( (G(t x)G(t x)^mathrmtr) p(t x) right)\n    endalign*","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"In this way, the Fokker-Planck equation becomes","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    beginalign*\n        fracpartial ppartial t + nabla_x cdot bigg( bigg(  f(t x) - frac1-theta(t)2 nabla_x cdot ( G(t x)G(t x)^mathrmtr ) \n         qquad qquad - frac1-theta(t)2 G(t x)G(t x)^mathrmtrnabla_x log p(t x) bigg) p(t x) bigg) \n         qquad qquad qquad qquad = fractheta(t)2nabla_x^2  left( (G(t x)G(t x)^mathrmtr) p(t x) right)\n    endalign*","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"The associated splitted-up probability flow SDE reads","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    beginalign*\n        mathrmdY_t = bigg(  f(t Y_t) - frac1- theta(t)2 nabla_y cdot ( G(t Y_t)G(t Y_t)^mathrmtr ) \n         qquad qquad - frac1 - theta(t)2 G(t Y_t)G(t Y_t)^mathrmtrnabla_y log p(t Y_t)bigg)mathrmdt + sqrttheta(t) G(t Y_t)mathrmdW_t\n    endalign*","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"As mentioned before, all these formulations are theoretically equivalent. But their practical applications differ.","category":"page"},{"location":"generative/probability_flow/#For-an-SDE-with-scalar-time-dependent-diagonal-noise","page":"Probability flow","title":"For an SDE with scalar time-dependent diagonal noise","text":"","category":"section"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"In the case that","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    G(t x) = g(t)mathbfI","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"the splitted-up probability flow SDE reduces to","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    beginalign*\n        mathrmdY_t = bigg(  f(t Y_t) - frac1 - theta(t)2 g(t)^2 nabla_y log p(t Y_t)bigg)mathrmdt + sqrttheta(t) g(t)mathrmdW_t\n    endalign*","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"with the Fokker-Planck equation","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t + nabla_x cdot bigg( bigg( f(t x) - frac1-theta(t)2 g(t)nabla_x log p(t x) bigg) p(t x) bigg) = fractheta(t)g(t)^22Delta_x p(t x)","category":"page"},{"location":"generative/probability_flow/#Connection-with-the-Karras-et-al-probability-flow-SDE","page":"Probability flow","title":"Connection with the Karras et al probability flow SDE","text":"","category":"section"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"If we set","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    f(t x) = 0 qquad g(t) = sqrt2dotsigma(t) sigma(t)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"and choose","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    theta(t) = frac2beta(t)sigma(t)^2g(t)^2","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"we get","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    beginalign*\n        - frac1 - theta(t)2 g(t)^2  = frac12(theta(t) - 1) g(t)^2 = frac12left( frac2beta(t)sigma(t)^2g(t)^2 - 1right)g(t)^2 = frac12left(2beta(t)sigma(t)^2 - g(t)^2right) \n         = frac12left( 2beta(t)sigma(t)^2 - 2dotsigma(t) sigma(t)right) = beta(t)sigma(t)^2 - dotsigma(t) sigma(t)\n    endalign*","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"and ","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    sqrttheta(t) g(t) = sqrt2beta(t) sigma(t)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Thus, we transform the splitted-up probability flow SDE into the probability flow SDE of Karras, Aittala, Aila, Laine (2022),","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    beginalign*\n        mathrmdY_t = left( -dotsigma(t)sigma(t) + beta(t)sigma(t)^2 right) nabla_y log p(t Y_t)mathrmdt + sqrt2beta(t) sigma(t)mathrmdW_t\n    endalign*","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"having the same distribution as the SDE","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    mathrmdX_t = sqrt2dotsigma(t)sigma(t)mathrmdW_t","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"which is associated with the Fokker-Planck equation","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    fracpartial ppartial t  = dotsigma(t)sigma(t)Delta_x p(t x)","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"Notice that now, instead of the free parameter theta(t), we have the free parameter beta(t) of Karras, Aittala, Aila, Laine (2022).","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"The motivation for writing it in this way, with dotsigma sigma as the diffusion coefficient, is that the heat kernel becomes","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    G(sigma(t)) = frac1(2pi sigma(t)^2)^d2 e^-frac12fracx^2sigma(t)^2","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"which is the probability density of the Gaussian mathcalN(0 sigma(t)^2mathbfI) The distribution p(t x) is given by the convolution","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"    p(t cdot) = G(sigma(t)) star p_0","category":"page"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"where p_0=p_0(x) is the initial probability density of the distribution we are attempting to model. This is just a reparametrization of the process directly in terms of a desired variance sigma(t)^2","category":"page"},{"location":"generative/probability_flow/#References","page":"Probability flow","title":"References","text":"","category":"section"},{"location":"generative/probability_flow/","page":"Probability flow","title":"Probability flow","text":"J. Sohl-Dickstein, E. A. Weiss, N. Maheswaranathan, S. Ganguli (2015), \"Deep unsupervised learning using nonequilibrium thermodynamics\", ICML'15: Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, 2256-2265\nY. Song and S. Ermon (2019), \"Generative modeling by estimating gradients of the data distribution\", NIPS'19: Proceedings of the 33rd International Conference on Neural Information Processing Systems, no. 1067, 11918-11930\nJ. Ho, A. Jain, P. Abbeel (2020), \"Denoising diffusion probabilistic models\", in Advances in Neural Information Processing Systems 33, NeurIPS2020\nD. Maoutsa, S. Reich, M. Opper (2020), \"Interacting particle solutions of Fokker-Planck equations through gradient-log-density estimation\", Entropy, 22(8), 802, DOI: 10.3390/e22080802\nY. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, B. Poole (2020), \"Score-based generative modeling through stochastic differential equations\", arXiv:2011.13456\nT. Karras, M. Aittala, T. Aila, S. Laine (2022), Elucidating the design space of diffusion-based generative models, Advances in Neural Information Processing Systems 35 (NeurIPS 2022)","category":"page"},{"location":"generative/denoising_score_matching/#Denoising-score-matching-of-Pascal-Vincent","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"","category":"section"},{"location":"generative/denoising_score_matching/#Introduction","page":"Denoising score matching of Pascal Vincent","title":"Introduction","text":"","category":"section"},{"location":"generative/denoising_score_matching/#Aim","page":"Denoising score matching of Pascal Vincent","title":"Aim","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Explore the denoising score matching method proposed by Pascal Vincent (2011) and illustrate it by fiting a multi-layer perceptron to model the score function of a one-dimensional synthetic Gaussian-mixture distribution.","category":"page"},{"location":"generative/denoising_score_matching/#Motivation","page":"Denoising score matching of Pascal Vincent","title":"Motivation","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"The motivation is to continue building a solid background on score-matching diffusion.","category":"page"},{"location":"generative/denoising_score_matching/#Background","page":"Denoising score matching of Pascal Vincent","title":"Background","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Aapo Hyvärinen (2005) proposed fitting directly the score of a model distribution. This is obtained, in theory, by minimizing an explicit score matching objective function. However, this function requires knowing the supposedly unknown target score function. The trick used by Aapo Hyvärinen (2005) was then to do an integration by parts and rewrite the optimization problem in terms of an implicit score matching objective function, which yields the same minima and does not require further information from the target distribution other than some sample points.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"The implicit score matching method requires, however, the derivative of the score function of the model distribution, which is costly to compute in general.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Then, Vincent (2011) explored the idea of using non-parametric Parzen density estimation to directly approximate the explicit score matching objective, making a connection with denoising autoenconders (proposed earlir by Pascal himself, as a co-author in Vincent, Larochelle, Lajoie, Bengio, and Manzagol(2010)), and proposing the denoising score matching method.","category":"page"},{"location":"generative/denoising_score_matching/#Objetive-function-for-denoising-score-matching","page":"Denoising score matching of Pascal Vincent","title":"Objetive function for denoising score matching","text":"","category":"section"},{"location":"generative/denoising_score_matching/#The-original-explicit-and-implicit-score-matching","page":"Denoising score matching of Pascal Vincent","title":"The original explicit and implicit score matching","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"The score-matching method from Aapo Hyvärinen (2005) aims to fit the score function psi(mathbfx boldsymboltheta) of the model distribution to the score function psi_X(mathbfx) of a random variable mathbfX by minimizing the implicit score matching objective","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    J_mathrmISM(boldsymboltheta) = int_mathbbR p_mathbfX(mathbfx) left( frac12leftboldsymbolpsi(mathbfx boldsymboltheta)right^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx boldsymboltheta) right)mathrmdmathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"which is equivalent to minimizing the explicit score matching objective","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    J_mathrmESM(boldsymboltheta) = frac12int_mathbbR^d p_mathbfX(mathbfx) leftboldsymbolpsi(mathbfx boldsymboltheta) - boldsymbolpsi_mathbfX(mathbfx)right^2mathrmdmathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"due to the following identity obtained via integration by parts in the expectation","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    J_mathrmESM(boldsymboltheta) = tilde J_mathrmISM(boldsymboltheta) + C_sigma","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"where C_sigma is constant with respect to the parameters boldsymboltheta. The advantage of tilde J_mathrmISM(boldsymboltheta) is that it does not involve the unknown score function of X. It does, however, involve the gradient of the modeled score function, which is expensive to compute.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"In practice, this is further approximated by the empirical distribution tilde p_0 given by","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde p_0(mathbfx) = frac1Nsum_n=1^N delta(mathbfx - mathbfx_n)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"so the implemented implicit score matching objective is","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde J_mathrmISMtilde p_0(boldsymboltheta) = frac1Nsum_n=1^N left( frac12leftboldsymbolpsi(mathbfx_n boldsymboltheta)right^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx_n boldsymboltheta) right)","category":"page"},{"location":"generative/denoising_score_matching/#Using-Parzen-estimation","page":"Denoising score matching of Pascal Vincent","title":"Using Parzen estimation","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Aapo Hyvärinen (2005) briefly mentions that minimizing J_mathrmESM(boldsymboltheta) directly is \"basically a non-parametric estimation problem\", but dismisses it for the \"simple trick of partial integration to compute the objective function very easily\". As we have seen, the trick is fine for model functions for which we can compute the gradient without much trouble, but for modeling it with a neural network, for instance, it becomes computationally expensive.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"A few years later, Vincent (2011) considered the idea of using a Parzel kernel density estimation","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde p_sigma(mathbfx) = frac1sigma^dint_mathbbR^d Kleft(fracmathbfx - tildemathbfxsigmaright) mathrmdtilde p_0(tildemathbfx) = frac1sigma^d Nsum_n=1^N Kleft(fracmathbfx - mathbfx_nsigmaright)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"where sigma  0 is a kernel window parameter and K(mathbfx) is a kernel density properly normalized to have mass one. In this way, the explicit score matching objective function is approximated by","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde J_mathrmESMtilde p_sigma(boldsymboltheta) = frac12int_mathbbR^d tilde p_sigma(mathbfx) leftboldsymbolpsi(mathbfx boldsymboltheta) - boldsymbolnabla_mathbfxlog tilde p_sigma(mathbfx)right^2mathrmdmathbfx","category":"page"},{"location":"generative/denoising_score_matching/#Denoising-autoencoder","page":"Denoising score matching of Pascal Vincent","title":"Denoising autoencoder","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"However, Pascal Vincent (2011) did not use this as a final objective function. Pascal further simplified the objective function tilde J_mathrmESMtilde p_sigma(boldsymboltheta) by expanding the gradient of the logpdf of the Parzen estimator, writing a double integral with a conditional probability, simplifying the computation of the gradient of the logarithm of the Parzen estimation, which involves the log of a sum, to the gradient of the logarithm of the conditional probability, which involves the log of a single kernel.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"In this way, Pascal arrived at the (Parzen) denoising score matching objective function","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde J_mathrmDSMtilde p_sigma(boldsymboltheta) = frac12int_mathbbR^d int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx)left boldsymbolpsi(tildemathbfx boldsymboltheta) - boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfxmathbfx) right^2 mathrmdmathbfxmathrmdtildemathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"where tilde p_sigma(tildemathbfxmathbfx) is the conditional density","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde p_sigma(tildemathbfxmathbfx) = frac1sigma^dKleft(fractildemathbfx - mathbfxsigmaright)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Notice that the empirical distribution is not a further approximation to this objective function. It comes directly from the Parzen estimator. So, we can write","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde J_mathrmDSMtilde p_sigma(boldsymboltheta) = frac12frac1Nsum_n=1^N int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx_n) left boldsymbolpsi(tildemathbfx boldsymboltheta) - boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfxmathbfx_n) right^2 mathrmdtildemathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"We do need, however, for the sake of implementation, to approximate the (inner) expectation with respect to the conditional distribution. This is achieved by drawing a certain number of sample points from the conditional distribution associated with tilde p_sigma(tildemathbfxmathbfx_n).","category":"page"},{"location":"generative/denoising_score_matching/#Denoising-autoencoder-with-the-standard-Gaussian-kernel","page":"Denoising score matching of Pascal Vincent","title":"Denoising autoencoder with the standard Gaussian kernel","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"At this point, choosing the kernel of the Parzen estimation to be the standard Gaussian kernel","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    G(mathbfx) = frac1sqrt2pi e^-frac12 mathbfx^2","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"the conditional distribution is a Normal distribution with mean mathbfx_n and variance sigma^2. Hence, for each n=1 ldots N, we draw M sample points tildemathbfx_nm, m=1 ldots M, according to","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tildemathbfx_nm sim mathcalN(mathbfx_n sigma^2) quad m=1 ldots M","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Then, using the associated empirical distribution ","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde p_sigma 0(tildemathbfxmathbfx_n) = frac1Msum_m=1^M delta(tildemathbfx - tildemathbfx_nm)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"we arrive at the empirical denoising score matching objective","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde J_mathrmDSMtilde p_sigma 0(boldsymboltheta) = frac12frac1NMsum_n=1^N sum_m=1^M left boldsymbolpsi(mathbfx_n m boldsymboltheta) - boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx_nmmathbfx_n) right^2 mathrmdtildemathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"With the Gaussian kernel, we have","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    beginalign*\n        boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx_nmmathbfx_n)  = boldsymbolnabla_tildemathbfx logleft( frac1sqrt2pisigma^d e^-frac12 left(fractildemathbfx - mathbfx_nsigmaright)^2 right) Bigg_tildemathbfx=tildemathbfx_n m \n         = boldsymbolnabla_tildemathbfx left( -frac12 left(fractildemathbfx - mathbfx_nsigmaright)^2 - log(sqrt2pisigma^d) right)Bigg_tildemathbfx=tildemathbfx_n m \n         = left( - fractildemathbfx - mathbfx_nsigma^2 right)Bigg_tildemathbfx=tildemathbfx_n m \n         = - fractildemathbfx_n m - mathbfx_nsigma^2 \n         = fracmathbfx_n - tildemathbfx_n msigma^2\n    endalign*","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Thus, in this case, the empirical denoising score matching objective reads","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde J_mathrmDSMtilde p_sigma 0(boldsymboltheta) = frac12frac1NMsum_n=1^N sum_m=1^M left boldsymbolpsi(mathbfx_n m boldsymboltheta) - fracmathbfx_n - tildemathbfx_n msigma^2 right^2 mathrmdtildemathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Often, with N sufficiently large, it suffices to take M=1, i.e. a single \"corrupted\" sample tildemathbfx_n, for each \"clean\" sample point mathbfx_n. In this way, the double summation becomes a single summation and the computation is just as fast as the one with the score of the unconditional Parzen estimation, with the benefit similar to the denosing autoencoders.","category":"page"},{"location":"generative/denoising_score_matching/#Energy-based-modeling","page":"Denoising score matching of Pascal Vincent","title":"Energy based modeling","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"The model distribution is chosen by Vincent (2011) in the form","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    p_boldsymboltheta(mathbfx) = frac1Z(boldsymboltheta) e^-U(mathbfx boldsymboltheta)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"for an energy potential U(mathbfx boldsymboltheta) of the form","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    U(mathbfx boldsymboltheta) = - frac1sigma^2left( mathbfccdot mathbfx - frac12mathbfx^2 + sum_j=1^d operatornamesoftplusleft(mathbfW_jcdot mathbfx + b_jright)right)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"where","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    boldsymboltheta = (mathbfW mathbfb mathbfc) quad mathbfWin mathbbR^dtimes d mathbfb mathbfcinmathbfR^d","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"with mathbfW_j being the rows of the matrix mathbfW, and operatornamesigmoid() is an activation function. For this model, the score function can be computed explicitly Vincent (2011), being","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    boldsymbolnabla_mathbfx p(mathbfx boldsymboltheta) = frac1sigma^2left( mathbfW^mathrmtroperatornamesigmoidleft(mathbfWmathbfx + mathbfbright) + mathbfc - mathbfxright)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"When substitute for in the denoising score matching objective, we obtain a loss function directly in terms of the parameters boldsymboltheta = (mathbfW mathbfb mathbfc).","category":"page"},{"location":"generative/denoising_score_matching/#Connection-with-denoising-autoencoder","page":"Denoising score matching of Pascal Vincent","title":"Connection with denoising autoencoder","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"This brings us to the connection, discussed by Vincent (2011),  with denoising autoencoders, which were proposed a bit earlier by Vincent, Larochelle, Lajoie, Bengio, and Manzagol(2010).","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"In an autoencoder, as introduced by Kramer (1991), one has two models, an encoder model mathbfy = mathbff_boldsymbolxi(mathbfx) and a decoder mathbfx = mathbfg_boldsymboleta(mathbfy), and the objective is to be able to encode and decode the sample, and recover the original sample as close as possible, i.e.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    J(boldsymbolxi boldsymboleta) = frac1N sum_n=1^N leftmathbfx_n - mathbfg_boldsymboleta(mathbff_boldsymbolxi(mathbfx_n))right","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Of course, this is useful when the latent space of the encoded information mathbfy is much smaller than the sample space, otherwise we just need to model the identity operator.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"In a denoising autoencoder, proposed by Vincent, Larochelle, Lajoie, Bengio, and Manzagol(2010), one first \"corrupts\" the sample points according to some distribution law, say","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tildemathbfx_n sim mathcalP(tildemathbfxmathbfx_n)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"and then use the corrupted sample to train the encoder/decoder pair with the objective function","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    J_mathcalP(boldsymbolxi boldsymboleta) = frac1N sum_n=1^N leftmathbfx_n - mathbfg_boldsymboleta(mathbff_boldsymbolxi(tildemathbfx_n)) right","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"The idea is that the encoder/decoder model learns to better \"reconstruct\" the information even from \"imperfect\" information. Think about the case of encoding/decoding a handwritten message, where the letters are not \"perfect\" according to any font style.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"In Vincent (2011), by choosing the score model of the form","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    boldsymbolpsi(mathbfx boldsymboltheta) = frac1sigma^2left( mathbfW^mathrmtr operatornamesigmoidleft(mathbfWmathbfx + mathbfbright) + mathbfc - mathbfxright)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"where boldsymboltheta = (mathbfW mathbfb mathbfc) are the parameters and operatornamesigmoid() is an activation function, and choosing the noise according to","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    mathcalP(tildemathbfxmathbfx_n) = mathcalN(mathbfx_n sigma^2)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"one obtains the connection","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde J_mathrmDSMtilde p_sigma 0(boldsymboltheta) = frac12sigma^4 tilde J_mathcalP(boldsymboltheta)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"where tilde J_mathcalP(boldsymboltheta) is similar to the denoising autoencoder objective J_mathcalP(boldsymbolxi boldsymboleta), and is defined by","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde J_mathcalP(boldsymboltheta) = frac1N sum_n=1^N leftmathbfx_n - mathbfh_boldsymboltheta(tildemathbfx_n) right","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"where mathbfh_boldsymboltheta(mathbfx) is almost of the form of an encoder/decoder, namely","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    mathbfh_boldsymboltheta(mathbfx) = mathbfg_boldsymboltheta(mathbff_boldsymboltheta(mathbfx)) - mathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"with","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    f_boldsymboltheta(mathbfx) = mathrmsigmoidleft(mathbfWmathbfx + mathbfbright) quad mathbfg_boldsymboltheta(mathbfy) = mathbfW^mathrmtrmathbfy + mathbfc","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Remember that here we are not trying to encode/decode the variate mathbfx itself, but its score function, so the above structure is compatible with that.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Vincent (2011) does not mention explicitly that what we denoted above by mathbfh_boldsymboltheta(mathbfx) is not exactly of the form mathbfg_boldsymboltheta(mathbff_boldsymboltheta(mathbfx)) and actually seems to suggest they are of the same form, for the sake of the connection with a denoising autoenconder. But we see here that it is not. Let us not freak out about that, though. This is good enough to draw some connection between denoising score matching and denoising autoencoder and to have this as an inspiration.","category":"page"},{"location":"generative/denoising_score_matching/#Proof-that-{\\tilde-J}_{\\mathrm{ESM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-{\\tilde-J}_{\\mathrm{DSM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-C_\\sigma","page":"Denoising score matching of Pascal Vincent","title":"Proof that tilde J_mathrmESMtilde p_sigma(boldsymboltheta) = tilde J_mathrmDSMtilde p_sigma(boldsymboltheta) + C_sigma","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"We start by renaming the dummy variable in the expression for tilde J_mathrmESMtilde p_sigma(boldsymboltheta), writing","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde J_mathrmESMtilde p_sigma(boldsymboltheta) = frac12int_mathbbR^d tilde p_sigma(tildemathbfx) leftboldsymbolpsi(tildemathbfx boldsymboltheta) - boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx)right^2mathrmdtildemathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Then, we expand the integrand of tilde J_mathrmESMtilde p_sigma(boldsymboltheta) and write","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    beginalign*\n        tilde J_mathrmESMtilde p_sigma(boldsymboltheta)  = frac12int_mathbbR^d tilde p_sigma(tildemathbfx) leftboldsymbolpsi(tildemathbfx boldsymboltheta) - boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx)right^2mathrmdtildemathbfx \n         = frac12int_mathbbR^d tilde p_sigma(tildemathbfx) left( leftboldsymbolpsi(tildemathbfx boldsymboltheta)right^2 - 2boldsymbolpsi(tildemathbfx boldsymboltheta) cdot boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx) + leftboldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx)right^2right)mathrmdtildemathbfx\n    endalign*","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"The last term is constant with respect to the trainable parameters boldsymboltheta, so we just write","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde J_mathrmESMtilde p_sigma(boldsymboltheta) = frac12int_mathbbR^d tilde p_sigma(tildemathbfx) left( leftboldsymbolpsi(tildemathbfx boldsymboltheta)right^2 - 2boldsymbolpsi(tildemathbfx boldsymboltheta) cdot boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx)right)mathrmdtildemathbfx + C_sigma 1","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"where","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    C_sigma 1 = frac12int_mathbbR^d tilde p_sigma(tildemathbfx) leftboldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx)right^2mathrmdtildemathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Now, notice we can write","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde p_sigma(tildemathbfx) = frac1sigma^dint_mathbbR^d Kleft(fractildemathbfx - mathbfxsigmaright) mathrmdtilde p_0(mathbfx) = int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) mathrmdtilde p_0(mathbfx) = int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx) mathrmdmathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"where tilde p_sigma(tildemathbfxmathbfx) is the conditional density","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde p_sigma(tildemathbfxmathbfx) = frac1sigma^dKleft(fractildemathbfx - mathbfxsigmaright)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Thus, the first term in the objective function becomes","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    frac12int_mathbbR^d tilde p_sigma(tildemathbfx) leftboldsymbolpsi(tildemathbfx boldsymboltheta)right^2mathrmdtildemathbfx = frac12int_mathbbR^d int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx) leftboldsymbolpsi(tildemathbfx boldsymboltheta)right^2mathrmdmathbfxmathrmdtildemathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"It remains to treat the second term. For that, we use that","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx) = frac1tilde p_sigma(tildemathbfx) boldsymbolnabla_tildemathbfxtilde p_sigma(tildemathbfx)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Thus,","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    beginalign*\n        int_mathbbR^d tilde p_sigma(tildemathbfx) boldsymbolpsi(tildemathbfx boldsymboltheta) cdot boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx)mathrmdtildemathbfx  = int_mathbbR^d boldsymbolpsi(tildemathbfx boldsymboltheta) cdot boldsymbolnabla_tildemathbfxtilde p_sigma(tildemathbfx)mathrmdtildemathbfx \n    endalign*","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Now we write that","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    beginalign*\n        boldsymbolnabla_tildemathbfxtilde p_sigma(tildemathbfx)  = boldsymbolnabla_tildemathbfx int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx) mathrmdmathbfx \n         = int_mathbbR^d boldsymbolnabla_tildemathbfxtilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx) mathrmdmathbfx \n         = int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) boldsymbolnabla_tildemathbfx log tilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx) mathrmdmathbfx\n    endalign*","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Hence,","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    beginalign*\n        int_mathbbR^d tilde p_sigma(tildemathbfx) boldsymbolpsi(tildemathbfx boldsymboltheta) cdot boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx)mathrmdtildemathbfx  = int_mathbbR^d boldsymbolpsi(tildemathbfx boldsymboltheta) cdot left(int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) boldsymbolnabla_tildemathbfx log tilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx) mathrmdmathbfxright)mathrmdtildemathbfx \n         = int_mathbbR^d int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx) boldsymbolpsi(tildemathbfx boldsymboltheta) cdot boldsymbolnabla_tildemathbfx log tilde p_sigma(tildemathbfxmathbfx) mathrmdmathbfxmathrmdtildemathbfx\n    endalign*","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Putting the terms together, we find that","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    beginalign*\n        tilde J_mathrmESMtilde p_sigma(boldsymboltheta)  = frac12int_mathbbR^d tilde p_sigma(tildemathbfx) left( leftboldsymbolpsi(tildemathbfx boldsymboltheta)right^2 - 2boldsymbolpsi(tildemathbfx boldsymboltheta) cdot boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfx)right)mathrmdtildemathbfx + C_sigma 1 \n         = frac12int_mathbbR^d int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx) left( leftboldsymbolpsi(tildemathbfx boldsymboltheta)right^2 - 2boldsymbolpsi(tildemathbfx boldsymboltheta) cdot boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfxmathbfx)right)mathrmdmathbfxmathrmdtildemathbfx + C_sigma 1\n    endalign*","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Now we add and subtract the constant (with respect to the parameters boldsymboltheta)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    C_sigma 2 = frac12int_mathbbR^d int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx) leftboldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfxmathbfx)right^2 mathrmdmathbfxmathrmdtildemathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"With that, we finally obtain the desired relation","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    beginalign*\n        tilde J_mathrmESMtilde p_sigma(boldsymboltheta)\n         = frac12int_mathbbR^d int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx) Bigg( leftboldsymbolpsi(tildemathbfx boldsymboltheta)right^2 \n         qquadqquad - 2boldsymbolpsi(tildemathbfx boldsymboltheta) cdot boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfxmathbfx) + leftboldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfxmathbfx)right^2Bigg)mathrmdmathbfxmathrmdtildemathbfx + C_sigma 1 - C_sigma 2 \n         = frac12int_mathbbR^d int_mathbbR^d tilde p_sigma(tildemathbfxmathbfx) tilde p_0(mathbfx)left boldsymbolpsi(tildemathbfx boldsymboltheta) - boldsymbolnabla_tildemathbfxlog tilde p_sigma(tildemathbfxmathbfx) right^2 mathrmdmathbfxmathrmdtildemathbfx + C_sigma 1 - C_sigma 2 \n         = tilde J_mathrmDSMtilde p_sigma(boldsymboltheta) + C_sigma\n    endalign*","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"where","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    C_sigma = C_sigma 1 - C_sigma 2","category":"page"},{"location":"generative/denoising_score_matching/#Numerical-example","page":"Denoising score matching of Pascal Vincent","title":"Numerical example","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"We illustrate, numerically, the use of the denoising (explicit) score matching objective tilde J_mathrmDSMtilde p_sigma to model a synthetic univariate Gaussian mixture distribution. However, instead using an energy based method and model an energy potential of the density as done by Vincent (2011), we model directly the score function.","category":"page"},{"location":"generative/denoising_score_matching/#Julia-language-setup","page":"Denoising score matching of Pascal Vincent","title":"Julia language setup","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"We use the Julia programming language for the numerical simulations, with suitable packages.","category":"page"},{"location":"generative/denoising_score_matching/#Packages","page":"Denoising score matching of Pascal Vincent","title":"Packages","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"using StatsPlots\nusing Random\nusing Distributions\nusing Lux # artificial neural networks explicitly parametrized\nusing Optimisers\nusing Zygote # automatic differentiation\nusing Markdown\n\nnothing # hide","category":"page"},{"location":"generative/denoising_score_matching/#Reproducibility","page":"Denoising score matching of Pascal Vincent","title":"Reproducibility","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"We set the random seed for reproducibility purposes.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"rng = Xoshiro(12345)\nnothing # hide","category":"page"},{"location":"generative/denoising_score_matching/#Data","page":"Denoising score matching of Pascal Vincent","title":"Data","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"We build the usual target model and draw samples from it.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"target_prob = MixtureModel([Normal(-3, 1), Normal(3, 1)], [0.1, 0.9])\n\nxrange = range(-10, 10, 200)\ndx = Float64(xrange.step)\nxx = permutedims(collect(xrange))\ntarget_pdf = pdf.(target_prob, xrange')\ntarget_score = gradlogpdf.(target_prob, xrange')\n\nsample_points = permutedims(rand(rng, target_prob, 1024))","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Visualizing the sample data drawn from the distribution and the PDF.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"plt # hide","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Visualizing the score function.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"plt # hide","category":"page"},{"location":"generative/denoising_score_matching/#The-neural-network-model","page":"Denoising score matching of Pascal Vincent","title":"The neural network model","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"The neural network we consider is a simple feed-forward neural network made of a single hidden layer, obtained as a chain of a couple of dense layers. This is implemented with the LuxDL/Lux.jl package.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"We will see that we don't need a big neural network in this simple example. We go as low as it works.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"model = Chain(Dense(1 => 8, relu), Dense(8 => 1))","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"The LuxDL/Lux.jl package uses explicit parameters, that are initialized (or obtained) with the Lux.setup function, giving us the parameters and the state of the model.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model","category":"page"},{"location":"generative/denoising_score_matching/#Loss-function","page":"Denoising score matching of Pascal Vincent","title":"Loss function","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Here it is how we implement the empirical denoising score matching objective","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    tilde J_mathrmDSMtilde p_sigma 0(boldsymboltheta) = frac12frac1NMsum_n=1^N sum_m=1^M left boldsymbolpsi(mathbfx_n m boldsymboltheta) - fracmathbfx_n - tildemathbfx_n msigma^2 right^2 mathrmdtildemathbfx","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"First we precompute the matrix (mathbfa_nm)_nm given by","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    mathbfa_nm = fracmathbfx_n - tildemathbfx_n msigma^2","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Then, at each iteration of the optimization process, we take the current parameters boldsymboltheta and apply the model to the perturbed points tildemathbfx_n m to obtain the predicted scores boldsymbolpsi_nm^boldsymboltheta with values","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    boldsymbolpsi_nm^boldsymboltheta = boldsymbolpsi(tildemathbfx_nm boldsymboltheta)","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"and then compute half the mean square distance between the two matrices:","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"    frac12sum_m=1^M sum_n=1^N left boldsymbolpsi_nm^boldsymboltheta - mathbfa_nmright^2","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"In the implementation below, we just use M=1, so the matrices (boldsymbolpsi_nm^boldsymboltheta)_nm and (mathbfa_nm)_nm are actually just vectors. Besides, this is a scalar example, i.e. with d=1, so they are indeed plain real-valued vectors (psi_n1)_n and (a_n1)_n.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"In general, though, these objects (boldsymbolpsi_nm^boldsymboltheta)_nm and (mathbfa_nm)_nm are mathbbR^d-vector-valued matrices.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"So, here is how we prepare the data.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"sigma = 0.3\nnoised_sample_points = sample_points .+ sigma .* randn(size(sample_points))\ndsm_target = ( sample_points .- noised_sample_points ) ./ sigma ^ 2\ndata = (noised_sample_points, dsm_target)\nnothing # hide","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"and here is the implementation of the loss function","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"function loss_function_dsm(model, ps, st, data)\n    noised_sample_points, dsm_target = data\n    y_score_pred, st = Lux.apply(model, noised_sample_points, ps, st)\n    loss = mean(abs2, y_score_pred .- dsm_target) / 2\n    return loss, st, ()\nend\nnothing # hide","category":"page"},{"location":"generative/denoising_score_matching/#Optimization-setup","page":"Denoising score matching of Pascal Vincent","title":"Optimization setup","text":"","category":"section"},{"location":"generative/denoising_score_matching/#Optimization-method","page":"Denoising score matching of Pascal Vincent","title":"Optimization method","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"We use the Adam optimiser.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"opt = Adam(0.01)\n\ntstate_org = Lux.Training.TrainState(model, ps, st, opt)","category":"page"},{"location":"generative/denoising_score_matching/#Automatic-differentiation-in-the-optimization","page":"Denoising score matching of Pascal Vincent","title":"Automatic differentiation in the optimization","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"As mentioned, we setup differentiation in LuxDL/Lux.jl with the FluxML/Zygote.jl library.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"vjp_rule = Lux.Training.AutoZygote()","category":"page"},{"location":"generative/denoising_score_matching/#Processor","page":"Denoising score matching of Pascal Vincent","title":"Processor","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"We use the CPU instead of the GPU.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"dev_cpu = cpu_device()\n## dev_gpu = gpu_device()","category":"page"},{"location":"generative/denoising_score_matching/#Check-differentiation","page":"Denoising score matching of Pascal Vincent","title":"Check differentiation","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Check if Zygote via Lux is working fine to differentiate the loss functions for training.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Lux.Training.compute_gradients(vjp_rule, loss_function_dsm, data, tstate_org)","category":"page"},{"location":"generative/denoising_score_matching/#Training-loop","page":"Denoising score matching of Pascal Vincent","title":"Training loop","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Here is the typical main training loop suggest in the LuxDL/Lux.jl tutorials, but sligthly modified to save the history of losses per iteration.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"function train(tstate, vjp, data, loss_function, epochs, numshowepochs=20, numsavestates=0)\n    losses = zeros(epochs)\n    tstates = [(0, tstate)]\n    for epoch in 1:epochs\n        grads, loss, stats, tstate = Lux.Training.compute_gradients(vjp,\n            loss_function, data, tstate)\n        if ( epochs ≥ numshowepochs > 0 ) && rem(epoch, div(epochs, numshowepochs)) == 0\n            println(\"Epoch: $(epoch) || Loss: $(loss)\")\n        end\n        if ( epochs ≥ numsavestates > 0 ) && rem(epoch, div(epochs, numsavestates)) == 0\n            push!(tstates, (epoch, tstate))\n        end\n        losses[epoch] = loss\n        tstate = Lux.Training.apply_gradients(tstate, grads)\n    end\n    return tstate, losses, tstates\nend","category":"page"},{"location":"generative/denoising_score_matching/#Training","page":"Denoising score matching of Pascal Vincent","title":"Training","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Now we train the model with the objective function tilde J_mathrmESMtilde p_sigmatilde p_0(boldsymboltheta).","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_dsm, 500, 20, 125)\nnothing # hide","category":"page"},{"location":"generative/denoising_score_matching/#Results","page":"Denoising score matching of Pascal Vincent","title":"Results","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Testing out the trained model.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"y_pred = Lux.apply(tstate.model, xrange', tstate.parameters, tstate.states)[1]","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Visualizing the result.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"plot(title=\"Fitting\", titlefont=10)\n\nplot!(xrange, target_score', linewidth=4, label=\"score function\")\n\nscatter!(sample_points', s -> gradlogpdf(target_prob, s), label=\"data\", markersize=2)\n\nplot!(xx', y_pred', linewidth=2, label=\"predicted MLP\")","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Just for the fun of it, let us see an animation of the optimization process.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"gif(anim, fps = 20) # hide","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"paux = exp.(accumulate(+, y_pred) .* dx)\npdf_pred = paux ./ sum(paux) ./ dx\nplot(title=\"Original PDF and PDF from predicted score function\", titlefont=10)\nplot!(xrange, target_pdf', label=\"original\")\nplot!(xrange, pdf_pred', label=\"recoverd\")","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"And the animation of the evolution of the PDF.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"gif(anim, fps = 10) # hide","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"We also visualize the evolution of the losses.","category":"page"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false)","category":"page"},{"location":"generative/denoising_score_matching/#References","page":"Denoising score matching of Pascal Vincent","title":"References","text":"","category":"section"},{"location":"generative/denoising_score_matching/","page":"Denoising score matching of Pascal Vincent","title":"Denoising score matching of Pascal Vincent","text":"Pascal Vincent (2011), \"A connection between score matching and denoising autoencoders,\" Neural Computation, 23 (7), 1661-1674, doi:10.1162/NECOa00142\nAapo Hyvärinen (2005), \"Estimation of non-normalized statistical models by score matching\", Journal of Machine Learning Research 6, 695-709\nP. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and P.-A. Manzagol (2010), \"Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion\". Journal of Machine Learning Research. 11 (110), 3371-3408\nM. A. Kramer (1991), \"Nonlinear principal component analysis using autoassociative neural networks\", AIChE Journal. 37 (2), 233–243. doi:10.1002/aic.690370209.","category":"page"},{"location":"bayesian/linear_regression/#Linear-Regression-in-several-ways","page":"Many Ways to Linear Regression","title":"Linear Regression in several ways","text":"","category":"section"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"The plan is to do a simple linear regression in julia, in several different ways. We'll use plain least squares Base.:\\, the genereral linear model package JuliaStats/GLM.jl and the probabilistic programming package Turing.jl.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"using Distributions, GLM, Turing, StatsPlots","category":"page"},{"location":"bayesian/linear_regression/#The-test-data","page":"Many Ways to Linear Regression","title":"The test data","text":"","category":"section"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"This is a simple test set. We just generate a synthetic sample with a bunch of points approximating a straight line. We actually create two tests, an unperturbed straight line and a perturbed one.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"num_points = 20\nxx = range(0.0, 1.0, length=num_points)\n\nintercept = 1.0\nslope = 2.0\nε = 0.1\n\nyy = intercept .+ slope * xx\n\nyy_perturbed = yy .+ ε * randn(num_points)\n\nplt = plot(title=\"Synthetic data\", titlefont=10, ylims=(0.0, 1.1 * (intercept + slope)))\nplot!(plt, xx, yy, label=\"unperturbed line\")\nscatter!(plt, xx, yy_perturbed, label=\"perturbed sample\")","category":"page"},{"location":"bayesian/linear_regression/#Straightforward-least-squares","page":"Many Ways to Linear Regression","title":"Straightforward least squares","text":"","category":"section"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"The least square solution hat x to a linear problem Ax = b is the vector hat x that minimizes the sum of the squares of the residuals b - Ax, i.e.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"    hat x = argmin_x Ax - b^2","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"The solution is obtained by solving the normal equation","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"    (A^t A)hat x = A^t b","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"In julia, hat x can be found by using the function Base.:\\, which is actually a polyalgorithm, meaning it uses different algorithms depending on the shape and type of A. ","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"When A is an invertible square matrix, then hat x = A^-1b is the unique solution of Ax = b.\nWhen A has more rows than columns and the columns are linearly independent, then hat x = (A^tA)^-1A^tb is the unique least square approximation solution of the overdetermined system Ax = b.\nWhen A has more columns than rows and the rows are linearly independent, then hat x = A^t(AA^t)^-1b is the unique least norm solution of the underdetermined system Ax = b.\nIn all other cases, attempting to solve Ab throws an error.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"First we build the Vandermonde matrix.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"A = [ones(length(xx)) xx]\nsize(A)","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"Now we solve the least square problem with the unperturbed data, solving it explicitly with hat x = (A^tA)^-1A^tb and via A setminus b, and checking both against the original slope and intercept.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"betahat = inv(transpose(A) * A) * transpose(A) * yy\n\nbetahat ≈ A \\ yy ≈ [intercept, slope]","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"Now we solve it with the perturbed data","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"betahat = inv(transpose(A) * A) * transpose(A) * yy_perturbed\n\nbetahat ≈ A \\ yy_perturbed","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"We extract the intercept and slope of the fitted line","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"intercepthat, slopehat = betahat","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"and use that to build the fitted line","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"yy_hat = intercepthat .+ slopehat * xx ","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"which looks as follows","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"plt = plot(title=\"Synthetic data and least square fit\", titlefont=10, ylims=(0.0, 1.1 * (intercept + slope)))\nplot!(plt, xx, yy, label=\"unperturbed line\")\nscatter!(plt, xx, yy_perturbed, label=\"perturbed sample\")\nplot!(plt, xx, yy_hat, label=\"fitted line\")","category":"page"},{"location":"bayesian/linear_regression/#Bayesian-linear-regression-with-Turing.jl","page":"Many Ways to Linear Regression","title":"Bayesian linear regression with Turing.jl","text":"","category":"section"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"Now we use Turing.jl to fit via Bayesian inference. We start by defining a model, as a compound distribution.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"@model function regfit(x, y)\n    σ² ~ InverseGamma()\n    σ = sqrt(σ²)\n    intercept ~ Normal(0.0, 10.0)\n    slope ~ Normal(0.0, 10.0)\n\n    for i in eachindex(x)\n        v = intercept + slope * x[i]\n        y[i] ~ Normal(v, σ)\n    end\nend","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"Let's use the Hamiltonian Monte Carlo method to infer the parameters of the model.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"model = regfit(xx, yy_perturbed)\n\nchain = sample(model, HMC(0.05, 10), 4_000)","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"plot(chain)","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"We can access again the summary statistics for the Markov Chain generated by the sampler as follows.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"summarize(chain)","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"The whole values of the parameters computed along the chain are accessible via chain[[:intercept]].value, chain[[:slope]].value, and chain[[:σ²]].value","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"We can also directly compute the mean of each of them,","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"mean(chain, [:intercept, :slope, :σ²])","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"and use them to find the Bayesian fitted regression line","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"yy_bayes = mean(chain, :intercept) .+ mean(chain, :slope) * xx","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"plt = plot(title=\"Synthetic data and LSQ and Turing fit\", titlefont=10, ylims=(0.0, 1.1 * (intercept + slope)))\nscatter!(plt, xx, yy_perturbed, label=\"perturbed sample\")\nplot!(plt, xx, yy, label=\"unperturbed line\")\nplot!(plt, xx, yy_hat, label=\"LSQ fitted line\")\nplot!(plt, xx, yy_bayes, label=\"Bayesian fitted line\")","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"The least square and Bayesian fits are pretty close to each other:","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"extrema(yy_hat - yy_bayes)","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"Now it remains to compute and plot the credible intervals. First, we plot the ensemble of lines generated with the chain.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"plt = plot(title=\"Synthetic data and Turing posterior\", titlefont=10, ylims=(0.0, 1.1 * (intercept + slope)))\nplot!(plt, xx, yy_bayes, label=\"Bayesian fitted line\", color=2)\nfor (c, m) in eachrow(view(chain.value.data, :, 2:3, 1))\n    plot!(plt, xx, c .+ m * xx, alpha=0.01, color=2, label=false)\nend\nscatter!(plt, xx, yy_perturbed, label=\"perturbed sample\", color=1)","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"Now we use again the values computed along the chain to find the credible interval at each point x.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"quantiles = reduce(hcat, quantile([c + m * x for (c, m) in eachrow(view(chain.value.data, :, 2:3, 1))], [0.025, 0.975]) for x in xx)","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"With the computed quantiles, we are ready to plot the Bayesian fit with the credible interval.","category":"page"},{"location":"bayesian/linear_regression/","page":"Many Ways to Linear Regression","title":"Many Ways to Linear Regression","text":"plt = plot(title=\"Synthetic data and Turing fit with 95% credible interval\", titlefont=10, ylims=(0.0, 1.1 * (intercept + slope)))\nplot!(plt, xx, yy_bayes, ribbon=(yy_bayes .- view(quantiles, 1, :), view(quantiles, 2, :) .- yy_bayes), label=\"Bayesian fitted line\", color=2)\nscatter!(plt, xx, yy_perturbed, label=\"perturbed sample\", color=1)\nplot!(plt, xx, yy, label=\"unperturbed line\", color=1)","category":"page"},{"location":"generative/score_matching_aapo/#Score-matching-of-Aapo-Hyvärinen","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"","category":"section"},{"location":"generative/score_matching_aapo/#Introduction","page":"Score matching of Aapo Hyvärinen","title":"Introduction","text":"","category":"section"},{"location":"generative/score_matching_aapo/#Aim","page":"Score matching of Aapo Hyvärinen","title":"Aim","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Here we revisit the original score-matching method of Aapo Hyvärinen (2005) and apply it to fit a normal distribution to a sample of a univariate random variable just for illustrative purposes.","category":"page"},{"location":"generative/score_matching_aapo/#Motivation","page":"Score matching of Aapo Hyvärinen","title":"Motivation","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"The motivation is to revisit the original idea of Aapo Hyvärinen (2005), as a first step towards building a solid background on score-matching diffusion.","category":"page"},{"location":"generative/score_matching_aapo/#Background","page":"Score matching of Aapo Hyvärinen","title":"Background","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Generative score-matching diffusion methods use Langevin dynamics to draw samples from a modeled score function. It rests on the idea of Aapo Hyvärinen (2005) that one can directly fit the score function from the sample data, using a suitable implicit score matching loss function not depending on the unknown score function of the random variable. This loss function is obtained by a simple integration by parts on the explicit score matching objective function given by the expected square distance between the score of the model and score of the unknown target distribution, also known as the Fisher divergence. The integration by parts separates the dependence on the unknown target score function from the parameters of the model, so the fitting process (minimization over the parameters of the model) does not depend on the unknown distribution.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"It is worth noticing, in light of the main objective of score-matching diffusion, that the original work of Aapo Hyvärinen (2005) has no diffusion. It is a direct modeling of the score function in the original probability space. But this is a fundamental work.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"We also mention that the work of Aapo Hyvärinen (2005) uses the modified loss function to fit some very specific predefined models. There are three examples. In these examples, the gradient of the model can be computed somewhat more explicitly. There is no artificial neural network involved and no need for automatic differention (AD) (those were proposed in subsequent works, as we will see).","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"In a subsequent work, Köster and Hyvärinen (2010) applied the method to fit the score function from a model probability with log-likelihood obtained from a two-layer neural network, but in this case the gradient of the score function could still be expressed somehow explicitly.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"With that in mind, we illustrate this approach by fitting a Gaussian distribution to samples of a univariate radom variables.","category":"page"},{"location":"generative/score_matching_aapo/#The-score-function","page":"Score matching of Aapo Hyvärinen","title":"The score function","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"For the theoretical discussion, we denote the PDF of a multivariate random variable mathbfX, with values in mathbbR^d, dinmathbbN, by p_mathbfX(mathbfx) and the score function by","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    boldsymbolpsi_mathbfX(mathbfx) = boldsymbolnabla_mathbfxlog(p_mathbfX(mathbfx)) = left( fracpartialpartial x_i log(p_mathbfX(mathbfx))right)_i=1 ldots d","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"which is a vector field in mathbbR^d.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"The parametrized modeled score function is denoted by ","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    boldsymbolpsi(mathbfx boldsymboltheta) = boldsymbolnabla_mathbfxp(mathbfx boldsymboltheta) = left( fracpartialpartial x_j p(mathbfx boldsymboltheta)right)_j=1 ldots d","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"with parameter values boldsymboltheta.","category":"page"},{"location":"generative/score_matching_aapo/#Loss-functions-for-score-matching","page":"Score matching of Aapo Hyvärinen","title":"Loss functions for score matching","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"The score-matching method of Aapo Hyvärinen (2005) rests on the idea of rewriting the explicit score matching loss function J_mathrmESM(boldsymboltheta) in terms of the implicit score matching loss function J_mathrmISM(boldsymboltheta) and then approximating the latter by the empirical implicit score matching loss function tilde J_mathrmISMtilde p_0(boldsymboltheta), with","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"J_mathrmESM(boldsymboltheta) = J_mathrmISM(boldsymboltheta) + C approx tilde J_mathrmISMtilde p_0(boldsymboltheta) + C","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"for a constant C (with respect to the parameters boldsymboltheta of the model), so that the optimization process has (approximately) the same gradients","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"boldsymbolnabla_boldsymboltheta J_mathrmESM(boldsymboltheta) = boldsymbolnabla_boldsymboltheta J_mathrmISM(boldsymboltheta) approx boldsymbolnabla_boldsymboltheta tilde J_mathrmISMtilde p_0(boldsymboltheta)","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"More precisly, the idea of the score-matching method is as follows.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"1. Start with the explicit score matching","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Fit the model by minimizing the expected square distance between the score function of the model, boldsymbolpsi(mathbfx boldsymboltheta) and the actual score function boldsymbolpsi_mathbfX(mathbfx), which is termed explicit score matching (ESM),","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    J_mathrmESM(boldsymboltheta) = frac12int_mathbbR^d p_mathbfX(mathbfx) leftboldsymbolpsi(mathbfx boldsymboltheta) - boldsymbolpsi_mathbfX(mathbfx)right^2mathrmdmathbfx","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Since the score function is the gradient of the logpdf, this is connected with the Fisher divergence","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    F(p_mathbfX p_boldsymboltheta) = int_mathbbR^d p_mathbfX(mathbfx) left nabla_mathbfxlog p_mathbfX(mathbfx) - nabla_mathbfxlog p(mathbfx boldsymboltheta)right^2 mathrmdmathbfx","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"except that the modeled score function may not be exactly the gradient of a probability density function (the constraint of being the gradient of a function might not be valid for some models such as the usual neural networks).","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"2. Rewrite it with the implicit score matching","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Use integration by parts in the expectation to write that","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    J_mathrmESM(boldsymboltheta) = J_mathrmISM(boldsymboltheta) + C","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"where C is constant with respect to the parameters, so we only need to minimize tilde J_mathrmISM, given by","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    J_mathrmISM(boldsymboltheta) = int_mathbbR p_mathbfX(mathbfx) left( frac12leftboldsymbolpsi(mathbfx boldsymboltheta)right^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx boldsymboltheta) right)mathrmdmathbfx","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"which does not involve the unknown score function of mathbfX. This is called implicit score matching (ISM).","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Notice the two functions have the same gradient, hence the minimization is, theoretically, the same (apart from the approximation with the empirical distribution and the different round-off errors). This implicit score matching loss function, however, involves the gradient of the modeled score function, which might be expensive to compute.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"3. Approximate it with the empirical implicit score matching","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"In practice, the implicit score-matching loss function, which depends on the unknown p_mathbfX(mathbfx), is estimated via the empirical distribution, obtained from the sample data (mathbfx_n)_n=1^N. Thus, we minimize","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    tilde J_mathrmISMtilde p_0 =  frac1Nsum_n=1^N left( frac12boldsymbolpsi(mathbfx_n boldsymboltheta)^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx_n boldsymboltheta) right)","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"where the empirical distribution is given by","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    tilde p_0 = frac1N sum_n=1^N delta_mathbfx_n","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Therefore, we call this the empirical implicit score matching.","category":"page"},{"location":"generative/score_matching_aapo/#Concerning-the-gradient-in-the-loss-function","page":"Score matching of Aapo Hyvärinen","title":"Concerning the gradient in the loss function","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"As mentioned before, computing a derivative to form the loss function becomes expensive when combined with the usual optimization methods to fit a neural network, as they require the gradient of the loss function itself, i.e. the optimization process involves the gradient of the gradient of something. Because of that, other methods are developed, such as using kernel density estimation, auto-encoders, finite-differences, and so on. We will explore them in due course. For the moment, we will just sketch the proof of J_mathrmESM(boldsymboltheta) = J_mathrmISM(boldsymboltheta) + C and apply the method to models for which the gradient can be computed more explicitly.","category":"page"},{"location":"generative/score_matching_aapo/#Proof-that-J_{\\mathrm{ESM}}({\\boldsymbol{\\theta}})-J_{\\mathrm{ISM}}({\\boldsymbol{\\theta}})-C","page":"Score matching of Aapo Hyvärinen","title":"Proof that J_mathrmESM(boldsymboltheta) = J_mathrmISM(boldsymboltheta) + C","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"We separate the one-dimensional from the multi-dimensional case for the sake of clarity.","category":"page"},{"location":"generative/score_matching_aapo/#One-dimensional-case","page":"Score matching of Aapo Hyvärinen","title":"One-dimensional case","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"We start with the one-dimensional version of the proof from Aapo Hyvärinen (2005). In this case,","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    J_mathrmISM(boldsymboltheta) = int_mathbbR p_X(x) left( frac12psi(x boldsymboltheta)^2 + fracpartialpartial x psi(x boldsymboltheta) right)mathrmdx","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Since this is a one-dimensional problem, the score function is a scalar and we have","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    psi(x boldsymboltheta) - psi_X(x)^2 = psi(x boldsymboltheta)^2 - 2psi(x boldsymboltheta) psi_X(x) + psi_X(x)^2","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Thus","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    J_mathrmESM(boldsymboltheta) = frac12int_mathbbR p_X(x) left(psi(x boldsymboltheta)^2 - 2psi(x boldsymboltheta)psi_X(x)right)mathrmdx + C","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"where","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    C = frac12int_mathbbR p_X(x) psi_X(x)^2mathrmdx","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"does not depend on boldsymboltheta.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"For the mixed term, we use that the score function is","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    psi_X(x) = fracmathrmdmathrmdxlog(p_X(x))","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Differentiating the logarithm and using integration by parts, we find","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"beginalign*\n    -int_mathbbR p_X(x) psi(x boldsymboltheta)psi_X(x)mathrmdx  = -int_mathbbR p_X(x) psi(x boldsymboltheta)fracmathrmdmathrmdxlog(p_X(x))mathrmdx \n     = -int_mathbbR p_X(x) psi(x boldsymboltheta)frac1p_X(x)fracmathrmdmathrmdxp_X(x)mathrmdx \n     = -int_mathbbR psi(x boldsymboltheta)fracmathrmdmathrmdxp_X(x)mathrmdx \n     = int_mathbbR fracpartialpartial xpsi(x boldsymboltheta)p_X(x)mathrmdx\nendalign*","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Thus, we rewrite J_mathrmESM(boldsymboltheta) as","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    J_mathrmESM(boldsymboltheta) = int_mathbbR p_X(x) left(frac12psi(x boldsymboltheta)^2 + fracpartialpartial xpsi(x boldsymboltheta)right)mathrmdx + C","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"which is precisely J_mathrmESM(boldsymboltheta) = J_mathrmISM(boldsymboltheta) + C.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"For this proof to be justified, we need the constant to be finite,","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    C = frac12int_mathbbR p_X(x) psi_X(x)^2mathrmdx  infty","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"the score function of the model not to grow too fast at infinity,","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    psi(x boldsymboltheta) p_X(x) rightarrow 0 quad x rightarrow infty","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"for every value boldsymboltheta of the parameter; and the score function of the model to be smooth everywhere on the support of the distribution, again for every value of the parameter.","category":"page"},{"location":"generative/score_matching_aapo/#Multi-dimensional-case","page":"Score matching of Aapo Hyvärinen","title":"Multi-dimensional case","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"For the multi-dimensional version of the proof, we have","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    boldsymbolpsi(mathbfx boldsymboltheta) - boldsymbolpsi_mathbfX(mathbfx)^2 = boldsymbolpsi(mathbfx boldsymboltheta)^2 - 2boldsymbolpsi(mathbfx boldsymboltheta) cdot boldsymbolpsi_mathbfX(mathbfx) + boldsymbolpsi_mathbfX(mathbfx)^2","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Thus,","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    J_mathrmESM(boldsymboltheta) = frac12int_mathbbR p_mathbfX(mathbfx) left(boldsymbolpsi(mathbfx boldsymboltheta)^2 - 2boldsymbolpsi(mathbfx boldsymboltheta)boldsymbolpsi_mathbfX(mathbfx)right)mathrmdmathbfx + C","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"where","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    C = frac12int_mathbbR p_mathbfX(mathbfx) boldsymbolpsi_mathbfX(mathbfx)^2mathrmdmathbfx","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"does not depend on boldsymboltheta.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"For the middle term, we use explicitly that the score function is the gradient of the log of the pdf of the distribution,","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    boldsymbolpsi_mathbfX(mathbfx) = boldsymbolnabla_mathbfxlog(p_mathbfX(mathbfx))","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Differentiating the logarithm and using the Divergence Theorem for the integration by parts, we find","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"beginalign*\n    -int_mathbbR p_mathbfX(mathbfx) boldsymbolpsi(mathbfx boldsymboltheta) cdot boldsymbolpsi_mathbfX(mathbfx)mathrmdmathbfx  = -int_mathbbR p_mathbfX(mathbfx) boldsymbolpsi(mathbfx boldsymboltheta)boldsymbolnabla_mathbfxlog(p_mathbfX(mathbfx))mathrmdmathbfx \n     = -int_mathbbR p_mathbfX(mathbfx) boldsymbolpsi(mathbfx boldsymboltheta)frac1p_mathbfX(x)boldsymbolnabla_mathbfxp_mathbfX(mathbfx)mathrmdmathbfx \n     = -int_mathbbR boldsymbolpsi(mathbfx boldsymboltheta)boldsymbolnabla_mathbfxp_mathbfX(mathbfx)mathrmdmathbfx \n     = int_mathbbR boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx boldsymboltheta)p_mathbfX(mathbfx)mathrmdmathbfx\nendalign*","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Thus, we rewrite J_mathrmESM(boldsymboltheta) as","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    J_mathrmESM(boldsymboltheta) = int_mathbbR p_mathbfX(mathbfx) left(frac12boldsymbolpsi(mathbfx boldsymboltheta)^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx boldsymboltheta)right)mathrmdmathbfx + C","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"which is precisely J_mathrmESM(boldsymboltheta) = J_mathrmISM(boldsymboltheta) + C.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Similarly to the one-dimensional case, for this proof to be justified, we need the constant to be finite,","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    C = frac12int_mathbbR p_mathbfX(mathbfx) boldsymbolpsi_mathbfX(mathbfx)^2mathrmdmathbfx  infty","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"the score function of the model not to grow too fast at infinity,","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    boldsymbolpsi(mathbfx boldsymboltheta) p_mathbfX(mathbfx) rightarrow mathbf0 quad mathbfx rightarrow infty","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"for every value boldsymboltheta of the parameter; and the score function of the model to be smooth everywhere on the support of the distribution, again for every value of the parameter.","category":"page"},{"location":"generative/score_matching_aapo/#About-the-conditions-on-the-model-function","page":"Score matching of Aapo Hyvärinen","title":"About the conditions on the model function","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"The conditions on the smoothness and on the growth of the score function of the model distribution are usually fine for the common neural network models when using smooth and uniformly bounded activation functions. Piecewise smooth and/or growing activation functions might fail these requirements, depending on the unkown target distribution.","category":"page"},{"location":"generative/score_matching_aapo/#Numerical-example","page":"Score matching of Aapo Hyvärinen","title":"Numerical example","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"We exemplify the score-matching method fitting a Normal distribution to a synthetic univariate random variable X. We take as the target model a Gaussian mixture with the corresponding means relatively close to each other so that fitting a single Normal distribution to them is not too far off.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Say we have a sample x_n_n=1^N of X, where NinmathbbN.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"scatter(sample_points, one.(sample_points), xlims=extrema(xrange), ylims=(0, 2), axis=false, legend=false, grid=false, size=(600, 80)) # hide","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"The model is a score function of a Gaussian distribution mathcalN(mu sigma^2), whose PDF is","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    p_theta(x) = p(x mu sigma) = frac1sqrt2pisigma e^-frac12left(fracx - musigmaright)^2","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"with parameters boldsymboltheta = (mu sigma). The logpdf is","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    log p(x mu sigma) = -frac12left(fracx - musigmaright)^2 - logleft(sqrt2pisigmaright)","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"And the score function is","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    psi(x mu sigma) = fracpartialpartial x p(x mu sigma) = - fracx - musigma^2","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"The derivative of the score function, needed for the loss function, is constant with respect to x, but depends on the parameter sigma,","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    fracpartialpartial x psi(x mu theta) = -frac1sigma^2","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Thus, the implicit score matching loss becomes","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    J_mathrmISM(boldsymboltheta) = tilde J_mathrmISM(mu sigma) = int_mathbbR p_X(x) left( frac12left(fracx - musigma^2right)^2 - frac1sigma^2 right)mathrmdx","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"The approximation with the empirical distribution is","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"    tilde J_mathrmISMtilde p_0(boldsymboltheta) = tilde J_mathrmISMtilde p_0(mu sigma) = frac1N sum_n=1^N left( frac12left(fracx_n - musigma^2right)^2 - frac1sigma^2 right)","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Computing this loss for the given model yields the following plot over a reasonable range of values for mu and sigma.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"loss_function(mu, sigma) = mean( (xn - mu)^2 / sigma^4 / 2 - 1 / sigma^2 for xn in sample_points) # hide\nnothing # hide","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"surface(murange, sigmarange, cutitoff ∘ loss_function, title=\"Graph of the loss function\", titlefont=10, color=:vik) # hide","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"heatmap(murange, sigmarange, cutitoff ∘ loss_function, title=\"Heatmap of the loss function\", titlefont=10, color=:vik) # hide","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"In this example, the optimal parameters can be found numerically to be approximately mu = 32 and sigma = 15, or more precisely,","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"(j, i) = argmin([loss_function(mu, sigma) for sigma in sigmarange, mu in murange]).I # hide\nmu = murange[i] # hide\nsigma = sigmarange[j] # hide\nprintln(\"μ = $(round(mu, digits=4)), σ = $(round(sigma, digits=4))\") # hide","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"We do not actually perform a minimization in this case. We simply sweep the values computed for the previous two plots and find the location of the smallest one. This is good enough for this illustrative example.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"With that approximate minimizer, we have our modeled Normal distribution fitting the sample. The result can be visualized as follows.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"plot(plt) # hide","category":"page"},{"location":"generative/score_matching_aapo/#Conclusion","page":"Score matching of Aapo Hyvärinen","title":"Conclusion","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"This concludes our review of Aapo Hyvärinen (2005) and illustrates the use of empirical implicit score matching to model a univariate random variable by a closed-form model.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"The work of Aapo Hyvärinen (2005) has some more elaborate models, namely a i) multivariate Gaussian model; a ii) basic independent component analysis model; and an iii) overcomplete model for image data.","category":"page"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"As we mentioned earlier, our interest, however, is on modeling directly the score function using a neural network and for which the gradient needs to be handled properly. For that, other techniques were developed, which will be examined next.","category":"page"},{"location":"generative/score_matching_aapo/#References","page":"Score matching of Aapo Hyvärinen","title":"References","text":"","category":"section"},{"location":"generative/score_matching_aapo/","page":"Score matching of Aapo Hyvärinen","title":"Score matching of Aapo Hyvärinen","text":"Aapo Hyvärinen (2005), \"Estimation of non-normalized statistical models by score matching\", Journal of Machine Learning Research 6, 695-709\nU. Köster, A. Hyvärinen (2010), \"A two-layer model of natural stimuli estimated with score matching\", Neural. Comput. 22 (no. 9), 2308-33, doi: 10.1162/NECOa00010","category":"page"},{"location":"probability/convergence_notions/#Convergence-notions","page":"Convergence notions","title":"Convergence notions","text":"","category":"section"},{"location":"probability/convergence_notions/#Weak-convergence","page":"Convergence notions","title":"Weak convergence","text":"","category":"section"},{"location":"probability/convergence_notions/#Strong-convergence","page":"Convergence notions","title":"Strong convergence","text":"","category":"section"},{"location":"probability/convergence_notions/#Total-variation-norm","page":"Convergence notions","title":"Total variation norm","text":"","category":"section"},{"location":"probability/convergence_notions/#Weiserstein-distance","page":"Convergence notions","title":"Weiserstein distance","text":"","category":"section"},{"location":"sampling/box_muller/#Box-Muller-method","page":"Box-Muller transform","title":"Box-Muller method","text":"","category":"section"},{"location":"bayesian/mortality_tables/#Modeling-mortality-tables","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"","category":"section"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"In this section, we attempt to fit the Gompertz-Makeham and the Heligman-Pollard models to a selected mortality table.","category":"page"},{"location":"bayesian/mortality_tables/#The-Gompertz-Makeham-model","page":"Modeling mortality tables","title":"The Gompertz-Makeham model","text":"","category":"section"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"In the Gompertz-Makeham model, the force of mortality (akin to the hazard function) mu_x is given by","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"    mu_x = Ae^Bx + C","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"for age x. The force of mortality represents the instantaneous rate of mortality at a certain age x, in an annual basis.  It is closely related to the mortality rate q_x, which is the percentage of deaths in a population per year, which can be interpreted as the probability a person at an age x, in years, dies before reaching age x+1. Under certain assumptions, the two are related by","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"    mu_x = fracq_x1 - q_x qquad q_x = fracmu_x1 + mu_x","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"The terms A and B are associated with the Gompertz law Ae^Bx, while the term C is an additional term provided by Makeham, which combine to form the Gompertz-Makeham model.","category":"page"},{"location":"bayesian/mortality_tables/#The-Heligman-Pollard-model","page":"Modeling mortality tables","title":"The Heligman-Pollard model","text":"","category":"section"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"The Gompertz-Makeham model approximates reasonably well the force of mortality, especially the growth seen in adult years, but a better model is the Heligman-Pollard, that also approximates well the childhood and young groups and the eldery years. This model takes the form","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"    mu_x = A^(x + B)^C + D e^-E ln(xF)^2 + fracGH^x1 + KGH^x","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"for suitable coefficients A B C D E F G H K. It is common to see the Heligman-Pollard models with K=0, which is the main model suggested by the authors, but in the same paper they also discuss two extensions of the model, one of them being the one above.","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"We can clearly distinguish three terms in the model, with the first term, with parameters A B C, modeling the steep exponential decline in mortality in the early childhood years due in part to a relatively high degree of mortality in the newborn; the second term, with parameters D E F, representing the log-normal bump in mortality in the youth ages; and the last term, with parameters G H K, with the exponential growth at middle to older ages. Notice the last term follows the original Gompertz law (without the additional term due to Makeham).","category":"page"},{"location":"bayesian/mortality_tables/#A-mortality-table","page":"Modeling mortality tables","title":"A mortality table","text":"","category":"section"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"We start by loading the necessary packages","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"using Distributions, Turing, StatsPlots","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"We illustrate the modeling process with the United States 1997 mortality table. We removed the data from ages 0-1 and 100+ hoping for a better fit.","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"x = collect(1:99)\n# mortality rate\nqx = [\n    0.00055\n    0.00036\n    0.00029\n    0.00023\n    0.00021\n    0.00020\n    0.00019\n    0.00017\n    0.00015\n    0.00014\n    0.00014\n    0.00019\n    0.00028\n    0.00041\n    0.00055\n    0.00068\n    0.00078\n    0.00085\n    0.00089\n    0.00093\n    0.00098\n    0.00101\n    0.00101\n    0.00101\n    0.00100\n    0.00099\n    0.00100\n    0.00103\n    0.00108\n    0.00114\n    0.00119\n    0.00126\n    0.00133\n    0.00140\n    0.00149\n    0.00157\n    0.00167\n    0.00178\n    0.00192\n    0.00206\n    0.00222\n    0.00239\n    0.00257\n    0.00278\n    0.00300\n    0.00325\n    0.00352\n    0.00380\n    0.00411\n    0.00444\n    0.00482\n    0.00524\n    0.00571\n    0.00623\n    0.00685\n    0.00755\n    0.00833\n    0.00916\n    0.01005\n    0.01101\n    0.01208\n    0.01321\n    0.01439\n    0.01560\n    0.01679\n    0.01802\n    0.01948\n    0.02127\n    0.02338\n    0.02565\n    0.02799\n    0.03043\n    0.03297\n    0.03563\n    0.03843\n    0.04147\n    0.04494\n    0.04904\n    0.05385\n    0.05938\n    0.06555\n    0.07241\n    0.07990\n    0.08812\n    0.09653\n    0.10556\n    0.11539\n    0.12616\n    0.13802\n    0.15085\n    0.16429\n    0.17813\n    0.19250\n    0.20764\n    0.22354\n    0.23999\n    0.25653\n    0.27295\n    0.28915\n]\n# mx = - log.(1.0 .- qx) # force of mortality # roughly the same as below\nmx = qx ./ (1.0 .- qx) # force of mortality\nscatter(x, qx, yscale=:log10, legend=:topleft, label=\"qx\")\nscatter!(x, mx, yscale=:log10, legend=:topleft, label=\"mx\")","category":"page"},{"location":"bayesian/mortality_tables/#The-Gompertz-Makeham-model-in-Turing.jl","page":"Modeling mortality tables","title":"The Gompertz-Makeham model in Turing.jl","text":"","category":"section"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"First we start by defining the function that characterizes the Gompertz-Makeham model","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"function gompertz_makeham(x, p)\n    A, B, C = p\n    m = A * exp(B * x) + C\n    return m\nend","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Now we define the compound probability model, assigning Beta distributions to the parameters. But, as mentioned before, the initial prior is very important. It is not easy to get a good fit. So, first, we approximate by \"hand\", with trial and error, to get the following approximate fit:","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"let (A, B, C) = (0.00001, 0.1, 0.001)\n    m = A * exp.(B * x) .+ C\n    plt = plot(yscale=:log10, title=\"Force of mortality\", titlefont=10, xlabel=\"age\", ylabel=\"force of mortality\", legend=:topleft)\n    plot!(plt, x, m, label=\"Gompertz-Makeham hand-fit\")\n    scatter!(plt, x, mx, label=\"data\")\nend","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"With these values, we define the prior Beta distributions for the compound probability model with parameters that yield a mean near those values.","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"@model function gompertz_makeham_model(x, m)\n    A ~ Beta(2, 99998)\n    B ~ Beta(2, 18)\n    C ~ Beta(2, 1998)\n    σ² ~ InverseGamma()\n    σ = sqrt(σ²)\n    p = (A, B, C)\n\n    for i in eachindex(x)\n        y = gompertz_makeham(x[i], p)\n        m[i] ~ Normal(y, σ)\n    end\nend","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Now we instantiate the Turing model","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"model_gm = gompertz_makeham_model(x, mx)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"and fit it:","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"# chain_gm = sample(model_gm, HMC(0.05, 10), 40_000)\nchain_gm = sample(model_gm, NUTS(0.65), 5_000)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Here is the result of the MCMC:","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"plot(chain_gm)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"We can see the mean values of the parameters as follows","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"mean(chain_gm)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"The mean fit is given by","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"m_gm = [gompertz_makeham(xi, mean(chain_gm, [:A, :B, :C]).nt.mean) for xi in x]","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"and we plot it","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"plt = plot(yscale=:log10, title=\"Force of mortality\", titlefont=10, xlabel=\"age\", ylabel=\"force of mortality\", legend=:topleft)\nplot!(plt, x, m_gm, label=\"Gompertz-Makeham fit\")\nscatter!(plt, x, mx, label=\"data\")","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"It remains to compute the 95% credible interval,","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"quantiles_gm = reduce(\n    hcat,\n    quantile(\n        [\n            gompertz_makeham(xi, (A, B, C)) for (A, B, C) in eachrow(view(chain_gm.value.data, :, 1:3, 1))\n        ],\n        [0.025, 0.975]\n        )\n    for xi in x\n)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"and plot it","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"plt = plot(yscale=:log10, title=\"Force of mortality\", titlefont=10, xlabel=\"age\", ylabel=\"force of mortality\", legend=:topleft)\nplot!(plt, x, m_gm, ribbon=(m_gm .- view(quantiles_gm, 1, :), view(quantiles_gm, 2, :) .- m_gm), label=\"Gompertz-Makeham fit\")\nscatter!(plt, x, mx, label=\"data\")","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Notice how the function with the means of the parameters is outside the quantiles, which is based on the function values of the parameter samples. Let's check the last portion of the ensemble.","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"plt = plot(yscale=:log10, title=\"Force of mortality\", titlefont=10, xlabel=\"age\", ylabel=\"force of mortality\", legend=nothing)\nplot!(plt, x, m_gm, label=\"Bayesian fitted line\", color=2)\nfor (A, B, C) in eachrow(view(chain_gm.value.data, 4500:5000, 1:3, 1))\n    plot!(plt, x, x -> gompertz_makeham(x, (A, B, C)), alpha=0.1, color=2, label=false)\nend\nscatter!(plt, x, mx, color=1)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Let's look at just a few samples to have a better look at the dependence of the function on the sampled values:[off]","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"[off]: How often do you see x mapsto f_mathrmmean(p)(x) fall off the credible interval of the family x mapsto f_p(x)_p, where p is the set of parameters? It happens.","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"plt = plot(yscale=:log10, title=\"Force of mortality\", titlefont=10, xlabel=\"age\", ylabel=\"force of mortality\", legend=nothing)\nplot!(plt, x, m_gm, label=\"Bayesian fitted line\", color=2)\nfor (A, B, C) in eachrow(view(chain_gm.value.data, 1000:50:2000, 1:3, 1))\n    plot!(plt, x, x -> gompertz_makeham(x, (A, B, C)), alpha=0.4, color=3, label=false)\nend\nscatter!(plt, x, mx, color=1)","category":"page"},{"location":"bayesian/mortality_tables/#The-Heligman-Pollard-in-Turing.jl","page":"Modeling mortality tables","title":"The Heligman-Pollard in Turing.jl","text":"","category":"section"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Now we consider the Heligman-Pollard model.","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"First we start by defining the function that characterizes the model:","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"function heligman_pollard(x, p)\n    A, B, C, D, E, F, G, H, K = p\n    m = A^((x + B)^C) + D * exp(-E * log(x / F)^2) + (G * H^x) / (1 + K * G * H^x)\n    return m\nend","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Now we define the compound probability model. As mentioned before, the initial prior is very important. We start with numbers of the order of those given in the original article by Heligman and Pollard. They considered a number of examples, but, as a starting point, we borrow only the data from the 1970-1972 period, separated by gender:","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Parameter Males 1970-72 Females 1970-1972\nA 0.00160 0.00142\nB 0.00112 0.0350\nC 0.1112 0.1345\nD 0.00163 0.00038\nE 16.71 21.86\nF 20.03 18.27\nG 0.0000502 0.0000507\nH 1.1074 1.0937\nK 2.416 -2.800","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"The difference in the sign of K between the male and female populations is justified by the difference in mortality for the elderly, although the data showed in the article both look more like in the description of the male mortality. Let's see how an approximation of that looks like, keeping a positive sign for K because of this observation.","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"let (A, B, C, D, E, F, G, H, K) = (0.0015, 0.018, 0.012, 0.001, 19.0, 19.0, 0.00005, 1.1, 1.0)\n    m = [heligman_pollard(xi, (A, B, C, D, E, F, G, H, K)) for xi in x]\n    plt = plot(yscale=:log10, title=\"Force of mortality\", titlefont=10, xlabel=\"age\", ylabel=\"force of mortality\", legend=:topleft)\n    plot!(plt, x, m, label=\"Heligman-Pollard hand-fit\")\n    scatter!(plt, x, mx, label=\"data\")\nend","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Ok, that seems like a reasonable starting point. So we choose the following priors for each parameter:","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Parameter prior mean\nA Beta(15, 9985) 0.0015\nB Beta(18, 982) 0.018\nC Beta(12, 988) 0.012\nD Beta(2, 1998) 0.001\nE Gamma(38, 0.5) 19.0\nF Gamma(38, 0.5) 19.0\nG Beta(5, 99995) 0.00005\nH Gamma(2, 0.5) 1.0\nK Gamma(2, 0.5) 1.0","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"But these turned out not to be so good. We either look for better informative priors or use slightly less informative priors. We fiddle a little bit with the parameters to get the following improvement.","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"let (A, B, C, D, E, F, G, H, K) = (0.0003, 0.02, 0.08, 0.0008, 15.0, 20.0, 0.00005, 1.1, 1.0)\n    m = [heligman_pollard(xi, (A, B, C, D, E, F, G, H, K)) for xi in x]\n    plt = plot(yscale=:log10, title=\"Force of mortality\", titlefont=10, xlabel=\"age\", ylabel=\"force of mortality\", legend=:topleft)\n    plot!(plt, x, m, label=\"Heligman-Pollard hand-fit\")\n    scatter!(plt, x, mx, label=\"data\")\nend","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Based on that, we choose the following priors:","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"@model function heligman_pollard_model(x, m)\n    A ~ Beta(3, 9997) # Beta(1, 660) # Beta(15, 9985)\n    B ~ Beta(2, 98) # Beta(1, 50) # Beta(18, 982)\n    C ~ Beta(8, 92) # Beta(12, 988)\n    D ~ Beta(8, 9992) # Beta(1, 999) # Beta(2, 1998)\n    E ~ Gamma(30, 0.5) # Gamma(19, 1) # Gamma(38, 0.5)\n    F ~ Gamma(40, 0.5) # Gamma(19, 1) # Gamma(38, 0.5)\n    G ~ Beta(5, 99995) # Beta(1, 19999) # Beta(5, 99995)\n    H ~ Gamma(2.2, 0.5) # Gamma(1, 1) # Gamma(2, 0.5)\n    K ~ Gamma(2.0, 0.5) # Gamma(1, 1) # Gamma(2, 0.5)\n    σ² ~ InverseGamma()\n    σ = sqrt(σ²)\n\n    for i in eachindex(x)\n        y = A ^ ((x[i] + B) ^ C) + D * exp( - E * (log(x[i]) - log(F)) ^ 2) + G * H ^ (x[i]) # / (1 + K * G * H ^ (x[i]) )\n        m[i] ~ Normal(y, σ)\n    end\nend","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Now we instantiate the Heligman-Pollard Turing model","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"model_hp = heligman_pollard_model(x, mx)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"and fit it:","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"# chain_hp = sample(model_hp, HMC(0.05, 10), 4_000) # Pure HMC didn't converge\n# chain_hp = sample(model_hp, MH(), 5_000) # Metropolis-Hasting didn't converge\n# chain_hp = sample(model_hp, Gibbs(MH(:A, :B, :C), MH(:D, :E, :F), HMC(0.65, 5, :G, :H, :K)), 5_000) # I am afraid I am not getting this right\nchain_hp = sample(model_hp, NUTS(0.85), 5_000)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Here is the result of the MCMC:","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"plot(chain_hp)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"We can see the mean values of the parameters as follows","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"mean(chain_hp)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"The mean fit is given by","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"m_hp = [heligman_pollard(xi, mean(chain_hp, [:A, :B, :C, :D, :E, :F, :G, :H, :K]).nt.mean) for xi in x]","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"and we plot it","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"plt = plot(yscale=:log10, title=\"Force of mortality\", titlefont=10, xlabel=\"age\", ylabel=\"force of mortality\", legend=:topleft)\nplot!(plt, x, m_hp, label=\"Heligman-Pollard fit\")\nscatter!(plt, x, mx, label=\"data\")","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"It remains to compute the 95% credible interval,","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"quantiles_hp = reduce(\n    hcat,\n    quantile(\n        [\n            heligman_pollard(xi, p) for p in eachrow(view(chain_hp.value.data, :, 1:9, 1))\n        ],\n        [0.025, 0.975]\n        )\n    for xi in x\n)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"and plot it","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"plt = plot(yscale=:log10, title=\"Force of mortality\", titlefont=10, xlabel=\"age\", ylabel=\"force of mortality\", legend=:topleft)\nplot!(plt, x, m_hp, ribbon=(m_hp .- view(quantiles_hp, 1, :), view(quantiles_hp, 2, :) .- m_hp), label=\"Heligman-Pollard fit\")\nscatter!(plt, x, mx, label=\"data\")","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Notice how the function with the means of the parameters is again outside the quantiles, which is based on the function values of the parameter samples. Let's check the last portion of the ensemble:","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"plt = plot(yscale=:log10, title=\"Force of mortality\", titlefont=10, xlabel=\"age\", ylabel=\"force of mortality\", legend=nothing)\nplot!(plt, x, m_hp, label=\"Bayesian fitted line\", color=2)\nfor p in eachrow(view(chain_hp.value.data, 4500:5000, 1:9, 1))\n    plot!(plt, x, x -> heligman_pollard(x, p), alpha=0.1, color=2, label=false)\nend\nscatter!(plt, x, mx, color=1)","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"Let's look at just a few samples to have a better look at the dependence of the function on the sampled values:","category":"page"},{"location":"bayesian/mortality_tables/","page":"Modeling mortality tables","title":"Modeling mortality tables","text":"plt = plot(yscale=:log10, title=\"Force of mortality\", titlefont=10, xlabel=\"age\", ylabel=\"force of mortality\", legend=nothing)\nplot!(plt, x, m_hp, label=\"Bayesian fitted line\", color=2)\nfor p in eachrow(view(chain_hp.value.data, 1000:50:2000, 1:9, 1))\n    plot!(plt, x, x -> heligman_pollard(x, p), alpha=0.4, color=3, label=false)\nend\nscatter!(plt, x, mx, color=1)","category":"page"},{"location":"sampling/langevin_sampling/#Langevin-sampling","page":"Langevin sampling","title":"Langevin sampling","text":"","category":"section"},{"location":"sampling/langevin_sampling/#Introduction","page":"Langevin sampling","title":"Introduction","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"One of the cornerstones of score-based generative models is the method of sampling from the score function of a distribution via Langevin dynamics. Our aim here is to review the method of sampling via Langevin dynamics based on the score function.","category":"page"},{"location":"sampling/langevin_sampling/#Langevin-dynamics","page":"Langevin sampling","title":"Langevin dynamics","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The velocity of a particle moving in a fluid has long been known to be reduced by friction forces with the surrounding fluid particles. For relatively slowly moving particles, when the surrouding fluid flow is essentially laminar, this friction force is regarded to be proportional to the velocity, in what is known as the Stokes law. When the motion is relatively fast and the flow around the particle is turbulent, this friction tends to be proportional to the square of the velocity.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"If this were the only force, though, a particle initially at rest on a still fluid would remain forever at rest. That is not the case, as observed by the botanist Robert Brown (1828). His observations led to what is now known as Brownian motion, and which is formally modeled as a Wiener process (see e.g. Einstein (1905) and Mörters and Peres (2010)). A Wiener process describes the (random) position of a particle which is initially at rest and is put into motion by the erratic collisions with the nearby fluid particles.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"When in motion, both forces are actually in effect, a deterministic one dependent on the velocity and a random one due to irregular collisions. In a short time scale, the inertia forces are negligible and we recover the Brownian motion. For larger times scales, the Langevin is more appropriate since it takes both forces into account.","category":"page"},{"location":"sampling/langevin_sampling/#Langevin-equation","page":"Langevin sampling","title":"Langevin equation","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"We start with the Langevin equation for a free particle and then introduce the equation with a potential field.","category":"page"},{"location":"sampling/langevin_sampling/#Langevin-equation-for-a-free-particle","page":"Langevin sampling","title":"Langevin equation for a free particle","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"In the Langevin model, both viscous and random collision forces affect the momentum of the particle (Paul Langevin (1908)). In this model, the position x_t of a particle of mass m at time t is given by","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    m ddot x_t = - a mu dot x_t + alpha xi_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"where a is a caractheristic length of the particle; mu is the molecular viscosity, associated with the frictional drag force assumed proportional to the velocity; and alpha is a proportionality coefficient associated with a white noise term xi_t modeling the random collisions with the fluid particles, i.e. xi_t is a Gaussian (distribution) process with zero mean, mathbbExi_t = 0 and delta correlated, mathbbExi_txi_s = delta_0(t - s) The two coefficients are connected by","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    alpha = sqrt2amu k_B T","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"where k_B is the Boltzmann constant and T is the temperature of the fluid.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The white noise is highly irregular, so the equation above is made rigorous with the theory of stochastic differential equations when casted in the form","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mathrmdY_t = -nu Y_t mathrmdt + sigma mathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"where Y_t_t is a stochastic processes representing the evolution of the velocity in time; nu = amu  m is a kinematic damping factor (with dimension 1texttttime); sigma=alpham is called the diffusion parameter; and W_t_t is a Wiener process, whose formal derivative represents the white noise. The solution Y_t_t of the equation above is known as the Ornstein-Uhlenbeck stochastic process. The relation between sigma and nu becomes","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    sigma = sqrtfrac2nu k_B Tm","category":"page"},{"location":"sampling/langevin_sampling/#Langevin-equation-with-an-energy-potential","page":"Langevin sampling","title":"Langevin equation with an energy potential","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"This is all fine for a nearly free particle, affected only by friction and by smaller nearby particles. More generally, one may also consider a particle under an extra force field with potential U=U(x). In this case, the equation is modified to","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    m ddot x_t = - amu dot x_t - mnabla U(x_t) + alpha xi_t","category":"page"},{"location":"sampling/langevin_sampling/#Rigorous-stochastic-formulation","page":"Langevin sampling","title":"Rigorous stochastic formulation","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The rigorous stochastic formulation takes the form of a system,","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    begincases\n        mathrmdX_t = Y_tmathrmdt \n        mathrmdY_t = (-nu Y_t - nabla U(X_t))mathrmdt + sigma mathrmdW_t\n    endcases","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"These are called the Langevin equation or Langevin system.","category":"page"},{"location":"sampling/langevin_sampling/#Physical-dimensions","page":"Langevin sampling","title":"Physical dimensions","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"We want to check the physical dimensions of the terms in the Langevin equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    m ddot x_t = - a mu dot x_t - mnabla U(x_t) + alpha xi_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"where","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    alpha = sqrt2amu k_B T","category":"page"},{"location":"sampling/langevin_sampling/#Basic-physical-dimensions","page":"Langevin sampling","title":"Basic physical dimensions","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"We denote the physical dimensions by","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    quad M = texttt mass quad L = texttt length quad T = texttt time quad Theta = texttt temperature ","category":"page"},{"location":"sampling/langevin_sampling/#Physical-dimension-of-variables-and-parameters","page":"Langevin sampling","title":"Physical dimension of variables and parameters","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The variable x_t denotes position at time t hence its physical dimension, x_t is length,","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    x_t = L","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The time derivative has dimension of one over time, i.e.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    leftfracmathrmdmathrmd tright = frac1T","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The Dirac delta delta_0(cdot) in the definition of white noise is the (time) derivative of the Heaviside function H(t) = chi_0 infty)(t) The Heaviside is adimensional, so","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    delta_0 = frac1T","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Since the dimension of the correlation is","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    leftmathbbExi_txi_sright = xi_t^2","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"and","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    xi_t^2 = leftmathbbExi_txi_sright = leftdelta_0right = frac1T","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"we find that","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    xi_t = frac1sqrtT","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"For consistency reasons, the dimension of mu has to be","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mu = fracMLT","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The potential field is the potential energy over the mass of the particle under the potential field, thus","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    U(x) = fracL^2T^2","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The dimension of the Boltzmann constant is that of energy over temperature, i.e.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    k_B = fracML^2T^2Theta","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"With that, the dimension of alpha becomes","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    alpha = sqrtamu k_B T = sqrtL fracMLT fracML^2T^2Theta Theta = sqrtfracM^2L^2T^3 = fracMLT^32","category":"page"},{"location":"sampling/langevin_sampling/#Physical-dimensions-of-the-Langevin-equation","page":"Langevin sampling","title":"Physical dimensions of the Langevin equation","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Now we check that all the terms in the Langevin equation have the same physical dimension of force, since it is an expression of Newton's second law of motion. Indeed, the first term has dimension","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mddot x_t = m leftfracmathrmd^2mathrmdt^2right x_t = M frac1T^2 L = fracMLT^2","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The second term has dimension","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    amu dot x_t = a mu leftfracmathrmdmathrmdtright x_t = L fracMLT frac1T L = fracMLT^2","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The potential term has dimension","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mnabla U(x_t) = M frac1L fracL^2T^2 = fracMLT^2","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The last term has dimension","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    alpha xi_t = alpha xi_t = fracMLT^32frac1T^12 = fracMLT^2","category":"page"},{"location":"sampling/langevin_sampling/#Physical-dimension-of-the-stochastic-equation-for-the-random-velocity","page":"Langevin sampling","title":"Physical dimension of the stochastic equation for the random velocity","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Looking now at the equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mathrmdY_t = -nu Y_t mathrmdt + sigma mathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"we first observe that","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    nu = leftfracamumright = L fracMLT frac1M = fracLT","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"and","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    sigma = leftfracalphamright = fracMLT^32 frac1M = fracLT^32","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Since the W_t sim mathcalN(0 t) = sqrttmathcalN(0 1) we see that","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mathrmdW_t = W_t = sqrtT","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"This is consistent with the idea that the white noise xi_t_t is formally the time derivative of the Wiener process W_t_t ","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Now, we see that","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mathrmdY_t = Y_t = fracLT","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"while","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    nu Y_t mathrmdt = frac1T fracLT T = fracLT","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"and","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    sigma mathrmdW_t = fracLT^32 T^12 = fracLT","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"establishing the consistency of the equation in terms of physical dimension.","category":"page"},{"location":"sampling/langevin_sampling/#The-overdamped-limit","page":"Langevin sampling","title":"The overdamped limit","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"In the Langevin equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    m ddot x_t = - a mu dot x_t - mnabla U(x_t) + alpha xi_t qquad alpha = sqrt2amu k_B T","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"the term m ddot x_t represents the inertial force. When the motion is relatively slow, this inertia might be negligible when compared with the drag force. Dropping this term yields the equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    0 = - nu dot x_t - nabla U(x_t) + alpha xi_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"which we can write in the usual form of the overdamped Langevin equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mu dot x_t = - nabla U(x_t) + alpha xi_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The corresponding stochastic system reduces to a single equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    nu mathrmdX_t = - nabla U(X_t)mathrmdt + sigma mathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"For this approximation to be valid, we look at the ratio between the inertial force mddot x_t and the damping force -amu dot x_t We have","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    fracmddot x_tamu dot x_t sim frac1nufracDelta Y_tY_tDelta t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The inertial force is negligible when","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    fracDelta Y_tY_t ll nu Delta t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"which can be interpreted as when the relative variations Delta Y_tY_t in velocity are relatively small or when the damping is relatively large. This is consistent with saying that we obtain the first order equation in the overdamped regime.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"In the absence of a force field U=U(x), we are left with","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    nu mathrmdX_t = sigma mathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"which is the Brownian motion equation, with the solution","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    X_t = fracsigmanu = sqrtfrac2k_B Tamu W_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"In this way, we recover the Brownian motion from the Langevin equation as the overdamped limit without a force field.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Notice the right hand side above has indeed the dimension of length,","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    leftsqrtfrac2k_B Tamu W_t right = sqrtfracML^2Theta T^2Theta frac1LfracLTM sqrtT = sqrtfracL^2T sqrtT = L","category":"page"},{"location":"sampling/langevin_sampling/#Adimensionalization","page":"Langevin sampling","title":"Adimensionalization","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"With a proper rescaling, we obtain the adimensional overdamped Langevin equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mathrmdtilde X_t = - nabla_tilde xtilde U(tilde X_tilde t)mathrmdtilde t + sqrt2mathrmdtilde W_tilde t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"We do the details of this change of variables below. See also Section 6.5 of Grigorios Pavliotis (2014).","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"We start with the equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    nu mathrmdX_t = - nabla U(X_t)mathrmdt + sigma mathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"and divide it by anu so that","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    frac1amathrmdX_t = - frac1anunabla U(X_t)mathrmdt + fracsigmaanu mathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Since sigma = sqrt2nu k_B T  m and nu = amu  m we write","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    fracsigmaanu = fracsqrt2nu k_B T  manu = sqrtfrac2nu k_B Ta^2 m nu^2 = sqrtfrac2 k_B Ta^2 m nu = sqrtfrac2k_B Ta^3mu","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Thus,","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    frac1amathrmdX_t = - frac1anunabla U(X_t)mathrmdt + sqrtfrac2k_B Ta^3mumathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The time and length scales are changed to","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    tilde t = nu t quad tilde x = fracxa","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Accordingly, we set","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    tilde X_tilde t = frac1a tilde X_tilde t  nu = frac1a X_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Thus,","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    frac1a mathrmdX_t = mathrmdtilde X_tilde t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"We also define the adimensional potential","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    tilde U(tilde x) = frac1a^2nu^2U(atilde x) = frac1a^2nu^2 U(x)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Thus,","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    - frac1anunabla_x U(X_t)mathrmdt = - frac1anu nabla_x left(a^2nu^2 tilde Uleft(fracX_taright) right)fracmathrmdtilde tnu = - anabla_x left( tilde Uleft(fracX_taright)right)mathrmdtilde t = - anabla_tilde x tilde U(tilde X_tilde t)frac1amathrmdtilde t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"so that","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    - frac1anunabla_x U(X_t)mathrmdt = - nabla_tilde x tilde U(tilde X_tilde t)mathrmdtilde t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Finally we set","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    tilde W_tilde t = sqrtfrack_B Ta^3mu W_tilde t  nu = sqrtfrack_B Ta^3mu W_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"so that","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    sqrtfrac2k_B Ta^3mu mathrmdW_t = sqrt2mathrmdtilde W_tilde t ","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Notice that","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    left sqrtfrac2k_B Ta^3mu right = sqrtfracML^2Theta T^2 ThetafracLTL^3 M = sqrtfrac1T qquad leftmathrmdW_tright = sqrtT","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"so tilde W_tilde t is indeed adimensional.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Combining the terms, we obtain the adimensional equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mathrmdtilde X_tilde t = - nabla_tilde x tilde U(tilde X_tilde t)mathrmdtilde t + sqrt2mathrmdtilde W_tilde t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The factor sqrt2 could have been included in the definition of tilde W_tilde t but it was left out because it will compensate the one-half term coming from the Itô formula and both eventually cancel out when computing the invariant distribution.","category":"page"},{"location":"sampling/langevin_sampling/#The-limit-as-\\nu-\\rightarrow-\\infty.","page":"Langevin sampling","title":"The limit as nu rightarrow infty","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"If one does the rescaling above in the full equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    m ddot x_t = - amu dot x_t - mnabla U(x_t) + alpha xi_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"one obtains the overdamped limit exactly when taking the limit nu rightarrow infty We leave this as an exercise.","category":"page"},{"location":"sampling/langevin_sampling/#The-asymptotic-distribution","page":"Langevin sampling","title":"The asymptotic distribution","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"In the inviscid deterministic case, the Langevin equation reads","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    m ddot x_t = - m nabla U(x_t)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"and the level sets","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    left(x v) frac12v^2 + U(x) = cright","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"of the total energy are invariant by the solution group. In the viscous deterministic case","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    m ddot x_t = - amu dot x_t - mnabla U(x_t)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"the solutions tend to the equilibria states min_x U(x), or more precisely to the variety","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    (x v) v = nabla U(x) = 0","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"In the full viscous, stochastic equation, the tendency to go to the equilibria is balanced by the diffusion, and the system tends to a stochastic equilibrium represented by a distribution with probability density function","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    p_U(x v) = frac1Z e^-fracmk_B Tleft( fracv^22 + U(x)right)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"where Z is a normalization constant to have p_U(x v) integrate to 1.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"A similar behavior occurs in the overdamped Langevin equation, for which the equilibrium distribution is given by","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    p_U(x) = frac1Z_0 e^-fracmk_B T U(x)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"where Z_0 is another normalization constant.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"We now discuss in more details the equilibrium distribution in the overdamped equation. For that, we look at the Fokker-Plank equation for","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    numathrmd X_t = - nabla U(X_t)mathrmdt + sqrtfrac2nu k_B TmmathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"In general, a stochastic differential equation of the form","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mathrmd X_t = mu(t X_t) mathrmdt + sigma(t X_t)mathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"is associated with the Fokker-Planck equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    fracpartialpartial t p(t x) = - nabla_x cdot left(mu(t x) p(t x)right) + frac12 Delta_x left( sigma(t x)^2 p(t x) right)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"where p(t x) is such that x mapsto p(t x) is the probability density function of the solution X_t, i.e. the marginal distribution at time t of the process X_t_t. For the overdamped Langevin equation above, the Fokker-Planck equation takes the form","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    fracpartialpartial t p(t x) = frac1nunabla_x cdot left(nabla U(x) p(t x)right) + frack_B Tnu mDelta_x p(t x)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"which can also be written as","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    fracpartialpartial t p(t x) = frac1nunabla_x cdot left(nabla U(x) p(t x) + frack_B Tmnabla_x p(t x) right)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"At the equilibrium, the probability density function p(t x) = p_infty(x) is independent of time and satisfies","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    nabla_x cdot left(nabla U(x) p_infty(x) + frack_B Tmnabla_x p_infty(x) right) = 0","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"In the one-dimensional case, this means that","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    fracpartial U(x)partial x p_infty(x) + frack_B Tmfracpartial p_infty(x)partial t = C","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"for some constant C. This can be written in the form of the first order differential equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    fracpartial p_infty(x)partial t + fracmk_B Tfracpartial U(x)partial x p_infty(x) = fracmk_B T C","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"This equation can be solved using the integrating factor","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    e^fracmk_B T U(x)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"But assuming that the terms on the left hand side of the first order differential equation vanish when x rightarrow infty, the constant C must be zero. In this case, the solution simplifies to","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    p_infty(x) = C_0 e^-fracmk_B T U(x)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"for some other constant C_0, which we may write as C_0 = 1Z_0 and obtain the expression","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    p_infty(x) = frac1Z_0 e^-fracmk_B T U(x)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"The constant Z_0 is a normalization factor to yield that p(x) is a proper probability density function, with total mass 1, i.e.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    Z_0 = int_-infty^infty e^-fracmk_B T U(x)mathrmdx","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"One can check that the PDF above is also a solution in the multi-dimensional case.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"When the potential U=U(x) grows sufficiently rapidly as xrightarrow infty, this distribution is the unique equilibrium. In the case of thermodynamics, this corresponds to thermodynamic equilibrium and this is known as the Boltzmann distribution. The condition that the potential grows sufficiently rapidly at infinite means that the potential well is deep enough to confine the particle.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Abstracting away from the physical model and considering the overdamped Langevin equation in the form","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mathrmd X_t = - nabla U(X_t)mathrmdt + sqrt2gammamathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"for some constant gamma  0, then the Fokker-Planck equation reads","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    fracpartialpartial t p(t x) = nabla_x cdot left(nabla U(x) p(t x)right) + gammaDelta_x p(t x)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"and the stationary distribution takes the form","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    p_infty(x) = frac1Z_0 e^-fracU(x)gamma","category":"page"},{"location":"sampling/langevin_sampling/#Convergence-to-the-asymptotic-distribution","page":"Langevin sampling","title":"Convergence to the asymptotic distribution","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"There are many rigorous results concerning the convergence to the equilibrium distribution, discussing conditions for the convergence, metrics, and rate of convergence. We will discuss them in more details in due course.","category":"page"},{"location":"sampling/langevin_sampling/#Sampling-from-the-score-function-via-Langevin-dynamics","page":"Langevin sampling","title":"Sampling from the score function via Langevin dynamics","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Now, suppose we take for the potential U=U(x) minus a multiple of the logpdf of a random variable X with probability density function p_X(x) up to an arbitrary constant, i.e.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    U(x) = - gamma log p_X(x) + C","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"for some constants gamma and C. The score function is connected to the gradient of the potential by","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    psi_X(x) = nabla_x log p_X(x) = - frac1gamma nabla_x U(x)","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"In this case, we can write the PDF as","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    p_X(x) = e^log p_X(x) = e^-U(x)gamma + Cgamma = frac1Z e^-U(x)gamma","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"for a (normalizing) constant Z = e^-Cgamma. Then we see that the PDF p_X(x) is exactly the equilibrium of the Langevin equation","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mathrmdX_t = -nabla U(X_t)mathrmdt + sqrt2gammamathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"which can be written as","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"    mathrmdX_t = gammapsi_X(X_t)mathrmdt + sqrt2gammamathrmdW_t","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"This lead to a sampling method to draw samples from a distribution using its score function, as introduced by Gareth Roberts and Richard Tweedie (1996).","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"As mentioned above, questions about the conditions for the convergence, rate of converge and convergence metric are of great importance, and they are also important for sampling purposes. Other relevant question concern the stability of the equilibrium solution, when for instance an approximate score function is used. This is also relevant when the modeled score function (say via a neural network) might even not be exactly the gradient of a potential. We will leave these questions to another opportunity.","category":"page"},{"location":"sampling/langevin_sampling/#Numerical-example","page":"Langevin sampling","title":"Numerical example","text":"","category":"section"},{"location":"sampling/langevin_sampling/#One-dimensional-numerical-example","page":"Langevin sampling","title":"One-dimensional numerical example","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"We first illustrate the Langevin sampling by drawing samples for a univariate Gaussian mixture distribution.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Markdown.parse(\"\"\"The Gaussian mixture distribution is composed of Normal distributions ``\\\\mathcal{N}($(ns[1][1]), $(ns[1][2]))`` and ``\\\\mathcal{N}($(ns[2][1]), $(ns[2][2]))``, with weights $(ps[1]) and $(ps[2]), respectively. The PDF and score functions look as follows.\"\"\") # hide\nplt1 = plot(xrange, x -> pdf(prob, x), title=\"PDF of the Gaussian mixture\", titlefont=10, legend=false) # hide\nplt2 = plot(xrange, x -> -logpdf(prob, x), title=\"Potential \\$-\\\\operatorname{logpdf}\\$ of the Gaussian mixture\", titlefont=10, legend=false) # hide\nplt3 = plot(xrange, x -> gradlogpdf(prob, x), title=\"Score function of the Gaussian mixture\", titlefont=10, legend=false) # hide\nplot(plt1, plt2, plt3, size=(600, 900), layout=(3, 1)) # hide","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Markdown.parse(\"\"\"Now we draw samples from it using the overdamped Langevin equation with ``\\\\gamma = $gamma``. We start with samples from a normal distribution ``\\\\mathcal{N}($mu0, $sigma0^2)`` and evolve them according to the equation, from the initial time ``t_0 = $t0`` up to time ``t_f = $tf``.\"\"\") # hide","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Here is tx plot of the ensemble of solutions of the stochastic overdamped Langevin equation.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"plot(tt, xt, legend=false) # hide","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"We obtain the following histogram at the final time:","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"histogram(xt[end, :], nbins=40, xlims=extrema(xrange), label=\"normalized histogram\", normalize=true) # hide\nplot!(xrange, pt[end, :], label=\"Langevin evolved PDF\") # hide\nplot!(xrange, x -> pdf(prob, x), label=\"desired PDF\") # hide","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"We may also visualize a surface plot and a heatmap of the evolution of the Fokker-Planck equation for the density.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"surface(tt, xrange, pt', color=:vik, title=\"Surface plot of the evolution of the PDF\", titlefont=10, xlabel=\"t\", ylabel=\"x\") # hide","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"heatmap(tt, xrange, pt', color=:vik, title=\"Heatmap of the evolution of the PDF\", titlefont=10, xlabel=\"t\", ylabel=\"x\") # hide","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"With an animation just for fun.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"anim # hide","category":"page"},{"location":"sampling/langevin_sampling/#Two-dimensional-numerical-example","page":"Langevin sampling","title":"Two-dimensional numerical example","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Let's do a two-dimensional example, now. We consider a trimodal bivariate normal distribution and use the two-dimensional overdamped Langevin equations to obtain samples from the score function of the distribution.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Here is a visualization of the distribution and its score vector field.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"heatmap(xrange, yrange, (x, y) -> pdf(target_prob, [x, y]), title=\"pdf (heatmap) and score function (vector field)\", titlefont=10, legend=false, color=:vik) # hide\nquiver!(xx, yy, quiver = (uu[1, :] ./ 8, uu[2, :] ./ 8), color=:yellow, alpha=0.5) # hide","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Markdown.parse(\"\"\"Now we draw samples from it using the overdamped Langevin equation with ``\\\\gamma = $gamma``, and starting with samples from a standard normal distribution, evolving the particles from the initial time ``t_0 = $t0`` up to time ``t_f = $tf``.\\n\"\"\") # hide","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Let us see the location of the generated sample points and their histogram.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"plot(title=\"histogram and particles of the generated sample\", titlefont=10) # hide\nhistogram2d!(xt[1, :, end], xt[2, :, end], bins=40, normalize=true, color=:vik) # hide\nscatter!(xt[1, :, end], xt[2, :, end], markersize=2, markercolor=:white, label=false) # hid2","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Observe how many more particles are trapped near the modal point in the middle. In the target distribution, this is the smallest nodal point, but it seems the highest. Given enough time, though, the particles do tend to the proper distribution.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Let us see an animation for fun.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"anim # hide","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Now we draw samples starting from a uniform distribution of points on the square -6 6^2, which encompasses all three modal regions.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Here is what we get.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"plot(title=\"histogram and particles of the generated sample\", titlefont=10) # hide\nhistogram2d!(xt[1, :, end], xt[2, :, end], bins=40, normalize=true, color=:vik) # hide\nscatter!(xt[1, :, end], xt[2, :, end], markersize=2, markercolor=:white, label=false) # hid2","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Notice this is closer to the desired distribution. With the initial points spread out over the modal regions, the particles have less trouble moving to the asymptotic distribution.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"Again, let us see an animation.","category":"page"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"anim # hide","category":"page"},{"location":"sampling/langevin_sampling/#References","page":"Langevin sampling","title":"References","text":"","category":"section"},{"location":"sampling/langevin_sampling/","page":"Langevin sampling","title":"Langevin sampling","text":"R. Brown (1828), \"A brief account of microscopical observations made in the months of June, July and August, 1827, on the particles contained in the pollen of plants; and on the general existence of active molecules in organic and inorganic bodies\". Philosophical Magazine. 4 (21), 161-173. doi:10.1080/14786442808674769\nA. Einstein (1905), \"Über die von der molekularkinetischen Theorie der Wärme geforderte Bewegung von in ruhenden Flüssigkeiten suspendierten Teilchen\" [On the Movement of Small Particles Suspended in Stationary Liquids Required by the Molecular-Kinetic Theory of Heat], Annalen der Physik, 322 (8), 549-560, doi:10.1002/andp.19053220806\nP. Mörters and Y. Peres (2010), \"Brownian motion\", Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, Cambridge. With an appendix by Oded Schramm and Wendelin Werner\nP. Langevin (1908), \"Sur la théorie du mouvement brownien [On the Theory of Brownian Motion]\". C. R. Acad. Sci. Paris. 146: 530–533 \nG. A. Pavliotis (2014), \"The Langevin Equation. In: Stochastic Processes and Applications\". Texts in Applied Mathematics, vol 60. Springer, New York, NY, doi:10.1007/978-1-4939-1323-7_6\nG. O. Roberts, R. L. Tweedie (1996), \"Exponential Convergence of Langevin Distributions and Their Discrete Approximations\", Bernoulli, Vol. 2, No. 4, 341-363, doi:10.2307/3318418","category":"page"},{"location":"sampling/rejection_sampling/#Rejection-sampling-method","page":"Rejection sampling","title":"Rejection sampling method","text":"","category":"section"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"The Rejection Sampling method, or Acceptance-rejection method, was proposed by von Neumann (1951). See, for instance, Liu (2004) and Gamerman and Lopes (2006).","category":"page"},{"location":"sampling/rejection_sampling/#Setting","page":"Rejection sampling","title":"Setting","text":"","category":"section"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"One considers a univariate random variable X with density p=p(x) under the following assumptions:","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"We may not know the density p(x) but we do know a non-negative function f(x) proportional to the density, with some unknown normalizing constant Z  0 i.e.\n     p(x) = fracf(x)Z \nWe know how to sample from another random variable X with known density q=q(x) which bounds a multiple of the function f(x) with a known bound, i.e. for some known M0","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    f(x) leq M q(x) quad forall x","category":"page"},{"location":"sampling/rejection_sampling/#The-rejection-sampling-method","page":"Rejection sampling","title":"The rejection sampling method","text":"","category":"section"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Under this setting, we obtain samples of X by sampling from X and accepting or rejecting the candidate sample according to a specific criteria, and we repeat the process until a candidate is accepted, and for as many samples that we want. More precisely, here are the steps of the method.","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Draw a sample x of X which we call a candidate sample;\nCompute the acceptance ratio r(x) where","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    r(x) = fracf(x)Mq(x)","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Draw a sample u from the uniform distribution operatornameUniform(0 1)\nAccept/reject step:\nIf u leq r(x) accept the sample x as a sample x=x of the desired random variable X\notherwise, if u  r(x) reject the sample x and repeat the process drawing a new candidate and so on, until a candidate sample is accepted.\nRepeat for as many samples as desired.","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"How do you check that this really yields samples of X","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Let us start with another, but related, question: How often is a candidate sample accepted?","category":"page"},{"location":"sampling/rejection_sampling/#Expected-acceptance-rate","page":"Rejection sampling","title":"Expected acceptance rate","text":"","category":"section"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"First, notice that","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    mathbbP(X textrm is accepted) = mathbbPleft(U leq fracf(X)Mq(X)right) = int_q(x)  0 mathbbPleft( U leq fracf(x)Mq(x) bigg X = xright) q(x)mathrmdx","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"where the integral is restricted to the region q(x)  0 since q(x) is the PDF of X and q(x)  0 is a carrier of the random variable X i.e. q(X)  0 almost surely.","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"The probability of U being less than f(x)Mq(x) is precisely this ratio, i.e.","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    mathbbPleft( U leq fracf(x)Mq(x) bigg X = xright) = fracf(x)Mq(x)","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"again in the region q(x)  0 Thus,","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    beginalign*\n        mathbbP(X textrm is accepted)  = int_q(x)  0 fracf(x)Mq(x) q(x)mathrmdx = int_q(x)  0 fracf(x)M mathrmdx \n         = fracZM int_q(x)  0 fracf(x)Z mathrmdx = int_q(x)  0 p(x) mathrmdx = fracZM\n    endalign*","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Recall that M is the bound on f, so that the ratio ZM is related to the bound on the PDF itself,","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    p(x) = fracf(x)Z leq fracMZq(x)","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Thus, the tighter the bound, the higher the acceptance rate. A poor acceptance rate means we will have to compute a lot of proposed samples and a lot of acceptance checks to obtain a relativaly small portion of actual samples of the desired distribution.","category":"page"},{"location":"sampling/rejection_sampling/#Distribution-of-the-accepted-samples","page":"Rejection sampling","title":"Distribution of the accepted samples","text":"","category":"section"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"We may now check the distribution of the accepted samples. This is expressed by the CDF","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    F_X textrm is accepted = mathbbP(X leq x  X textrm is accepted)","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"This can be computed via","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    F_X textrm is accepted = mathbbP(X leq x  X textrm is accepted) = fracmathbbP(X leq x  X textrm is accepted)mathbbP(X textrm is accepted)","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"The numerator is given by","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    beginalign*\n        mathbbP(X leq x  X textrm is accepted)  = mathbbPleft( X leq x  U leq fracf(X)Mq(X)right) \n         = int_q(x)  0  x leq x mathbbPleft( U leq fracf(x)Mq(x) right) q(x) mathrmdx \n         = int_q(x)  0  x leq x int_0 leq u leq f(x)Mq(x) q(x) mathrmdu mathrmdx \n         = int_q(x)  0  x leq x fracf(x)Mq(x) q(x)mathrmdx \n         = int_xleq x fracf(x)M mathrmdx \n         = fracZMint_xleq x fracf(x)Z mathrmdx \n         = fracZM int_-infty^x p(x)mathrmdx \n         = fracZM F_X(x)\n    endalign*","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Thus,","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    F_X textrm is accepted = mathbbP(X leq x  X textrm is accepted) = fracmathbbP(X leq x  X textrm is accepted)mathbbP(X textrm is accepted) = fracfracZM F_X(x)fracZM = F_X(x)","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"In other words, the probability distribution of the accepted samples of X is precisely the distribution of X","category":"page"},{"location":"sampling/rejection_sampling/#Numerical-example","page":"Rejection sampling","title":"Numerical example","text":"","category":"section"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Let us draw samples from a synthetic distribution with density proportional to a function which is a polynomial with an exponential envelope, of the form","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    f(x) = (3x^3 + 2x^2 - 4x)^2e^-x^2","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(xx, f, title=\"Plot of \\$f(x)\\$\", titlefont=10, linewidth=2, xlims=(-6,6), legend=false) # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"One can actually compute the normalizing constant we can write","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    f(x) = (9x^6 + 12x^5 - 20x^4 - 16x^3 + 16x^2) e^-x^2","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"so that the integral with the odd powers vanish and we are left with","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    int_-infty^infty f(x) mathrmdx = 9 int_-infty^infty x^6 e^-x^2mathrmdx - 20 int_-infty^infty x^4 e^-x^2mathrmdx + 16 int_-infty^infty x^2 e^-x^2mathrmdx","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"and each integral can be seen as multiples of the moments of a normal distribution with zero mean and variance 12 Thus,","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    int_-infty^infty f(x) mathrmdx = sqrt2pisigma^2 left( 9 mathbbEY^6 - 20mathbbEY^4 + 16mathbbEY^2right)","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"where Y sim mathcalN(0 sigma^2) sigma^2 = 12 Since","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    mathbbEY^2n = sigma^n 2^-n(2n)n","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"we have, in particular,","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    mathbbEY^6 = 15 sigma^6 = frac158 quad mathbbEY^6 = 15 sigma^6 = frac34 quad mathbbEY^2 = 15 sigma^6 = frac12","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Thus,","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    Z = int_-infty^infty f(x) mathrmdx = sqrtpi left( 9 frac158 - 20frac34 + 16frac12right) = frac798sqrtpi approx 1750","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"This is the factor Z in the expression for the density f=f(x)","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    p(x) = fracf(x)Z = frac879sqrtpi(3x^3 + 2x^2 - 4x)^2e^-x^2","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"Plots of PDF \\$p\\$ and proportional function \\$f\\$ of desired distribution\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nplot!(xx, f, label=\"f\") # hide\nplot!(xx, p, label=\"pdf\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Now we need a bound with respect to the density of an easy distribution to sample. We may take X to be the standard normal distribution, for which the density is","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    q(x) = frac1sqrt2pi e^-frac12x^2","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"and then we need to find M such that f(x) leq M q(x) i.e.","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    (9x^6 + 12x^5 - 20x^4 - 16x^3 + 16x^2) e^-x^2 leq fracMsqrt2pi e^-frac12x^2","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"For that, we first need to compute the maximum values of the terms of the form x^n e^-x^22 Since the critical points of such a function occur at x = pm sqrtn we have","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    x^n e^-x^2 leq n^n2 e^-n2e^-x^22","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"for any ninmathbbN With that, and discarding the negative term with even power, we bound","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    beginalign*\n        f(x)  = (9x^6 + 12x^5 - 20x^4 - 16x^3 + 16x^2)e^-x^2 \n         leq sqrt2pi(9 times 6^3 e^-3 + 12 times 5^52 e^-52 + 16 times 3^32 e^-32 + 16 times 2 e^-1)frac1sqrt2pi e^-x^22\n    endalign*","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"for all xinmathbbR Rounding up the coefficient to an integer, we find that","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    f(x) leq 457 q(x)","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"so we take","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    M = 457","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"This bound can be visualized as follows","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"Plot of \\$f(x)\\$ and \\$Mq(x)\\$\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nplot!(xx, f, label=\"\\$f(x)\\$\") # hide\nplot!(xx, g, label=\"\\$Mq(x)\\$\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Well, one can see it is a loose bound, which will amount to too many rejections. We should find a tighter bound. Let us look for a bound with respect to the density of a normal distribution with variance 2 instead of the standard normal. For that, we split the exponential as","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    e^-x^2 = e^-frac34x^2 e^-frac14x^2","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"so the second exponential goes to the PDF e^-x^24sqrt4pi of the distribution mathcalN(0 2) while the first exponential is used to bound the polynomial part,","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    sqrt4pi(9x^6 + 12x^5 - 20x^4 - 16x^3 + 16x^2)e^-frac34x^2 leq M","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Since the critical points of x^ne^-3x^24 occur at x = pm sqrt2n3 we have","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    x^n e^-frac34x^2 leq left(frac2n3right)^n2 e^-n2","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Thus,","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    beginalign*\n         sqrt4pi(9x^6 + 12x^5 - 20x^4 - 16x^3 + 16x^2)e^-frac34x^2 \n         qquad leq sqrt4pi(9times 4^2 e^-2 + 12 times left(frac103right)^52 e^-52 + 16 times 2^32 e^-32 + 16left(frac43right) * e^-1)\n    endalign*","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"so we can take","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"M = 204","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"We can see this bound is a bit tighter than the previous one, but it is still not tight enough as we can see by the high rate of rejection of more than 90% (the estimated value is ZM approx 00858).","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"Plot of \\$f(x)\\$ and \\$Mq(x)\\$\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nplot!(xx, f, label=\"\\$f(x)\\$\") # hide\nplot!(xx, g, label=\"\\$Mq(x)\\$\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"histogram of proposed samples and PDF of proposal random variable\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nhistogram!(proposed_samples, normalize=:pdf, bins=40, label=\"histogram\") # hide\nplot!(xx, q, label=\"pdf\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"histogram of accepted samples and PDF of desired random variable\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nhistogram!(accepted_samples, normalize=:pdf, bins=40, label=\"histogram\") # hide\nplot!(xx, p, label=\"pdf\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"comparison of all uniform values and accepted ones\\nacceptance ratio: $(round(sum(accepted_samples)/num_proposals, sigdigits=2))\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nplot!(xx, x -> f(x) / maximum(f.(xx)), alpha=0.5, label=\"f/max(f)\") # hide\nplot!(xx, x -> f(x) / g(x), label=\"ratio\") # hide\nscatter!(proposed_samples, uniform_samples, markersize=2, alpha=0.2, label=\"uniform\") # hide\nscatter!(accepted_samples, accepted_uniform_samples, markersize=2, label=\"accepted\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"We can certainly improve acceptance rate by looking for a tighter bound. A numerical investigation reveals that we can apparently take M as low as 88","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"    max_-6 leq x leq 6 left(fracf(x)q(x)right) approx 875","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Using this bound, the expected acceptance rate is Z approx 1750  88 approx 01989 so we more than double the acceptance rate, and we have a better approximation of the distribution.","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"Plot of \\$f(x)\\$ and \\$Mq(x)\\$\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nplot!(xx, f, label=\"\\$f(x)\\$\") # hide\nplot!(xx, g, label=\"\\$Mq(x)\\$\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"histogram of proposed samples and PDF of proposal random variable\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nhistogram!(proposed_samples, normalize=:pdf, bins=40, label=\"histogram\") # hide\nplot!(xx, q, label=\"pdf\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"histogram of accepted samples and PDF of desired random variable\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nhistogram!(accepted_samples, normalize=:pdf, bins=40, label=\"histogram\") # hide\nplot!(xx, p, label=\"pdf\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"comparison of all uniform values and accepted ones\\nacceptance ratio: $(round(sum(accepted_samples)/num_proposals, sigdigits=2))\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nplot!(xx, x -> f(x) / maximum(f.(xx)), alpha=0.5, label=\"f/max(f)\") # hide\nplot!(xx, x -> f(x) / g(x), label=\"ratio\") # hide\nscatter!(proposed_samples, uniform_samples, markersize=2, alpha=0.2, label=\"uniform\") # hide\nscatter!(accepted_samples, accepted_uniform_samples, markersize=2, label=\"accepted\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"We can improve the sampling process much more by working with a normal distribution centered on the mean value obtained from f which seems to be near x = 168","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"Plot of \\$f(x)\\$ and \\$Mq(x)\\$\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nplot!(xx, f, label=\"\\$f(x)\\$\") # hide\nplot!(xx, g, label=\"\\$Mq(x)\\$\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"histogram of proposed samples and PDF of proposal random variable\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nhistogram!(proposed_samples, normalize=:pdf, bins=40, label=\"histogram\") # hide\nplot!(xx, q, label=\"pdf\") # hide\nvline!([mu], label=\"mean\")","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"histogram of accepted samples and PDF of desired random variable\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nhistogram!(accepted_samples, normalize=:pdf, bins=40, label=\"histogram\") # hide\nplot!(xx, p, label=\"pdf\") # hide","category":"page"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"plot(title=\"comparison of all uniform values and accepted ones\\nacceptance ratio: $(round(sum(accepted_samples)/num_proposals, sigdigits=2))\", titlefont=10, linewidth=2, xlims=(-6,6)) # hide\nplot!(xx, x -> f(x) / maximum(f.(xx)), linewidth=2, alpha=0.5, label=\"f/max(f)\") # hide\nplot!(xx, x -> f(x) / g(x), label=\"ratio\") # hide\nscatter!(proposed_samples, uniform_samples, markersize=2, alpha=0.2, label=\"uniform\") # hide\nscatter!(accepted_samples, accepted_uniform_samples, markersize=2, label=\"accepted\") # hide","category":"page"},{"location":"sampling/rejection_sampling/#References","page":"Rejection sampling","title":"References","text":"","category":"section"},{"location":"sampling/rejection_sampling/","page":"Rejection sampling","title":"Rejection sampling","text":"Dani Gamerman, Hedibert F. Lopes, \"Markov Chain Monte Carlo Stochastic Simulation for Bayesian Inference,\" Second Edition, Chapman and Hall/CRC, New York, 2006\nJun S. Liu, \"Monte Carlo Strategies in Scientific Computing,\" Springer Series in Statistics, Springer-Verlag New York 2004\nJohn von Neumann, \"Various techniques used in connection with random digits. Monte Carlo methods\" Nat. Bureau Standards, 12 (1951), 36–38.","category":"page"},{"location":"sampling/gibbs/#Gibbs-sampling","page":"Gibbs sampling","title":"Gibbs sampling","text":"","category":"section"},{"location":"generative/score_matching_neural_network/#Score-matching-a-neural-network","page":"Score matching a neural network","title":"Score matching a neural network","text":"","category":"section"},{"location":"generative/score_matching_neural_network/#Introduction","page":"Score matching a neural network","title":"Introduction","text":"","category":"section"},{"location":"generative/score_matching_neural_network/#Aim","page":"Score matching a neural network","title":"Aim","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Apply the score-matching method of Aapo Hyvärinen (2005) to fit a neural network model of the score function to a univariate Gaussian distribution. This borrows ideas from Kingma and LeCun (2010), of using automatic differentiation to differentiate the neural network, and from Song and Ermon (2019), of modeling directly the score function, instead of the pdf or an energy potential for the pdf.","category":"page"},{"location":"generative/score_matching_neural_network/#Motivation","page":"Score matching a neural network","title":"Motivation","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"The motivation is to revisit the original idea of Aapo Hyvärinen (2005) and see how it performs for training a neural network to model the score function.","category":"page"},{"location":"generative/score_matching_neural_network/#Background","page":"Score matching a neural network","title":"Background","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"The idea of Aapo Hyvärinen (2005) is to directly fit the score function from the sample data, using a suitable implicit score matching loss function not depending on the unknown score function of the random variable. This loss function is obtained by a simple integration by parts on the explicit score matching objective function given by the expected square distance between the score of the model and the score of the unknown target distribution, also known as the Fisher divergence. The integration by parts separates the dependence on the unknown target score function from the parameters of the model, so the fitting process (minimization over the parameters of the model) does not depend on the unknown distribution.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"The implicit score matching method requires, however, the derivative of the score function of the model pdf, which is costly to compute in general. In Hyvärinen's original work, all the examples considered models for which the gradient can be computed somewhat more explicitly. There was no artificial neural network involved.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"In a subsequent work, Köster and Hyvärinen (2010) applied the method to fit the score function from a model probability with log-likelihood obtained from a two-layer neural network, so that the gradient of the score function could still be expressed somehow explicitly.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"After that, Kingma and LeCun (2010) considered a larger artificial neural network and used automatic differentiation to optimize the model. They also proposed a penalization term in the loss function, to regularize and stabilize the optimization process, yielding a regularized implicit score matching method. The model in Kingma and LeCun (2010) was not of the pdf directly, but of an energy potential, i.e. with","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"    p_boldsymboltheta(mathbfx) = frac1Z(boldsymboltheta) e^-U(mathbfx boldsymboltheta)","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"where U(mathbfx boldsymboltheta) is modeled after a neural network.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Finally, Song and Ermon (2019) proposed modeling directly the score function as a neural network s(mathbfx boldsymboltheta), i.e.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"    boldsymbolnabla_mathbfxp_boldsymboltheta(mathbfx) = s(mathbfx boldsymboltheta)","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Song and Ermon (2019), however, went further and proposed a different method (based on several perturbations of the data, each of which akin to denoising score matching). At this point, we do not address the main method proposed in Song and Ermon (2019), we only borrow the idea of modeling directly the score function instead of the pdf or an energy potential of the pdf.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"In a sense, we do an analysis in hindsight, combining ideas proposed in subsequent articles, to implement the implicit score matching method in a different way. In summary, we illustrate the use of automatic differentiation to allow the application of the implicit score matching and the regularized implicit score matching methods to directly fit the score function as modeled by a neural networks.","category":"page"},{"location":"generative/score_matching_neural_network/#Loss-function-for-implicit-score-matching","page":"Score matching a neural network","title":"Loss function for implicit score matching","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"The score-matching method of Aapo Hyvärinen (2005) aims to minimize the empirical implicit score matching loss function tilde J_mathrmISMtilde p_0 given by","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"    tilde J_mathrmISMtilde p_0 = frac1Nsum_n=1^N left( frac12boldsymbolpsi(mathbfx_n boldsymboltheta)^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx_n boldsymboltheta) right)","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"where (mathbfx_n)_n=1^N is the sample data from a unknown target distribution and where boldsymbolpsi(mathbfx_n boldsymboltheta) is a parametrized model for the desired score function.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"The method rests on the idea of rewriting the explicit score matching loss function J_mathrmESM(boldsymboltheta) (essentially the Fisher divergence) in terms of the implicit score matching loss function J_mathrmISM(boldsymboltheta), showing that ","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"J_mathrmESM(boldsymboltheta) = J_mathrmISM(boldsymboltheta) + C","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"and then approximating the latter by the empirical implicit score matching loss function tilde J_mathrmISMtilde p_0(boldsymboltheta).","category":"page"},{"location":"generative/score_matching_neural_network/#Numerical-example","page":"Score matching a neural network","title":"Numerical example","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"We illustrate the method, numerically, to model a synthetic univariate Gaussian mixture distribution.","category":"page"},{"location":"generative/score_matching_neural_network/#Julia-language-setup","page":"Score matching a neural network","title":"Julia language setup","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"We use the Julia programming language for the numerical simulations, with suitable packages.","category":"page"},{"location":"generative/score_matching_neural_network/#Packages","page":"Score matching a neural network","title":"Packages","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"using StatsPlots\nusing Random\nusing Distributions\nusing Lux # artificial neural networks explicitly parametrized\nusing Optimisers\nusing Zygote # automatic differentiation\nusing Markdown\n\nnothing # hide","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"There are several Julia libraries for artificial neural networks and for automatic differentiation (AD). The most established package for artificial neural networks is the FluxML/Flux.jl library, which handles the parameters implicitly, but it is moving to explicit parameters. A newer library that handles the parameters explicitly is the LuxDL/Lux.jl library, which is taylored to the differential equations SciML ecosystem.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Since we aim to combine score-matching with neural networks and, eventually, with stochastic differential equations, we thought it was a reasonable idea to experiment with the LuxDL/Lux.jl library.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"As we mentioned, the LuxDL/Lux.jl library is a newer package and not as well developed. In particular, it seems the only AD that works with it is the FluxML/Zygote.jl library. Unfortunately, the FluxML/Zygote.jl library is not so much fit to do AD on top of AD, as one can see from e.g. Zygote: Design limitations. Thus we only illustrate this with a small network on a simple univariate problem.","category":"page"},{"location":"generative/score_matching_neural_network/#Reproducibility","page":"Score matching a neural network","title":"Reproducibility","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"We set the random seed for reproducibility purposes.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"rng = Xoshiro(12345)\nnothing # hide","category":"page"},{"location":"generative/score_matching_neural_network/#Data","page":"Score matching a neural network","title":"Data","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"We build the target model and draw samples from it.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"The target model is a univariate random variable denoted by X and defined by a probability distribution. Associated with that we consider its PDF and its score-function.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"target_prob = MixtureModel([Normal(-3, 1), Normal(3, 1)], [0.1, 0.9])\n\nxrange = range(-10, 10, 200)\ndx = Float64(xrange.step)\nxx = permutedims(collect(xrange))\ntarget_pdf = pdf.(target_prob, xrange')\ntarget_score = gradlogpdf.(target_prob, xrange')\n\nlambda = 0.1\nsample_points = permutedims(rand(rng, target_prob, 1024))\ndata = (sample_points, lambda)","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Visualizing the sample data drawn from the distribution and the PDF.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"plt # hide","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Visualizing the score function.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"plt # hide","category":"page"},{"location":"generative/score_matching_neural_network/#The-neural-network-model","page":"Score matching a neural network","title":"The neural network model","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"The neural network we consider is a simple feed-forward neural network made of a single hidden layer, obtained as a chain of a couple of dense layers. This is implemented with the LuxDL/Lux.jl package.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"We will see that we don't need a big neural network in this simple example. We go as low as it works.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"model = Chain(Dense(1 => 8, sigmoid), Dense(8 => 1))","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"The LuxDL/Lux.jl package uses explicit parameters, that are initialized (or obtained) with the Lux.setup function, giving us the parameters and the state of the model.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model","category":"page"},{"location":"generative/score_matching_neural_network/#Loss-function","page":"Score matching a neural network","title":"Loss function","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Here it is how we implement the objective tilde J_mathrmISMtilde p_0(boldsymboltheta).","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"function loss_function_EISM_Zygote(model, ps, st, sample_points)\n    smodel = StatefulLuxLayer{true}(model, ps, st)\n    y_pred = smodel(sample_points)\n    dy_pred = only(Zygote.gradient(sum ∘ smodel, sample_points))\n    loss = mean(dy_pred .+ y_pred .^2 / 2)\n    return loss, smodel.st, ()\nend","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"We also implement a regularized version as proposed by Kingma and LeCun (2010).","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"function loss_function_EISM_Zygote_regularized(model, ps, st, data)\n    sample_points, lambda = data\n    smodel = StatefulLuxLayer{true}(model, ps, st)\n    y_pred = smodel(sample_points)\n    dy_pred = only(Zygote.gradient(sum ∘ smodel, sample_points))\n    loss = mean(dy_pred .+ y_pred .^2 / 2 .+ lambda .* dy_pred .^2 )\n    return loss, smodel.st, ()\nend","category":"page"},{"location":"generative/score_matching_neural_network/#Optimization-setup","page":"Score matching a neural network","title":"Optimization setup","text":"","category":"section"},{"location":"generative/score_matching_neural_network/#Optimization-method","page":"Score matching a neural network","title":"Optimization method","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"We use the Adam optimiser.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"opt = Adam(0.01)\n\ntstate_org = Lux.Training.TrainState(model, ps, st, opt)","category":"page"},{"location":"generative/score_matching_neural_network/#Automatic-differentiation-in-the-optimization","page":"Score matching a neural network","title":"Automatic differentiation in the optimization","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"As mentioned, we setup differentiation in LuxDL/Lux.jl with the FluxML/Zygote.jl library.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"vjp_rule = Lux.Training.AutoZygote()","category":"page"},{"location":"generative/score_matching_neural_network/#Processor","page":"Score matching a neural network","title":"Processor","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"We use the CPU instead of the GPU.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"dev_cpu = cpu_device()\n## dev_gpu = gpu_device()","category":"page"},{"location":"generative/score_matching_neural_network/#Check-differentiation","page":"Score matching a neural network","title":"Check differentiation","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Check if Zygote via Lux is working fine to differentiate the loss functions for training.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"@time Lux.Training.compute_gradients(vjp_rule, loss_function_EISM_Zygote, sample_points, tstate_org)\nnothing # hide","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"It is pretty slow to run it the first time, since it envolves compiling a specialized method for it. Remember there is already a gradient on the loss function, so this amounts to a double automatic differentiation. The subsequent times are faster, but still slow for training:","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"@time Lux.Training.compute_gradients(vjp_rule, loss_function_EISM_Zygote, sample_points, tstate_org)\nnothing # hide","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Now the version with regularization.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"@time Lux.Training.compute_gradients(vjp_rule, loss_function_EISM_Zygote_regularized, data, tstate_org)\nnothing # hide","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"@time Lux.Training.compute_gradients(vjp_rule, loss_function_EISM_Zygote_regularized, data, tstate_org)\nnothing # hide","category":"page"},{"location":"generative/score_matching_neural_network/#Training-loop","page":"Score matching a neural network","title":"Training loop","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Here is the typical main training loop suggest in the LuxDL/Lux.jl tutorials, but sligthly modified to save the history of losses per iteration.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"function train(tstate, vjp, data, loss_function, epochs, numshowepochs=20, numsavestates=0)\n    losses = zeros(epochs)\n    tstates = [(0, tstate)]\n    for epoch in 1:epochs\n        grads, loss, stats, tstate = Lux.Training.compute_gradients(vjp,\n            loss_function, data, tstate)\n        if ( epochs ≥ numshowepochs > 0 ) && rem(epoch, div(epochs, numshowepochs)) == 0\n            println(\"Epoch: $(epoch) || Loss: $(loss)\")\n        end\n        if ( epochs ≥ numsavestates > 0 ) && rem(epoch, div(epochs, numsavestates)) == 0\n            push!(tstates, (epoch, tstate))\n        end\n        losses[epoch] = loss\n        tstate = Lux.Training.apply_gradients(tstate, grads)\n    end\n    return tstate, losses, tstates\nend","category":"page"},{"location":"generative/score_matching_neural_network/#Training","page":"Score matching a neural network","title":"Training","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Now we train the model with the objective function tilde J_mathrmISMtilde p_0(boldsymboltheta).","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"@time tstate, losses, tstates = train(tstate_org, vjp_rule, sample_points, loss_function_EISM_Zygote, 500, 20, 100)\nnothing # hide","category":"page"},{"location":"generative/score_matching_neural_network/#Results","page":"Score matching a neural network","title":"Results","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Testing out the trained model.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"y_pred = Lux.apply(tstate.model, xrange', tstate.parameters, tstate.states)[1]","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Visualizing the result.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"plot(title=\"Fitting\", titlefont=10)\n\nplot!(xrange, target_score', linewidth=4, label=\"score function\")\n\nscatter!(sample_points', s -> gradlogpdf(target_prob, s), label=\"data\", markersize=2)\n\nplot!(xx', y_pred', linewidth=2, label=\"predicted MLP\")","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Just for the fun of it, let us see an animation of the optimization process.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"gif(anim, fps = 20) # hide","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"paux = exp.(accumulate(+, y_pred) .* dx)\npdf_pred = paux ./ sum(paux) ./ dx\nplot(title=\"Original PDF and PDF from predicted score function\", titlefont=10)\nplot!(xrange, target_pdf', label=\"original\")\nplot!(xrange, pdf_pred', label=\"recoverd\")","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"And the animation of the evolution of the PDF.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"gif(anim, fps = 10) # hide","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"We also visualize the evolution of the losses.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false)","category":"page"},{"location":"generative/score_matching_neural_network/#Training-with-the-regularization-term","page":"Score matching a neural network","title":"Training with the regularization term","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Now we train the model with the objective function tilde J_mathrmISMtilde p_0(boldsymboltheta).","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_EISM_Zygote_regularized, 500, 20, 100)\nnothing # hide","category":"page"},{"location":"generative/score_matching_neural_network/#Results-2","page":"Score matching a neural network","title":"Results","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Testing out the trained model.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"y_pred = Lux.apply(tstate.model, xrange', tstate.parameters, tstate.states)[1]","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Visualizing the result.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"plot(title=\"Fitting\", titlefont=10)\n\nplot!(xrange, target_score', linewidth=4, label=\"score function\")\n\nscatter!(sample_points', s -> gradlogpdf(target_prob, s), label=\"data\", markersize=2)\n\nplot!(xx', y_pred', linewidth=2, label=\"predicted MLP\")","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Just for the fun of it, let us see an animation of the optimization process.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"gif(anim, fps = 20) # hide","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"paux = exp.(accumulate(+, y_pred) .* dx)\npdf_pred = paux ./ sum(paux) ./ dx\nplot(title=\"Original PDF and PDF from predicted score function\", titlefont=10)\nplot!(xrange, target_pdf', label=\"original\")\nplot!(xrange, pdf_pred', label=\"recoverd\")","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"And the animation of the evolution of the PDF.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"gif(anim, fps = 10) # hide","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"We also visualize the evolution of the losses.","category":"page"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false)","category":"page"},{"location":"generative/score_matching_neural_network/#References","page":"Score matching a neural network","title":"References","text":"","category":"section"},{"location":"generative/score_matching_neural_network/","page":"Score matching a neural network","title":"Score matching a neural network","text":"Aapo Hyvärinen (2005), \"Estimation of non-normalized statistical models by score matching\", Journal of Machine Learning Research 6, 695-709\nU. Köster, A. Hyvärinen (2010), \"A two-layer model of natural stimuli estimated with score matching\", Neural. Comput. 22 (no. 9), 2308-33, doi: 10.1162/NECOa00010\nDurk P. Kingma, Yann Cun (2010), \"Regularized estimation of image statistics by Score Matching\", Advances in Neural Information Processing Systems 23 (NIPS 2010)\nY. Song and S. Ermon (2019), \"Generative modeling by estimating gradients of the data distribution\", NIPS'19: Proceedings of the 33rd International Conference on Neural Information Processing Systems, no. 1067, 11918-11930","category":"page"},{"location":"markov_chains/mc_definitions/#Discrete-time-Markov-chains","page":"Essential definitions","title":"Discrete-time Markov chains","text":"","category":"section"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"Many important probabilistic models fit the framework of a Markov chain, including the Markov Chain Monte Carlo (MCMC) methods, as the name says it. Here we explore some of its concepts and properties. Markov chains can be indexed with either discrete or continous \"time\" variables, but here we only consider the discrete-time case.","category":"page"},{"location":"markov_chains/mc_definitions/#Definition","page":"Essential definitions","title":"Definition","text":"","category":"section"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"Markov chains are families of random variables (X_n)_nin I over an index set I such that, essentially, only the most recent known state determines the future of the chain. The index set I can be continuous or discrete, but here we are only interested on the discrete case I = mathbbZ_geq 0 = 0 1 2 ldots  The index set is usually referred to as the time variable, while the values of the random variables live on a space mathcalX called the state or event space.","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"The event space mathcalX can be either countable (finite or infinite, with the discrete topology) or continuous (e.g. mathcalX = mathbbR^d dinmathbbN or some infinite dimensional Hilbert or Banach space). We are mostly interested in the continuous case mathcalX = mathbbR^d dinmathbbN but some examples are given with mathcalX = 1 ldots n ninmathbbN or mathcalX=mathbbZ for illustrative purposes and intuitive assessment. In any case, we always assume it is a topological space.","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"The random variables are functions X_nOmega rightarrow mathcalX which are assumed to be measurable from a probability space (Omega mathcalF mathbbP) with sigma-algebra mathcalF and probability distribution mathbbP to a measurable space, which we take here to be (mathcalX mathcalB(mathcalX)) where mathcalB(mathcalX) denotes the Borel sigma-algebra of the topological space mathcalX","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"In the discrete-time case, the Markov property for the discrete-time process (X_n)_n to be a Markov chain can be written as","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    mathbbP(X_n+1X_0in E_0 X_1 in E_1 ldots X_nin E_n) = mathbbP(X_n+1X_nin E_n)","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"for all Borel sets E_0 ldots E_n The continuos-time version has a similar condition, based on the notion of filtration of a sigma-algebra, but we do not need to worry about this in the time-discrete case.","category":"page"},{"location":"markov_chains/mc_definitions/#Transition-probabilities","page":"Essential definitions","title":"Transition probabilities","text":"","category":"section"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"Markov chains can be described by transition probabilities. We will define them in both non-homogeneous and homogeneous cases in time, but after that we will only consider the homogeneous case.","category":"page"},{"location":"markov_chains/mc_definitions/#The-non-homogeneous-time-discrete-case","page":"Essential definitions","title":"The non-homogeneous time-discrete case","text":"","category":"section"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"A Markov chain can be fully characterized by the transition probabilities","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    K_n m(E F) = mathbbP(X_min FX_nin E)","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"for any pair E Fsubset mathcalX of Borel sets, where n m = 0 1 ldots In particular, we denote","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    K_n m(x F) = mathbbP(X_n+1in FX_n = x)","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"for any Borel set Esubset mathcalX and any point xinmathcalX Notice that ","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"The set map K_n m(x cdot) is a probability measure on mathcalX for each xinmathcalX\nThe map K_n m(cdot F) is a measurable function from mathcalX to 0 1 for each Borel set Fsubset mathcalX","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"When mathcalX = mathbbR^d din mathbbN we say that the transition probability K_n m has a transition kernel or transition density k_n m = k_n m(x y) when K_n m(x cdot) is absolutely continous with respect to the Lebesgue measure, so that","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    K_n m(x F) = int_F k_n m(x y) mathrmdy","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"and","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    K_n m(E F) = int_E int_F k_n m(x y) mathrmdymathrmdx","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"Since K_n m(x cdot) is a probability distribution, we have","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    int_mathcalX k_nm(x y) mathrmdy = K_n(x mathcalX) = 1","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"But K_nm(E F) is contined on X_nin E so K_n m(cdot y) need not be a probability distribution.","category":"page"},{"location":"markov_chains/mc_definitions/#The-time-homogeneous-case","page":"Essential definitions","title":"The time-homogeneous case","text":"","category":"section"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"Very often, as in most examples we are interested in, here, the transition probabilities only depend on the \"time difference\" m-n i.e. it is time homogeneous, or autonomous. More precisely, the Markov chain is called time homogeneous when","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    K_k k + n(E F) = K_0 n(E F) quad forall n k = 0 1 2 ldots forall E FinmathcalB(mathcalX)","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"In this case, we define the nth-step transition probability by","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    K_n(E F) = K_0 n(E F) = K_k k+n(E F)","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"The corresponding density k_n(x y) is called the nth-step transition density.","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"The one-step transition probability and density are simply denoted without any subscript,","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    beginalign*\n        K(E F)  = K_1(E F) = mathbbP(X_n+1 in F  X_nin E) \n        K(x F)  = K_1(x F) = mathbbP(X_n+1 in F  X_n = x) \n        k(x y) = k_1(x y)\n    endalign*","category":"page"},{"location":"markov_chains/mc_definitions/#The-evolution-of-distributions","page":"Essential definitions","title":"The evolution of distributions","text":"","category":"section"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"We denote by P_n the probability distribution of the random variable X_n i.e.","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    P_n(E) = mathbbP(X_nin E) quad forall EinmathcalB(mathcalX)","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"Due to the nature of a Markov process, the distribution of P_n+1 only depends on the distribution of P_n and on the transition distribution. More generally, P_k+n depends on P_k and, in particular, the distribution P_n of X_n depends on the distribution P_0 of X_0","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"More precisely, we can express this dependence via the Chapman-Kolmogorov equation, which, in the case the transition probabilities admit a density, reads","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    K_m+n(x F) = int_mathcalX K_n(y F)k_m(x y)mathrmdy","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"for any Borel set FsubsetmathcalX","category":"page"},{"location":"markov_chains/mc_definitions/#The-Markov-operator","page":"Essential definitions","title":"The Markov operator","text":"","category":"section"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"Given the one-step transition probability K(cdot cdot) in the time-homogeneous case, on defines the associated Markov operator KmathcalP(mathcalX)rightarrow mathcalP(mathcalX) that takes a distribution Pin mathcalP(mathcalX) on mathcalX to the \"next step\" distribution PKinmathcalP(mathcalX) defined by","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    (PK)(E) = int_mathcalX K(x E)mathrmdP(x)","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"In particular, if P_n is the distribution of X_n then the distribution of X_n+1 is KP_n i.e.","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    P_n+1 = P_nK quad textrmfor  X_j sim P_j","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"Rmk: Another common notation in the integration is with P(mathrmdx) instead of mathrmdP(x) ","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"Rmk: We use the same K to denote the Markov operator on mathcalP(mathcalX) and the one-step probability distribution K(cdot cdot) on mathcalXtimesmathcalX","category":"page"},{"location":"markov_chains/mc_definitions/#Finite-state-case","page":"Essential definitions","title":"Finite-state case","text":"","category":"section"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"When the state is finite, say mathcalX = 1 2 ldots n the transition operator can be characterized by the transitions K(i j) of going from state i to state j. This defines a matrix,","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    K = left(K_1(i j)right)_ij=1^n = beginbmatrix\n        k_11  k_12  cdots  k_1n \n        k_21  k_22  ddots  vdots \n        vdots  ddots  ddots  k_n-1n \n        k_n1  cdots  k_nn-1  k_nn\n    endbmatrix","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"where k_i j = K(i j) Each row sums up to one:","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    sum_j=1^n k_ij = sum_j=1^n K_1(i j) = K_1(i mathcalX) = 1","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"The n-step transition operator is obtained by simply composing the 1-step transition operator,","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    beginalign*\n        left(K_n(i j)right)_ij  = left(K_0n(i j)right)_ij = left(K_n-1 n(i j)right)_ijleft(K_n-2 n-1(i j)right)_ijcdots left(K_0 1(i j)right)_ij \n         = left(K(i j)right)_ij^n = K^n\n    endalign*","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"If we denote the distribution of a given state X_n by a row vector","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    P_n = p_1 ldots p_n quad p_i = mathbbP(X_n = i)","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"then","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"    beginalign*\n        P_n+1  = mathbbP(X_n+1 = j)_j=1 ldots n = leftsum_i=1^n mathbbP(X_n+1 = j  X_n = i) mathbbP(X_n = 1)right_j=1 ldots n  \n         = leftsum_i=1^n K_i j p_iright_j=1 ldots n = beginbmatrix p_1  p_2  cdots  p_nendbmatrix beginbmatrix\n            k_11  k_12  cdots  k_1n \n            k_21  k_22  ddots  vdots \n            vdots  ddots  ddots  k_n-1n \n            k_n1  cdots  k_nn-1  k_nn\n        endbmatrix = P_n K\n    endalign*","category":"page"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"where the product P_n K is to be understood as the matrix product of a row vector p_1 ldots p_n of the distribution of X_n with the transition matrix K to yield another row vector with the distributions for the next state. Thus, K is also a representation of the Markov operator.","category":"page"},{"location":"markov_chains/mc_definitions/#References","page":"Essential definitions","title":"References","text":"","category":"section"},{"location":"markov_chains/mc_definitions/","page":"Essential definitions","title":"Essential definitions","text":"C. P. Robert, G. Casella (2004), \"Monte Carlo Statistical Methods\", Second Edition, Springer Texts in Statistics, Springer New York, NY\nG. F. Lawler (2006), \"Introduction to Stochastic Processes\", 2nd Edition. Chapman and Hall/CRC, New York.","category":"page"},{"location":"#Welcome","page":"Random Notes","title":"Welcome","text":"","category":"section"},{"location":"","page":"Random Notes","title":"Random Notes","text":"\"Writing is a way to explore a question and gain control over it,\" - William Zinsser, Writing to Learn: How to Write - And Think - Clearly about Any Subject at All","category":"page"},{"location":"","page":"Random Notes","title":"Random Notes","text":"These are just random notes about math and the julia language, which eventually may go into some future lecture notes.","category":"page"},{"location":"generative/score_based_sde/#Score-based-generative-modeling-through-stochastic-differential-equations","page":"Score-based SDE model","title":"Score-based generative modeling through stochastic differential equations","text":"","category":"section"},{"location":"generative/score_based_sde/#Introduction","page":"Score-based SDE model","title":"Introduction","text":"","category":"section"},{"location":"generative/score_based_sde/#Aim","page":"Score-based SDE model","title":"Aim","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Review the work of Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020) that takes a complex data distribution, adds noise to it via a stochastic differential equation and generates new samples by modeling the reverse process. It is a generalization to the continuous case of the previous discrete processes of denoising diffusion probabilistic models and multiple denoising score matching.","category":"page"},{"location":"generative/score_based_sde/#Background","page":"Score-based SDE model","title":"Background","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"After Aapo Hyvärinen (2005) proposed the implicit score matching to model a distribution by fitting its score function, several works followed it, including the denosing score matching of Paul Vincent (2011), which perturbed the data so the analytic expression of the score function of the perturbation could be used. Then the denoising diffusion probabilistic models, of Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015) and Ho, Jain, and Abbeel (2020), and the multiple denoising score matching, of Song and Ermon (2019), went one step further by adding several levels of noise, facilitating the generation process. The work of Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020) extended that idea to the continuous case, adding noise via a stochastic differential equation.","category":"page"},{"location":"generative/score_based_sde/#Forward-SDE","page":"Score-based SDE model","title":"Forward SDE","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"A initial unknown probability distribution with density p_0=p_0(x) associated with a random variable X_0 is embedded into the distribution of an SDE of the form","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    mathrmdX_t = f(t)X_tmathrmdt + g(t)mathrmdW_t","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"with initial condition X_0 The solution can be obtained with the help of the integrating factor e^-int_0^t f(s)mathrmds associated with the deterministic part of the equation. In this case,","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    beginaligned\n        mathrmdleft(X_te^-int_0^t f(s)mathrmdsright)  = mathrmdX_t e^-int_0^t f(s)mathrmds - X_t f(t) e^int_0^t f(s)mathrmds mathrmdt \n         = left(f(t)X_tmathrmdt + g(t)mathrmdW_tright)e^-int_0^t f(s)mathrmds - X_t f(t) e^-int_0^t f(s)mathrmds mathrmdt \n         = g(t)e^-int_0^t f(s)mathrmdsmathrmdW_t\n    endaligned","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Integrating yields","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    X_te^-int_0^t f(s)mathrmds - X_0 = int_0^t g(s)e^-int_0^s f(tau)mathrmdtaumathrmdW_s","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Moving the exponential term to the right hand side yields the solution","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    X_t = X_0 e^int_0^t f(s)mathrmds + int_0^t e^int_s^t f(tau)mathrmdtaug(s)mathrmdW_s","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The mean value evolves according to","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    mathbbEX_t = mathbbEX_0 e^int_0^t f(s)mathrmds","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Using the Itô isometry, the second moment evolves with","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    mathbbEX_t^2 = mathbbEX_0^2e^2int_0^t f(s)mathrmds + int_0^t e^2int_s^t f(tau)mathrmdtaug(s)^2mathrmds","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Hence, the variance is given by","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    operatornameVar(X_t) = operatornameVar(X_0)e^2int_0^t f(s)mathrmds + int_0^t e^2int_s^t f(tau)mathrmdtaug(s)^2mathrmds","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Thus, the probability density function p(t x) can be obtained by conditioning it at each initial point, with","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    p(t x) = int_mathbbR p(t x  0 x_0) p_0(x_0)mathrmdx_0","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"and","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    p(t x  0 x_0) = mathcalN(x mu(t)x_0 sigma(t)^2)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"where","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    mu(t) = e^int_0^t f(s)mathrmds","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"and","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    sigma(t)^2 = int_0^t e^2int_s^t f(tau)mathrmdtaug(s)^2mathrmds","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The probability density function p(t x) can also be obtained with the help of the Fokker-Planck equation","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    fracpartial ppartial t + nabla_x cdot (f(t) p(t x)) = frac12Delta_x left( g(t)^2 p(t x) right)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"whose fundamental solutions are precisely p(t x  0 x_0) = mathcalN(x mu(t)x_0 sigma(t)^2)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"For the Stein score, we have","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    nabla_x log p(t x  0 x_0) = nabla_x left( - frac(x - mu(t)x_0)^22sigma(t)^2 right) = - fracx - mu(t)x_0sigma(t)^2","category":"page"},{"location":"generative/score_based_sde/#Examples","page":"Score-based SDE model","title":"Examples","text":"","category":"section"},{"location":"generative/score_based_sde/#Variance-exploding-SDE","page":"Score-based SDE model","title":"Variance-exploding SDE","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"For example, in the variance-exploding case (VE SDE), as discussed in Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020), as the continuous limit of the Multiple Denoising Score Matching, we have","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    f(t) = 0 quad g(t) = sqrtfracmathrmd(sigma(t)^2)mathrmdt","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"so that","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    mu(t) = 1","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"and","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    sigma(t)^2 = int_0^t fracmathrmd(sigma(s)^2)mathrmdsmathrmds = sigma(t)^2 - sigma(0)^2","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Thus,","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    p(t x  0 x_0) = mathcalNleft( x x_0 sigma(t)^2 - sigma(0)^2right)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The Stein score becomes","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    nabla_x log p(t x  0 x_0) = nabla_x left( - frac(x - mu(t)x_0)^22sigma(t)^2 right) = - fracx - x_0sigma(t)^2 - sigma(0)^2","category":"page"},{"location":"generative/score_based_sde/#Variance-preserving-SDE","page":"Score-based SDE model","title":"Variance-preserving SDE","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"In the variance-preserving case (VP SDE), as discussed in Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020), as the continuous limit of the Denoising Diffusion Probabilistic Model,","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    f(t) = -frac12beta(t) quad g(t) = sqrtbeta(t)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"so that","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    mu(t) = e^-frac12int_0^t beta(s)mathrmds","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"and","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    sigma(t)^2 = int_0^t e^-int_s^t beta(tau)mathrmdtaubeta(s)mathrmds = left -e^-int_s^t beta(tau)mathrmdtau right_s=0^s=t = 1 - e^-int_0^t beta(tau)mathrmdtau","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Thus,","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    p(t x  0 x_0) = mathcalNleft( x x_0 e^-frac12int_0^t beta(s)mathrmds 1 - e^-int_0^t beta(tau)mathrmdtauright)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The Stein score becomes","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    nabla_x log p(t x  0 x_0) = nabla_x left( - frac(x - mu(t)x_0)^22sigma(t)^2 right) = - fracx - x_0 e^-frac12int_0^t beta(s)mathrmds1 - e^-int_0^t beta(tau)mathrmdtau","category":"page"},{"location":"generative/score_based_sde/#Sub-variance-preserving-SDE","page":"Score-based SDE model","title":"Sub-variance-preserving SDE","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"In the sub-variance-preserving case (VP SDE), proposed in Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020) as an alternative to the previous ones,","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    f(t) = -frac12beta(t) quad g(t) = sqrtbeta(t)(1 - e^-2int_0^t beta(s)mathrmds)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"so that","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    mu(t) = e^-frac12int_0^t beta(s)mathrmds","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"and","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    beginalign*\n        sigma(t)^2  = int_0^t e^-int_s^t beta(tau)mathrmdtaubeta(s)(1 - e^-2int_0^s beta(tau)mathrmdtau)mathrmds \n         = int_0^t e^-int_s^t beta(tau)mathrmdtaubeta(s)mathrmds - int_0^t e^-int_s^t beta(tau)mathrmdtaue^-2int_0^s beta(tau)mathrmdtaubeta(s)mathrmds \n         = int_0^t e^-int_s^t beta(tau)mathrmdtaubeta(s)mathrmds - int_0^t e^-int_0^t beta(tau)mathrmdtaue^-int_0^s beta(tau)mathrmdtaubeta(s)mathrmds \n         = 1 - e^-int_0^t beta(tau)mathrmdtau - e^-int_0^t beta(tau)mathrmdtau int_0^t e^-int_0^s beta(tau)mathrmdtaubeta(s)mathrmds \n         = 1 - e^-int_0^t beta(tau)mathrmdtau + e^-int_0^t beta(tau)mathrmdtau lefte^-int_0^s beta(tau)mathrmdtauright_s=0^t \n         = 1 - e^-int_0^t beta(tau)mathrmdtau + e^-int_0^t beta(tau)mathrmdtau left(e^-int_0^t beta(tau)mathrmdtau - 1right) \n         = 1 - 2e^-int_0^t beta(tau)mathrmdtau + e^-2int_0^t beta(tau)mathrmdtau \n         = left(1 - e^-int_0^t beta(tau)mathrmdtauright)^2\n    endalign*","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Thus,","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    p(t x  0 x_0) = mathcalNleft( x x_0 e^-frac12int_0^t beta(s)mathrmds left(1 - e^-int_0^t beta(tau)mathrmdtauright)^2right)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The Stein score becomes","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    nabla_x log p(t x  0 x_0) = nabla_x left( - frac(x - mu(t)x_0)^22sigma(t)^2 right) = - fracx - x_0 e^-frac12int_0^t beta(s)mathrmdsleft(1 - e^-int_0^t beta(tau)mathrmdtauright)^2","category":"page"},{"location":"generative/score_based_sde/#Loss-function","page":"Score-based SDE model","title":"Loss function","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The loss function for training is a continuous version of the loss for the multiple denoising score-matching. In that case, we had","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    J_textrmSMLD(boldsymboltheta) = frac12Lsum_i=1^L lambda(sigma_i) mathbbE_p(mathbfx)p_sigma_i(tildemathbfxmathbfx)left left s_boldsymboltheta(tildemathbfx sigma_i) - fracmathbfx - tildemathbfxsigma_i^2 right^2 right","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"where lambda = lambda(sigma_i) is a weighting factor. When too many levels are considered, one takes a stochastic approach and approximate the loss J_textrmSMLD(boldsymboltheta) by","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    J_textrmSMLD^*(boldsymboltheta) = frac12lambda(sigma_i) mathbbE_p(mathbfx)p_sigma_i(tildemathbfxmathbfx)left left s_boldsymboltheta(tildemathbfx sigma_i) - fracmathbfx - tildemathbfxsigma_i^2 right^2 right","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"with","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    sigma_i sim operatornameUniform1 2 ldots L","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The continuous version becomes","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    J_textrmSDE^*(boldsymboltheta) = frac12lambda(t) mathbbE_p_0(mathbfx_0)p(t tildemathbfx0 mathbfx_0)left left s_boldsymboltheta(t tildemathbfx) - boldsymbolnabla_tildemathbfx log p(t tildemathbfx0 mathbfx_0) right^2 right","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"with","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    t sim operatornameUniform0 T","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"In practice, the empirical distribution is considered for p_0(mathbfx_0) and a stochastic approach is taken by sampling a single tildemathbfx_n sim p(t_n tildemathbfx0 mathbfx_n) besides t_n sim operatornameUniform(0 T) Thus, the loss takes the form","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    tilde J_textrmSDE^*(boldsymboltheta) = frac12Nsum_n=1^N lambda(t_n) left left s_boldsymboltheta(t_n tildemathbfx_n) - boldsymbolnabla_tildemathbfx log p(t_n tildemathbfx_n0 mathbfx_n) right^2 right","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"with","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    mathbfx_n sim p_0 quad t_n sim operatornameUniform0 T quad mathbfx_n sim p(t_n x  0 mathbfx_n)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The explicit form for the distribution p(t_n x  0 mathbfx_n) and its score boldsymbolnabla_tildemathbfx log p(t_n tildemathbfx_n0 mathbfx_n) depends on the choice of the SDE.","category":"page"},{"location":"generative/score_based_sde/#Numerical-example","page":"Score-based SDE model","title":"Numerical example","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"We illustrate, numerically, the use of the score-based SDE method to model a synthetic univariate Gaussian mixture distribution.","category":"page"},{"location":"generative/score_based_sde/#Julia-language-setup","page":"Score-based SDE model","title":"Julia language setup","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"We use the Julia programming language for the numerical simulations, with suitable packages.","category":"page"},{"location":"generative/score_based_sde/#Packages","page":"Score-based SDE model","title":"Packages","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"using StatsPlots\nusing Random\nusing Distributions\nusing Lux # artificial neural networks explicitly parametrized\nusing Optimisers\nusing Zygote # automatic differentiation\nusing Markdown\n\nnothing # hide","category":"page"},{"location":"generative/score_based_sde/#Reproducibility","page":"Score-based SDE model","title":"Reproducibility","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"We set the random seed for reproducibility purposes.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"rng = Xoshiro(12345)\nnothing # hide","category":"page"},{"location":"generative/score_based_sde/#Data","page":"Score-based SDE model","title":"Data","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"We build the usual target model and draw samples from it.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Visualizing the sample data drawn from the distribution and the PDF.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"plt # hide","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Visualizing the score function.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"plt # hide","category":"page"},{"location":"generative/score_based_sde/#Parameters","page":"Score-based SDE model","title":"Parameters","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Here we set some parameters for the model and prepare any necessary data.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"trange = 0.0:0.01:1.0","category":"page"},{"location":"generative/score_based_sde/#Variance-exploding","page":"Score-based SDE model","title":"Variance exploding","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"We start visualizing the score function in the variance exploding case, with sigma(t) = sqrtt, so that g(t) = sqrtmathrmd(sigma(t)^2)mathrmdt = 1, besides f(t) = 0 and mu(t) = 1","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"f_ve(t) = 0.0\ng_ve(t) = 1.0\nmu_ve(t) = 1.0\nsigma_ve(t) = sqrt(t)\n\nprob_kernel_ve(t, x0) = Normal( x0, sigma_ve(t) )\np_kernel_ve(t, x, x0) = pdf(prob_kernel_ve(t, x0), x)\nscore_kernel_ve(t, x, x0) = gradlogpdf(prob_kernel_ve(t, x0), x)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"surface(trange, xrange, (t, x) -> log(sum(x0 -> pdf(prob_kernel_ve(t, x0), x) * pdf(target_prob, x0), xrange)))","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"heatmap(trange, xrange, (t, x) -> log(sum(x0 -> pdf(prob_kernel_ve(t, x0), x) * pdf(target_prob, x0), xrange)))","category":"page"},{"location":"generative/score_based_sde/#Variance-preserving","page":"Score-based SDE model","title":"Variance preserving","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"We also visualize the variance preserving case.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"beta_min = 0.1\nbeta_max = 20.0\n\nf_vp(t; βₘᵢₙ=beta_min, βₘₐₓ=beta_max) = ( βₘᵢₙ + t * ( βₘₐₓ - βₘᵢₙ ) ) / 2\ng_vp(t; βₘᵢₙ=beta_min, βₘₐₓ=beta_max) = √( βₘᵢₙ + t * ( βₘₐₓ - βₘᵢₙ ) )\n\nprob_kernel_vp(t, x0; βₘᵢₙ=beta_min, βₘₐₓ=beta_max) = Normal( x0 * exp( - t^4 * ( βₘₐₓ - βₘᵢₙ ) / 4 - t * βₘᵢₙ / 2 ), 1 - exp( - t^4 * ( βₘₐₓ - βₘᵢₙ ) / 2 - t * βₘᵢₙ ))\np_kernel_vp(t, x, x0) = pdf(prob_kernel_vp(t, x0), x)\nscore_kernel_vp(t, x, x0) = gradlogpdf(prob_kernel_vp(t, x0), x)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"surface(trange, xrange, (t, x) -> log(sum(x0 -> pdf(prob_kernel_vp(t, x0), x) * pdf(target_prob, x0), xrange)))","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"heatmap(trange, xrange, (t, x) -> log(sum(x0 -> pdf(prob_kernel_vp(t, x0), x) * pdf(target_prob, x0), xrange)))","category":"page"},{"location":"generative/score_based_sde/#Preparation","page":"Score-based SDE model","title":"Preparation","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"For the implementation, we consider the variance-exploding (VE) case, with sigma(t) = sqrtt so that","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    f(t) = 0 quad g(t) = sqrtfracmathrmd(sigma(t)^2)mathrmdt = 1","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"with","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    mu(t) = 1","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    sigma(t)^2 = int_0^t fracmathrmd(sigma(s)^2)mathrmdsmathrmds = sigma(t)^2 - sigma(0)^2 = t^2","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"and","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    p(t x  0 x_0) = mathcalNleft( x x_0 t^2right)","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The score conditioned on a initial condition reads","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"    nabla_x p(t x  0 x_0) = - fracx - x_0t^2","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"T = 1.0\nsigma(t) = sqrt(t)\nlambda(t) = 1","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"data = copy(sample_points)","category":"page"},{"location":"generative/score_based_sde/#The-neural-network-model","page":"Score-based SDE model","title":"The neural network model","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The neural network we consider is a simple feed-forward neural network made of a single hidden layer, obtained as a chain of a couple of dense layers. This is implemented with the LuxDL/Lux.jl package.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"We need a little bigger neural network to capture the time-dependent score.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"model = Chain(Dense(2 => 64, relu), Dense(64 => 64, relu), Dense(64 => 1))","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The LuxDL/Lux.jl package uses explicit parameters, that are initialized (or obtained) with the Lux.setup function, giving us the parameters and the state of the model.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model","category":"page"},{"location":"generative/score_based_sde/#Loss-function-2","page":"Score-based SDE model","title":"Loss function","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"function loss_function_sde(model, ps, st, data)\n    sample_points = data\n\n    ts = reshape(0.001 .+ (T - 0.001) * rand(rng, size(sample_points, 2)), 1, :)\n\n    ws = randn(rng, size(sample_points))\n    diffused = sigma.(ts) .* ws\n    noisy_sample_points = sample_points .+ diffused\n##    scores = ( sample_points .- noisy_sample_points ) ./ sigma.(ts) .^ 2 \n\n    model_input = [noisy_sample_points; ts]\n    \n\n    y_score_pred, st = Lux.apply(model, model_input, ps, st)\n\n##    loss = mean(abs2, (y_score_pred .- scores)) / 2\n    loss = mean(abs2, sigma.(ts) .* y_score_pred .+ ws)\n    return loss, st, ()\nend","category":"page"},{"location":"generative/score_based_sde/#Optimization-setup","page":"Score-based SDE model","title":"Optimization setup","text":"","category":"section"},{"location":"generative/score_based_sde/#Optimization-method","page":"Score-based SDE model","title":"Optimization method","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"We use the Adam optimiser.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"opt = Adam(0.01)\n\ntstate_org = Lux.Training.TrainState(model, ps, st, opt)","category":"page"},{"location":"generative/score_based_sde/#Automatic-differentiation-in-the-optimization","page":"Score-based SDE model","title":"Automatic differentiation in the optimization","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"As mentioned, we setup differentiation in LuxDL/Lux.jl with the FluxML/Zygote.jl library.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"vjp_rule = Lux.Training.AutoZygote()","category":"page"},{"location":"generative/score_based_sde/#Processor","page":"Score-based SDE model","title":"Processor","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"We use the CPU instead of the GPU.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"dev_cpu = cpu_device()\n## dev_gpu = gpu_device()","category":"page"},{"location":"generative/score_based_sde/#Check-differentiation","page":"Score-based SDE model","title":"Check differentiation","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Check if Zygote via Lux is working fine to differentiate the loss functions for training.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Lux.Training.compute_gradients(vjp_rule, loss_function_sde, data, tstate_org)","category":"page"},{"location":"generative/score_based_sde/#Training-loop","page":"Score-based SDE model","title":"Training loop","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Here is the typical main training loop suggest in the LuxDL/Lux.jl tutorials, but sligthly modified to save the history of losses per iteration.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"function train(tstate, vjp, data, loss_function, epochs, numshowepochs=20, numsavestates=0)\n    losses = zeros(epochs)\n    tstates = [(0, tstate)]\n    for epoch in 1:epochs\n        grads, loss, stats, tstate = Lux.Training.compute_gradients(vjp,\n            loss_function, data, tstate)\n        if ( epochs ≥ numshowepochs > 0 ) && rem(epoch, div(epochs, numshowepochs)) == 0\n            println(\"Epoch: $(epoch) || Loss: $(loss)\")\n        end\n        if ( epochs ≥ numsavestates > 0 ) && rem(epoch, div(epochs, numsavestates)) == 0\n            push!(tstates, (epoch, tstate))\n        end\n        losses[epoch] = loss\n        tstate = Lux.Training.apply_gradients(tstate, grads)\n    end\n    return tstate, losses, tstates\nend","category":"page"},{"location":"generative/score_based_sde/#Training","page":"Score-based SDE model","title":"Training","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Now we train the model with the objective function tilde J_mathrmESMtilde p_sigmatilde p_0(boldsymboltheta).","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_sde, 2000,80, 80)\n#nothing # hide","category":"page"},{"location":"generative/score_based_sde/#Results","page":"Score-based SDE model","title":"Results","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Checking out the trained model.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"plt # hide","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"plt # hide","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Just for the fun of it, let us see an animation of the optimization process.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"gif(anim, fps = 20) # hide","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"And the animation of the evolution of the PDF.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"gif(anim, fps = 10) # hide","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"We also visualize the evolution of the losses.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"plot(losses[8:end], title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false) # hide","category":"page"},{"location":"generative/score_based_sde/#Sampling-with-reverse-SDE","page":"Score-based SDE model","title":"Sampling with reverse SDE","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Now we sample the modeled distribution with the reverse SDE.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Here are the trajectories.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"plot(title=\"$(length(x0)) reverse SDE trajectories\", titlefont=10, legend=false) # hide\nplot!(tt, xt, xlabel=\"\\$t\\$\", ylabel=\"\\$x\\$\") # hide","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"The sample histogram obtained at the end of the trajectories.","category":"page"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"plot(title=\"Histogram at the end of sampling\", titlefont=10) # hide\nhistogram!(xt[begin, :], bins=40, normalize=:pdf, xlims=extrema(xrange), label=\"sample\") # hide\nplot!(xrange, x -> pdf(target_prob, x), label=\"target PDF\", xlabel=\"\\$x\\$\") # hide\nplot!(xrange, pdf_pred', label=\"model PDF\") # hide","category":"page"},{"location":"generative/score_based_sde/#References","page":"Score-based SDE model","title":"References","text":"","category":"section"},{"location":"generative/score_based_sde/","page":"Score-based SDE model","title":"Score-based SDE model","text":"Aapo Hyvärinen (2005), \"Estimation of non-normalized statistical models by score matching\", Journal of Machine Learning Research 6, 695-709\nPascal Vincent (2011), \"A connection between score matching and denoising autoencoders,\" Neural Computation, 23 (7), 1661-1674, doi:10.1162/NECOa00142\nJ. Sohl-Dickstein, E. A. Weiss, N. Maheswaranathan, S. Ganguli (2015), \"Deep unsupervised learning using nonequilibrium thermodynamics\", ICML'15: Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, 2256-2265\nY. Song and S. Ermon (2019), \"Generative modeling by estimating gradients of the data distribution\", NIPS'19: Proceedings of the 33rd International Conference on Neural Information Processing Systems, no. 1067, 11918-11930\nJ. Ho, A. Jain, P. Abbeel (2020), \"Denoising diffusion probabilistic models\", in Advances in Neural Information Processing Systems 33, NeurIPS2020\nY. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, B. Poole (2020), \"Score-based generative modeling through stochastic differential equations\", arXiv:2011.13456","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/#Irreducibility-and-recurrence-in-the-continuous-space-case","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"","category":"section"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"Irreducibility is a fundamental concept related to the uniqueness of an invariant measure, when it exists, but it does not necessarily implies that it exists.","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/#Definition","page":"Irreducibility and recurrence in the continuous-space case","title":"Definition","text":"","category":"section"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"A time-homogeneous Markov chain (X_n)_n with n-step transition probability K_n(x cdot) is called P-irreducible, with respect to a probability distribution P if","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"    EinmathcalB(mathcalX) P(E)  0 Longrightarrow sum_nin mathbbN K_n(x E)  0 quad forall xin mathcalX","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"This is equivalent to assuming that, ","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"    xinmathcalX EinmathcalB(mathcalX)  P(E)  0 Longrightarrow exists n=n(x E)inmathbbN  K_n(x E)  0","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"The Markov chain is called strongly P-irreducible when n(x E) = 1 for all such x and E","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"Irreducibility means that any measurable set with positive measure is eventually reached by the chain, with positive probability, starting from any point in mathcalX","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"There are several concepts related to irreducibility","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/#First-return-time","page":"Irreducibility and recurrence in the continuous-space case","title":"First return time","text":"","category":"section"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"The integer n(x E) in the equivalent definition of irreducibility can be taken to be the first such integer, which gives the notion of first return time. We do not need irreducibility to define the first return as long as we agree that it is infinity when it does not return.","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"More precisely, given a Borel set Esubset mathcalX and a point x of a given time-discrete Markov chain (X_n)_n the first return of x to E is defined by","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"    n(x E) = infleftninmathcalNcup+infty  n = infty or X_n_X_0 = x in Eright","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/#Stopping-time","page":"Irreducibility and recurrence in the continuous-space case","title":"Stopping time","text":"","category":"section"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"Instead of a function n(x E) from mathcalXtimesmathcalB(mathcalX) to mathbbN we can consider a random variable version of the first return map, which is a random variable from Omega to mathbbN defined as follows.","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"Given a Borel set Esubset mathcalX the stopping time tau_E at E of the Markov chain is the random variable defined by","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"    tau_E = inf ninmathbbNcup+infty  n = +infty textrm or  X_nin E","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"It should be clear that tau_E = infty if the chain never reaches E or it is the first time n such that X_n reaches E","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"The first return time and the stopping time are related by tau_E(omega) = n(X_0(omega) E) for any sample omegainOmega","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"The quantity","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"    P(tau_E  infty)","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"is the probability of return to E in a finite number of steps.","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/#Number-of-passages","page":"Irreducibility and recurrence in the continuous-space case","title":"Number of passages","text":"","category":"section"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"Another useful quantity is the random variable for the number of passages in E","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"    eta_E = sum_n=1^infty mathbb1_X_n in A","category":"page"},{"location":"markov_chains/mc_irreducibility_and_recurrence/#Example","page":"Irreducibility and recurrence in the continuous-space case","title":"Example","text":"","category":"section"},{"location":"markov_chains/mc_irreducibility_and_recurrence/","page":"Irreducibility and recurrence in the continuous-space case","title":"Irreducibility and recurrence in the continuous-space case","text":"Alternating chain example (e.g. X_n+1 = X_n pm 2, so only even or odd integers are reached, so it is not irreducible). Continuous example (e.g. something like X_n+1 = X_n pm X_n + 2 + Beta)","category":"page"},{"location":"sampling/convergence_metropolis/#Convergence-of-the-Metropolis-Hastings-method","page":"Convergence of Metropolis-Hastings","title":"Convergence of the Metropolis-Hastings method","text":"","category":"section"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"The convergences of the Metropolis-Hastings and Gibbs MCMC methods were proved in the early 1990's, in a number of articles, under reasonable assumptions. The rate of convergence, however, can be either sub-geometric or geometric, depending on the assumptions. These convergences are based on classical conditions of stability of Markov Chains. We will follow here the paper Mengersen & Tweedie (1996) and the second edition of the classic book Meyn & Tweeedie (2009) (the first edition Meyn & Tweeedie (1993) was published a few years before the article).","category":"page"},{"location":"sampling/convergence_metropolis/#Fundamental-Markov-chain-concepts","page":"Convergence of Metropolis-Hastings","title":"Fundamental Markov chain concepts","text":"","category":"section"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"The fundamental result, for Markov chains, that we use here is the following","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"note: Theorem (Convergence for a Markov chain)\nLet (X_n)_n be a Markov chain with transition probability A_n(x E) = mathbbP(X_nin E  X_0 = x) where Esubset mathcalX is a Borel measurable set, on the event space mathcalX=mathbbR^d for some dinmathbbN Let p=p(x) be a probability density function, with respect to the Lebesgue measure on mathcalX and suppose the Markov chain is p-irreducible and aperiodic. Then, for p-almost every initial condition xin mathcalX    A_n(x cdot) - p_mathrmTV rightarrow 0 quad nrightarrow inftywhere mu_mathrmTV = sup_AinmathcalB(mathcalX)mu(A) is the total variation norm.","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"We need to clarify some terminology first.","category":"page"},{"location":"sampling/convergence_metropolis/#Irreducibility","page":"Convergence of Metropolis-Hastings","title":"Irreducibility","text":"","category":"section"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"We start with the notion of tilde P-irreducibility (see Section 4.2, page 82, of Meyn & Tweeedie (2009)).","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"note: Definition (irreducible chain)\nA Markov chain (X_n)_n with transition probability A_n(x cdot) is called tilde P-irreducible, with respect to a probability distribution tilde P if    tilde P(E)  0 Longrightarrow sum_nin mathbbN A_n(x E)  0 quad forall xin mathcalXThis is equivalent to assuming that, for all xinmathcalX and all measurable set E with tilde P(E)  0 there exists n(x E) such that A_n(x E)  0 The Markov chain is called strongly tilde P-irreducible when n(x E) = 1 for all such x and E","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"Irreducibility means that any measurable set with positive measure is eventually reached by the chain, with positive probability, starting from any point in mathcalX","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"The definition of irreversibility can be also be made with the notion of stopping time at a set.","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"note: Definition (stopping time)\nLet (X_n)_n be a Markov chain with transition probability A_n(x cdot) Given a measurable set Esubset mathcalX the stopping time tau_E at E of the Markov chain is defined as tau_E = infty if tau_Enotin E for all ninmathbbN or    tau_E = infninmathbbN  X_nin Eotherwise.","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"Thus, the chain is tilde P-irreducible when tilde P(tau_E  0  X_0 = x)  0 for every x and every tilde P(E)  0","category":"page"},{"location":"sampling/convergence_metropolis/#Recurrence","page":"Convergence of Metropolis-Hastings","title":"Recurrence","text":"","category":"section"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"tilde P","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"-Irreducibility implies that any set E of positive tilde P-measure is reached, at some step n(x E) from any point x in space. A stronger property is that of recurrence, when the set is visited infinitely often.","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"note: Recurrence\nA Markov chain (X_n)_n with transition probability A_n(x cdot) is called tilde P-irreducible, with respect to a probability distribution tilde P if    tilde P(E)  0 Longrightarrow sum_nin mathbbN A_n(x E)  0 quad forall xin mathcalX","category":"page"},{"location":"sampling/convergence_metropolis/#Small-sets","page":"Convergence of Metropolis-Hastings","title":"Small sets","text":"","category":"section"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"For the aperiodicity, we need the concept of small set. (see Section 5.2, page 102, of Meyn & Tweeedie (2009)).","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"note: Definition (small set)\nLet (X_n)_n be a Markov chain with n-transition probability A_n(x cdot) A set C is called a small set if there exist ninmathbbN delta  0 and a probability measure nu such that    A_n(x E) geq deltanu(E) quad forall xin C forall EinmathcalB(E)","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"Equivalently, some authors take delta = 1 and ask nu to be a nontrivial measure, without necessarily being normalized to a probability measure.","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"One motivation behind this notion is that, when 0delta  1 we can write","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"    A_n(x E) = deltanu(E) + (1-delta)K_n(x E) quad forall EinmathcalB(mathcalX)","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"where K_n(x E) = (A_n(x E) - nu(E))(1-delta) is itself a probability distribution, and notice that the n-transition probability has a nontrivial portion nu that does not depend on the initial point x This allows us to get some uniform bounds.","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"The case delta  1 is not possible. Indeed, notice that the condition for being a small set means that","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"    mu_n(x E) = A_n(x E) - deltanu(E) geq 0 ","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"which implies that the signed measure mu_n(x cdot) is nonnegative and, hence, is actually a measure. Notice then that","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"    0 leq mu_n(x E) leq mu_n(x mathbbR) = A_n(x mathbbR) - deltanu(mathbbR) = 1 - delta","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"This means not only that delta leq 1 but also that, if delta = 1 then mu_n(x E) = 0 for all E and hence A_n(x cdot) = deltanu(cdot)","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"In summary, we must have 0  delta leq 1 If delta = 1 then A(x E) = delta nu(E) is independent of x on C. And if 0  delta  1 A(x E) = delta nu(E) + (1-delta)K_n(x cdot) so that there is at least a nontrivial part of A(xcdot) that is independent of x on C In any case, this allows us to obtain uniform lower bounds for the transition distribution.","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"But that does not give us much intuition to why it is called a small set, or in what sense that would be small. This can be illustrated with a few random walk examples.","category":"page"},{"location":"sampling/convergence_metropolis/#A-fair-random-walk","page":"Convergence of Metropolis-Hastings","title":"A fair random walk","text":"","category":"section"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"Consider the random walk (see e.g. Section 1.2.3 of Meyn & Tweeedie (2009))","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"    X_n+1 = X_n + W_n qquad W_n sim mathcalN(0 1)","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"on mathcalX = mathbbR If we take a set C_r=-r r where r  0 then, for each xin C the PDF mathcalN(y x 1) = e^-(x - y)^22sqrt2pi yinmathbbR of the normal distribution mathcalN(x 1) with mean x and variance 1 is such that","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"    mathcalN(y x 1) geq mathcalN(2r 0 1) = frac1sqrt2pie^-2r^2 quad forall xin C_r = -r r","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"Thus, if we take nu_r to be the uniform distribution over C_r and noticing that the Lebesgue measure of C_r is 2r and that A(x cdot) = mathcalN(x 1) is the transition probability of this random walk, we have","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"    A(x cdot) geq delta_r nu_r(cdot) quad delta_r = frac2rsqrt2pie^-r^2","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"More explicitly, we have, for any Borel set E and any xin C_r","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"    beginalign*\n        A(x E)  = frac1sqrt2piint_E e^-(x - y)^22 mathrmdy \n         geq frac1sqrt2piint_E cap C_r e^-(x - y)^22 mathrmdy \n         geq frac1sqrt2piint_E cap C_r e^-(2r)^22 mathrmdy \n         = frac1sqrt2pi e^-2r^2 int_Ecap C_r mathrmdy \n         = frac2rsqrt2pi e^-2r^2 frac12rint_Ecap C_r mathrmdy \n         = delta_r nu_r(E)\n    endalign*","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"The value of delta_r has its maximum at r = 12 with value e^-12sqrt2pi approx 024 decreasing to zero either as we increase r towards infty or decrease it towards zero. In a sense, delta_rnu_r(cdot) is small, regardless of r  0","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"plot(plts..., layout=(3, 1), size=(600, 900)) # hide","category":"page"},{"location":"sampling/convergence_metropolis/#Random-walk-on-a-half-line","page":"Convergence of Metropolis-Hastings","title":"Random walk on a half line","text":"","category":"section"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"Now we consider the following random walk on the nonnegative half line.","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"    X_n+1 = X_n + W_n^+ qquad W_n sim mathcalN(0 1)","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"where s^+ = max0 s for any real s","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"Note that X_n n=0 1 2 ldot can only assume nonnegative values, and that for any xgeq 0","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"    mathbbP(X_n+1 = 0X_n = x) = int_-infty^0 frac1sqrt2pi e^frac12y - x^2 = frac1sqrt2piint_-infty^-x e^frac12s^2 mathrmds = F_mathcalN(-x)  0","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"where F_mathcalN denotes the cumulative distribution function of the standard normal distribution.","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"Thus, if we take nu=nu_0 to be the delta distribution at x=0 we see that the singleton C=0 and any interval C=0 r r  0 is a small set for this random walk, since","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"    A(x E) geq F_mathcalN(-x)delta_0(E) geq deltanu_0(E) qquad forall EinmathcalB(mathbbR)","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"with delta = F_mathcalN(-r)","category":"page"},{"location":"sampling/convergence_metropolis/#Aperiodicity","page":"Convergence of Metropolis-Hastings","title":"Aperiodicity","text":"","category":"section"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"With the notion of small set, we have the definition of aperiodicity.","category":"page"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"note: Definition (aperiodic chain)\nLet (X_n)_n be a Markov chain with transition probability A_n(x cdot) Then, the chain is called aperiodic when, for some small set C with tilde p(C)  0 the greatest common divisor of all the integers ninmathbbN such that    A_n(x E) geq nu(E) quad forall xin E forall EinmathcalB(E)is 1","category":"page"},{"location":"sampling/convergence_metropolis/#Metropolis-Hastings-properties","page":"Convergence of Metropolis-Hastings","title":"Metropolis-Hastings properties","text":"","category":"section"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"With these definitions in mind and with the results above, we check that the Metropolis-Hastings chain is p-irreducible and aperiodic and, thus, it convergences, in total variation, to the desired distribution p when nrightarrow infty","category":"page"},{"location":"sampling/convergence_metropolis/#Further-concepts-and-properties","page":"Convergence of Metropolis-Hastings","title":"Further concepts and properties","text":"","category":"section"},{"location":"sampling/convergence_metropolis/#References","page":"Convergence of Metropolis-Hastings","title":"References","text":"","category":"section"},{"location":"sampling/convergence_metropolis/","page":"Convergence of Metropolis-Hastings","title":"Convergence of Metropolis-Hastings","text":"K. L. Mengersen, R. L. Tweedie (1996), \"Rates of convergence of the Hastings and Metropolis algorithms,\" The Annals of Statistics, 24, no. 1, 101-121\nS. P. Meyn, R. L. Tweeedie (1993), \"Markov Chains and Stochastic Stability,\" vol. 1, Springer-Verlag\nS. P. Meyn, R. L. Tweeedie (2009), \"Markov Chains and Stochastic Stability,\" vol. 2, Cambridge University Press","category":"page"},{"location":"sampling/empiricalsup_rejection/#Empirical-supremum-rejection-method","page":"Empirical supremum rejection sampling","title":"Empirical supremum rejection method","text":"","category":"section"},{"location":"sampling/empiricalsup_rejection/","page":"Empirical supremum rejection sampling","title":"Empirical supremum rejection sampling","text":"A variation of the von Neumann rejection sampling, proposed by Caffo, Booth, and Davison (2002) (see also Section 6.3.3 Empirical Supremum Rejection Sampling of Peng (2022)), relaxes the need to know a good bound for f(x) leq M q(x) Instead, one uses an adaptive guess that gets updated each time a sample is rejected and the acceptance rate is greater than one.","category":"page"},{"location":"sampling/empiricalsup_rejection/#Setting","page":"Empirical supremum rejection sampling","title":"Setting","text":"","category":"section"},{"location":"sampling/empiricalsup_rejection/","page":"Empirical supremum rejection sampling","title":"Empirical supremum rejection sampling","text":"The setting is similar to that of the rejection sampling method. One considers a univariate random variable X with density p=p(x) such that","category":"page"},{"location":"sampling/empiricalsup_rejection/","page":"Empirical supremum rejection sampling","title":"Empirical supremum rejection sampling","text":"We may not know the density p(x) but we do know a non-negative function f(x) proportional to the density, with some unknown normalizing constant Z  0 i.e.\n     p(x) = fracf(x)Z \nWe know how to sample from another random variable X with known density q=q(x) which bounds a multiple of the function f(x) with an unknown bound, i.e. for some unknown M0","category":"page"},{"location":"sampling/empiricalsup_rejection/","page":"Empirical supremum rejection sampling","title":"Empirical supremum rejection sampling","text":"    f(x) leq M q(x) quad forall x","category":"page"},{"location":"sampling/empiricalsup_rejection/#The-rejection-sampling-method","page":"Empirical supremum rejection sampling","title":"The rejection sampling method","text":"","category":"section"},{"location":"sampling/empiricalsup_rejection/","page":"Empirical supremum rejection sampling","title":"Empirical supremum rejection sampling","text":"Under this setting, we obtain samples of X by sampling from X and accepting or rejecting the candidate sample according to an acceptance ratio with an adaptive multiplicative factor, updating this factor if the ratio is larger than one, and repeating the process until a candidate is accepted, and for as many samples that we want. More precisely, here are the steps of the method.","category":"page"},{"location":"sampling/empiricalsup_rejection/","page":"Empirical supremum rejection sampling","title":"Empirical supremum rejection sampling","text":"Start with an educated guess C to hopefully bound f(x) by Cq(x)\nDraw a sample x of X which we call a candidate sample;\nCompute the acceptance ratio r(x C) where r(x C) = fracf(x)Cq(x)\nDraw a sample u from the uniform distribution operatornameUniform(0 1)\nAccept/reject/update step:\nIf u leq r(x) accept the sample x as a sample x=x of the desired random variable X\nOtherwise, if u  r(x) reject the sample x check whether r(x)  1 in which case the multiplicative factor C is updated by C=f(x)q(x) and then repeat the process drawing a new candidate and so on, until a candidate sample is accepted.\nRepeat for as many samples as desired.","category":"page"},{"location":"sampling/empiricalsup_rejection/#References","page":"Empirical supremum rejection sampling","title":"References","text":"","category":"section"},{"location":"sampling/empiricalsup_rejection/","page":"Empirical supremum rejection sampling","title":"Empirical supremum rejection sampling","text":"Brian S. Caffo, James G. Booth, A. C. Davison (2002), \"Empirical supremum rejection sampling,\" Biometrika, Volume 89, Issue 4, 745–754\nJohn von Neumann, \"Various techniques used in connection with random digits. Monte Carlo methods\" Nat. Bureau Standards, 12 (1951), 36–38.\nRoger D. Peng, \"Advanced Statistical Computing\", online","category":"page"},{"location":"sensitivity/overview/#Sensitivity-analysis","page":"Overview","title":"Sensitivity analysis","text":"","category":"section"},{"location":"sampling/hmc/#Hamiltonian-Monte-Carlo-(HMC)","page":"Hamiltonian Monte Carlo (HMC)","title":"Hamiltonian Monte Carlo (HMC)","text":"","category":"section"},{"location":"generative/reverse_flow/#Reverse-probability-flow","page":"Reverse probability flow","title":"Reverse probability flow","text":"","category":"section"},{"location":"generative/reverse_flow/#Aim","page":"Reverse probability flow","title":"Aim","text":"","category":"section"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Review the reverse probability flow used for sampling, after the Stein score function has been trained, as developed in Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole (2020) and Karras, Aittala, Aila, and Laine (2022), based on the probability flow ODE developed in these articles and on the reverse time diffusion equation model previously worked out by Anderson (1982).","category":"page"},{"location":"generative/reverse_flow/#Reverse-ODE","page":"Reverse probability flow","title":"Reverse ODE","text":"","category":"section"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"For an ODE of the form","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    fracmathrmdxmathrmdt = f(t x)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"reverting time, on a time interval 0 T is just a matter of decreasing t from T to 0 One way to think of it is via the integral formula","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    x(T) = x(t) + int_t^T f(s x(s))mathrmds","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"so that","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    x(t) = x(T) - int_t^T f(s x(s))mathrmds","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Another way is to write tilde x(tilde t) = x(T - tilde t) and use the chain rule","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    fracmathrmdtilde x(tilde t)mathrmdtilde t = -fracmathrmdxmathrmdt(T - tilde t) = - f(T-tilde t x(T-tilde t)) = -f(T-tilde t tilde x(tilde t))","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Integrating from 0 to T yields an integral relation equivalent to the previous one. In fact,","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    tilde x(tilde t) = tilde x(0) - int_0^tilde t f(T-tau tilde x(tau)) mathrmdtau","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Going back to x(cdot) and making the change of variables s = T - tau ","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    x(T - tilde t) = x(T) - int_0^T f(T-tau x(T-tau))mathrmdtau = x(T) + int_T^T-tilde t f(s x(s))mathrmds","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Back to t = T - tilde t yields","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    x(t) = x(T) - int_t^T f(s x(s))mathrmds","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The Euler method for the reverse flow is simply stepping backwards, from t to t - Delta t with the Taylor approximation reading","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    x(t_j) = x(t_j+1) - f(t_j+1 x(t_j+1))Delta t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"with","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    t_j = jDelta t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"for","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    Delta t = T  n","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"and ninmathbbN given.","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"If the initial condition is a random variable X_0 and the flow evolves to X_T then the reverse flow evolves back to X_0 By approximating X_T sim Y_T by another random variable Y_T say a standard normal distribution as in the generative diffusion processes, then the reverse flow evolves backwards towards an approximation Y_0 of the initial distribution X_0","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"We remark that this is a pathwise reversion, meaning that each forward path x(t) with initial condition x(0) is traced back by the reverse equation starting at the final point x(T) This is obtained without any knowledge of the prior solution, i.e. the backward integration only depends on the future of the solution. More precisely, we only need to know X_T and the function f(t x) in order to solve (or numerically approximate) the solution X_t for 0 leq t leq T","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"This is in contrast with the result for SDEs, for which, without knowledge of a forward solution X_t(omega) nor of the specific path W_t(omega) of the driving Weiner process, we are not able to trace back exactly the same solution only from the knowledge of X_T(omega) But the important fact is that we can still solve backwards the equation using a possibly different Wiener process and recover possibly different solutions of the forward equation, but which collectively give the same probability distribution. In order to trace back the exact forward paths, a specific Wiener process must be used.","category":"page"},{"location":"generative/reverse_flow/#Reverse-Itô-diffusion","page":"Reverse probability flow","title":"Reverse Itô diffusion","text":"","category":"section"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Consider now a forward evolution given by an Itô diffusion SDE","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathrmdX_t = f(t X_t)mathrmdt + G(t X_t)mathrmdW_t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"where the drift factor is a vector-valued function fItimes mathbbR^d rightarrow mathbbR^d, the driving process W_t in mathbbR^k is a vector of independent Wiener processes, and the diffusion factor is a matrix-valued, time-dependent function GItimes mathbbR^d rightarrow mathbbR^dtimes k","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"In the following proof, we cannot deduce that the reverse equation traces back exactly a given sample path X_t(omega) as in the ODE case. Instead, we only obtain that the reverse SDE generates the same probability distribution as the forward SDE. We will recover the same path only with a specific Wiener process, as done further below.","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Notice the reverse diffusion equation requires knowledge of the Stein score function, which fortunately is not a problem in the use case we have in mind, where the Stein score is properly modeled.","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"One way of obtaining the reverse SDE, as derived in Anderson (1982), and seen in other works (e.g. Haussmann and Pardoux (1986)), is by looking at the joint distribution p(t x_t s x_s) at two different times t and s and by working with conditional distributions. We do it differently here, though: we exploit the connection between the SDE and the probability flow, introduced by Maoutsa, Reich, Opper (2020) and generalized by Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020) and Karras, Aittala, Aila, Laine (2022).","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"For the stochastic differential equation above, the probability flow ODE obtained by Karras, Aittala, Aila, Laine (2022) reads (except for the symbol Y_t_t instead of X_t_t) ","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    fracmathrmdY_tmathrmdt = f(t Y_t) - frac12 nabla_x cdot ( G(t Y_t)G(t Y_t)^mathrmtr ) - frac12 G(t Y_t)G(t Y_t)^mathrmtrnabla_x log p(t Y_t)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Both X_t_t and Y_t_t have the same probability distribution p(t cdot)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"We now write the reverse ODE by making the change of variables tilde Y_tilde t = Y_T - tilde t with the reverse time variable tilde t = T - t It is just an ODE (pathwise), so the reverse equation follows from a straightforward chain rule, upon the change tilde t mapsto T - tilde t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        fracmathrmdtilde Y_tilde tmathrmdtilde t = fracmathrmdmathrmdtilde tY_T - tilde t = - fracmathrmdY_T - tilde tmathrmdtilde t  = - f(T - tilde t Y_T - tilde t) + frac12 nabla_y cdot ( G(T - tilde t Y_T - tilde t)G(T - tilde t Y_T - tilde t)^mathrmtr ) \n         qquad qquad + frac12 G(T - tilde t Y_T - tilde t)G(T - tilde t Y_T - tilde t)^mathrmtrnabla_y log p(T - tilde t Y_T - tilde t)\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"i.e.","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        fracmathrmdtilde Y_tilde tmathrmdtilde t  = - f(T - tilde t tilde Y_tilde t) + frac12 nabla_y cdot ( G(T - tilde t tilde Y_tilde t)G(T - tilde t tilde Y_tilde t)^mathrmtr ) \n         qquad qquad + frac12 G(T - tilde t tilde Y_tilde t)G(T - tilde t tilde Y_tilde t)^mathrmtrnabla_y log p(T - tilde t tilde Y_tilde t)\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The terms with GG^mathrmtr don't come with the right sign (for the conversion from probability flow ODE to the associated SDE), so we just rewrite it as (like adding and subtracting the same terms)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        fracmathrmdtilde Y_tilde tmathrmdtilde t  = - f(T - tilde t tilde Y_tilde t) + nabla_y cdot ( G(T - tilde t tilde Y_tilde t)G(T - tilde t tilde Y_tilde t)^mathrmtr ) \n         qquad qquad + G(T - tilde t tilde Y_tilde t)G(T - tilde t tilde Y_tilde t)^mathrmtrnabla_y log p(T - tilde t tilde Y_tilde t) \n         qquad qquad - frac12 nabla_y cdot ( G(T - tilde t tilde Y_tilde t)G(T - tilde t tilde Y_tilde t)^mathrmtr ) \n         qquad qquad - frac12 G(T - tilde t tilde Y_tilde t)G(T - tilde t tilde Y_tilde t)^mathrmtrnabla_y log p(T - tilde t tilde Y_tilde t)\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Now, with the proper sign, the last two terms on the right hand side become the diffusion term in the associated SDE for which this is the probability flow equation, namely","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        mathrmdtilde X_tilde t  = bigg( - f(T - tilde t tilde X_tilde t) + nabla_x cdot ( G(T - tilde t tilde X_tilde t)G(T - tilde t tilde X_tilde t)^mathrmtr ) \n         qquad qquad + G(T - tilde t tilde X_tilde t)G(T - tilde t tilde X_tilde t)^mathrmtrnabla_x log p(T - tilde t tilde X_tilde t) bigg) mathrmdtilde t\n         qquad qquad qquad + G(T - tilde t tilde X_tilde t)mathrmdtilde W_tilde t\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"where tilde W_tilde t_tilde t is a (possibly different) Wiener process. In integral form, the equation for tilde X_tilde t integrating from tilde t = 0 to tilde t = T - t reads","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        tilde X_tilde t - tilde X_0  = int_0^tilde t bigg( - f(T - tilde tau tilde X_tilde tau) + nabla_x cdot ( G(T - tilde tau tilde X_tilde tau)G(T - tilde tau tilde X_tilde tau)^mathrmtr ) \n         qquad qquad + G(T - tilde tau tilde X_tilde tau)G(T - tilde tau tilde X_tilde tau)^mathrmtrnabla_x log p(T - tilde tau tilde X_tilde tau) bigg) mathrmdtilde tau\n         qquad qquad qquad + int_0^tilde t G(T - tilde tau tilde X_tilde tau)mathrmdtilde W_tilde tau\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Back to the original (forward) time t = T - tilde t setting hat X_t = tilde X_T - t = tilde X_tilde t and making the change of variable tau = T - tilde tau in the integral term, this becomes","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        hat X_t - hat X_T  = int_t^T bigg( - f(tau hat X_tau) + nabla_x cdot ( G(tau hat X_tau)G(tau hat X_tau)^mathrmtr ) \n         qquad qquad + G(tau hat X_tau)G(tau hat X_tau)^mathrmtrnabla_x log p(tau hat X_tau) bigg) mathrmdtau\n         qquad qquad qquad - int_t^T G(tau hat X_tau)mathrmdtilde W_T-tau\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"which can be written as","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        hat X_T - hat X_t  = int_t^T bigg( f(tau hat X_tau) - nabla_x cdot ( G(tau hat X_tau)G(tau hat X_tau)^mathrmtr ) \n         qquad qquad - G(tau hat X_tau)G(tau hat X_tau)^mathrmtrnabla_x log p(tau hat X_tau) bigg) mathrmd tau\n         qquad qquad qquad + int_t^T G(tau hat X_tau)small triangledownmathrmdhat W_tau\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"with shorthand","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        mathrmdhat X_t  = bigg( f(t hat X_t) - nabla_x cdot ( G(t hat X_t)G(t hat X_t)^mathrmtr ) \n         qquad qquad - G(t hat X_t)G(t hat X_t)^mathrmtrnabla_x log p(t hat X_t) bigg) mathrmdt + G(tau hat X_t)small triangledownmathrmdhat W_t\n    endalign* ","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"where","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    hat W_t = tilde W_T - t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"with the understanding that hat W_t_0 leq t leq T is a backward Wiener process, for which hat W_T = 0 the term hat X_t = tilde X_T - t is independent of previous steps of the backward Wiener process, such as hat W_t - tau - hat W_t = tilde W_T - t + tau - tilde W_T - t tau  0 and the stochastic integral with small triangledownmathrmdhat W_t is a backward Itô integral, given by","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    int_t^T hat H_tau small triangledownmathrmdhat W_tau = lim sum_i=0^n-1 hat H_t_i+1 ( hat W_t_i+1 - hat W_t_i )","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"where t = tau_0  tau_1  tau_n = T and the limit is taken as max_i=0 n-1tau_i+1 - tau_i rightarrow 0 This is essentially the Itô integral rephrased backwards, since the filtration is also reversed. Let us examine this more carefully.","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"We start with the Itô integral","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    int_0^T - t tilde H_tilde taumathrmdtilde W_tilde tau","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"defined for any given (non-antecipative) process H_tilde t_tilde t geq 0 with respect to a (forward) Wiener process tilde W_tilde t_tilde t geq 0 This can be thought as the limit, as the mesh 0 = tilde tau_0  tilde tau_1  ldots  tilde tau_n = T - tilde t is refined, of the sums","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    sum_j=1^n tilde H_tilde tau_j-1(tilde W_tilde tau_j - tilde W_tilde tau_j-1)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Now we define the points tau_j = T - tilde tau_j which form a mesh T = tau_0 = T - tilde tau_0  ldots T - tilde tau_n = T - t = tau_n The summation can be written as","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    sum_j=1^n tilde H_tilde tau_j-1(tilde W_tilde tau_j - tilde W_tilde tau_j-1) = sum_j=1^n tilde H_T - tau_j-1 ( tilde W_T - tau_j - tilde W_T - tau_j-1 )","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Defining hat H_t = tilde H_T - t and hat W_t = tilde W_T - t we write the above as","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    sum_j=1^n hat H_tau_j-1 ( hat W_tau_j - hat W_tau_j-1 )","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"But notice that, now, tau_j  tau_j-1 In order to make this fact look more natural, we reindex the summation with i = N - j and define the mesh with hat tau_i = tau_N-i so that","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        sum_j=1^n hat H_tau_j-1 ( hat W_tau_j - hat W_tau_j-1 )  = sum_i=0^n-1 hat H_tau_N-i-1 ( hat W_tau_N-i - hat W_tau_N-i-1 ) \n         = sum_i=0^n-1 hat H_tau_N-(i+1) ( hat W_tau_N-i - hat W_tau_N-(i+1) ) \n         = sum_i=0^n-1 hat H_hat tau_i+1 ( hat W_hat tau_i - hat W_hat tau_i+1 ) \n         = - sum_i=0^n-1 hat H_hat tau_i+1 ( hat W_hat tau_i+1 - hat W_hat tau_i )\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The mesh runs from hat tau_0 = tau_N = T-t to hat tau_N = tau_0 = T As the mesh is refined, this becomes the backward Itô integral","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    -int_t^T hat H_hat tausmall triangledownmathrmdhat W_hat tau","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Thus, we have obtained the following identity between the forward and backward Itô integrals,","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    int_0^T - t tilde H_tilde taumathrmdtilde W_tilde tau = -int_t^T hat H_hat tausmall triangledownmathrmdhat W_hat tau","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"with the relevant changes of variables","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    hat H_t = tilde H_T - t qquad hat W_t = tilde W_T - t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The process tilde H_tilde t is independent of future increments of the Wiener process tilde W_tilde t_tilde t geq 0 if, and only if, hat H_t is independent of previous increments of the backward Wiener process hat W_t_0leq t leq T","category":"page"},{"location":"generative/reverse_flow/#Tracing-back-the-same-forward-paths-with-a-specific-Wiener-process","page":"Reverse probability flow","title":"Tracing back the same forward paths with a specific Wiener process","text":"","category":"section"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Notice we wrote, above, hat X_t instead of X_t because the paths might not be the same, although the distributions are. In order to trace back the same sample paths, one must use a specific Wiener process bar W_t_tgeq 0 defined as the weak solution (i.e. with the specific original Wiener process W_t_tgeq 0 of the forward path)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathrmdbar W_t = mathrmdW_t + frac1p(t X_t)nabla_x cdot (p(t X_t) G(t X_t)) mathrmdt","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"i.e.","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    bar W_t = W_t + int_0^t frac1p(s X_s)nabla_x cdot (p(s X_s) G(s X_s)) mathrmds","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"With this noise, if X_t_tgeq 0 is the solution of the forward diffusion equation","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathrmdX_t = f(t X_t)mathrmdt + G(t X_t)mathrmdW_t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"then it also solves the reverse equation","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathrmdX_t = bar f(t X_t)mathrmdt + G(t X_t)small triangledownmathrmdbar W_t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"where","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        bar f(t x)  = f(t x) - nabla_x cdot ( G(t x)G(t x)^mathrmtr ) - G(t x)G(t x)^mathrmtrnabla_x log p(t x) \n         = f(t x) - frac1p(t x)nabla_x cdot (G(t x)G(t x)^mathrmtr p(t x))\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The fact that bar W_t_tgeq 0 is actually a Wiener process is based on the characterization of Wiener processes as almost surely continuous martingales with W_0 = 0 and with quadratic variation W_t W_t = t for all tgeq 0","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The fact that it is a martingale follows from the fact that the integral term is itself a martingale. Indeed, this follows from","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        mathbbEbigg int_t^t+tau  frac1p(s X_s)nabla_x cdot (p(s X_s) G(s X_s)) mathrmdsbigg = int_Omega int_t^t+tau frac1p(s X_s(omega))nabla_x cdot (p(s X_s(omega)) G(s X_s(omega))) mathrmdsmathrmdmathbbP(omega) \n         =  int_t^t+tau int_mathbbR frac1p(s x)nabla_x cdot (p(s x) G(s x)) p(s x)mathrmdxmathrmds \n         = int_t^t+tau int_mathbbR nabla_x cdot (p(s x) G(s x)) mathrmdxmathrmds \n         = 0\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"for arbitrary t tau geq 0 provided we have sufficient decay of p(s x) G(s x) as xrightarrow pminfty","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Now, since the second term in the definition of bar W_t is a Riemann integral, its quadratic variation is zero, and thus","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    bar W_t bar W_t_t = W_t W_t_t = t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Hence, from the Lévy characterization, bar W_t_tgeq 0 is a Wiener process.","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The fact that X_t is independent of previous steps of bar W_t_t geq 0 say bar W_t_2 - bar W_t_1 0 leq t_1  t_2 leq t follows from the facts that X_t is adapted to W_t_tgeq 0 and that W_t itself is independent of previous steps of bar W_t_t geq 0 The proof of that is a bit involved, though, and can be found in Anderson (1982). Here, we content ourselves in proving that in a specific simple case below.","category":"page"},{"location":"generative/reverse_flow/#A-simple-scalar-example","page":"Reverse probability flow","title":"A simple scalar example","text":"","category":"section"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"For illustrative purposes, consider the trivial diffusion equation","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathrmdX_t = sigma mathrmdW_t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"with","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    X_0 = 0","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The solution is simply","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    X_t = sigma W_t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The marginal probability densities of this stochastic process are","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    p(t x) = frac1sqrt2pi sigma^2 te^-frac12fracx^2sigma^2t quad xinmathbbR","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"for t  0 In this case,","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    frac1p(s x)nabla_x cdot (p(s x) G(s x)) = sigma frac1p(s x)nabla_x cdot (p(s x)) = sigma nabla_x log(p(s x))","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"with","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    sigmanabla_x log(p(s x)) = sigma nabla_x left( -frac12fracx^2sigma^2t - log(sqrt2pi sigma^2 t) right) = - fracxsigma t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Thus, the reverse Wiener process takes the form","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    bar W_t = W_t - int_0^t fracX_ssigma s mathrmds = W_t - int_0^t fracW_ssmathrmds","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Write","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    X_T - X_t = sigma W_T - sigma W_t = sigma bar W_T - sigma bar W_t + sigmaint_t^T fracW_ssmathrmds = sigma (bar W_T - bar W_t) + int_t^T fracX_ssmathrmds","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"This becomes the reverse diffusion equation","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathrmdX_t = fracX_ttmathrmdt + sigmamathrmdbar W_t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The diffusion term is a trivial constant term, but, nevertheless, we still have the remarkable property that X_t=sigma W_t is independent of previous increments of bar W_t Indeed, both are Gaussian processes with zero mean, so the covariance, with 0 leq t - tau  t is given by","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        mathbbEX_t (bar W_t - bar W_t - tau)  = sigmamathbbEleft W_t (bar W_t - bar W_t - tau)right \n         = sigmamathbbEleft W_t left(W_t - W_t - tau - int_t-tau^t fracW_ssmathrmdsright)right \n         = sigmamathbbEleft W_t^2right - sigmamathbbEleftW_t W_t - tauright - int_t-tau^t fracmathbbEW_t W_ssmathrmds \n         = sigma t - sigma mint t - tau - sigma int_t-tau^t fracmint ssmathrmds \n         = sigma t - sigma (t - tau) - sigma int_t-tau^t mathrmds \n         = sigma t - sigma (t - tau) - sigma tau \n         = 0\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"showing that they are uncorrelated. Similarly with","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathbbEX_t_2 (bar W_t_1 - bar W_t_0) = sigma t_1 - sigma t_0 - sigma (t_1 - t_0) = 0","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"for 0 leq t_0  t_1 leq t_2","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"In order to see that bar W_t_t geq 0 is, in fact, a Wiener process, we first notice that the formula in the definition implies that it is a Gaussian process with zero expectation at each time. Now we compute the covariance, at times t s geq 0 ","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        mathbbEbar W_t bar W_s  = mathbbEleft left(W_t - int_0^t fracW_tautaumathrmdtauright)left(W_s - int_0^s fracW_xiximathrmdxiright)right \n         = mathbbEleft W_t W_s - int_0^s fracW_t W_xiximathrmdxi - int_0^t fracW_tau W_staumathrmdtau + int_0^t int_0^s fracW_tau W_xitauximathrmdximathrmdtauright \n         = mathbbEW_t W_s - int_0^s fracmathbbEW_t W_xiximathrmdxi - int_0^t fracmathbbEW_tau W_staumathrmdtau + int_0^t int_0^s fracmathbbEW_tau W_xitauximathrmdximathrmdtau \n         = mint s - int_0^s fracmint xiximathrmdxi - int_0^t fracmintau staumathrmdtau + int_0^t int_0^s fracmintau xitauximathrmdximathrmdtau\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Assuming 0 leq s leq t we obtain","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    beginalign*\n        mathbbEbar W_t bar W_s  = s - int_0^s mathrmdxi - int_0^s mathrmdtau - int_s^t fracstaumathrmdtau + int_0^s int_0^tau frac1taumathrmdximathrmdtau + int_0^s int_tau^s frac1ximathrmdximathrmdtau + int_s^t int_0^s frac1taumathrmdximathrmdtau\n         = s - s - s - int_s^t fracstaumathrmdtau + int_0^s mathrmdtau + int_0^s int_0^xi frac1ximathrmdtaumathrmdxi + int_s^t fracstaumathrmdtau  \n         = s - s - s + s + s \n         = s\n    endalign*","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"For 0 leq t leq s we get","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathbbEbar W_t bar W_s = t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"which means that","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathbbEbar W_t bar W_s = mint s","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Thus, by the characterization of Wiener processes as the Gaussian processes with zero mean and correlation mint s we see that bar W_t_t geq 0 is indeed a Wiener process.","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"As a final remark, notice that, if we revert time tilde t = T - t in the equation","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathrmdX_t = fracX_ttmathrmdt + sigmamathrmdbar W_t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"we find","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathrmdtilde X_tilde t = - fractilde X_tilde tT - tilde tmathrmdtilde t + sigmamathrmdtilde W_tilde t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"for tilde X_tilde t = X_T - tilde t = X_t and tilde W_tilde t = bar W_T - tilde t This is the Brownian bridge equation, except that we start at tilde X_0 = X_T and end up at tilde X_T = X_0","category":"page"},{"location":"generative/reverse_flow/#An-example-with-a-time-dependent-diffusion-coefficient","page":"Reverse probability flow","title":"An example with a time-dependent diffusion coefficient","text":"","category":"section"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Let us consider now a different example, with a time-varying diffusion coefficient. We start with X_0 = 0 and consider the SDE with f=0 and g=g(t) = sqrt2sigma(t)sigma(t) for a given sigma=sigma(t)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"begincases\n    mathrmdX_t = sqrt2sigma(t)sigma(t)mathrmdW_t \n    X_tbigg_t=0 = 0\nendcases","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The solution is a time-changed Brownian motion,","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    X_t = int_0^t sqrt2sigma(s)sigma(s) mathrmdW_s = W_sigma(t)^2","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"The probability density function for the process is","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    p(t x) = G(sigma(t)) = frac1sqrt2pisigma(t)^2 e^-frac12fracx^2sigma(t)^2","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"where G=G(sigma) is the probability density function of the normal distribution mathcalN(0 sigma^2)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Since","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"ln p(t x) = -frac12fracx^2sigma(t)^2 - ln(sqrt2pisigma(t)^2)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"the Stein score function of the process X_t_tgeq 0 is","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    nabla_x ln p(t x) = -fracxsigma(t)^2","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Hence, the reverse equation","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathrmdX_t = -g(t)^2nabla_x ln p(t X_t) mathrmdt + g(t)small triangledownmathrmdhat W_t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"becomes","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathrmdX_t = fracg(t)^2sigma(t)^2 X_tmathrmdt + g(t)small triangledownmathrmdhat W_t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"or, in terms of sigma and sigma","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    mathrmdX_t = 2fracsigma(t)sigma(t) X_tmathrmdt + sqrt2sigma(t)sigma(t)mathrmdbar W_t","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"where","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"    bar W_t = W_t - int_0^t fracg(s)sigma(s)^2 X_s mathrmds = W_t - int_0^t sqrtfrac2sigma(s)sigma(s) X_s mathrmds","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"This is iterated recursively backwards in time, with","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"X_t_j - X_t_j-1 = int_t_j-1^t_j 2fracsigma(s)sigma(s) X_s mathrmds + int_t_j-1^t_j g(s)small triangledownmathrmdhat W_s","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"which we approximate with","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"X_t_j - X_t_j-1 approx 2fracsigma(t_j)sigma(t_j) X_t_j (t_j - t_j-1) + g(t_j) (hat W_t_j - hat W_t_j-1)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"We implement this example below, in order to recover, backwards, the specific paths of the forward diffusion.","category":"page"},{"location":"generative/reverse_flow/#Numerics","page":"Reverse probability flow","title":"Numerics","text":"","category":"section"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"using StatsPlots\nusing Random\nusing Distributions\nusing Markdown\n\nnothing # hide","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"rng = Xoshiro(12345)\nnothing # hide","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"trange = range(0.0, 1.0, step=0.01)\nnumsamples = 1024\n\nsigma(t) = t\nsigmaprime(t) = 1\ng(t) = sqrt(2 * sigma(t) * sigmaprime(t))\n\nx0 = 0.0\n\nXt = zeros(size(trange, 1), numsamples)\ndt = Float64(trange.step)\ndWt = sqrt(dt) .* randn(length(trange), numsamples)\nWt = zero(Xt)\n@assert axes(Xt, 1) == axes(trange, 1)\n@inbounds for m in axes(Xt, 2)\n    n1 = first(eachindex(axes(Xt, 1), axes(trange, 1)))\n    Xt[n1, m] = x0\n    Wt[n1, m] = 0.0\n    @inbounds for n in Iterators.drop(eachindex(axes(trange,1), axes(Xt, 1)), 1)\n        Xt[n, m] = Xt[n1, m] + g(trange[n1]) * dWt[n1, m]\n        Wt[n, m] = Wt[n1, m] + dWt[n1, m]\n        n1 = n\n    end\nend","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"histogram(title=\"histogram of Xt\", titlefont=10, Xt[end, :], bins=40)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"histogram(title=\"histogram of Wt\", titlefont=10, Wt[end, :], bins=40)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"plot(title=\"Sample paths of Xt\", titlefont=10)\nplot!(trange, Xt[:, 1:200], color=1, alpha=0.2, legend=false)\nplot!(trange, Xt[:, 1:5], color=2, linewidth=1.5, legend=false)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"barWt = zero(Xt)\nVt = zero(Xt)\nfor m in axes(barWt, 2)\n    n1 = first(eachindex(axes(barWt, 1), axes(trange, 1)))\n    barWt[n1, m] = 0.0\n    Vt[n1, m] = 0.0\n    @inbounds for n in Iterators.drop(eachindex(axes(trange,1), axes(barWt, 1), axes(Xt, 1), axes(Vt, 1)), 1)\n        Vt[n, m] = Vt[n1, m] - g(trange[n]) / sigma(trange[n])^2 * Xt[n1, m] * dt\n        barWt[n, m] = Wt[n, m] + Vt[n, m]\n        n1 = n\n    end\nend","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"histogram(title=\"histogram of barWt\", titlefont=10, barWt[end, :], bins=40)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"plot(title=\"Sample paths Wt\", titlefont=10, ylims=(-4, 4))\nplot!(trange, Wt[:, 1:200], color=1, alpha=0.2, label=false)\nplot!(trange, Wt[:, 1:5], color=2, linewidth=1.5, label=false)\nplot!(trange, mean(barWt, dims=2), color=3, label=\"mean\")\nplot!(trange, sqrt.(mean(Wt .^2, dims=2)), color=4, label=\"std. dev.\")\nplot!(trange, -sqrt.(mean(Wt .^2, dims=2)), color=4, label=false)\nplot!(trange, t -> sqrt(t), color=5, label=\"t ↦ √t\")\nplot!(trange, t -> -sqrt(t), color=5, label=false)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"plot(title=\"Sample paths barWt\", titlefont=10, ylims=(-4, 4))\nplot!(trange, barWt[:, 1:200], color=1, alpha=0.2, label=false)\nplot!(trange, barWt[:, 1:5], color=2, linewidth=1.5, label=false)\nplot!(trange, mean(barWt, dims=2), color=3, label=\"mean\")\nplot!(trange, sqrt.(mean(barWt .^2, dims=2)), color=4, label=\"std. dev.\")\nplot!(trange, -sqrt.(mean(barWt .^2, dims=2)), color=4, label=false)\nplot!(trange, t -> sqrt(t), color=5, label=\"t ↦ √t\")\nplot!(trange, t -> -sqrt(t), color=5, label=false)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Oddly enough, the distribution of bar W_t is a little bit squeezed, but the reverse flow is working nonetheless. But something is amiss.","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"Xtback = zeros(size(trange, 1), numsamples)\n\ndt = Float64(trange.step)\n@assert axes(Xtback, 1) == axes(trange, 1)\nfor m in axes(Xtback, 2)\n    n1 = last(eachindex(axes(Xtback, 1), axes(trange, 1)))\n    Xtback[n1, m] = Xt[end, m]\n    for n in Iterators.drop(Iterators.reverse(eachindex(axes(trange,1), axes(Xtback, 1), axes(barWt, 1))), 1)\n        Xtback[n, m] = Xtback[n1, m] - 2 * sigmaprime(trange[n1]) / sigma(trange[n1]) * Xtback[n1, m] * dt - g(trange[n1]) * (barWt[n1, m] - barWt[n, m])\n        n1 = n\n    end\nend","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"plot(title=\"Sample paths reverse Xt\", titlefont=10)\nplot!(trange, Xtback[:, 1:200], color=1, alpha=0.2, legend=false)\nplot!(trange, Xtback[:, 1:5], color=2, linewidth=1.5, legend=false)","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"plot(title=\"Some sample paths of both Xt (blue) and reverse Xt (red)\", titlefont=10, legend=false)\nplot!(trange, Xt[:, 1:5], color=1, label=\"forward\")\nplot!(trange, Xtback[:, 1:5], color=2, linewidth=1.5, label=\"reverse\")","category":"page"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"nothing","category":"page"},{"location":"generative/reverse_flow/#References","page":"Reverse probability flow","title":"References","text":"","category":"section"},{"location":"generative/reverse_flow/","page":"Reverse probability flow","title":"Reverse probability flow","text":"B. D. O. Anderson (1982). Reverse-time diffusion equation models, Stochastic Process. Appl., vol. 12, no. 3, 313–326, DOI: 10.1016/0304-4149(82)90051-5\nU. G. Haussmann, E. Pardoux (1986). Time reversal of diffusions, Ann. Probab. 14, no. 4, 1188-1205\nD. Maoutsa, S. Reich, M. Opper (2020), \"Interacting particle solutions of Fokker-Planck equations through gradient-log-density estimation\", Entropy, 22(8), 802, DOI: 10.3390/e22080802\nY. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, B. Poole (2020), \"Score-based generative modeling through stochastic differential equations\", arXiv:2011.13456\nT. Karras, M. Aittala, T. Aila, S. Laine (2022), Elucidating the design space of diffusion-based generative models, Advances in Neural Information Processing Systems 35 (NeurIPS 2022)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/#Recurrence-in-the-countable-space-case","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"","category":"section"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Recurrence is a fundamental concept related to the existence of invariant measures. We explore such concept here, in the context of a countable state space.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/#Setting","page":"Recurrence in the countable-space case","title":"Setting","text":"","category":"section"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Here, we assume that (X_n)_n is a time-homogeneous, discrete-time Markov chain with a countable state space. More precisely, we assume the indices are n=0 1 2 ldots and that the space mathcalX is finite or countably infinite. The sample space is the probability space (Omega mathcalF mathbbP) where mathcalF is the sigma-algebra on the set Omega and mathbbP is the probability distribution. The one-step transition distribution is denoted by K(x y) = mathbbP(X_n+1 = y  X_n = x) and is independent of n=0 1 ldots thanks to the time-homogeneous assumption. Similary, the n-step transition distribution is denoted K_n(x y) = mathbbP(X_k+n = y  X_k = x) for n=1 2 ldots independently of k=0 1 ldots","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/#Definitions","page":"Recurrence in the countable-space case","title":"Definitions","text":"","category":"section"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"We start with some fundamental definitions.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/#Return-time","page":"Recurrence in the countable-space case","title":"Return time","text":"","category":"section"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"note: Definition (return time)\nGiven a point xinmathcalX we define the return time to x by    tau_x = infleftninmathbbNcup+infty  n = infty textrm or  X_n = xright","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"By definition, tau_x is a random variable with values in mathbbN We call it return time, but, in the definition itself, we do not condition it on X_0 = x so it is not always a \"return\" time, per se; the quantity","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(tau_x  infty)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"is just the probability of reaching x in a finite number of steps. It is more like a \"first arrival\" time. Only when conditioned to X_0 = x that","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(tau_x  infty  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"is indeed the probability of returning to x in a finite number of steps. Meanwhile, for y neq x","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(tau_y  infty  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"is the probability of reaching y from x in a finite number of steps. ","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/#Number-of-passages","page":"Recurrence in the countable-space case","title":"Number of passages","text":"","category":"section"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Another useful quantity is the random variable denoting the number of passages through a given state xinmathcalX","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"note: Definition (number of passages)\nThe number of passages through a given state xinmathcalX is defined by    eta_x = ninmathbbN X_n = x = sum_n=1^infty mathbb1_X_n = x","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"By definition, eta_x is a random variable with nonnegative integer values. Notice we did not include the starting time n=0 in the definition. Some authors do, while others don't (e.g. Robert and Casella (2004) don't, while Lawler (2006) does).","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/#Relations-between-return-time-and-number-of-visits","page":"Recurrence in the countable-space case","title":"Relations between return time and number of visits","text":"","category":"section"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"There are some important relations between return time and number of visits. Indeed, the first return time is finite if, and only if, the state is visited at least once. This is valid for each sample point. We can express this as","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    tau_x(omega)  infty quad Longleftrightarrow quad eta_x(omega) geq 1 quad forall omega in Omega","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"As a consequence,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(tau_x  infty  X_0 = x) = mathbbP(eta_x geq 1  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"The complement of that is","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(tau_x = infty  X_0 = x) = mathbbP(eta_x = 0  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"More generally, the chances of having multiple visits is a power of the return time. This follows from the Markov property of the chain, since once back to x for the m-1 time, the chances of coming back again is the same as coming back for the first time. And the chances of not returning after the m-1 visit is the same as the chances of never arriving any time.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"note: Proposition (return time and number of visits)\nLet xinmathcalX and set    q = mathbbP(tau_x  infty  X_0 = x)Then,    mathbbP(eta_x geq m  X_0 = x) = q^mand    mathbbP(eta_x = m  X_0 = x) = q^m(1 - q)for any m = 0 1 2 ldots","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Proof. By definition, we have eta_x geq 0 thus the equality mathbbP(eta_x geq m  X_0 = x) = q^m for m = 0 is trivial. Now, for minmathcalN we have","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        mathbbP(eta_x geq m  X_0 = x)  = mathbbPbigg( exist n_1 ldots n_min mathbbN X_i = x n_m-1  i leq n_m Leftrightarrow i = n_m \n         hspace1in bigg X_j = x 0 leq j leq n_m-1 Leftrightarrow j = 0 n_1 ldots n_m-1bigg) \n         quad times mathbbPbigg( exist n_1 ldots n_m-1 in mathbbN X_i = x n_m-2  i leq n_m-1 Leftrightarrow i = n_m-1 \n         hspace1in bigg X_j = x 0 leq j leq n_m-2 Leftrightarrow j = 0 n_1 ldots n_m-2bigg) \n         quad times cdots \n         quad times mathbbPbigg( exist n_1 in mathbbN X_i = x 0  i leq n_1 Leftrightarrow i = n_1 bigg X_0 = x bigg)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"By the Markov property of the chain, only the most recent conditioned state is important, so that","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        mathbbP(eta_x geq m  X_0 = x)  = mathbbPleft( exist n_1 ldots n_min mathbbN X_i = x 1leq i leq n_m Leftrightarrow i = n_1 ldotsn_m  X_0 = xright) \n         = mathbbPbigg( exist n_m-1 n_min mathbbN X_i = x n_m-1  i leq n_m Leftrightarrow i = n_m bigg X_n_m-1 = xbigg) \n          times mathbbPbigg( exist n_m-2 n_m-1 in mathbbN X_i = x n_m-2  i leq n_m-1 Leftrightarrow i = n_m-1 bigg X_n_m-2 = x bigg) \n          times cdots \n          times mathbbPbigg( exist n_1 in mathbbN X_i = x 0  i leq n_1 Leftrightarrow i = n_1 bigg X_0 = x bigg)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"By the time-homogeneous property, we can shift each probability by -n_k-1 to see that only the time differences d_k = n_k - n_k-1 matters, for k=1 ldots m with all the events conditioned at the initial time n_0 = 0, i.e.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        mathbbP(eta_x geq m  X_0 = x)  = mathbbPbigg( exist d_m in mathbbN X_i = x 0  i leq d_m Leftrightarrow i = d_m bigg X_0 = xbigg) \n          times mathbbPbigg( exist d_m-1 in mathbbN X_i = x 0  i leq d_m-1 Leftrightarrow i = d_m-1 bigg X_0 = x bigg) \n          times cdots \n          times mathbbPbigg( exist d_1 in mathbbN X_i = x 0  i leq d_1 Leftrightarrow i = d_1 bigg X_0 = x bigg)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"The difference is just a matter of notation, for which we can denote them all by d and write","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(eta_x geq m  X_0 = x) = mathbbPbigg( exist d in mathbbN X_i = x 0  i leq d Leftrightarrow i = d bigg X_0 = xbigg)^m","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"The existence of one such d is equivalent to eta_x geq 1 which is equivalent to tau_x  infty se we can write","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(eta_x geq m  X_0 = x) = mathbbP(tau_x  infty  X_0 = x)^m = q^m","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"for all minmathbbN which completes the proof of the first statement.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Now, for any m=0 1 2 ldots the events tau_x = m and tau_x geq m+1 are independent, so that","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        mathbbP(eta_x = m  X_0 = x)  = mathbbP(eta_x geq m  X_0 = x) - mathbbP(eta_x geq m + 1  X_0 = x) \n         = q^m - q^m+1 \n         = q^m (1 - q)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"which completes the proof. □  ","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/#Recurrence-and-Transience","page":"Recurrence in the countable-space case","title":"Recurrence and Transience","text":"","category":"section"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"As the name says it, recurrence refers to a property that occurs repeatedly in time. In the case of a state xinmathcalX we are interested in knowning how often the state is observed, i.e. how often X_n = x with respect to ninmathbbN","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"The idea is that a state that is not visited after some instant in time is, in some sense, transient, while others that get visited infinitely often in time are recurrent. But since this is a stochastic process, we must quantify how often this happens in a probabilistic way, i.e. with respect to the underlying probability measure. This can be measured by the probability of a state to be visited infinitely often in the chain, i.e.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(X_n = x textrm infinitely often  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"If the probability is one, we will almost surely observe this state infinitely many times. If the probability is zero, we will almost surely observe this state at most a finite number of times. What if the probability is in between zero and one? Could it be in a superpositioned state, i.e. in some instances it is visited infinitely often while in other instances it is visited only finitely-many times? Fortunately, this cannot happen. The probability is either zero or one, and we can definitely characterize it as recurrent or transient. This is a manifestation of the Kolmogorov zero-one law for the tail event ","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    X_n = textrmio = bigcap_ninmathbbNbigcup_mgeq nX_m = x","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"note: Proposition (zero-one law for infinitely-many visits)\nConsider a state xinmathcalX Then either    mathbbP(X_n = x textrm infinitely often  X_0 = x) = 1or    mathbbP(X_n = x textrm infinitely often  X_0 = x) = 0","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Proof. The idea is to use the Markov property of the chain, that if the probability of being visited once after the initial time is q then, the probability of having m visits is q^m to deduce that, at the limit mrightarrow infty it is either zero or one, depending on whether 0 leq q  1 or q = 1 ","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"More precisely, we know that","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(X_n = x textrm infinitely often  X_0 = x) = mathbbP(eta_x = infty  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"This means","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(X_n = x textrm infinitely often  X_0 = x) = mathbbP(eta_x geq m forall minmathbbN  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"But","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    eta_x geq m forall minmathbbN X_0 = x  = bigcap_minmathbbNeta_x geq m X_0 = x","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"with the intersection being of non-increasing sets, with respect to increasing minmathbbN Thus, by the continuity of probability measures,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(eta_x geq m forall minmathbbN X_0 = x) = lim_mrightarrow mathbbP(eta_x geq m X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Similarly,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(eta_x geq m forall minmathbbN  X_0 = x) = lim_mrightarrow mathbbP(eta_x geq m  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"We have already seen that","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(eta_x geq m  X_0 = x) = q^m","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"where","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    q = mathbbP(tau_x  infty  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Thus,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(eta_x geq m forall minmathbbN  X_0 = x) = lim_mrightarrow q^m","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Clearly,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    lim_mrightarrow q^m = 0 quad textrmif  0  q leq 1","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"and","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    lim_mrightarrow q^m = 1 quad textrmif  q = 1","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Since q is a probability, which can only assume values in the range 0leq q leq 1 the only possible limits are 0 and 1, proving the result. □","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"With this in mind, we have the following definitions.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"note: Definition (recurrent and transient states)\nA state x is called recurrent when    mathbbP(X_n = x textrm infinitely often  X_0 = x) = 1and is called transient when    mathbbP(X_n = x textrm infinitely often  X_0 = x) = 0with no intermediate values being possible.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Equivalent definitions of recurrence can be made with the notions of number of passages and return time. In that regard, we have the following result, which we borrow, essentially, from Lawler (2006), except that we do not include the time n=0 in the number of passages, so the formula is slightly different.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"note: Theorem (characterizations of recurrent and transient states)\nFor any state xinmathcalX we have    x textrm is recurrent  quad Longleftrightarrow quad mathbbP(tau_x  infty  X_0 = x) = 1 quad Longleftrightarrow quad mathbbEeta_x  X_0 = x = inftyand    x textrm is transient  quad Longleftrightarrow quad mathbbP(tau_x  infty  X_0 = x)  1 quad Longleftrightarrow quad mathbbEeta_x  X_0 = x  inftyMoreover, we have the relation    mathbbEeta_x  X_0 = x = fracmathbbP(tau_x  infty  X_0 = x)1 - mathbbP(tau_x  infty  X_0 = x)with the understanding that the left hand side is infinite when the probability in the right hand side is 1.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Proof. We have that tau_x = infty iff X_n never returns to x If tau_x  infty then it returns to x in finite time at least once. If tau_x  infty with probability one, then, with probability one, it will return again and again to x still with probability one, since the countable intersection of sets of full measure still has full measure. Thus,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(X_n = x textrm infinitely often  X_0 = x) = 1 quad Longleftrightarrow quad mathbbP(tau_x  infty  X_0 = x) = 1","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"This proves that x is recurrent if, and only if, mathbbP(tau_x  infty  X_0 = x) = 1 which is the first part of the equivalence in the recurrence case. The complement of that is precisely that x is transient if, and only if, mathbbP(tau_x  infty  X_0 = x)  1","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"For the remaining equivalences, let us suppose, first, that x is transient. Then, as we have seen,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    q = mathbbP(tau_x  infty  X_0 = x)  1","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"We compute the expectation of the number of passages by","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        mathbbEeta_x  X_0 = x  = mathbbEleft sum_n=1^infty mathbb1_X_n = x bigg X_0 = xright = sum_n=1^infty mathbbEleftmathbb1_X_n = x bigg X_0 = xright \n         = sum_n=1^infty mathbbP(X_n = x  X_0 = x) = sum_n=1^infty p_n(x x)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"We can also compute this in a different way. Since eta_x is always an integer, its expectation is given by","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbEeta_x  X_0 = x = sum_m=1^infty m mathbbP(eta_x = m  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"We need a way to calculate mathbbP(eta_x = m  X_0 = x) for each integer minmathbbN When eta_x = m it means it returns to x m times and then it does not return anymore. This means that mathbbP(eta_x = m  X_0 = x) = q^m Thus,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbEeta_x  X_0 = x = sum_m=1^infty m q^m","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Let S = sum_m=1^infty m q^m so that qS = sum_m=1^infty m q^m+1 = sum_m=2^infty (m-1)q^m and hence","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    (1 - q)S = S - qS = q + sum_m=1^infty q^m = sum_m=1^infty q^m = fracq1 - q","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Thus,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbEeta_x  X_0 = x = fracmathbbP(tau_x  infty  X_0 = x)1 - mathbbP(tau_x  infty  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"(In Lawler (2006), the number of passages includes the initial time n=1 so that the formula obtained is 1(1-q) instead of q(1 - q))","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"When","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    q = mathbbP(tau_x  infty  X_0 = x) = 1","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"then","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(tau_x  infty  X_0 = x) geq r","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"for any 0  r  1 and we get, similarly, that","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbEeta_x  X_0 = x geq sum_m=1^infty m r^m = fracr(1 - r) rightarrow infty","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"as r rightarrow 1 so that mathbbEeta_x  X_0 = x = infty","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"This proves the identity between the expectation and the probability. In particular, the expectation is finite if, and only if, the probability is strictly less than one, which proves the remaining equivalences. □","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"These equivalences are true, in general, only in the countable case; see page 222 of Robert and Casella (2004).","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Another equivalence with recurrence is the following.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"note: Proposition (characterizations of recurrent and transient states)\nGiven a state xinmathcalX we have the equality    mathbbEeta_x  X_0 = x = sum_n=1^infty K_n(x x)and, therefore, x is recurrent, when    sum_n=1^infty K_n(x x) = inftyand x is transient, when    sum_n=1^infty K_n(x x)  infty","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Proof. The identity is proved using the definition of eta_x Indeed,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        mathbbEeta_x  X_0 = x  = mathbbEleftsum_n=1^infty mathbb1_X_n = x bigg X_0 = xright \n         = sum_n=1^infty mathbbEleftmathbb1_X_n = x bigg X_0 = xright \n         = sum_n=1^infty mathbbPleftX_n = x bigg X_0 = xright \n         = sum_n=1^infty K_n(x x)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Now, the characterization of recurrence and transience of x follow from this identity and from the corresponding characterizations in terms of the expectation mathbbEeta_x  X_0 = x This completes the proof. □","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"For instance, we have seen that the random walk X_n+1 = X_n + B_n where B_n are Bernoulli i.i.d. with states +1 with probability p and -1 with probability 1 - p where 0  p  1 For any x yinmathcalX=mathbbZ and ninmathbbN the transition probability K_n(x y) is zero if y - x and n have different parity or when n  y - x and is given by the binomial distribution","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    p_n(m) = beginpmatrix n  i endpmatrix p^i(1-p)^j","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"with","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    i = fracn + m2 quad j = n - i = fracn - m2 quad m = y - x","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"when","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    m leq n quad m n textrm with same parity","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Thus, we can write","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    K_n(x y) = begincases\n        beginpmatrix n  fracn + y - x2 endpmatrix p^(n+y-x)2(1-p)^(n + x - y)2  x - y leq n  x - y n textrm same parity \n        0  textrmotherwise\n    endcases","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"In particular, the probability of returning to x is","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    K_n(x x) = begincases\n        beginpmatrix n  fracn2 endpmatrix p^n2(1-p)^n2  n textrm is even \n        0  textrmotherwise\n    endcases","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"We have","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    X_n = x textrm infinitely often  X_0 = x = bigcap_n inmathbbNbigcup_m geq n min mathbbN X_m = x  X_0 = x","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Thus, by the Borel-Cantelli Lemma,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbPleft(X_n = x textrm infinitely often  X_0 = xright) = 0","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"since","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        sum_ninmathbbN mathbbPleft(X_m = x  X_0 = xright)  = sum_ninmathbbN n textrm even beginpmatrix n  fracn2 endpmatrix p^n2(1-p)^n2 \n         = sum_ninmathbbN beginpmatrix 2n  n endpmatrix p^n(1-p)^n = sum_ninmathbbN frac(2n)2(n) (p(1-p))^n\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Using Stirling's approximation","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    n approx sqrt2pi nleft(fracneright)^n quad (2n) approx sqrt4pi nleft(frac2neright)^2n","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"we have","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    frac(2n)2(n) approx fracsqrt4pi n2sqrt2pi nleft(frac2neright)^2nleft(fracenright)^n = fracsqrt22left(frac4neright)^n","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"and we find","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    sum_ninmathbbN mathbbPleft(X_m = x  X_0 = xright) approx fracsqrt22sum_ninmathbbN left(frac4np(1-p)eright)^n = infty","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Thus, the chain is recurrent.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/#Recurrent-chain","page":"Recurrence in the countable-space case","title":"Recurrent chain","text":"","category":"section"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"When every state is recurrent we say that the chain is recurrent.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"note: Definition (recurrent chain)\nThe Markov chain is called recurrent when every state is recurrent, i.e.    mathbbP(X_n = x textrm infinitely often  X_0 = x) = 1 quad forall xinmathcalX","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/#Existence-of-invariant-distribution","page":"Recurrence in the countable-space case","title":"Existence of invariant distribution","text":"","category":"section"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Recurrence is a fundamental property associated with the existence of invariant measures. But the associated invariant measure may be finite or infinite. If it is finite, then we can normalize it and obtain a stationary probability distribution. The condition for finiteness of the invariant measure associated with a recurrent state x is that the expectation of tau_x conditioned to X_0 = x be finite. If such expectation is finite, then necessarily tau_x is finite almost surely and, hence, x is recurrent. But a state can be recurrent without this expectation being finite. Some authors call the latter case null recurrence, meaning that the state is recurrent but it is not associated with a stationary probability distribution. Otherwise, it is called positive recurrence.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"note: Theorem (recurrence implies existence of invariant measure)\nSuppose that xinmathcalX is recurrent. Then    tilde P_x(z) = sum_n=1^infty mathbbP(X_n = z n leq tau_x  X_0 = x) = mathbbEleftsum_n=1^tau_x mathbb1_X_n = y bigg X_0 = xrightdefines a non-trivial invariant measure for the Markov chain, which may be finite or infinite, with    tilde P_x(mathcalX) = mathbbEtau_x  X_0 = xThus, if, moreover,    mathbbEtau_x  X_0 = x  inftythen this measure is finite and can be normalized to a stationary probability distribution    P_x(z) = frac1mathbbEtau_x  X_0 = x sum_n=1^infty mathbbP(X_n = z tau_x geq n  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"The proof below is adapted from Theorem 6.37 of Robert and Casella (2004). Notice we are not assuming irreducibility, so we are not claiming that this invariant distribution is unique. In fact, we may have several non-connected recurrent state, each associated with a different invariant measure. We'll later see the condition of irreducibility to avoid such non-connected states and find a unique invariant probability distribution.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Proof. First of all, since the space is discrete and each tilde P_x(z) geq 0 for zinmathcalX it follows that tilde P_x defines indeed a measure on mathcalX Let us check that tilde P_x is in fact a nontrivial measure and that it is invariant. ","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"In order to show that it is non-trivial, we prove that tilde P_x(x) = 1 This will also be a crucial fact in the proof of invariance. This follows from","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        tilde P_x(x)  = sum_n=1^infty mathbbP(X_n = x tau_x geq n  X_0 = x) \n         = sum_n=1^infty mathbbP(X_n = x tau_x = n  X_0 = x) \n         = sum_n=1^infty mathbbP(tau_x geq n  X_0 = x)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Thanks to the recurrence assumption on x we have tau_x  infty almost surely, when conditioned on X_0 = x which means tau_x = infty  X_0 = x has zero measure. Thus, ","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        tilde P_x(x)  = sum_n=1^infty mathbbP(n leq tau_x  infty  X_0 = x) \n         = mathbbP(cup_ninmathbbN tau_x = n  X_0 = x) \n         = mathbbP(tau_x  infty  X_0 = x)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Using again the fact that x is recurrent, we have mathbbP(tau_x  infty  X_0 = x) = 1 which means","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    tilde P_x(x) = 1","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"as we wanted.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Now, let us check that tilde P_x is invariant. We need to show that","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    sum_yinmathcalX K(y z)tilde P_x(y) = tilde P_x(z)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"for every zinmathcalX For that, we write","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        sum_yinmathcalX K(y z)tilde P_x(y)  = sum_yinmathcalX K(y z)sum_n=1^infty mathbbP(X_n = y tau_x geq n  X_0 = x) \n         = sum_n=1^infty sum_yinmathcalX K(y z) mathbbP(X_n = y tau_x geq n  X_0 = x)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"We split the sum according to y=x and yneq x so that","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        sum_yinmathcalX K(y z)tilde P_x(y)  = sum_n=1^infty K(x z) mathbbP(X_n = x tau_x geq n  X_0 = x) \n         qquad + sum_n=1^infty sum_yneq x K(y z) mathbbP(X_n = y tau_x geq n  X_0 = x) \n         = K(x z) tilde P_x(x) + sum_n=1^infty sum_yneq x mathbbP(X_n+1 = z X_n = y tau_x geq n  X_0 = x) \n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"For yneq z we have","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbP(X_n+1 = z X_n = y tau_x geq n  X_0 = x) = mathbbP(X_n+1 = z X_n = y tau_x geq n+1  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Thus,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        sum_yinmathcalX K(y z)tilde P_x(y)  = K(x z) tilde P_x(x) + sum_n=1^infty sum_yneq x mathbbP(X_n+1 = z X_n = y tau_x geq n+1  X_0 = x) \n         = K(x z) tilde P_x(x) + sum_n=1^infty mathbbP(X_n+1 = z tau_x geq n+1  X_0 = x) \n         = K(x z) tilde P_x(x) + sum_n=2^infty mathbbP(X_n = z tau_x geq n  X_0 = x)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"where in the last step we just reindexed the summation. Now we use that tilde P_x(x) = 1 (as proved above) and that ","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    K(x z) = mathbbP(X_1 = z  X_0 = x) = mathbbP(X_1 = z tau_x geq 1  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"(since tau_x geq 1 always), to obtain","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        sum_yinmathcalX K(y z)tilde P_x(y)  = mathbbP(X_1 = z tau_x geq 1  X_0 = x) + sum_n=2^infty mathbbP(X_n = z tau_x geq n  X_0 = x) \n         = sum_n=1^infty mathbbP(X_n = z tau_x geq n  X_0 = x) \n         = tilde P_x(z)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"proving the invariance.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Now we compute tilde P_x(mathcalX) We have","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    beginalign*\n        tilde P_x(mathcalX)  = sum_zinmathcalX P_x(z) \n         = sum_zinmathcalXsum_n=1^infty mathbbP(X_n = z tau_x geq n  X_0 = x) \n         = sum_n=1^infty sum_zinmathcalX mathbbP(X_n = z tau_x geq n  X_0 = x) \n         = sum_n=1^infty mathbbP( tau_x geq n  X_0 = x) \n         = sum_n=1^infty sum_m=n^infty mathbbP(tau_x = m  X_0 = x) \n         = sum_m=1^infty sum_n=1^m mathbbP(tau_x = m  X_0 = x) \n         = sum_m=1^infty m mathbbP(tau_x = m  X_0 = x) \n         = mathbbEtau_x  X_0 = x\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"If we assumed that ","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    mathbbEtau_x  X_0 = x  infty","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"it follows that the measure tilde P is finite, so we can normalize tilde P by this expectation to obtain the invariant probability distribution","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    P(z) = frac1mathbbEtau_x  X_0 = x sum_n=1^infty mathbbP(X_n = z tau_x geq n  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"This concludes the proof.□","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Remark. Notice that tilde P_x(z) defines a measure regardless of x being recurrent or not. And it is always non-trivial, in fact, because sum_yin mathbbZ K(x z) = 1 there must exist some zinmathcalZ for which X_0 = x and X_1 = z with positive probability, and thus, since tau_x geq 1 always,","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    tilde P_x(z) = sum_n=1^infty mathbbP(X_n = z n leq tau_x  X_0 = x) geq mathbbP(X_1 = z tau_x geq 1  X_0 = 1) = mathbbP(X_1 = z  X_0 1) = K(x z)  0","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"But this measure may not be invariant. The recurrence is needed to assure that tilde P_x is invariant.","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"Remark. The expression","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"        tilde P_x(z) = sum_n=1^infty mathbbP(X_n = z n leq tau_x  X_0 = x) = mathbbEleftsum_n=1^tau_x mathbb1_X_n = y bigg X_0 = xright","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"for the invariant measure appears naturally when we assume that an invariant measure exists. Indeed, for an invariant measure tilde P and for any two states x zinmathcalX one can show, by recusively using that the measure is invariant and by splitting the corresponding summation into the state equal to x and the states different from x that","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"    tilde P(z) geq tilde P_x(z)tilde P(x)","category":"page"},{"location":"markov_chains/mc_countableX_recurrence/","page":"Recurrence in the countable-space case","title":"Recurrence in the countable-space case","text":"This inequality will be proved in the following pages. This is then used to prove the uniqueness (up to a multiplicative constant) of the invariant measure (local or global, depending on whether just the chain is reducible or irreducible). In any case, we see, from this calculation, that the expression for tilde P_x(z) appears naturally from the hypothesis of invariance alone. This expression measures how often the chain visits a certain state z When in statistical equilibrium, this is what we expect as how frequent the state is observed.","category":"page"},{"location":"sampling/prng/#Pseudo-random-number-generators-(PRNGs)","page":"Random number generators","title":"Pseudo random number generators (PRNGs)","text":"","category":"section"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"A fundamental task in probability programming is the generation of seemingly random numbers. The starting point is that of a uniform distribution. This is not a trivial problem, though. John von Neumann apparently once said the following","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"\"Any one who considers arithmetical means of producing random digits is, of course, in a state of sin.\" - John von Neumann (quoted by D. E. Knuth, in \"The Art of Computer Programming II\", Addison-Wesley Longman Publishing Co. 1997)","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"It is possible, however, to generate, in a computer, truly random numbers, by measuring external physical phenomena, such as thermal noise, sound noise, atmospheric turbulence, photo-eletric effects, quantum effects, amongst others. See, for instance, Wikipedia: Hardware random number generator and RANDOM.ORG. Truly random numbers are fundamental in some applications where security is critical, and this class of generators are termed TRNG (True Random Number Generators). But generating such numbers is quite costly and slow. Because of that, not-so-random numbers are generated instead.","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"Most computer-generated sequences of random numbers are based on deterministic algorithms, which are termed PRNG (Pseudo Random Number Generators). They generate deterministic sequences of numbers having a nearly uniform distribution and an aparent independence between draws. The first number in the sequence may be changed according to a given seed, which is then the only possible source of actual randomness.","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"In somewhat critical situations, at least the seed may be chosen truly random, from some external source of entropy from the operating system, such as mouse movement, keys pressed, cpu temperature fluctuations, etc. In less critical cases, though, the generating of pseudo random numbers is sufficient.","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"In any case, the study of PRNG algorithms forms an important research topic and it is still an active area of research. Many randomness tests are available to check the strong and weak points of many algorithms.","category":"page"},{"location":"sampling/prng/#Geradores-Congruentes-Lineares","page":"Random number generators","title":"Geradores Congruentes Lineares","text":"","category":"section"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"For illustrative purposes, a simple family of methods that are easy to implement is that of linear congruencial generators (LCGs). It is a family parametrized by three parameters: a multiplier a an increment c and a modulus m Then, given a certain non-negative integer seed X_0 one generates a sequence (X_n)_nin mathbbN according to the rule","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"    X_n+1 = (a X_n + c) operatornamemod m","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"The sequence is, necessarily, periodic and generates at most m-1 different numbers, but the periodicity may be smaller than that, depending on the combination of parameters. Because of that m needs to be large, and a c and m are chosen with no direct simple relation between them.","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"Compare, for instance, the two cases below","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"plt1 = scatter(1:n, X, title = \"Generated sequence\\n(a = $a, c = $c, m = $m)\", titlefont = 10, label = false, markersize = 1) # hide\nplt2 = histogram(X, label = false, xaxis = \"X\", yaxis = \"contagem\", title = \"Histogram\", titlefont = 10, bins = 50) # hide\nplot(plt1, plt2, layout = 2, size = (800, 400)) # hide","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"plt1 = scatter(1:m-1, X, title = \"Generated sequence\\n(a = $a, c = $c, m = $m)\", titlefont = 10, label = false, markersize = 1) # hide\nplt2 = histogram(X, label = false, xaxis = \"X\", yaxis = \"contagem\", title = \"Histogram\", titlefont = 10, bins = 50) # hide\nplot(plt1, plt2, layout = 2, size = (800, 400)) # hide","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"For a longer sequence, we need to increase the modulus.","category":"page"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"plt1 = scatter(1:m-1, X, title = \"Generated sequence\\n(a = $a, c = $c, m = $m)\", titlefont = 10, label = false, markersize = 1) # hide\nplt2 = histogram(X, label = false, xaxis = \"X\", yaxis = \"contagem\", title = \"Histogram\", titlefont = 10, bins = 50) # hide\nplot(plt1, plt2, layout = 2, size = (800, 400)) # hide","category":"page"},{"location":"sampling/prng/#Other-algorithms","page":"Random number generators","title":"Other algorithms","text":"","category":"section"},{"location":"sampling/prng/","page":"Random number generators","title":"Random number generators","text":"Many other families exist, such as permuted congruential generators (PCGs), Mersenne-Twister, and Xorshift, of which the Xoshiro256 is a popular choice.","category":"page"},{"location":"generative/2d_FD_score_matching/#Finite-difference-score-matching-of-a-two-dimensional-Gaussian-mixture-model","page":"2D finite-difference score matching","title":"Finite-difference score-matching of a two-dimensional Gaussian mixture model","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/#Introduction","page":"2D finite-difference score matching","title":"Introduction","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Here, we modify the previous finite-difference score-matching example to fit a two-dimensional model.","category":"page"},{"location":"generative/2d_FD_score_matching/#Julia-language-setup","page":"2D finite-difference score matching","title":"Julia language setup","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"We use the Julia programming language with suitable packages.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"using StatsPlots\nusing Random\nusing Distributions\nusing Lux # artificial neural networks explicitly parametrized\nusing Optimisers\nusing Zygote # automatic differentiation\n\nnothing # hide","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"We set the random seed for reproducibility purposes.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"rng = Xoshiro(12345)\nnothing # hide","category":"page"},{"location":"generative/2d_FD_score_matching/#Data","page":"2D finite-difference score matching","title":"Data","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"We build the target model and draw samples from it. This time the target model is a bivariate random variable.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"xrange = range(-8, 8, 120)\nyrange = range(-8, 8, 120)\ndx = Float64(xrange.step)\ndy = Float64(yrange.step)\n\ntarget_prob = MixtureModel([MvNormal([-3, -3], [1 0; 0 1]), MvNormal([3, 3], [1 0; 0 1]), MvNormal([-1, 1], [1 0; 0 1])], [0.4, 0.4, 0.2])\n\ntarget_pdf = [pdf(target_prob, [x, y]) for y in yrange, x in xrange]\ntarget_score = reduce(hcat, gradlogpdf(target_prob, [x, y]) for y in yrange, x in xrange)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"sample_points = rand(rng, target_prob, 1024)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"surface(xrange, yrange, target_pdf, title=\"PDF\", titlefont=10, legend=false, color=:vik)\nscatter!(sample_points[1, :], sample_points[2, :], [pdf(target_prob, [x, y]) for (x, y) in eachcol(sample_points)], markercolor=:lightgreen, markersize=2, alpha=0.5)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"heatmap(xrange, yrange, target_pdf, title=\"PDF\", titlefont=10, legend=false, color=:vik)\nscatter!(sample_points[1, :], sample_points[2, :], markersize=2, markercolor=:lightgreen, alpha=0.5)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"surface(xrange, yrange, (x, y) -> logpdf(target_prob, [x, y]), title=\"Logpdf\", titlefont=10, legend=false, color=:vik)\nscatter!(sample_points[1, :], sample_points[2, :], [logpdf(target_prob, [x, y]) for (x, y) in eachcol(sample_points)], markercolor=:lightgreen, alpha=0.5, markersize=2)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"meshgrid(x, y) = (repeat(x, outer=length(y)), repeat(y, inner=length(x)))\nxx, yy = meshgrid(xrange[begin:8:end], yrange[begin:8:end])\nuu = reduce(hcat, gradlogpdf(target_prob, [x, y]) for (x, y) in zip(xx, yy))","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"heatmap(xrange, yrange, (x, y) -> logpdf(target_prob, [x, y]), title=\"Logpdf (heatmap) and score function (vector field)\", titlefont=10, legend=false, color=:vik)\nquiver!(xx, yy, quiver = (uu[1, :] ./ 8, uu[2, :] ./ 8), color=:yellow, alpha=0.5)\nscatter!(sample_points[1, :], sample_points[2, :], markersize=2, markercolor=:lightgreen, alpha=0.5)","category":"page"},{"location":"generative/2d_FD_score_matching/#The-neural-network-model","page":"2D finite-difference score matching","title":"The neural network model","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"The neural network we consider is again a simple feed-forward neural network made of a single hidden layer. For the 2d case, we need to bump it a little bit, doubling the width of the hidden layer.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"model = Chain(Dense(2 => 16, relu), Dense(16 => 2))","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"The LuxDL/Lux.jl package uses explicit parameters, that are initialized (or obtained) with the Lux.setup function, giving us the parameters and the state of the model.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model","category":"page"},{"location":"generative/2d_FD_score_matching/#Loss-functions-for-score-matching","page":"2D finite-difference score matching","title":"Loss functions for score-matching","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"The loss function is again based on Aapo Hyvärinen (2005), combined with the work of Pang, Xu, Li, Song, Ermon, and Zhu (2020) using finite differences to approximate the divergence of the modeled score function.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"In the multidimensional case, say on mathbbR^d, dinmathbbN, the explicit score matching loss function is given by","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"    J_mathrmESM(boldsymboltheta) = frac12int_mathbbR^d p_mathbfX(mathbfx) boldsymbolpsi(mathbfx boldsymboltheta) - boldsymbolpsi_mathbfX(mathbfx)^2mathrmdmathbfx","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"where p_mathbfX(mathbfx) is the PDF of the target distribution.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"The integration by parts in the expectation yields J_mathrmESM(boldsymboltheta) = J_mathrmISM(boldsymboltheta) + C, where C is constant with respect to the parameters and the implicit score matching loss function J_mathrmISM(boldsymboltheta) is given by","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"    J_mathrmISM(boldsymboltheta) = int_mathbbR p_mathbfX(mathbfx) left( frac12boldsymbolpsi(mathbfx boldsymboltheta)^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx boldsymboltheta) right)mathrmdmathbfx","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"which does not involve the unknown score function of mathbfX. It does, however, involve the divergence of the modeled score function, which is expensive to compute.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"In practice, the loss function is estimated via the empirical distribution, so the unknown p_mathbfX(mathbfx) is handled implicitly by the sample data (mathbfx_n)_n, and we minimize the empirical implicit score matching loss function","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"    tilde J_mathrmISMtilde p_0 =  frac1Nsum_n=1^N left( frac12boldsymbolpsi(mathbfx_n boldsymboltheta)^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx_n boldsymboltheta) right)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Componentwise, with boldsymbolpsi(mathbfx boldsymboltheta) = (psi_i(mathbfx boldsymboltheta))_i=1^d, this is written as","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"    tilde J_mathrmISMtilde p_0 = frac1Nsum_n=1^N sum_i=1^d left( frac12psi_i(mathbfx_n boldsymboltheta)^2 + fracpartialpartial x_i psi_i(mathbfx_n boldsymboltheta) right)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"As mentioned before, computing a derivative to form the loss function becomes expensive when combined with the usual optimization methods to fit a neural network, as they require the gradient of the loss function itself, so we approximate the derivative of the modeled score function by centered finite differences. With the model calculated at the displaced points, we just average them to avoid computing the model at the sample point itself. This leads to the empirical finite-difference (implicit) score matching loss function","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"    tilde J_mathrmFDSMtilde p_0 = frac1Nsum_n=1^N sum_i=1^d Bigg( frac12left(frac1dsum_j=1^d fracpsi_i(mathbfx_n + deltamathbfe_j boldsymboltheta) + psi_i(mathbfx_n - deltamathbfe_j boldsymboltheta)2right)^2  qquad qquad qquad qquad qquad qquad qquad qquad qquad + fracpsi_i(mathbfx_n + deltamathbfe_i boldsymboltheta) - psi_i(mathbfx_n - deltamathbfe_i boldsymboltheta)2delta Bigg)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Since this is a synthetic problem and we actually know the target distribution, we implement the empirical explicit score matching loss function","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"    tilde J_mathrmESMtilde p_0(boldsymboltheta) = frac12frac1Nsum_n=1^N boldsymbolpsi(mathbfx_n boldsymboltheta) - boldsymbolpsi_mathbfX(mathbfx_n)^2","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"This is used as a sure check whether the neural network is sufficient to model the score function and for checking the optimization process, since in theory this should be roughly (apart from the approximations by the empirical distribution, the finite-difference approximation, and the round-off errors) a constant different from the loss function for tilde J_mathrmFDSMtilde p_0.","category":"page"},{"location":"generative/2d_FD_score_matching/#Implementation-of-{\\tilde-J}_{\\mathrm{FDSM}{\\tilde-p}_0}({\\boldsymbol{\\theta}})","page":"2D finite-difference score matching","title":"Implementation of tilde J_mathrmFDSMtilde p_0(boldsymboltheta)","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"In the two-dimensional case, d = 2, this becomes","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"    beginalign*\n        tilde J_mathrmFDSMtilde p_0  = frac1Nsum_n=1^N sum_i=1^d Bigg( frac12left(frac1dsum_j=1^d fracpsi_i(mathbfx_n + deltamathbfe_j boldsymboltheta) + psi_i(mathbfx_n - deltamathbfe_j boldsymboltheta)2right)^2 \n         qquad qquad qquad qquad qquad qquad qquad qquad qquad + fracpsi_i(mathbfx_n + deltamathbfe_i boldsymboltheta) - psi_i(mathbfx_n - deltamathbfe_i boldsymboltheta)2delta Bigg) \n         = frac1Nsum_n=1^N sum_i=1^2 Bigg( frac12left(sum_j=1^2 fracpsi_i(mathbfx_n + deltamathbfe_j boldsymboltheta) + psi_i(mathbfx_n - deltamathbfe_j boldsymboltheta)4right)^2 \n         qquad qquad qquad qquad qquad qquad qquad qquad qquad + fracpsi_i(mathbfx_n + deltamathbfe_i boldsymboltheta) - psi_i(mathbfx_n - deltamathbfe_i boldsymboltheta)2delta Bigg) \n         = frac1N frac12 sum_n=1^N sum_i=1^2 left(sum_j=1^2 fracpsi_i(mathbfx_n + deltamathbfe_j boldsymboltheta) + psi_i(mathbfx_n - deltamathbfe_j boldsymboltheta)4right)^2 \n         qquad qquad qquad qquad qquad qquad + frac1Nsum_n=1^N fracpsi_1(mathbfx_n + deltamathbfe_1 boldsymboltheta) - psi_1(mathbfx_n - deltamathbfe_1 boldsymboltheta)2delta \n         qquad qquad qquad qquad qquad qquad + frac1Nsum_n=1^N fracpsi_2(mathbfx_n + deltamathbfe_2 boldsymboltheta) - psi_2(mathbfx_n - deltamathbfe_2 boldsymboltheta)2delta\n    endalign*","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"function loss_function(model, ps, st, data)\n    sample_points, deltax, deltay = data\n    s_pred_fwd_x, = Lux.apply(model, sample_points .+ [deltax, 0.0], ps, st)\n    s_pred_bwd_x, = Lux.apply(model, sample_points .- [deltax, 0.0], ps, st)\n    s_pred_fwd_y, = Lux.apply(model, sample_points .+ [0.0, deltay], ps, st)\n    s_pred_bwd_y, = Lux.apply(model, sample_points .- [0.0, deltay], ps, st)\n    s_pred = ( s_pred_bwd_x .+ s_pred_fwd_x .+ s_pred_bwd_y .+ s_pred_fwd_y) ./ 4\n    dsdx_pred = (s_pred_fwd_x .- s_pred_bwd_x ) ./ 2deltax\n    dsdy_pred = (s_pred_fwd_y .- s_pred_bwd_y ) ./ 2deltay\n    loss = mean(abs2, s_pred) + mean(view(dsdx_pred, 1, :)) +  mean(view(dsdy_pred, 2, :)) \n    return loss, st, ()\nend","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"We included the steps for the finite difference computations in the data passed to training to avoid repeated computations.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"xmin, xmax = extrema(sample_points[1, :])\nymin, ymax = extrema(sample_points[2, :])\ndeltax, deltay = (xmax - xmin) / 2size(sample_points, 2), (ymax - ymin) / 2size(sample_points, 2)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"data = sample_points, deltax, deltay","category":"page"},{"location":"generative/2d_FD_score_matching/#Implementation-of-{\\tilde-J}_{\\mathrm{ESM}{\\tilde-p}_0}({\\boldsymbol{\\theta}})","page":"2D finite-difference score matching","title":"Implementation of tilde J_mathrmESMtilde p_0(boldsymboltheta)","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"As a sanity check, we also include the empirical explicit score matching loss function, which uses the know score functions of the target model.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"In the two-dimensional case, this is simply the mean square value of all the components.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"    tilde J_mathrmESMtilde p_0(boldsymboltheta) = frac12 frac1Nsum_n=1^N boldsymbolpsi(mathbfx_n boldsymboltheta) - boldsymbolpsi_mathbfX(mathbfx_n)^2 = frac12 frac1Nsum_n=1^N sum_i=1^2 left(psi_i(mathbfx_n boldsymboltheta) - psi_mathbfX i(mathbfx_n) right)^2","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"function loss_function_cheat(model, ps, st, data)\n    sample_points, score_cheat = data\n    score_pred, st = Lux.apply(model, sample_points, ps, st)\n    loss = mean(abs2, score_pred .- score_cheat)\n    return loss, st, ()\nend","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"The data in this case includes information about the target distribution.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"score_cheat = reduce(hcat, gradlogpdf(target_prob, u) for u in eachcol(sample_points))\ndata_cheat = sample_points, score_cheat","category":"page"},{"location":"generative/2d_FD_score_matching/#Computing-the-constant","page":"2D finite-difference score matching","title":"Computing the constant","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"The expression tilde J_mathrmESMtilde p_0(boldsymboltheta) approx tilde J_mathrmISMtilde p_0(boldsymboltheta) + C can be used to test the implementation of the different loss functions. For that, we need to compute the constant C. This can be computed with a fine mesh or with a Monte-Carlo approximation. We do both just for fun.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"function compute_constante(target_prob, xrange, yrange)\n    dx = Float64(xrange.step)\n    dy = Float64(yrange.step)\n    Jconstant = sum(pdf(target_prob, [x, y]) * sum(abs2, gradlogpdf(target_prob, [x, y])) for y in yrange, x in xrange) * dx * dy / 2\n    return Jconstant\nend    ","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"function compute_constante_MC(target_prob, sample_points)\n    Jconstant = mean(sum(abs2, gradlogpdf(target_prob, s)) for s in eachcol(sample_points)) / 2\n    return Jconstant\nend    ","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Jconstant = compute_constante(target_prob, xrange, yrange)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Jconstant_MC = compute_constante_MC(target_prob, sample_points)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"constants = [(n, compute_constante_MC(target_prob, rand(rng, target_prob, n))) for _ in 1:100 for n in (1, 10, 20, 50, 100, 500, 1000, 2000, 4000)]","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"scatter(constants, markersize=2, title=\"constant computed by MC and fine mesh\", titlefont=10, xlabel=\"sample size\", ylabel=\"value\", label=\"via various samples\")\nhline!([Jconstant], label=\"via fine mesh\")\nhline!([Jconstant_MC], label=\"via working sample\", linestyle=:dash)","category":"page"},{"location":"generative/2d_FD_score_matching/#A-test-for-the-implementations-of-the-loss-functions","page":"2D finite-difference score matching","title":"A test for the implementations of the loss functions","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Notice that, for a sufficiently large sample and sufficiently small discretization step delta, we should have","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"    tilde J_mathrmESMtilde p_0(boldsymboltheta) approx J_mathrmESM(boldsymboltheta) = J_mathrmISM(boldsymboltheta) + C approx tilde J_mathrmFDSM(boldsymboltheta) + C approx tilde J_mathrmFDSMtilde p_0(boldsymboltheta) + C","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"which is a good test for the implementations of the loss functions. For example:","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"first(loss_function_cheat(model, ps, st, data_cheat))","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"first(loss_function(model, ps, st, data)) + Jconstant","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Let us do a more statistically significant test.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"test_losses = reduce(\n    hcat,\n    Lux.setup(rng, model) |> pstj -> \n    [\n        first(loss_function_cheat(model, pstj[1], pstj[2], data_cheat)),\n        first(loss_function(model, pstj[1], pstj[2], data))\n    ]\n    for _ in 1:30\n)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"plot(title=\"Loss functions at random model parameters\", titlefont=10)\nscatter!(test_losses[1, :], label=\"\\${\\\\tilde J}_{\\\\mathrm{ESM}{\\\\tilde p}_0}\\$\")\nscatter!(test_losses[2, :], label=\"\\${\\\\tilde J}_{\\\\mathrm{FDSM}{\\\\tilde p}_0}\\$\")\nscatter!(test_losses[2, :] .+ Jconstant, label=\"\\${\\\\tilde J}_{\\\\mathrm{FDSM}{\\\\tilde p}_0} + C\\$\")","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"One can check by visual inspection that the agreement between tilde J_mathrmESMtilde p_0(boldsymboltheta) - C and tilde J_mathrmFDSMtilde p_0(boldsymboltheta) seems reasonably good. Let us estimate the relative error.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"rel_errors = abs.( ( test_losses[2, :] .+ Jconstant .- test_losses[1, :] ) ./ test_losses[1, :] )\nplot(title=\"Relative error at random model parameters\", titlefont=10, legend=false)\nscatter!(rel_errors, markercolor=2, label=\"error\")\nmm = mean(rel_errors)\nmmstd = std(rel_errors)\nhline!([mm], label=\"mean\")\nhspan!([mm+mmstd, mm-mmstd], fillbetween=true, alpha=0.3, label=\"65% margin\")","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Ok, good enough, just a few percentage points.","category":"page"},{"location":"generative/2d_FD_score_matching/#An-extra-test-for-the-implementations-of-the-loss-functions-and-the-gradient-computation","page":"2D finite-difference score matching","title":"An extra test for the implementations of the loss functions and the gradient computation","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"We also have","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"    boldsymbolnabla_boldsymboltheta tilde J_mathrmESMtilde p_0(boldsymboltheta) approx boldsymbolnabla_boldsymboltheta tilde J_mathrmFDSMtilde p_0(boldsymboltheta)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"which is another good test, which also checks the gradient computation, but everything seems fine, so no need to push this further.","category":"page"},{"location":"generative/2d_FD_score_matching/#Optimization-setup","page":"2D finite-difference score matching","title":"Optimization setup","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/#Optimization-method","page":"2D finite-difference score matching","title":"Optimization method","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"As usual, we use the ADAM optimization.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"opt = Adam(0.003)\n\ntstate_org = Lux.Training.TrainState(model, ps, st, opt)","category":"page"},{"location":"generative/2d_FD_score_matching/#Automatic-differentiation-in-the-optimization","page":"2D finite-difference score matching","title":"Automatic differentiation in the optimization","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"FluxML/Zygote.jl is used for the automatic differentiation as it is currently the only AD backend working with LuxDL/Lux.jl.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"vjp_rule = Lux.Training.AutoZygote()","category":"page"},{"location":"generative/2d_FD_score_matching/#Processor","page":"2D finite-difference score matching","title":"Processor","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"We use the CPU instead of the GPU.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"dev_cpu = cpu_device()\n## dev_gpu = gpu_device()","category":"page"},{"location":"generative/2d_FD_score_matching/#Check-differentiation","page":"2D finite-difference score matching","title":"Check differentiation","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Check if AD is working fine to differentiate the loss functions for training.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Lux.Training.compute_gradients(vjp_rule, loss_function, data, tstate_org)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Lux.Training.compute_gradients(vjp_rule, loss_function_cheat, data_cheat, tstate_org)","category":"page"},{"location":"generative/2d_FD_score_matching/#Training-loop","page":"2D finite-difference score matching","title":"Training loop","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Here is the typical main training loop suggest in the LuxDL/Lux.jl tutorials, but sligthly modified to save the history of losses per iteration and the model state for animation.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"function train(tstate, vjp, data, loss_function, epochs, numshowepochs=20, numsavestates=0)\n    losses = zeros(epochs)\n    tstates = [(0, tstate)]\n    for epoch in 1:epochs\n        grads, loss, stats, tstate = Lux.Training.compute_gradients(vjp,\n            loss_function, data, tstate)\n        if ( epochs ≥ numshowepochs > 0 ) && rem(epoch, div(epochs, numshowepochs)) == 0\n            println(\"Epoch: $(epoch) || Loss: $(loss)\")\n        end\n        if ( epochs ≥ numsavestates > 0 ) && rem(epoch, div(epochs, numsavestates)) == 0\n            push!(tstates, (epoch, tstate))\n        end\n        losses[epoch] = loss\n        tstate = Lux.Training.apply_gradients(tstate, grads)\n    end\n    return tstate, losses, tstates\nend","category":"page"},{"location":"generative/2d_FD_score_matching/#Cheat-training-with-{\\tilde-J}_{\\mathrm{ESM}{\\tilde-p}_0}","page":"2D finite-difference score matching","title":"Cheat training with tilde J_mathrmESMtilde p_0","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"We first train the model with the known score function on the sample data. That is cheating. The aim is a sanity check, to make sure the proposed model is good enough to fit the desired score function and that the setup is right.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"@time tstate_cheat, losses_cheat, tstates_cheat = train(tstate_org, vjp_rule, data_cheat, loss_function_cheat, 2000, 20, 100)\nnothing # hide","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Testing out the trained model.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"uu_cheat = Lux.apply(tstate_cheat.model, vcat(xx', yy'), tstate_cheat.parameters, tstate_cheat.states)[1]","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"heatmap(xrange, yrange, (x, y) -> logpdf(target_prob, [x, y]), title=\"Logpdf (heatmap) and score functions (vector fields)\", titlefont=10, color=:vik, xlims=extrema(xrange), ylims=extrema(yrange), legend=false)\nquiver!(xx, yy, quiver = (uu[1, :] ./ 8, uu[2, :] ./ 8), color=:yellow, alpha=0.5)\nscatter!(sample_points[1, :], sample_points[2, :], markersize=2, markercolor=:lightgreen, alpha=0.5)\nquiver!(xx, yy, quiver = (uu_cheat[1, :] ./ 8, uu_cheat[2, :] ./ 8), color=:cyan, alpha=0.5)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"gif(anim, fps = 10) # hide","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"plot(losses_cheat, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false)","category":"page"},{"location":"generative/2d_FD_score_matching/#Real-training-with-{\\tilde-J}_{\\mathrm{FDSM}{\\tilde-p}_0}","page":"2D finite-difference score matching","title":"Real training with tilde J_mathrmFDSMtilde p_0","text":"","category":"section"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Now we go to the real thing.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function, 2000, 20, 100)\nnothing # hide","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Testing out the trained model.","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"uu_pred = Lux.apply(tstate.model, vcat(xx', yy'), tstate.parameters, tstate.states)[1]","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"heatmap(xrange, yrange, (x, y) -> logpdf(target_prob, [x, y]), title=\"Logpdf (heatmap) and score functions (vector fields)\", titlefont=10, color=:vik, xlims=extrema(xrange), ylims=extrema(yrange), legend=false)\nquiver!(xx, yy, quiver = (uu[1, :] ./ 8, uu[2, :] ./ 8), color=:yellow, alpha=0.5)\nscatter!(sample_points[1, :], sample_points[2, :], markersize=2, markercolor=:lightgreen, alpha=0.5)\nquiver!(xx, yy, quiver = (uu_pred[1, :] ./ 8, uu_pred[2, :] ./ 8), color=:cyan, alpha=0.5)","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"gif(anim, fps = 10) # hide","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"plot(losses, title=\"Evolution of the losses\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", label=\"\\${\\\\tilde J}_{\\\\mathrm{FDSM}{\\\\tilde p}_0}\\$\")\nplot!(losses_cheat, linestyle=:dash, label=\"\\${\\\\tilde J}_{\\\\mathrm{ESM}{\\\\tilde p}_0}\\$\")\nplot!(losses .+ Jconstant, linestyle=:dash, color=1, label=\"\\${\\\\tilde J}_{\\\\mathrm{FDSM}{\\\\tilde p}_0} + C\\$\")","category":"page"},{"location":"generative/2d_FD_score_matching/","page":"2D finite-difference score matching","title":"2D finite-difference score matching","text":"Ok, that seems visually good enough. We will later check the sampling from this score function via Langevin sampling.","category":"page"},{"location":"sampling/metropolis/#Metropolis-and-Metropolis-Hastings-methods","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings methods","text":"","category":"section"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"The Metropolis algorithm was proposed by N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, E. Teller (1953) as a means to compute the equilibrium state of a many-particle system. The actual computations were done in the MANIAC I (Mathematical Analyzer Numerical Integrator and Automatic Computer Model I), an early computer developed under the direction of Nicholas Metropolis, at the Los Alamos Scientific Laboratory, and used, in particular, for the development of the hydrogen bomb, which most of the authors of this paper were involved with.","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"In the application, one aims to compute mean quantities of interest with respect to a statistical equilibrium state P of a many-particle system with potential energy U(x) which amounts to computing integrals with the probability density function of the form","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    p(x) = frace^-U(x)Z","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"More generally, one considers f(x) such that","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    p(x) = fracf(x)Z","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"for a possibly unknown normalizing constant Z In the setting above, f(x) = e^-U(x) The aim, then, is to draw samples of a distribution knowning the PDF only up to a multiplicative constant.","category":"page"},{"location":"sampling/metropolis/#The-Metropolis-algorithm","page":"Metropolis and Metropolis-Hastings","title":"The Metropolis algorithm","text":"","category":"section"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Let us consider the case in which the event space is a finite dimensional space mathcalX = mathbbR^d dinmathbbE, and the desired probability distribution P is absolutely continuous with respect to the Lebesgue measure mathrmdx with density p(x) = f(x)Z for a known function f=f(x) and a possibly unkown normalization factor Z","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"The algorithm is built upon the idea of designing a Markov chain (X_n)_n=0 1 ldots and drawing a (single) sample path (x_n)_n=0 1 ldots as a representative of the distribution, as follows","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Choose a symmetric (and stationary) proposal transition probability Q = Q(x cdot) with kernel density q(x y) of going from state X_n = x to state X_n+1 = y\nChoose a initial state x_0\nProceed by induction to define the state x_n+1 from a given state x_n as follows\nChoose a candidate x sim Q(x_n cdot)\nCompute the acceptance ratio r(x_n x) where r(x y) = fracf(y)f(x) = fracp(y)p(x)\nDraw a sample u from a standard uniform distribution, u sim operatornameUniform0 1\nAccept/reject step:\nif u leq r(x_n x) accept the state x and set x_n+1 = x\nif u  r(x_n x) reject the state x and repeat the previous state, x_n+1 = x_n\nDiscard a initial transient time N called the burn-in time and consider the states x_N+1 x_N+2 ldots as a sample of the desired distribution.","category":"page"},{"location":"sampling/metropolis/#The-transition-kernel-of-the-Metropolis-algorithm","page":"Metropolis and Metropolis-Hastings","title":"The transition kernel of the Metropolis algorithm","text":"","category":"section"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"The density q(x y) is the kernel density of a proposal distribution Q(x cdot) The actual kernel of the Markov chain (X_n)_n=0 1 ldots  is affected by the acceptance/rejection step. When going from state x to state y neq x assuming f(x)  0 the chances of the proposed state of being accepted has probability density","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    minleft1 fracf(y)f(x)right","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"When f(x) = 0 one should definitely accept any y, thus we consider the acceptance factor","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    alpha(x y) = begincases\n        minleft1 fracf(y)f(x)right  f(x)  0 \n        1  f(x) = 0\n    endcases","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Then, the actual transition probability A(x E) = mathbbP(X_n+1 in E  X_n = x) of going from state X_n = x to a state X_n+1 in a measurable set E has density","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    a(x y) = q(x y)alpha(x y)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Thus, if p_X_n(x) is the density of the X_n state, then the density p_X_n+1(x) of the next state X_n+1 is given by","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    p_X_n+1(x) = int_mathcalX a(x y) p_X_n(x)mathrmdx","category":"page"},{"location":"sampling/metropolis/#The-equilibrium-distribution","page":"Metropolis and Metropolis-Hastings","title":"The equilibrium distribution","text":"","category":"section"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Any equilibrium distribution tilde p(x) must, then, satisfy the equation","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    tilde p(x) = int_mathcalX a(x y) tilde p(x)mathrmdx quad xinmathcalX","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"In particular, we must check whether the density p=p(x) of the desired distribution is an equilibrium distribution. This is obtained by checking a stronger condition known as the detailed balance equation.","category":"page"},{"location":"sampling/metropolis/#Detailed-balance-equation","page":"Metropolis and Metropolis-Hastings","title":"Detailed balance equation","text":"","category":"section"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"A distribution, with density tilde p(x) is said to satisfy the detailed balance equation of a Markov chain with transition kernel a(x y) when","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    a(x y)tilde p(x) = a(y x)tilde p(y) quad textas  x yin mathcalX","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"This says that, under a given probability state with density tilde p the chances of going from a measurable set B to a measurable set C are the same as those of going from C back to B It is a reversibility condition. This implies the stationarity of the distribution, as follows.","category":"page"},{"location":"sampling/metropolis/#Stationarity-of-a-distribution-satisfying-the-detailed-balance-equation","page":"Metropolis and Metropolis-Hastings","title":"Stationarity of a distribution satisfying the detailed balance equation","text":"","category":"section"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Given a state X_n with density tilde p=tilde p(x) the density of the next state X_n+1 = y is given by","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    y mapsto int_mathcalX q(x y)tilde p(x)mathrmdx","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Assuming the detailed balance equation, we have","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    int_mathcalX q(x y)tilde p(x)mathrmdx = int_mathcalX q(y x)tilde p(y)mathrmdx","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Since this is a transition kernel, it should satisfy the condition","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    int_mathcalX q(x y) mathrmdy = 1","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"which essentially says that if we start at x we should go somewhere with probability one. Switching the variables x and y we find that","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    int_mathcalX q(x y)tilde p(x)mathrmdx = int_mathcalX q(y x)tilde p(y)mathrmdx = tilde p(y)int_mathcalX q(y x)mathrmdx = tilde p(y)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"This shows that tilde p is a stationary density distribution.","category":"page"},{"location":"sampling/metropolis/#Detailed-balance-equation-and-stationarity-of-the-Metropolis-algorithm","page":"Metropolis and Metropolis-Hastings","title":"Detailed balance equation and stationarity of the Metropolis algorithm","text":"","category":"section"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"We have seen that the transition density of the Metropolis algorithm is","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    a(x y) = q(x y)alpha(x y)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"where","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    alpha(x y) = begincases\n        minleft1 fracf(y)f(x)right  f(x)  0 \n        1  f(x) = 0\n    endcases","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Now we check the detailed balance equation for the distribution density p(x) = f(x)Z","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"We only need to check the condition almost surely on x yinmathcalX so it suffices to consider x y such that f(x) f(y)  0 When 0  f(x) leq f(y) we have","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    alpha(x y) = minleft1 fracf(y)f(x)right =  fracf(y)f(x) = fracp(y)p(x)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"and","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    alpha(y x) = minleft1 fracf(x)f(y)right = 1","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Thus,","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    a(x y) p(x) = q(x y)alpha(x y) p(x) = q(x y)fracp(y)p(x)p(x) = q(x y) p(y)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Since the proposal distribution is assumed to be symmetric, we have q(x y) = q(y x) and hence","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    a(x y) p(x) = q(y x)p(y) = q(y x)p(y)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Using that alpha(y x) = 1 we obtain","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    a(x y) p(x) = q(y x)alpha(y x)p(y) = a(y x)p(y)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Similarly, when 0  f(y) leq f(x) we find that","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    alpha(x y) = 1 quad alpha(y x) = fracp(x)p(y)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"and the result follows in the same way,","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    a(x y)p(x) = q(x y)p(x) = q(y x)fracp(x)p(y)p(y) = q(y x)alpha(y x)p(y) = a(y x)p(y)","category":"page"},{"location":"sampling/metropolis/#The-Metropolis-Hastings-algorithm","page":"Metropolis and Metropolis-Hastings","title":"The Metropolis-Hastings algorithm","text":"","category":"section"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Hastings (1970) extended the idea of the Metropolis algorithm to non-symmetric kernels. This is useful, for instance, when the possible events are restricted to a region of the phase space and we don't want to waste computational time generating proposal steps away of this region. For instance, if we want to generate samples of a distribution which we known to only accept non-negative coordinate values, we can use a truncated normal proposal distribution, centered on X_n = x and truncated to x geq 0 which leads to an assymetric density.","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"The modification is simple. We only need to modify the acceptance ratio to","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    r(x y) = fracf(y)q(y x)f(x)q(x y)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"when f(x)q(x y)  0 otherwise r(x y) = 1","category":"page"},{"location":"sampling/metropolis/#Transition-kernel","page":"Metropolis and Metropolis-Hastings","title":"Transition kernel","text":"","category":"section"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"In the Metropolis-Hastings method, the transition density is still of the form","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    a(x y) = q(x y)alpha(x y)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"but now","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    alpha(x y) = begincases\n        minleft1 fracf(y)q(y x)f(x)q(x y)right  f(x)q(x y)  0 \n        1  f(x)q(x y) = 0\n    endcases","category":"page"},{"location":"sampling/metropolis/#The-detailed-balance-equation","page":"Metropolis and Metropolis-Hastings","title":"The detailed balance equation","text":"","category":"section"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"The proof is similar. But we assume that q(x y)  0 when f(x) f(y)  0 (and consequently q(y x)  0). ","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"For the detailed balance equation, we only need to consider  x y such that f(x) f(y)  0 Thus, q(x y) q(y x)  0","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"When 0  f(y)q(y x) geq f(x)q(x y) we have","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    alpha(x y) = fracf(y)q(y x)f(x)q(x y) quad alpha(y x) = 1","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"so that","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    a(x y) = q(x y) fracf(y)q(y x)f(x)q(x y) = fracp(y)q(y x)p(x) qquad a(y x) = q(y x)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Thus,","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    a(x y) p(x) = p(y)q(y x) = p(y)a(y x)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"By symmetry in x and y the same follows if 0  f(x)q(x y) geq f(y)q(y x) i.e.","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"    p(y)a(y x) = a(y x) p(y)","category":"page"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"This proves the detailed balance equation, for the density p=p(x) with respect to the transition density of the Metropolis-Hasting Markov chain.","category":"page"},{"location":"sampling/metropolis/#References","page":"Metropolis and Metropolis-Hastings","title":"References","text":"","category":"section"},{"location":"sampling/metropolis/","page":"Metropolis and Metropolis-Hastings","title":"Metropolis and Metropolis-Hastings","text":"Nicholas Metropolis,  Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, and Edward Teller (1953), \"Equation of State Calculations by Fast Computing Machines,\" J. Chem. Phys. 21, 1087–1092\nW. K. Hastings (1970), \"Monte Carlo sampling methods using Markov chains and their applications,\" Biometrika 57 (1), 97-109\nJun S. Liu, \"Monte Carlo Strategies in Scientific Computing,\" Springer Series in Statistics, Springer-Verlag New York 2004","category":"page"},{"location":"markov_chains/mc_countableX_connections/#Connected-states,-irreducibility-and-uniqueness-of-invariant-measures","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"","category":"section"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"The notion of communicating states is a fundamental concept related to the uniqueness of an invariant measure, at least in a local scope. When every pair of states communicate with each other, then we have the notion of irreducibility, which extends the uniquenesse to a global scope.","category":"page"},{"location":"markov_chains/mc_countableX_connections/#Setting","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Setting","text":"","category":"section"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"As before, we assume that (X_n)_n is a time-homogeneous, discrete-time Markov chain with a countable state space. More precisely, we assume the indices are n=0 1 2 ldots and that the space mathcalX is finite or countably infinite. The sample space is the probability space (Omega mathcalF mathbbP) where mathcalF is the sigma-algebra on the set Omega and mathbbP is the probability distribution. The one-step transition distribution is denoted by K(x y) = mathbbP(X_n+1 = y  X_n = x) and is independent of n=0 1 ldots thanks to the time-homogeneous assumption. Similary, the n-step transition distribution is denoted K_n(x y) = mathbbP(X_k+n = y  X_k = x) for n=1 2 ldots independently of k=0 1 ldots","category":"page"},{"location":"markov_chains/mc_countableX_connections/#Definitions","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Definitions","text":"","category":"section"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"We start with some fundamental definitions.","category":"page"},{"location":"markov_chains/mc_countableX_connections/#Communicating-points","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Communicating points","text":"","category":"section"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Markov chains are about the probability of states changing with time. If starting at some state, some of the other states might be more likely to be observed in the future than others, and some might never be observed. We distinguish them by the notion of communication.","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"note: Definition (communicating points)\nWe say that x leads to y when there exists a nonnegative integer n=n(x y) such that K_n(x y)  0 When x leads to y, we write x rightarrow y If x does not lead to y we write x notrightarrow y When x leads to y and y leads to x we say that these states communicate with each other, and we write x leftrightarrow y","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Remark. Notice that this definition automatically gives that x leftrightarrow x for every state x even if x is transient and the chain that starts at x never returns to x Because of this, some authors defines xrightarrow y restricting n(x y) to be a positive integer. As a side effect, the communication property looses the reflexivity property which has to be enforced in the definition of an equivalence relation, so we can properly decompose the space into equivalence classes of communicating states.","category":"page"},{"location":"markov_chains/mc_countableX_connections/#Equivalence-class-of-communicating-states","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Equivalence class of communicating states","text":"","category":"section"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"The relation of mutual communication x leftrightarrow y is an equivalence class.","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"note: Fact (communication is an equivalence relation)\nThe relation x leftrightarrow y is an equivalence relation which we term communication relation. The communication class of a state x is denoted x","category":"page"},{"location":"markov_chains/mc_countableX_connections/#Closed-communication-class","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Closed communication class","text":"","category":"section"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"In particular, the state space can be decomposed into one or more communication classes. But a communication class may not carry an invariant measure. The chain may \"leak\" to other classes. More precisely, we may have one state in one class leading to another state in a different class. It is important to distinguish when this happens or not. For that, we have the following definition.","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"note: Definition (Closed communication class)\nA communication class C is called closed when for every xin C and every zinmathcalX such that xrightarrow z we also have zin C In other words, if xin C and zin mathcalXsetminus C then x notrightarrow z","category":"page"},{"location":"markov_chains/mc_countableX_connections/#Local-uniqueness-of-invariant-measures","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Local uniqueness of invariant measures","text":"","category":"section"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"First we have the following result, without any special assumption, but which will be key, for the uniqueness, when the state x is assumed to be recurrent and with positive probability for the assumed invariant measure.","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"note: Lemma (lower bound on an invariant measure)\nSuppose tilde P is an invariant measure for the Markov chain. Then, for any two states x zinmathcalX    tilde P(z) geq tilde P_x(z)tilde P(x)where    tilde P_x(z) = sum_n=1^infty mathbbP(X_n = z n leq tau_x  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Proof. If tilde P is a given invariant measure, then, using this invariance,","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P(z) = sum_y_1 K(y_1 z)tilde P(y_1)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Splitting the summation into y_1=x and y_1neq x we have","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P(z) = K(x z)tilde P(x) + sum_y_1neq x K(y_1 z)tilde P(y)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Using again the invariance for the term tilde P(y) inside the summation and spliting again the summation, we have","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    beginalign*\n        tilde P(z)  = K(x z)tilde P(x) + sum_y_1neq x K(y_1 z)left( sum_y_2 K(y_2 y_1)tilde P(y_2) right) \n         = K(x z)tilde P(x) + sum_y_1neq x K(x y_1)K(y_1 z)tilde P(x) + sum_y_1neq xsum_y_2neq x K(y_2 y_1)K(y_1 z)tilde P(y_2)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"By induction, we obtain","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    beginalign*\n        tilde P(z)  = K(x z)tilde P(x) \n         quad + sum_y_1neq x K(x y_1)K(y_1 z)tilde P(x) \n         quad + sum_y_1neq xsum_y_2neq x K(x y_1)K(y_1 z)tilde P(x) \n         quad + cdots \n         quad + sum_y_1neq xcdots sum_y_k-1neq x K(x y_k-1)K(y_k-2 y_k-1)cdots K(y_1 z)tilde P(x) \n         quad + sum_y_1neq xcdots sum_y_kneq x K(y_k y_k-1)K(y_k-1 y_k-2)cdots K(y_1 z)tilde P(x)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"for every kinmathbbN Negleting the last term at each iteration k we find that","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    beginalign*\n        tilde P(z)  geq bigg(K(x z) + sum_y_1neq x K(x y_1)K(y_1 z) + cdots \n         qquad + sum_y_1neq xcdots sum_y_k-1neq x K(x y_k-1)K(y_k-2 y_k-1)cdots K(y_1 z)bigg)tilde P(x)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Now notice that, for k=1","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    K(x z) = mathbbP(X_1 = z  X_0 = x) = mathbbP(X_1 = z tau_x geq 1  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"for k=2","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    sum_y_1neq x K(x y_1)K(y_1 z) = mathbbP(X_2 = z X_1 neq x  X_0 = x) = mathbbP(X_2 = z tau_x geq 2  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"and, more generally, for any kinmathbbN","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    beginalign*\n        sum_y_1neq xcdots sum_y_k-1neq x K(x y_k-1)K(y_k-2 y_k-1)cdots K(y_1 z)  = mathbbP(X_k = z X_k-1neq x ldots X_1 neq x  X_0 = x) \n         = mathbbP(X_k = z tau_x geq k  X_0 = x)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"The summation of all such kinmathbbN terms is precisely tilde P_x(z) and we find","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P(z) geq tilde P_x(z)tilde P(x)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"This concludes the proof. □","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"In the result above, we do not need to assume that x is recurrent. If it is not, then both terms on the right hand side may vanish and the inequality is vacuous. However, if x is recurrent and has positive measure tilde P(x)  0 with respect to the invariant measure, then we deduce that tilde P must be a multiple of tilde P_x meaning uniqueness up to a multiplicative constant, at least locally among all communicating states to x","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"In order to establish such result, let us first show that, if a state x is recurrent, then the associated invariant measure tilde P_x is positive over the communication class x and vanishes on the complement of x","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"note: Proposition\nSuppose x is a recurrent state and that x is a closed communication class. Then    tilde P_x(z)  0 quad Longleftrightarrow z in x","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Proof. If z = x then the result is immediate since tilde P_x(x) = 1 If zneq x but zin x then there exists ninmathbbN such that K_n(x z)  0 Since tilde P_x is invariant, we have","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P_x(z) = sum_yinmathcalX K_n(y z) tilde P_x(y) geq K(x z)tilde P_x(x)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Estimating from below the summation over yinmathcalx by the summand at y=x and using that K_n(x z)  0 and tilde P_x(x) = 1","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P_x(z) = sum_yinmathcalX K_n(y z) tilde P_x(y) geq K_n(x z)tilde P_x(x) = K_n(x z)  0","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"which proves that zin x implies tilde P_x(z) Now for the converse. Suppose tilde P_x(z)  0 If z = x then zin x and we are done. If zneq x we have, by the definition of this measure as","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P_x(z) = sum_n=1^infty mathbbP(X_n = z n leq tau_x  X_0 = x)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"that, for some ninmathbbN","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    mathbbP(X_n = z n leq tau_x  X_0 = x)  0","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"In particular,","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    K_n(x z) = mathbbP(X_n = z  X_0 = x) geq mathbbP(X_n = z n leq tau_x  X_0 = x)  0","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"which means that x rightarrow z Now, since x is closed, this means that zin x This completes the characterization of zin x as tilde P_x(z)  0.  □","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"note: Theorem (local uniqueness up to a multiplicative constant)\nAssume that x is a recurrent state with closed communication class x Suppose that tilde P is an invariant measure for the Markov chain which is carried by x and with tilde P(x)  0 Then, for any state z in x both    tilde P_x(z) tilde P(z)  0and    fractilde P(z)tilde P_x(z) geq fractilde P(x)tilde P_x(x)which implies that tilde P and tilde P_x are proportional i.e. there exists C  0 such that    fractilde P(z)tilde P_x(z) = C quad forall zin x","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Proof. It follows from the lemma on the lower bound on an invariant measure that","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P(z) geq tilde P_x(z)tilde P(x)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"for all zinmathcalX Since x is a recurrent state, it follows that tilde P_x is also an invariant measure and, as seen in the previous proposition, since x is closed,","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P_x(z)  0 quad forall zin x","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"We also know that","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P_x(x) = mathbbP(tau_x  infty  X_0 = x) = 1","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Thus, we obtain the inequality","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    fractilde P(z)tilde P_x(z) geq fractilde P(x)tilde P_x(x) quad forall zin x","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Since tilde P(x)  0 this implies that","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P(z)  0 quad forall zin x","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"This proves the first claim that tilde P is also positive on the communication class x","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Now, using that tilde P is invariant and is carried by x we have","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P(x) = sum_z K_n(z x)tilde P(z) = sum_zin x K_n(z x)tilde P(z)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Using the previous inequality and the fact that tilde P_x is also invariant and carried by x we have, for any ninmathbbN","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    beginalign*\n        tilde P(x)  = sum_zin x K_n(z x)tilde P(z) \n             geq fractilde P(x)tilde P_x(x) sum_zin x K_n(z x)tilde P_x(z) \n             = fractilde P(x)tilde P_x(x) tilde P_x(x) \n             = tilde P(x)\n    endalign*","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"This means that the inequality in the middle is actually an equality, i.e.","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    sum_zin x K_n(z x)tilde P(z) = fractilde P(x)tilde P_x(x) sum_zin x K_n(z x)tilde P_x(z)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Since for each z in x we have","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P(z) geq fractilde P(x)tilde P_x(x) tilde P_x(z)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"and the summation of these terms is equal, this means that each summand must be equal, i.e.","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    tilde P(z) = fractilde P(x)tilde P_x(x) tilde P_x(z) quad forall zin x","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Dividing by tilde P_x(z) which we know is positive over x yields the second claim.","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Finally, considering the constant","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    C = fractilde P(x)tilde P_x(x)","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"yields the claim that tilde P is proportional to tilde P_x completing the proof. □","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"note: Corollary\nSuppose the chain is recurrent and irreducible. Then there is only one invariant measure, up to a multiplicative constant.","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Proof. Since the chain is assumed to be recurrent, any xinmathcalX is recurrent, which means tilde P_x is a nontrivial invariant measure, for any xinmathcalX Since the chain is irreducible, the whole space is a single communication class and is also closed because the chain has nowhere else to go. Thus, any invariant measure is a multiple of any of the tilde P_x xinmathcalX and any pair tilde P_x and tilde P_y is one a constant multiple of the other.","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"note: Corollary (Kac's Theorem)\nSuppose the chain is irreducible and has a stationary probability distribution tilde P Then    tilde P(x) = frac1mathbbEtau_x  X_n = x","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Proof. ...","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Remark. If we consider the chain","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"    X_n+1 = begincases \n        X_n + 1  n neq -1 0 \n        X_n + 2  n = -1 \n        X_n  n = 0\n    endcases","category":"page"},{"location":"markov_chains/mc_countableX_connections/","page":"Connected states, irreducibility and uniqueness of invariant measures","title":"Connected states, irreducibility and uniqueness of invariant measures","text":"Then, the only recurrent state is X_n = 0 The associated stationary probability distribution is the Dirac Delta at X=0 On the other hand, the counting measure is also invariant and has measure 1 at any point, including the recurrent point X=0 but this measure is not proportional to the Dirac Delta, so it does not suffice to assume that tilde P is an invariant measure with tilde P(x)  0 at a recurrent point x One must assume that tilde P is carried by the equivalence class of x","category":"page"},{"location":"sampling/overview/#Overview-of-sampling-methods","page":"Overview","title":"Overview of sampling methods","text":"","category":"section"},{"location":"sampling/overview/","page":"Overview","title":"Overview","text":"A fundamental tool in Statistics is to be able to generate samples of a known distribution. The way to generate samples depends on how the distribution is given. We will see here different examples:","category":"page"},{"location":"sampling/overview/","page":"Overview","title":"Overview","text":"We may use a pseudo-random number generator (PRNG) to generate samples of a uniform distribution;\nThe integral transform method to generate samples of a scalar distribution when we known the inverse F^-1(x) of the CDF;\nDifferent sorts of transformation methods to generate samples of a distribution out of other distributions, such as the Box-Muller transform to generate pairs of independent normally distributed random numbers;\nThe Rejection sampling method when we only know a multiple f(x) of the PDF, i.e. p(x) = f(x)Z for some unknown Z, and we known how to sample from another distribution with PDF q=q(x) such that a bound of the form f(x) leq M q(x) for a given M is available;\nMarkov-Chain-Monte-Carlo (MCMC) methods to generate samples when we only know a multiple f(x) or the energy U(x) of the PDF, i.e. p(x) = f(x)Z or p(x) = e^-U(x)Z for an unknown or hard-to-compute normalizing constant Z such as the Gibbs sampler, the Metropolis algorithm, the Metropolis-Hastings method, and the Hamiltonian Monte-Carlo (HMC) method;\nLangevin sampling when we only know the Stein score s(x) = nablaln p(x) of the distribution.","category":"page"},{"location":"bayesian/bayesian_probprog/#Overview","page":"Bayesian probabilistic programming","title":"Overview","text":"","category":"section"},{"location":"bayesian/bayesian_probprog/","page":"Bayesian probabilistic programming","title":"Bayesian probabilistic programming","text":"It is tedious and many times impossible to do inference by hand. Fortunately, many steps can be automated and calculated with a computer, as in many other subjects. In the realm of probability, this is called probabilistic programming. We can use the computer, in any suitable language, to help us i) build Bayesian models, ii) draw samples from them, iii) do inference with them, and so on.","category":"page"},{"location":"bayesian/bayesian_probprog/","page":"Bayesian probabilistic programming","title":"Bayesian probabilistic programming","text":"For teaching purposes, it is important to make the code as explicit and clear as possible. But on the field, in actual applications, a more general and extensible framework is useful. For that, there exist a number of packages for probabilistic programming in several languages. In Julia, you can easily access classical tools and packages such as STAN, via Stan.jl, and pyMC, via JuliaPy/PyCall.jl or cjdoris/PythonCall.jl.","category":"page"},{"location":"bayesian/bayesian_probprog/","page":"Bayesian probabilistic programming","title":"Bayesian probabilistic programming","text":"But if you want to leverage all the power of Julia, a proper julia-native probabilistic programming package is the best choice, such as Turing.jl, Soss.jl, Gen.jl, and others. See the thread Current state of Julia Probabilistic Programming Languages and functionalities on Discourse for a discussion of the available packages.","category":"page"},{"location":"bayesian/bayesian_probprog/","page":"Bayesian probabilistic programming","title":"Bayesian probabilistic programming","text":"Here, we will mainly either compute things explicit, for didactical purposes, or use Turing.jl, with real applications in mind. It is easy to combine Turing.jl with other packages, such as those from SciML, to do Bayesing inference on models involving all sorts of differential equations.","category":"page"},{"location":"sampling/mcmc/#Markov-Chain-Monte-Carlo-(MCMC)","page":"Overview","title":"Markov Chain Monte Carlo (MCMC)","text":"","category":"section"},{"location":"sampling/mcmc/","page":"Overview","title":"Overview","text":"Markov Chain Monte Carlo methods take its name from the following characteristics.","category":"page"},{"location":"sampling/mcmc/","page":"Overview","title":"Overview","text":"One designs a Markov chain X_0 X_1 X_2 ldots with the property that any initial distribution X_0 converges to a desired distribution P X_n rightarrow X_infty sim P\nOne performs a Monte-Carlo sample by computing a (single) trajectory (x_n)_n such that, after an initial transient time called the burn-in time N the distribution of the (tail of the) sample trajectory, x_N+1 x_N+2 ldots is close to the stationary distribution X_infty sim P","category":"page"},{"location":"sampling/mcmc/","page":"Overview","title":"Overview","text":"For these two properties to hold, the desired distribution has to be a stationary distribution of the Markov chain, and the Markov chain has to be ergodic, so that (i) this is the only stationary distribution; (ii) any initial distribution converges to the stationary distribution; (iii) a single trajectory (almost surely) suffices to walk about the event space and statistically represent the desired stationary distribution.","category":"page"},{"location":"sampling/mcmc/","page":"Overview","title":"Overview","text":"There are a few such MCMC methods, such as the original Metropolis algorithm; its extension known as Metropolis-Hastings method; and the Hamiltonian Monte-Carlo (HMC) method.","category":"page"},{"location":"generative/sliced_score_matching/#Sliced-score-matching","page":"Sliced score matching","title":"Sliced score matching","text":"","category":"section"},{"location":"generative/sliced_score_matching/#Aim","page":"Sliced score matching","title":"Aim","text":"","category":"section"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"Detail the sliced score matching method proposed by Song, Garg, Shi, and Ermon (2020) to reduce the computational cost of the score-matching method for high-dimensional problems.","category":"page"},{"location":"generative/sliced_score_matching/#Background","page":"Sliced score matching","title":"Background","text":"","category":"section"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"The score-matching method proposed by Aapo Hyvärinen (2005) is based on minimizing the empirical implicit score matching objective function J_mathrmISMtilde p_0(boldsymboltheta) given by","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"    tilde J_mathrmISMtilde p_0 = frac1Nsum_n=1^N left( frac12boldsymbolpsi(mathbfx_n boldsymboltheta)^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx_n boldsymboltheta) right)","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"where boldsymbolpsi(mathbfx boldsymboltheta) is the score function of a parametrized model probability density function p(mathbfx boldsymboltheta) fitting the unknown score function boldsymbolpsi_mathbfX(mathbfx) of a random variable mathbfX in mathbbR^d, dinmathbbN, and mathbfx_n n=1 ldots N are Nin mathbbN sample points of this random variable.","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"The objective function J_mathrmISMtilde p_0(boldsymboltheta) is the approximation, using the empirical distribution","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"    tilde p_0(mathbfx) = frac1Nsum_n=1^N delta(mathbfx - mathbfx_n)","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"of the implicit score matching objective","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"    J_mathrmISM(boldsymboltheta) = int_mathbbR p_mathbfX(mathbfx) left( frac12leftboldsymbolpsi(mathbfx boldsymboltheta)right^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx boldsymboltheta) right)mathrmdmathbfx","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"where p_mathbfX(mathbfx) is the (also unknown) probability density function of X.","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"The difficulty of minimizing J_mathrmISMtilde p_0(boldsymboltheta) is the need to compute the divergence of the score function, which amounts to computing the Hessian of the model function, not to mention the gradient of the loss function itself, needed for the parameter optimization. This is very costly and scales badly with the dimension d of the random variable (and of the neural network).","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"To reduce this cost, Song, Garg, Shi, and Ermon (2020) proposed the sliced-score matching method (see also Song's blog on sliced score matching). In this method, only some directional derivatives are computed at each sample point, choosing randomly before the start of the minimization process.","category":"page"},{"location":"generative/sliced_score_matching/#The-sliced-score-matching-objective-function","page":"Sliced score matching","title":"The sliced score matching objective function","text":"","category":"section"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"In this method, for each sample point x_n, n=1 ldots N, one randomly draws M unitary vectors mathbfv_n m, m=1 ldots M, in the space mathbbR^d (say uniformly on the hypersphere, or with respect to a multivariate standard normal or a multivariate Rademacher distribution uniform on pm 1^d, as discussed in Song, Garg, Shi, and Ermon (2020)), forming the (empirical, implicit) sliced score matching objective function","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"    J_mathrmISSMtilde p_0tilde q_0(boldsymboltheta) = frac1NMsum_n=1^N sum_m=1^M left( frac12 left(mathbfv_nm cdot boldsymbolpsi(mathbfx_n boldsymboltheta) right)^2 + boldsymbolnabla_mathbfv_nmboldsymbolpsi(mathbfx_n boldsymboltheta) cdot mathbfv_nm right)","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"where","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"boldsymbolnabla_mathbfv_nmboldsymbolpsi(mathbfx_n boldsymboltheta)","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"is the directional derivative of boldsymbolpsi(mathbfx_n boldsymboltheta) along mathbfv_nm.","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"Under suitable conditions, the minimizer boldsymboltheta_N M of J_mathrmISSMtilde p_0(boldsymboltheta) converges to the minimizer boldsymboltheta of the implicit score matching J_mathrmISM(boldsymboltheta) (which is the same as that of the explicit score matching), when Nrightarrow infty, even with M fixed (but notice that the number NM of sample directions grows with N, already).","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"The divergence term in the original implicit score matching objective J_mathrmISM(boldsymboltheta) is computed as","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"    boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx boldsymboltheta) = sum_i=1^d fracpartial psi_ipartial x_i(mathbfx boldsymboltheta) = sum_i=1^d boldsymbolnabla_mathbfe_i boldsymbolpsi(mathbfx boldsymboltheta) cdot mathbfe_i","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"and scales with the dimension d of the event space. In contrast, the computation of the collection of M directional derivatives","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"    sum_m=1^M boldsymbolnabla_mathbfv_nmboldsymbolpsi(mathbfx_n boldsymboltheta) cdot mathbfv_nm","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"scales with M. For high-dimensional problems, as in the applications in mind, d is very large, and M is chosen much smaller than d, saving a lot of computational time.","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"The objective J_mathrmISSMtilde p_0(boldsymboltheta) can be seen as an approximation, with the empirical distributions (p_0 on mathbfx and q_0 on mathbfv), of the (implicit) sliced score matching objective","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"    J_mathrmISSM(boldsymboltheta) = int_mathbbR^d int_mathbbR^d p_mathbfX(mathbfx) q_mathbfV(mathbfv)left( frac12 left(mathbfv cdot boldsymbolpsi(mathbfx boldsymboltheta) right)^2 + boldsymbolnabla_mathbfvboldsymbolpsi(mathbfx boldsymboltheta) cdot mathbfv right) mathrmdmathbfvmathrmdmathbfx","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"for a probability density function q_mathbfV(mathbfv), associated with a random vector mathbfV for the directions (a uniform distribution on the hypersphere S_d-1subset mathbbR^d or a multivariate standard normal or a multivariate Rademacher distribution uniform on pm 1^d, as mentioned above) independent of X.","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"The objective J_mathrmISSM(boldsymboltheta), in turn, can be obtained via integration by parts, from the explicit score matching objective","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"    J_mathrmESSM(boldsymboltheta) = frac12 int_mathbbR^d int_mathbbR^dp_mathbfX(mathbfx) q_mathbfV(mathbfv)left mathbfv cdot boldsymbolpsi(mathbfx boldsymboltheta) + boldsymbolnabla_mathbfvboldsymbolpsi(mathbfx boldsymboltheta) cdot mathbfv right^2 mathrmdmathbfvmathrmdmathbfx","category":"page"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"We do not implement numerically the sliced score matching method since it is still computationally intensive for automatic differentiation and this approach won't be extended to our (current) final aim of denoising diffusion.","category":"page"},{"location":"generative/sliced_score_matching/#References","page":"Sliced score matching","title":"References","text":"","category":"section"},{"location":"generative/sliced_score_matching/","page":"Sliced score matching","title":"Sliced score matching","text":"Y. Song, S. Garg, J. Shi, S. Ermon (2020), Sliced Score Matching: A Scalable Approach to Density and Score Estimation, Proceedings of The 35th Uncertainty in Artificial Intelligence Conference, PMLR 115:574-584 – see also the arxiv version\nY. Song's blog on \"Sliced Score Matching: A Scalable Approach to Density and Score Estimation\"\nAapo Hyvärinen (2005), \"Estimation of non-normalized statistical models by score matching\", Journal of Machine Learning Research 6, 695-709","category":"page"},{"location":"sampling/invFtransform/#Probability-integral-transform-method","page":"Probability integral transform","title":"Probability integral transform method","text":"","category":"section"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"In some cases, such as for the exponential distributions, it is easy to invert the cumulative distribution function and use that to transform samples of the uniform distributions to samples of the desired distribution. This is based on the following result.","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"note: Probability Integral Transform (Universality of the Uniform Distribution)\nLet X be a univariate random variable and let F=F(x) be its cumulative distribution function. Then, U=F(X) is a standard uniform distribution, i.e. a uniform distribution over the interval 0 1","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"In other words, we can state this result in the following form:","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"note: Inverse Probability Integral Transform\nLet F=F(x) be the cumulative distribution function of a one-dimensional distribution mathbbP Let F^-1(u) = infx F(x) geq u and let U sim operatornameUniform(0 1) Then, X = F^-1(U) has the same distribution as mathbbP","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"This results says that, in principle, one can generate any one-dimensional distribution from a transformation of the uniform distribution. In practice, one needs a simple formula for the inverse x = F^-1(u) for this to be feasible. One such example is that of the exponential distribution. Before we focus on this example, let us prove the above result.","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"Proof of Probability Integral Transform.Suppose that F is invertible over the range 0 u  1 for simplicity. The CDF of U is then given byF_U(u) = mathbbP(U leq u) = mathbbP(F(X) leq u) = mathbbP(X leq F^-1(u)) = F(F^-1(u)) = uover this range. This means that the F_U is the CDF of the standard uniform distribution.","category":"page"},{"location":"sampling/invFtransform/#Example","page":"Probability integral transform","title":"Example","text":"","category":"section"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"Let us now consider the example of the exponential distribution. The exponential distribution with rate lambda  0 has the PDF","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"    p(x) = begincases\n        lambda e^-lambda x  x geq 0 \n        0  x  0\n    endcases","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"Its CDF is","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"    F(x) = begincases\n        int_0^x lambda e^-lambda xmathrmdx = 1 - e^-lambda x  x geq 0 \n        0  x  0\n    endcases","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"The inverse, for x geq 0 is given by","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"    beginalign*\n        u = F(x)  Leftrightarrow u = 1 - e^-lambda x \n         Leftrightarrow e^-lambda x = 1 - u \n         Leftrightarrow - lambda x = ln (1 - u) \n         Leftrightarrow x = - frac1lambda ln(1 - u)\n    endalign*","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"Thus,","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"    F^-1(u) = -frac1lambda ln(1 - u) quad 0 leq u  1","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"Let us generate a sample using this method.","category":"page"},{"location":"sampling/invFtransform/","page":"Probability integral transform","title":"Probability integral transform","text":"plt1 = histogram(U, title=\"Histogram of a sample of Unif(0, 1)\", titlefont=10, bins=20, normalized=:pdf, label=false) # hide\nplt2 = histogram(X, title=\"Histogram of Exp(λ=$λ) via inverse CDF\", titlefont=10, bins=20, normalized=:pdf, label=false) # hide\nplot(plt1, plt2, layout = 2, size = (800, 400)) # hide","category":"page"},{"location":"markov_chains/mc_countableX_convergencia/#Aperiodicidade-e-convergência-para-a-distribuição-estacionária","page":"Aperiodicidade e convergência para a distribuição estacionária","title":"Aperiodicidade e convergência para a distribuição estacionária","text":"","category":"section"},{"location":"markov_chains/mc_invariance/#Invariant-distributions","page":"Invariant distributions","title":"Invariant distributions","text":"","category":"section"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"Of particular interest, for time-homogeneous Markov chains, are the stationary distributions, i.e. such that X_n have the same law as X_0 for all n=0 1 2 ldots This is the same as saying that they all have the same distribution P which is invariant by the Markov operator.","category":"page"},{"location":"markov_chains/mc_invariance/#Definition","page":"Invariant distributions","title":"Definition","text":"","category":"section"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"More precisely, a probability distribution P on mathcalX is (time-)invariant or stationary for a time-homogenous discrete-time Markov chain (X_n)_n when P = PK i.e.","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    P(E) = int_mathcalX K(x E)mathrmdP(x)","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"where K(x E) = K_1(x E) = K_nn+1(x E) is the one-step transition probability of the Markov chain and the K in the equation P = PK is the associated Markov operator on the space mathcalP(mathcalX) of probability distributions on mathcalX","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"Sometimes it might be useful to consider measures with are not necessarily probability distributions. They may be finite or infinite, and sigma-finite or not. In any case, we call a measure rho (time-)invariant or stationary for the Markov chain if rho = rho K i.e.","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    rho(E) = int_mathcalX K(x E)mathrmdrho(x)","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"When the transition probability has a kernel k(x y) with respect to a measure mu(x) this can be written as","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    rho(E) = int_E int_mathcalX k(x y)mathrmdrho(x) mathrmdmu(y)","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"In the case of the Lebesgue measure, we simply have","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    rho(E) = int_E int_mathcalX k(x y)mathrmdrho(x) mathrmdy","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"If, moreover, rho has a density f with respect to the Lebesgue measure, this is equivalent to","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    f(y) = int_mathcalX k(x y)f(y)mathrmdx","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"In case the space mathcalX is countable, with the discrete topology, the invariance may be expressed pointwise:","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    rho(y) = sum_yinmathcalX K(x y)rho(x) quad forall yinmathcalX","category":"page"},{"location":"markov_chains/mc_invariance/#Examples","page":"Invariant distributions","title":"Examples","text":"","category":"section"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"A Markov chain may or may not have an invariant distribution and it may have a unique invariant distribution or several ones. This is a main topic of interest in the theory of Markov chains. Below, we give a few examples with these cases of uniqueness, non-uniqueness, and non-existence of invariant probability measures, also called stationary distributions.","category":"page"},{"location":"markov_chains/mc_invariance/#A-two-state-Markov-chain","page":"Invariant distributions","title":"A two-state Markov chain","text":"","category":"section"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"Let mathcalX = 1 2 and consider the Markov chain characterized by the one-step transition distribution","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    K = (K(i j))_ij=1^2 = beginbmatrix\n        1 - alpha  alpha \n        beta  1 - beta\n    endbmatrix","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"where 0  alpha beta  1 We can look for an invariant state by solving P = PK with P = (p 1-p) We have","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    begincases\n        p = p(1-alpha) + (1-p)beta \n        1 - p = palpha + (1-p)(1-beta)\n    endcases","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"This can be simplified to","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    p(alpha + beta) = beta","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"hence","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    p = fracbetaalpha + beta","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"Thus, there is a unique invariant distribution, which is given by","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    P = left(fracbetaalpha + beta fracalphaalpha + betaright)","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"If alpha  beta then state 1 is more likely to go to state 2 than the other way around. And this also means that, in the stationary state, state 2 is more likely than state 1. Similarly for beta  alpha If both are equal, then the stationary state is uniform in the state variables. In any case, we will see further on that any initial distribution converges to this unique stationary distribution.","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"When either or both parameters alpha and beta assume one of the extreme values 0 and 1 then we may or may not have a unique invariant measure.","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"Indeed, if only alpha = 0 with 0  beta leq 1 then p=1 and there is only one stationary distribution, concentrated at state x=1 If only beta = 0 with 0  alpha leq 1 then p=0 and there is, again, only one stationary distribution, which this time is concentrated at state x=2","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"If both alpha = beta = 0 then 0leq p leq 1 is arbitrary, and there are an infinite number of stationary distributions, one concentrated at x=1 another concentrated at x=2 and many others as convex combinations of both. Effectivaly, in this case of both alpha=beta=0 the Markov chain can be decoupled into two separate chains, one restricted to state x=1 and the other restricted to state x=2 Each has its own unique invariant measure, with the whole system having any convex combination of both as invariant measure.","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"Finally, if both alpha = beta = 1 then p=12 and we have again a unique invariant measure, with uniform probability in both states. The peculiarity of this example is that it has some periodic solutions in time. Indeed, if we start with X_0 = 1 or X_0 = 2 then it oscillates between both states. They do not converge to the stationary distribution.","category":"page"},{"location":"markov_chains/mc_invariance/#Random-walk-running-to-infinity","page":"Invariant distributions","title":"Random walk running to infinity","text":"","category":"section"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"In the finite-state case, we always have at least one invariant probability distribution. For a case with no invariant distribution, we need to go to an infinite-state case, either discrete or continuous. Here we consider an infinite but discrete example. Similary continuous-state examples can be easily constructed.","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"Consider a random walk","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    X_n = X_n + B_n quad n=0 1 2 ldots","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"on mathcalX = mathbbN where the B_n are i.i.d. Bernoulli-type random variables with equal probabilities of being 0 or +1 ","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    B_n sim operatornameBernoulli(0 1 12)","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"This means the one-step transition probability is","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    K(i j) = frac12delta_i j + frac12delta_ij-1","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"where delta_ij is the Kroenecker delta, equal to 1 when i=j and to 0 otherwise. Thus any sample path has 12 probability of staying at j=1 and 12 probability to move from i up to j=i+1 In (infinite-)matrix form, it has both the diagonal and the superdiagonal with entries 12 and all the other entries equal to zero.","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"If there were an equilibrium probability distribution p = (p_1 p_2 cdots) where p_n geq 0 and sum_ninmathbbN p_n = 1 we would have the equations","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    p_n = fracp_n + p_n+12 quad ninmathbbZ","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"This means","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    p_n+1 = p_n = p_1","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"so that","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    sum_ninmathbbN p_n = sum_ninmathbbN p_1 = infty","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"which makes it impossible to be a probability distribution, with sum_ninmathbbN p_n = 1 This means the chain admits no invariant probability distribution. The problem here is the fact that we ask the probability to be finite. In fact, the counting measure, or any multiple of it, is an invariant measure, which is not finite. (See the next example, which is similar).","category":"page"},{"location":"markov_chains/mc_invariance/#A-symmetric-random-walk-on-the-integers","page":"Invariant distributions","title":"A symmetric random walk on the integers","text":"","category":"section"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"Even if we are allowed to move up or down, we may not have an invariant probability distribution. Consider, for instance, the random walk","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    X_n+1 = X_n + B_n quad n = 0 1 2 ldots","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"on mathcalX = mathbbZ where the B_n are i.i.d. Bernoulli-type random variables with equal probabilities of being +1 or -1","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    B_n sim operatornameBernoulli(-1 +1 12)","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"This means the one-step transition probability is","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    K(i j) = frac12delta_i j-1 + frac12delta_ij+1","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"where delta_ij is the Kroenecker delta, equal to 1 when i=j and to 0 otherwise, so it has 12 probability to move from i to j=i+1 and 12 probability to move from i to j=i-1 In (infinite-)matrix form, it has both the subdiagonal and superdiagonal with entries 12 and all the other entries equal to zero.","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"If there were an equilibrium probability distribution p = (cdots p_-2 p_-1 p_0 p_1 p_2 cdots) where p_n geq 0 and sum_ninmathbbZ p_n = 1 we would have the equations","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    p_n = fracp_n-1 + p_n+12 quad ninmathbbZ","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"But this equation contradicts the conditions p_n geq 0 and sum_n p_n = 1 Indeed, the finite summation implies that liminf_nrightarrow infty p_n = 0 If some p_n  0 then we would have n_-  n and n_+  n such that p_n_- p_n_+  p_n This means that the maximum of p_j for n_- leq j leq n_+ occurs somewhere within the extreme values and also that there must be a point m with p_m-1 p_m+1 leq p_m and minp_m-1 p_m+1  p_m. In this case,","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    p_m  fracp_m-1 + p_m+12","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"contradicting the inequality above for the stationary distribution. Thus, one cannot have an invariant probability distribution for this Markov chain.","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"If we look for an invariant measure which is not necessarily finite, then we find out that the counting distribution is invariant. In fact, the counting distribution can be written as","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    P(E) = sum_nin mathbbZ delta_n(E)","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"where delta_n is the Dirac distribution at n i.e. delta_n(E) = 1 if nin E and = 0 otherwise. Then,","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    beginalign*\n        (PK)(E)  = sum_nin mathbbZ frac12left(delta_n-1(E) + delta_n+1(E)right) = frac12sum_nin mathbbN delta_n-1(E) + frac12sum_ninmathbbNdelta_n(E) \n         = frac12sum_iin mathbbN delta_i(E) + frac12sum_iinmathbbNdelta_i(E) = frac12P(E) + frac12P(E) = P(E)\n    endalign*","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"showing that P is invariant (or any constant multiple of P).","category":"page"},{"location":"markov_chains/mc_invariance/#Gaussian-random-walk-on-the-real-line","page":"Invariant distributions","title":"Gaussian random walk on the real line","text":"","category":"section"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"The last example is the random walk","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    X_n+1 = X_n + W_n quad n = 0 1 2 ldots","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"on the real line mathcalX = mathbbR where","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    W_n sim mathcalN(0 1)","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"are independent normal random variables. In this case, the kernel of the transition distribution is the Gaussian kernel","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    k(x y) = frac1sqrt2pi e^-frac12(y - x)^2","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"We may easily check that the Lebesgue measure lambda is invariant for this random walk:","category":"page"},{"location":"markov_chains/mc_invariance/","page":"Invariant distributions","title":"Invariant distributions","text":"    beginalign*\n        (lambda K)(E)  = int_E int_mathbbRk(x y)mathrmdxmathrmdy \n         = frac1sqrt2pi int_E int_mathbbR e^-frac12(y - x)^2 mathrmdxmathrmdy \n         = int_E mathrmdy \n         = lambda(E)\n    endalign*","category":"page"},{"location":"generative/ddpm/#Denoising-diffusion-probabilistic-models","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"","category":"section"},{"location":"generative/ddpm/#Introduction","page":"Denoising diffusion probabilistic models","title":"Introduction","text":"","category":"section"},{"location":"generative/ddpm/#Aim","page":"Denoising diffusion probabilistic models","title":"Aim","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Review denoising diffusion probabilistic models (DDPM) introduced in Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015) and further improved in Ho, Jain, and Abbeel (2020) (and slightly more in Nichol and Dhariwal (2021)).","category":"page"},{"location":"generative/ddpm/#Motivation","page":"Denoising diffusion probabilistic models","title":"Motivation","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Build a solid foundation on score-based generative diffusion models, for which DDPM, although not initially seen as score-based, is related to, as a discrete analog of the SDE model.","category":"page"},{"location":"generative/ddpm/#Background","page":"Denoising diffusion probabilistic models","title":"Background","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The main idea in Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli (2015) is to embed the random variable we want to model into a Markov chain and model the whole reverse process of the Markov chain. This is a much more complex task which greatly increases the dimension of the problem, but which yields more stability to both training and generative processes.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The desired random variable, for which we only have access to a sample, is considered as an initial condition to a Markov chain which gradually adds noise to the process so that it converges to a simple and tractable distribution, such as a normal or a binomial distribution. The training process fits a model to the reverse process of the Markov chain (starting back from a relatively large time step, where it will be close to the tractable distribution). Then, the model is used to reverse the process and generate (aproximate) samples of our target distribution from samples of the idealized tractable distribution. The tractable asymptotic distribution of the forward process becomes the initial distribution of the model reverse process, and the (initial) desired target distribution is approximated by the final distribution of the reverse model process.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The original work of Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli (2015) had great results but the model was a bit complex and training was costly. Ho, Jain, and Abbeel (2020) improved the model by fixing the variance of the model reverse process and simplifying the loss function in a stochastic gradient way, turning the method into an efficient one with great performance.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Further on, Nichol and Dhariwal (2021) showed improvements to the method by changing the linear variance schedule for the forward process proposed in the previous two works into a nonlinear one, which adds noise more gradually in the beginning and at the end. Another improvement was to learn the variance of the model reverse process in a very specific form, which allowed more flexibility in a way that did not hinder the training impractical.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Besides the original articles, another source, which in the beginning helped me understand the main ideas of the foundational articles, was the blog post What are diffusion models? Lil’Log by Lilian Weng (2021).","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"In a subsequent work, Song, Meng, Ermon (2021) improved the idea and introduced denoising diffusion implicit models, which is based on non-Markovian processes but amounts to the same training strategy and model. The advantage, then, is that sampling is greatly expedited with a non-Markovian reverse process that can sample directly from the tractable distribution. We do not detail this method here, though.","category":"page"},{"location":"generative/ddpm/#Details-of-the-method","page":"Denoising diffusion probabilistic models","title":"Details of the method","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We consider the unknown target distribution to be an initial distribution for a Markov process, so we denote the associated random variable by mathbfX_0 in mathbbR^d dinmathbbN and its probability density function by p_0(mathbfx) The sample points used for training are denoted by mathbfx_0^n_n=1^N","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The idea is to define a forward Markov process that gradually adds noise to the process and drives the distribution towards a tractable distribution such as a standard Gaussian or binomial distribution. This forward process is pretty well defined and straightforward to implement. From the initial sample points we obtain samples of the Markov process. The idea then is to use those sample trajectories to learn the reverse Markov process. With this model of the reverse process, we can build new sample points out of (new) samples of the standard Gaussian distribution, gradually denoising and noisy sample from the tractable distribution towards a sample of the desired distribution.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"In the case we consider here and as used in image generation, we add Gaussian noise and drive the system towards the standard Gaussian distribution. Since the reverse process starts with the standard Gaussian distribution and the process just adds Gaussian noises, the approximate reverse process is a Gaussian process. Thus we can just parametrized it by its (time-dependent) mean and variance. For the sake of simplicity of the training process, the variance is actually pre-defined, so we only train the mean of each reverse step. In turn, the mean is reparametrized and what is in fact learned is the noise that needs to be removed to go back to the sample space, granting the name denoising diffusion method. As it turns out, this noise is linked to the score function.","category":"page"},{"location":"generative/ddpm/#The-forward-Markov-chain","page":"Denoising diffusion probabilistic models","title":"The forward Markov chain","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The initial random variable mathbfX_0 is evolved in time as a Markov chain mathbfX_k_k according to","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbfX_k = sqrt1 - beta_kmathbfX_k-1 + sqrtbeta_kmathbfZ_k quad mathbfZ_k sim mathcalN(mathbf0 mathbfI)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"where boldsymbolbeta=beta_k_kin mathbbN is given, with 0  beta_k  1 for every k In practice, we stop at a sufficiently large step KinmathbbN so that k=1 2 ldots K","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The marginal probability density function of the step k conditioned on the step k-1 is","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p(mathbfx_kmathbfx_k-1) = mathcalNleft(mathbfx sqrt1 - beta_kmathbfx_k-1 beta_kmathbfIright)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"where mathcalN(mathbfx boldsymbolmu betamathbfI) is the Gaussian kernel","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathcalN(mathbfx boldsymbolmu betamathbfI) = frac1sqrt2pibeta^de^-frac12fracmathbfx - boldsymbolmu^2beta","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"with mathcalN(mathbfx mathbf0 mathbfI) being the standard Gaussian kernel.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"By taking the expectation of the recurrence relation of the Markov chain, we see that the means overlinemathbfX_k = mathbbEmathbfX_k evolve according to","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    overlinemathbfX_k = sqrt1 - beta_koverlinemathbfX_k-1","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"With 0  beta_k  1 we see that the mean value decays to zero exponentially,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    overlinemathbfX_k rightarrow 0 qquad k rightarrow infty","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Notice that","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    overlinemathbfX_k^2 = (1 - beta_k)overlinemathbfX_k-1^2","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"and","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbfX_k - overlinemathbfX_k = sqrt1 - beta_kleft(mathbfX_k-1 - overlinemathbfX_k-1right) + sqrtbeta_kmathbfZ_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thus,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    leftmathbfX_k - overlinemathbfX_kright^2 = (1 - beta_k)leftmathbfX_k-1 - overlinemathbfX_k-1right^2 + 2sqrt1 - beta_ksqrtbeta_kleft(mathbfX_k-1 - overlinemathbfX_k-1right)mathbfZ_k + beta_k mathbfZ_k^2","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Taking the expectation, we find that","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbbEleft leftmathbfX_k - overlinemathbfX_kright^2 right = (1 - beta_k) mathbbEleft leftmathbfX_k-1 - overlinemathbfX_k-1right^2 right + beta_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"This is precisely a recurrence relation for the variance,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    operatornameVar(mathbfX_k) = (1 - beta_k)operatornameVar(mathbfX_k-1) + beta_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The parameters boldsymbolbeta=beta_k_k are said to be a variance schedule.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"At the limit krightarrow infty with 0  beta_k  1 we see that the variance converges exponentially to one,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    operatornameVar(mathbfX_k) rightarrow 1 qquad k rightarrow infty","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thus, mathbfX_k_k converges to the standard Gaussian distribution.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We can also write","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    operatornameVar(mathbfX_k) - operatornameVar(mathbfX_k-1) = - beta_koperatornameVar(mathbfX_k-1) + beta_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"and","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    fracoperatornameVar(mathbfX_k) - operatornameVar(mathbfX_k-1)beta_k = -operatornameVar(mathbfX_k-1) + 1","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"so that the variance schedule boldsymbolbeta=beta_k_k is also interpreted as step sizes.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The probability density function p(mathbfx_0K) = p(mathbfx_0 ldots mathbfx_K) of the Markov chain, where mathbfx_0K = (mathbfx_0 dots mathbfx_K) is the portion of a trajectory up to step K satisfies the conditional marginal relation","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p(mathbfx_kmathbfx_k-1) sim mathcalN(sqrt1 - beta_kmathbfx_k-1 beta_k)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Then,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p(mathbfx_0Kmathbfx_0) = p(mathbfx_Kmathbfx_K-1)cdots p(mathbfx_1mathbfx_0) = prod_k=1^Kp(mathbfx_kmathbfx_k-1)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thus,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p(mathbfx_0K) = int_mathbbR^d prod_k=1^K p(mathbfx_kmathbfx_k-1)p_0(mathbfx_0)mathrmdmathbfx_0","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"An approximate distribution for the Markov chain is obtained with the empirical distribution based on samples of the initial random variable mathbfX_0 but we will not use this explicitly.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We can iterate the Markov transition formula and write","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        mathbfX_k  = sqrt1 - beta_kmathbfX_k-1 + sqrtbeta_kmathbfZ_k \n         = sqrt1 - beta_kleft( sqrt1 - beta_k-1mathbfX_k-2 + sqrtbeta_k-1mathbfZ_k-1 right) + sqrtbeta_kmathbfZ_k \n         = sqrt1 - beta_ksqrt1 - beta_k-1mathbfX_k-2 + sqrt1 - beta_ksqrtbeta_k-1mathbfZ_k-1 + sqrtbeta_kmathbfZ_k \n         = sqrt1 - beta_ksqrt1 - beta_k-1left( sqrt1 - beta_k-2mathbfX_k-3 + sqrtbeta_k-2mathbfZ_k-2 right) + sqrt1 - beta_ksqrtbeta_k-1mathbfZ_k-1 + sqrtbeta_kmathbfZ_k \n         = cdots \n         = sqrt1 - beta_k cdots sqrt1 - beta_1mathbfX_0 + sqrt1 - beta_kcdots sqrt1 - beta_1mathbfZ_1 + cdots + sqrt1 - beta_ksqrtbeta_k-1mathbfZ_k-1 + sqrtbeta_kmathbfZ_k\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"By defining","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    alpha_k = 1 - beta_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"we rewrite this as","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbfX_k = sqrtalpha_kcdots alpha_1mathbfX_0 + sqrtalpha_kcdotsalpha_2sqrt1 - alpha_1mathbfZ_1 + cdots + sqrtalpha_ksqrt1 - alpha_k-1mathbfZ_k-1 + sqrt1 - alpha_kmathbfZ_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Since the mathbfZ_k are standard Gaussian random variables, thus with zero mean and variance one, their linear combination is also a Gaussian with zero mean, while the variance is given by the sum of the variances, which ends up simplifying to","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"alpha_kcdotsalpha_2 (1 - alpha_1) + cdots + alpha_k(1 - alpha_k-1) + (1 - alpha_k) = 1 - alpha_kcdots alpha_1","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Defining now","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    baralpha_k = alpha_kcdotsalpha_1","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"we obtain","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbfX_k = sqrtbaralpha_kmathbfX_0 + sqrt1 - baralpha_kbarmathbfZ_k qquad barmathbfZ_k sim mathcalN(mathbf0 mathbfI)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"In other words, this means we can write","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p(mathbfx_kmathbfx_0) = mathcalN(mathbfx_k sqrtbaralpha_kmathbfx_0 1 - baralpha_k)","category":"page"},{"location":"generative/ddpm/#The-backward-Markov-chain","page":"Denoising diffusion probabilistic models","title":"The backward Markov chain","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Now we want to be able to revert the Markov chain. But what would be mathbfX_k-1 given mathbfX_k = mathbfx_k It turns out that we can also condition it on mathbfX_0 for training, and this leads to a tractable distribution.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"In fact, when conditioned on the initial sample, we can use Bayes' rule and write","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    pleft(mathbfx_k-1mathbfx_k mathbfx_0right) = fracpleft(mathbfx_kmathbfx_k-1 mathbfx_0right)pleft(mathbfx_k-1mathbfx_0right)pleft(mathbfx_kmathbfx_0right)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Using the Markovian property on the first term of the nominator and ignoring the normalization constant, we know that","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    pleft(mathbfx_kmathbfx_k-1 mathbfx_0right) = pleft(mathbfx_kmathbfx_k-1right) propto expleft(-frac12fracleft(mathbfx_k - sqrtalpha_kmathbfx_k-1right)^2beta_kright)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"while","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    pleft(mathbfx_k-1mathbfx_0right) propto expleft(-frac12fracleft(mathbfx_k-1 - sqrtbaralpha_k-1mathbfx_0right)^21 - baralpha_k-1right)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"and","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    pleft(mathbfx_kmathbfx_0right) propto expleft(-frac12fracleft(mathbfx_k - sqrtbaralpha_kmathbfx_0right)^21 - baralpha_kright)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thus,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    pleft(mathbfx_kmathbfx_k-1 mathbfx_0right) propto expleft( - frac12left(fracleft(mathbfx_k - sqrtalpha_kmathbfx_k-1right)^2beta_k + fracleft(mathbfx_k-1 - sqrtbaralpha_k-1mathbfx_0right)^21 - baralpha_k-1 - fracleft(mathbfx_k - sqrtbaralpha_kmathbfx_0right)^21 - baralpha_k right)right)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We separate the dependence on the variable mathbfx_k-1 from that on the conditioned variables mathbfx_k and mathbfx_0","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        pleft(mathbfx_kmathbfx_k-1 mathbfx_0right)  propto expbigg( - frac12bigg(fracmathbfx_k^2 - 2mathbfx_k sqrtalpha_kmathbfx_k-1 + alpha_kmathbfx_k-1^2beta_k \n         qquad qquad qquad + fracmathbfx_k-1^2 - 2mathbfx_k-1sqrtbaralpha_k-1mathbfx_0 + baralpha_k-1mathbfx_0^21 - baralpha_k-1 \n         qquad qquad qquad qquad qquad - fracmathbfx_k^2 - mathbfx_ksqrtbaralpha_kmathbfx_0 + baralpha_kmathbfx_0^21 - baralpha_k bigg)bigg) \n         = expbigg( -frac12bigg( left( fracalpha_kbeta_k + frac11 - baralpha_k-1right)mathbfx_k-1^2 \n         qquad qquad qquad - left(frac2sqrtalpha_kbeta_kmathbfx_k + frac2sqrtbaralpha_k-11 - baralpha_k-1mathbfx_0right)mathbfx_k-1 \n         qquad qquad qquad + left( frac1beta_k - frac11 - baralpha_kright)mathbfx_k^2 + fracsqrtbaralpha_k1 - baralpha_kmathbfx_kmathbfx_0 \n         qquad qquad qquad qquad qquad + left( fracbaralpha_k-11 - baralpha_k-1 - fracbaralpha_k1 - baralpha_k right)mathbfx_0^2bigg)bigg)\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Completing the squares, we write","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    left( fracalpha_kbeta_k + frac11 - baralpha_k-1right)mathbfx_k-1^2 - left(frac2sqrtalpha_kbeta_kmathbfx_k + frac2sqrtbaralpha_k-11 - baralpha_k-1mathbfx_0right)mathbfx_k-1 = fracleft(mathbfx_k-1 - tildeboldsymbolmu_kright)^2tildebeta_k - fractildeboldsymbolmu_k^2tilde beta_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"with","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        tildebeta_k  = frac1left( fracalpha_kbeta_k + frac11 - baralpha_k-1right) \n        fractildeboldsymbolmu_ktildebeta_k  = fracsqrtalpha_kbeta_kmathbfx_k + fracsqrtbaralpha_k-11 - baralpha_k-1mathbfx_0\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Using that beta_k = 1 - alpha_k we find the variance of pleft(mathbfx_kmathbfx_k-1 mathbfx_0right) to be","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    tildebeta_k = frac1left( fracalpha_kbeta_k + frac11 - baralpha_k-1right) = fracbeta_k(1 - baralpha_k-1)alpha_k(1 - baralpha_k-1) + beta_k = frac1 - baralpha_k-11 - baralpha_kbeta_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"With that, we rewrite the mean of pleft(mathbfx_kmathbfx_k-1 mathbfx_0right) as","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        tildeboldsymbolmu_k  = tildebeta_kleft(fracsqrtalpha_kbeta_kmathbfx_k + fracsqrtbaralpha_k-11 - baralpha_k-1mathbfx_0right) = frac1 - baralpha_k-11 - baralpha_kbeta_kleft(fracsqrtalpha_kbeta_kmathbfx_k + fracsqrtbaralpha_k-11 - baralpha_k-1mathbfx_0right) \n         = frac(1 - baralpha_k-1)sqrtalpha_k1 - baralpha_kmathbfx_k + fracbeta_ksqrtbaralpha_k-11 - baralpha_kmathbfx_0\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Then, we obtain","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        fractildeboldsymbolmu_k^2tilde beta_k  = frac1 - baralpha_k(1 - baralpha_k-1)beta_kleft(frac(1 - baralpha_k-1)sqrtalpha_k1 - baralpha_kmathbfx_k + fracbeta_ksqrtbaralpha_k-11 - baralpha_kmathbfx_0right) \n         = fracsqrtalpha_kbeta_kmathbfx_k + fracsqrtbaralpha_k-1(1 - baralpha_k-1)mathbfx_0\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thus, we write","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    pleft(mathbfx_kmathbfx_k-1 mathbfx_0right) propto expbigg( -frac12bigg( fracleft(mathbfx_k-1 - tildeboldsymbolmu_kright)^2tildebeta_k + tildegamma_k bigg)bigg)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"where","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        tildeboldsymbolmu_k  = tildeboldsymbolmu_k(mathbfx_k mathbfx_0) = frac(1 - baralpha_k-1)sqrtalpha_k1 - baralpha_kmathbfx_k + fracbeta_ksqrtbaralpha_k-11 - baralpha_kmathbfx_0 \n        tildebeta_k  = frac1 - baralpha_k-11 - baralpha_kbeta_k \n        tildegamma_k  = tildegamma_k(mathbfx_k mathbfx_0) = left( frac1beta_k - frac11 - baralpha_kright)mathbfx_k^2 + fracsqrtbaralpha_k1 - baralpha_kmathbfx_kmathbfx_0 \n         qquad qquad qquad qquad + left( fracbaralpha_k-11 - baralpha_k-1 - fracbaralpha_k1 - baralpha_k right)mathbfx_0^2 - fractildeboldsymbolmu_k^2tilde beta_k\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Hence, we find that","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    pleft(mathbfx_kmathbfx_k-1 mathbfx_0right) = mathcalNleft(mathbfx_k tildeboldsymbolmu_k tilde beta_kmathbfIright)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"With that, we can write","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    pleft(mathbfx_kmathbfx_k-1right) = int_mathbbR^d pleft(mathbfx_kmathbfx_k-1mathbfx_0right)p(mathbfx_0)mathrmdmathbfx_0","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Notice we can write the (initial) target distribution as","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p_0(mathbfx_0) = p(mathbfx_0) = int_(mathbfR^d)^K p(mathbfx_0K) mathrmdmathbfx_1K","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"and then","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p(mathbfx_0K) = int_mathbbR^d p(mathbfx_0Kmathbfx_0)mathrmdmathbfx_0","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"with","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p(mathbfx_0Kmathbfx_0) = p(mathbfx_0mathbfx_1 mathbfx_0)p(mathbfx_1mathbfx_2 mathbfx_0)cdots p(mathbfx_K-1mathbfx_K mathbfx_0)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"and","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p(mathbfx_k-1mathbfx_k mathbfx_0) = mathcalN(mathbfx_k-1 tildeboldsymbolmu_k(mathbfx_k mathbfx_0) tilde beta_kmathbfI)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Another way of writing this reverse process is through the recurrence relation","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbfX_k-1 = tildeboldsymbolmu_k(mathbfX_k mathbfX_0) + tildebeta_kmathbfZ_k quad mathbfZ_k sim mathcalN(mathbf0 mathbfI)","category":"page"},{"location":"generative/ddpm/#Reparametrization-trick","page":"Denoising diffusion probabilistic models","title":"Reparametrization trick","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"As mentioned earlier, conditioning p(mathbfx_k-1mathbfx_k mathbfx_0) on mathbfx_0 is good for training, but for not for sampling. Thus we reparametrize the relation and write tildeboldsymbolmu_k(mathbfX_k mathbfX_0) in terms of mathbfX_k and the added noise term. Then we model the added noise, as we will see.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"From the relation mathbfX_k = sqrtbaralpha_kmathbfX_0 + sqrt1 - baralpha_kbarmathbfZ_k where barmathbfZ_k sim mathcalN(mathbf0 mathbfI) we find that","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbfx_k = sqrtbaralpha_kmathbfx_0 + sqrt1 - baralpha_kbarboldsymbolepsilon_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"for a sample boldsymbolepsilon_k of the standard normal distribution. We use that to rewrite tildeboldsymbolmu_k in terms of mathbfx_0 and boldsymbolepsilon_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        tildeboldsymbolmu_k  = frac(1 - baralpha_k-1)sqrtalpha_k1 - baralpha_kmathbfx_k + fracbeta_ksqrtbaralpha_k-11 - baralpha_kmathbfx_0 \n         = frac(1 - baralpha_k-1)sqrtalpha_k1 - baralpha_kleft(sqrtbaralpha_kmathbfx_0 + sqrt1 - baralpha_kbarboldsymbolepsilon_kright) + fracbeta_ksqrtbaralpha_k-11 - baralpha_kmathbfx_0 \n         = frac(1 - baralpha_k-1)sqrtalpha_ksqrtbaralpha_k + beta_ksqrtbaralpha_k-11 - baralpha_kmathbfx_0 + frac(1 - baralpha_k-1)sqrtalpha_k1 - baralpha_ksqrt1 - baralpha_kbarboldsymbolepsilon_k \n         = frac((1 - baralpha_k-1)alpha_k + beta_k)sqrtbaralpha_k-11 - baralpha_kmathbfx_0 + frac(1 - baralpha_k-1)alpha_ksqrt1 - baralpha_ksqrtalpha_kbarboldsymbolepsilon_k \n         = frac(alpha_k - baralpha_k + beta_k)sqrtbaralpha_k-11 - baralpha_kmathbfx_0 + frac(1 - baralpha_k-1)alpha_ksqrt1 - baralpha_ksqrtalpha_kbarboldsymbolepsilon_k \n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Using that beta_k = 1 - alpha_k we find","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        tildeboldsymbolmu_k  = frac(1 - baralpha_k)sqrtbaralpha_k-11 - baralpha_kmathbfx_0 + fracalpha_k - baralpha_k(1 - baralpha_k)sqrtalpha_ksqrt1 - baralpha_kbarboldsymbolepsilon_k \n         = sqrtbaralpha_k-1mathbfx_0 + fracalpha_k - baralpha_k(1 - baralpha_k)sqrtalpha_ksqrt1 - baralpha_kbarboldsymbolepsilon_k \n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We can also rewrite mathbfx_0 in terms of mathbfx_k i.e.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbfx_0 = frac1sqrtbaralpha_kmathbfx_k - fracsqrt1 - baralpha_ksqrtbaralpha_kbarboldsymbolepsilon_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Plugging this into the formula for the mean tildeboldsymbolmu_k we obtain","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        tildeboldsymbolmu_k  = frac(1 - baralpha_k-1)sqrtalpha_k1 - baralpha_kmathbfx_k + fracbeta_ksqrtbaralpha_k-11 - baralpha_kleft(frac1sqrtbaralpha_kmathbfx_k - fracsqrt1 - baralpha_ksqrtbaralpha_kbarboldsymbolepsilon_kright) \n         = left(frac(1 - baralpha_k-1)sqrtalpha_k1 - baralpha_k + fracbeta_ksqrtbaralpha_k-1(1 - baralpha_k)sqrtbaralpha_kright)mathbfx_k - fracbeta_ksqrtbaralpha_k-11 - baralpha_kfracsqrt1 - baralpha_ksqrtbaralpha_kbarboldsymbolepsilon_k \n         = left(frac(1 - baralpha_k-1)sqrtalpha_k1 - baralpha_k + fracbeta_k(1 - baralpha_k)sqrtalpha_kright)mathbfx_k - fracbeta_ksqrt1 - baralpha_ksqrtalpha_kbarboldsymbolepsilon_k \n         = left(frac(1 - baralpha_k-1)alpha_k + beta_k(1 - baralpha_k)sqrtalpha_kright)mathbfx_k - fracbeta_ksqrt1 - baralpha_ksqrtalpha_kbarboldsymbolepsilon_k \n         = left(fracalpha_k - baralpha_k + beta_k(1 - baralpha_k)sqrtalpha_kright)mathbfx_k - fracbeta_ksqrt1 - baralpha_ksqrtalpha_kbarboldsymbolepsilon_k\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Using, again, that beta_k = 1 - alpha_k we find","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    tildeboldsymbolmu_k = frac1sqrtalpha_kmathbfx_k - frac1-alpha_ksqrt1 - baralpha_ksqrtalpha_kbarboldsymbolepsilon_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"In this way, we reparametrize the mean in terms of mathbfx_k and barboldsymbolepsilon_k instead of mathbfx_k and mathbfx_0 This is the form that serves as an inspiration to the model of the reverse process. With that, the reparametrization of mathbfx_k in terms of mathbfx_0 and barboldsymbolepsilon_k is then used for training, as we will see in what follows.","category":"page"},{"location":"generative/ddpm/#The-model","page":"Denoising diffusion probabilistic models","title":"The model","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We want to approximate the distribution of the Markov process with some model pdf p_boldsymboltheta(mathbfx_0K) which yields an approximation of the target pdf p_0(mathbfx_0) via","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p_boldsymboltheta(mathbfx_0) = int_(mathbfR^d)^K p_boldsymboltheta(mathbfx_0K) mathrmdmathbfx_1K","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"One of the key points in the forward Markov chain is  that the limit distribution of mathbfX_k as krightarrow infty is a standard normal distribution. Thus, for our model, we assume that the distribution at step K with K taken relatively large, is precisely a standard normal distribution. With that, the model is written as","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p_boldsymboltheta(mathbfx_0K) = int_mathbbR^d p_boldsymboltheta(mathbfx_0Kmathbfx_K)p_boldsymboltheta(mathbfx_K)mathrmdmathbfx_K","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"with","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p_boldsymboltheta(mathbfx_K) = mathcalN(mathbfx_K mathbf0 mathbfI)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We also have","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p_boldsymboltheta(mathbfx_0Kmathbfx_K) = p_boldsymboltheta(mathbfx_0mathbfx_1)p_boldsymboltheta(mathbfx_1mathbfx_2)cdots p_boldsymboltheta(mathbfx_K-1mathbfx_K)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"As in the reverse Markov process, we assume each p_boldsymboltheta(mathbfx_k-1mathbfx_k) is a Gaussian distribution. Hence, each conditional distribution is parametrized by its mean and its variance,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p_boldsymboltheta(mathbfx_k-1mathbfx_k) = mathcalN(mathbfx_k-1 boldsymbolmu_boldsymboltheta(mathbfx_k k) beta_boldsymboltheta(mathbfx_k k))","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015) modeled the mean and the covariance kernel of each reverse step and actually used a modified distribution multiplying it by a function r(mathbfx_k), but we do not consider this and go on model implemented in Ho, Jain, and Abbeel (2020).","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Indeed, due to the reparametrization trick used in the target Markov chain, we also reparametrize boldsymbolmu_boldsymboltheta(mathbfx_k k) in a similar way:","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    boldsymbolmu_boldsymboltheta(mathbfx_k k) = frac1sqrtalpha_kmathbfx_k - frac1-alpha_ksqrt1 - baralpha_ksqrtalpha_kboldsymbolepsilon_boldsymboltheta(mathbfx_k k)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Although beta_boldsymboltheta(mathbfx_k k) are also learnable, they are set to constants, for the sake of simplicity of the loss function:","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beta_boldsymboltheta(mathbfx_k k) = sigma_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"for pre-determined constants sigma_k k=1 ldots K Ho, Jain, and Abbeel (2020) experimented with some choices and found out that choosing sigma_k^2 = beta_k or sigma_k^2 = tildebeta_k yields about the same results. They correspond to opposite extremes, with sigma_k^2 = beta_k being optimal for mathbfX_0 sim mathcalN(mathbf0 mathbfI), while sigma_k^2 = tildebeta_k being optimal for a delta distribution mathbfX_0 = mathbfx_0, for a given deterministic mathbfx_0.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"In this way, the modeled reverse process, once boldsymbolepsilon_boldsymboltheta(mathbfx_k k) is properly trained, is given by","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbfX_k-1 = frac1sqrtalpha_kmathbfX_k - frac1-alpha_ksqrt1 - baralpha_ksqrtalpha_kboldsymbolepsilon_boldsymboltheta(mathbfX_k k) + sigma_k mathbfZ_k qquad mathbfZ_k sim mathcalN(mathbf0 mathbfI)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Actually, for the final step p_boldsymboltheta(mathbfx_0mathbfx_1) of the reverse process,  Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015) bases it on the first step of the forward trajectory, in order to \"remove the edge effect\" (see Appendix B.2):","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p_boldsymboltheta(mathbfx_0mathbfx_1) = p(mathbfx_1 mathbfx_0)fracmathcalN(mathbfx_0 mathbf0 mathbfI)mathcalN(mathbfx_1 mathbf0 mathbfI)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"In Ho, Jain, and Abbeel (2020), however, this is setup differently, being truncated to the support of the original distribution, which is assumed to represent an image, with data in 0 1 ldots 255 scaled to -1 1 i.e. each coordinate x_i i=1 ldots d in (a - 1275)  1275 a=0 ldots 255 so that","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p_boldsymboltheta(mathbfx_0mathbfx_1) = prod_i=1^d int_delta_-(x_0i)^delta_+(x_0i) mathcalN(x_i mu_boldsymboltheta i(mathbfx_1 1) sigma_1^2) mathbfx_i","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"with","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    delta_-(x_0i) = begincases\n        -infty  x = -1 \n        x - 1255  x  -11\n    endcases\n    qquad \n    delta_+(x_0i) = begincases\n        infty  x = 1 \n        x + 1255  x  1\n    endcases","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"In any case, our model is completely defined by boldsymbolepsilon_boldsymboltheta(mathbfx_k k) k=1 ldots K the parameters sigma_1 ldots sigma_K and the (final) conditional distribution p_boldsymboltheta(mathbfx_0mathbfx_1)","category":"page"},{"location":"generative/ddpm/#The-loss-function","page":"Denoising diffusion probabilistic models","title":"The loss function","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Now we need a loss function to train the parametrization boldsymbolepsilon_boldsymboltheta(mathbfx_k k) of our model.","category":"page"},{"location":"generative/ddpm/#The-cross-entropy-loss","page":"Denoising diffusion probabilistic models","title":"The cross-entropy loss","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Ideally, one would maximize the (log-)likelihood of the model, by minimizing the cross-entropy loss function","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    L_mathrmCE(boldsymboltheta) = H(p_0 p_boldsymboltheta) = mathbbE_p_0left-log p_boldsymboltheta(mathbfx_0)right = -int_mathbbR^d p_0(mathbfx_0)log p_boldsymboltheta(mathbfx_0)mathrmdmathbfx_0 approx -frac1Nsum_n=1^N log p_boldsymboltheta(mathbfx_0^n)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"But p_boldsymboltheta(mathbfx_0) given as","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p_boldsymboltheta(mathbfx_0) = int_(mathbfR^d)^K p_boldsymboltheta(mathbfx_0K) mathrmdmathbfx_1K","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"is intractable.","category":"page"},{"location":"generative/ddpm/#The-variational-lower-bound-loss","page":"Denoising diffusion probabilistic models","title":"The variational lower bound loss","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We substitute for p_boldsymboltheta(mathbfx_0) and multiply and divide by p(mathbfx_1Kmathbfx_0) to find ","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        L_mathrmCE(boldsymboltheta)  = mathbbE_p_0left-log p_boldsymboltheta(mathbfx_0)right \n         = -int_mathbbR^d p_0(mathbfx_0)log p_boldsymboltheta(mathbfx_0)mathrmdmathbfx_0 \n         = -int_mathbbR^d p_0(mathbfx_0)log left(int_(mathbfR^d)^K p_boldsymboltheta(mathbfx_0K) mathrmdmathbfx_1Kright)mathrmdmathbfx_0 \n         = -int_mathbbR^d p_0(mathbfx_0)log left(int_(mathbfR^d)^K p(mathbfx_1Kmathbfx_0) fracp_boldsymboltheta(mathbfx_0K)p(mathbfx_1Kmathbfx_0) mathrmdmathbfx_1Kright)mathrmdmathbfx_0\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Now we use Jensen's inequality to obtain the following upper bound for the cross-entropy loss,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        L_mathrmCE(boldsymboltheta)  leq -int_mathbbR^d p_0(mathbfx_0)int_(mathbfR^d)^K p(mathbfx_1Kmathbfx_0) log left(fracp_boldsymboltheta(mathbfx_0K)p(mathbfx_1Kmathbfx_0) right)mathrmdmathbfx_1Kmathrmdmathbfx_0 \n         = -int_(mathbfR^d)^K+1 p(mathbfx_0K) log left(fracp_boldsymboltheta(mathbfx_0K)p(mathbfx_1Kmathbfx_0) right)mathrmdmathbfx_0K \n         = int_(mathbfR^d)^K+1 p(mathbfx_0K) log left(fracp(mathbfx_1Kmathbfx_0)p_boldsymboltheta(mathbfx_0K) right)mathrmdmathbfx_0K\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"This expression defines what is called the variational lower bound loss","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    L_mathrmVLB(boldsymboltheta) = mathbbE_p(mathbfx_0K)left log fracp(mathbfx_1Kmathbfx_0)p_boldsymboltheta(mathbfx_0K) right = int_(mathbfR^d)^K+1 p(mathbfx_0K) log left(fracp(mathbfx_1Kmathbfx_0)p_boldsymboltheta(mathbfx_0K) right)mathrmdmathbfx_0K","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015) manipulated this loss to a more tractable form as follows","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        L_mathrmVLB(boldsymboltheta)  = mathbbE_p(mathbfx_0K)left log fracp(mathbfx_1Kmathbfx_0)p_boldsymboltheta(mathbfx_0K) right \n         = mathbbE_p(mathbfx_0K)left log fracprod_k=1^K p(mathbfx_kmathbfx_k-1)p_boldsymboltheta(mathbfx_K)prod_k=1^K p_boldsymboltheta(mathbfx_k-1mathbfx_k) right \n         = mathbbE_p(mathbfx_0K)left -log p_boldsymboltheta(mathbfx_K) + log prod_k=1^K fracp(mathbfx_kmathbfx_k-1)p_boldsymboltheta(mathbfx_k-1mathbfx_k) right \n         = mathbbE_p(mathbfx_0K)left -log p_boldsymboltheta(mathbfx_K) + sum_k=1^K log fracp(mathbfx_kmathbfx_k-1)p_boldsymboltheta(mathbfx_k-1mathbfx_k) right \n         = mathbbE_p(mathbfx_0K)left -log p_boldsymboltheta(mathbfx_K) + log fracp(mathbfx_1mathbfx_0)p_boldsymboltheta(mathbfx_0mathbfx_1) + sum_k=2^K log fracp(mathbfx_kmathbfx_k-1)p_boldsymboltheta(mathbfx_k-1mathbfx_k) right\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"From Bayes' rule and the Markovian property of X_k_k (as we derived earlier for pleft(mathbfx_k-1mathbfx_k mathbfx_0right)), we have","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    pleft(mathbfx_k-1mathbfx_k mathbfx_0right) = fracpleft(mathbfx_kmathbfx_k-1 mathbfx_0right)pleft(mathbfx_k-1mathbfx_0right)pleft(mathbfx_kmathbfx_0right) = fracpleft(mathbfx_kmathbfx_k-1right)pleft(mathbfx_k-1mathbfx_0right)pleft(mathbfx_kmathbfx_0right)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"which we can write as","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p(mathbfx_kmathbfx_k-1) = fracp(mathbfx_k-1mathbfx_k mathbfx_0)p(mathbfx_kmathbfx_0)p(mathbfx_k-1mathbfx_0)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Hence,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        L_mathrmVLB(boldsymboltheta)  = mathbbE_p(mathbfx_0K)left -log p_boldsymboltheta(mathbfx_K) + log fracp(mathbfx_1mathbfx_0)p_boldsymboltheta(mathbfx_0mathbfx_1) + sum_k=2^K log fracp(mathbfx_kmathbfx_k-1)p_boldsymboltheta(mathbfx_k-1mathbfx_k) right \n         = mathbbE_p(mathbfx_0K)left -log p_boldsymboltheta(mathbfx_K) + log fracp(mathbfx_1mathbfx_0)p_boldsymboltheta(mathbfx_0mathbfx_1) + sum_k=2^K log fracp(mathbfx_k-1mathbfx_k mathbfx_0)p_boldsymboltheta(mathbfx_k-1mathbfx_k) fracp(mathbfx_kmathbfx_0)p(mathbfx_k-1mathbfx_0) right \n         = mathbbE_p(mathbfx_0K)left -log p_boldsymboltheta(mathbfx_K) + log fracp(mathbfx_1mathbfx_0)p_boldsymboltheta(mathbfx_0mathbfx_1) + sum_k=2^K log fracp(mathbfx_k-1mathbfx_k mathbfx_0)p_boldsymboltheta(mathbfx_k-1mathbfx_k) + sum_k=2^K log fracp(mathbfx_kmathbfx_0)p(mathbfx_k-1mathbfx_0) right \n         = mathbbE_p(mathbfx_0K)left -log p_boldsymboltheta(mathbfx_K) + log fracp(mathbfx_1mathbfx_0)p_boldsymboltheta(mathbfx_0mathbfx_1) + sum_k=2^K log fracp(mathbfx_k-1mathbfx_k mathbfx_0)p_boldsymboltheta(mathbfx_k-1mathbfx_k) + log prod_k=2^K  fracp(mathbfx_kmathbfx_0)p(mathbfx_k-1mathbfx_0) right \n         = mathbbE_p(mathbfx_0K)left -log p_boldsymboltheta(mathbfx_K) + log fracp(mathbfx_1mathbfx_0)p_boldsymboltheta(mathbfx_0mathbfx_1) + sum_k=2^K log fracp(mathbfx_k-1mathbfx_k mathbfx_0)p_boldsymboltheta(mathbfx_k-1mathbfx_k) + log fracp(mathbfx_Kmathbfx_0)p(mathbfx_1mathbfx_0) right\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The first, second and fourth terms combine to yield","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        -log p_boldsymboltheta(mathbfx_K) + log fracp(mathbfx_1mathbfx_0)p_boldsymboltheta(mathbfx_0mathbfx_1) + log fracp(mathbfx_Kmathbfx_0)p(mathbfx_1mathbfx_0)  = -log p_boldsymboltheta(mathbfx_K) + log fracp(mathbfx_Kmathbfx_0)p_boldsymboltheta(mathbfx_0mathbfx_1) \n         = log fracp(mathbfx_Kmathbfx_0)p_boldsymboltheta(mathbfx_K) - log p_boldsymboltheta(mathbfx_0mathbfx_1)\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thus,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        L_mathrmVLB(boldsymboltheta)  = mathbbE_p(mathbfx_0K)left - log p_boldsymboltheta(mathbfx_0mathbfx_1) + sum_k=2^K log fracp(mathbfx_k-1mathbfx_k mathbfx_0)p_boldsymboltheta(mathbfx_k-1mathbfx_k) + log fracp(mathbfx_Kmathbfx_0)p_boldsymboltheta(mathbfx_K) right\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"This can be written as","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    L_mathrmVLB(boldsymboltheta) = L_mathrmVLB 0(boldsymboltheta) + L_mathrmVLB 1(boldsymboltheta) + cdots + L_mathrmVLB K(boldsymboltheta)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"where","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        L_mathrmVLB 0(boldsymboltheta)  = mathbbE_p(mathbfx_0K)left - log p_boldsymboltheta(mathbfx_0mathbfx_1) right \n        L_mathrmVLB k-1(boldsymboltheta)  = mathbbE_p(mathbfx_0K)left log fracp(mathbfx_k-1mathbfx_k mathbfx_0)p_boldsymboltheta(mathbfx_k-1mathbfx_k) right quad k = 2 ldots K \n        L_mathrmVLB K(boldsymboltheta)  = mathbbE_p(mathbfx_0K)left log fracp(mathbfx_Kmathbfx_0)p_boldsymboltheta(mathbfx_K) right\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Notice the terms with k0 involve Kullback-Leibler divergences.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"In the model, the last marginal is taken to be a standard normal distribution, and hence this term is constant and has no parameter to learn:","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    L_mathrmVLB K(boldsymboltheta) = L_mathrmVLB K = mathbbE_p(mathbfx_0K)left log fracp(mathbfx_Kmathbfx_0)mathcalN(mathbfx_K mathbf0 mathbfI) right","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thus, the variational lower bound becomes","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    L_mathrmVLB(boldsymboltheta) = L_mathrmVLB 0(boldsymboltheta) + L_mathrmVLB 1(boldsymboltheta) + cdots + L_mathrmVLB K","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015) went on to model the mean and the covariance kernel of each reverse step and modifying the distributions by a function r(mathbfx_k), but we do not consider this here and go on with the simplifications and improvements carried on by Ho, Jain, and Abbeel (2020).","category":"page"},{"location":"generative/ddpm/#Simplifications","page":"Denoising diffusion probabilistic models","title":"Simplifications","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Since the last term in L_mathrmVLB(boldsymboltheta) is constant, we only need to minimize ","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    L_mathrmVLB^*(boldsymboltheta) = L_mathrmVLB 0(boldsymboltheta) + L_mathrmVLB 1(boldsymboltheta) + cdots + L_mathrmVLB K-1(boldsymboltheta)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"For L_mathrmVLB k-1(boldsymboltheta) with k=2 ldots K we use that","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    pleft(mathbfx_k-1mathbfx_k mathbfx_0right) = mathcalNleft(mathbfx_k-1 tildeboldsymbolmu_k tilde beta_kmathbfIright)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"where","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        tildeboldsymbolmu_k  = tildeboldsymbolmu_k(mathbfx_k mathbfx_0) = frac(1 - baralpha_k-1)sqrtalpha_k1 - baralpha_kmathbfx_k + fracbeta_ksqrtbaralpha_k-11 - baralpha_kmathbfx_0 \n        tildebeta_k  = frac1 - baralpha_k-11 - baralpha_kbeta_k\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We have also modeled p_boldsymboltheta(mathbfx_k-1mathbfx_k) with","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p_boldsymboltheta(mathbfx_k-1mathbfx_k) = mathcalN(boldsymbolmu_boldsymboltheta(mathbfx_k k) sigma_kmathbfI)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Moreover,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        L_mathrmVLB k-1(boldsymboltheta)  = mathbbE_p(mathbfx_0K)left log fracp(mathbfx_k-1mathbfx_k mathbfx_0)p_boldsymboltheta(mathbfx_k-1mathbfx_k) right \n         = mathbbE_p(mathbfx_0 mathbfx_k)p(mathbfx_k-1mathbfx_0 mathbfx_k)left log fracp(mathbfx_k-1mathbfx_k mathbfx_0)p_boldsymboltheta(mathbfx_k-1mathbfx_k) right \n         = mathbbE_p(mathbfx_0 mathbfx_k)leftmathbbE_p(mathbfx_k-1mathbfx_0 mathbfx_k)left log fracp(mathbfx_k-1mathbfx_k mathbfx_0)p_boldsymboltheta(mathbfx_k-1mathbfx_k) rightright \n         = mathbbE_p(mathbfx_0 mathbfx_k) leftD_mathrmKLleft(p(mathbfx_k-1mathbfx_k mathbfx_0)  p_boldsymboltheta(mathbfx_k-1mathbfx_k)right)right\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The Kullback-Leibler divergence between two multivariate normals can be computed explicitly. In general, we have","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    D_mathrmKL(mathcalN(boldsymbolmu_1 boldsymbolSigma_1)  mathcalN(boldsymbolmu_2 boldsymbolSigma_2)) = frac12left( (boldsymbolmu_2 - boldsymbolmu_1) cdot boldsymbolSigma_2^-1(boldsymbolmu_2 - boldsymbolmu_1)  + operatornametr(boldsymbolSigma_2^-1boldsymbolSigma_1) - log fracdetboldsymbolSigma_1detboldsymbolSigma_2 - dright)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thus,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        L_mathrmVLB k-1(boldsymboltheta)  = frac12mathbbE_p(mathbfx_0 mathbfx_k) leftfractildeboldsymbolmu_k(mathbfx_k mathbfx_0) - boldsymbolmu_boldsymboltheta(mathbfx_k k) ^2sigma_k^2 + fractilde beta_ksigma_k^2 - logfractildebeta_k^dsigma_k^2d - dright \n         = frac12mathbbE_p(mathbfx_0 mathbfx_k) leftfractildeboldsymbolmu_k(mathbfx_k mathbfx_0) - boldsymbolmu_boldsymboltheta(mathbfx_k k) ^2sigma_k^2right + C_k\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"for a constant C_k (with respect to the trainable parameters boldsymboltheta), where","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        boldsymbolmu_boldsymboltheta(mathbfx_k k)  = frac1sqrtalpha_kmathbfx_k - frac1-alpha_ksqrt1 - baralpha_ksqrtalpha_kboldsymbolepsilon_boldsymboltheta(mathbfx_k k) \n        tildeboldsymbolmu_k(mathbfx_k mathbfx_0)  = frac(1 - baralpha_k-1)sqrtalpha_k1 - baralpha_kmathbfx_k + fracbeta_ksqrtbaralpha_k-11 - baralpha_kmathbfx_0\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thanks to the reparametrization,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    tildeboldsymbolmu_k = frac1sqrtalpha_kmathbfx_k - frac1-alpha_ksqrt1 - baralpha_ksqrtalpha_kbarboldsymbolepsilon_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thus,","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        tildeboldsymbolmu_k(mathbfx_k mathbfx_0) - boldsymbolmu_boldsymboltheta(mathbfx_k k)  = frac1sqrtalpha_kmathbfx_k - frac1-alpha_ksqrt1 - baralpha_ksqrtalpha_kbarboldsymbolepsilon_k - frac1sqrtalpha_kmathbfx_k + frac1-alpha_ksqrt1 - baralpha_ksqrtalpha_kboldsymbolepsilon_boldsymboltheta(mathbfx_k k) \n         = frac1-alpha_ksqrt1 - baralpha_ksqrtalpha_kleft(barboldsymbolepsilon_k - boldsymbolepsilon_boldsymboltheta(mathbfx_k k)right)\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Now we reparametrize the loss in terms of mathbfx_0 and barboldsymbolepsilon_k sim mathcalN(mathbf0 mathbfI) by writing mathbfx_k as","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbfx_k = sqrtbaralpha_kmathbfx_0 + sqrt1 - baralpha_kbarboldsymbolepsilon_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"With this reparametrization, the expectation also becomes in terms of mathbfx_0 and barboldsymbolepsilon_k so the loss becomes","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    L_mathrmVLB^*(boldsymboltheta) = L_mathrmVLB 0(boldsymboltheta) + L_mathrmVLB 1(boldsymboltheta) + cdots + L_mathrmVLB K-1(boldsymboltheta)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"with","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    L_mathrmVLB k-1(boldsymboltheta) = frac12sigma_k^2frac1-alpha_ksqrt1 - baralpha_ksqrtalpha_kmathbbE_p_0(mathbfx_0)mathcalN(barboldsymbolepsilon_k mathbf0 mathbfI) leftleftbarboldsymbolepsilon_k - boldsymbolepsilon_boldsymbolthetaleft(sqrtbaralpha_kmathbfx_0 + sqrt1 - baralpha_kbarboldsymbolepsilon_k kright) right^2right","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"for k=1 ldots K","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"At this point, a stochastic gradient descent approach is taken, and instead of descending along the gradient of the full sum of all L_mathrmVLB k-1(boldsymboltheta) and taking the expectation with respect to barboldsymbolepsilon_k only a single time step k and a single noise term barboldsymbolepsilon_k is taken at random for each sample point mathbfx_0^n n=1 ldots N so that the loss function taken in practice is","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    tilde L_mathrmVLB^*(boldsymboltheta) = frac1N sum_n=1^N frac12sigma_k_n^2frac1-alpha_k_nsqrt1 - baralpha_k_nsqrtalpha_k_n leftbarboldsymbolepsilon_k_n n - boldsymbolepsilon_boldsymbolthetaleft(sqrtbaralpha_k_nmathbfx_0^n + sqrt1 - baralpha_k_nbarboldsymbolepsilon_k_n n k_nright) right^2","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"where the k_n and the barboldsymbolepsilon_k_n n are chosen independently, at each epoch, according to","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"     k_n sim operatornameUniform(1 ldots K)  barboldsymbolepsilon_k_n n sim mathcalN(mathbf0 mathbfI)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"A further simplification proposed by Ho, Jain, and Abbeel (2020), which was found to perform better in practice, is to simply drop the weighting term and minimize","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    tilde L_mathrmVLB^mathrmsimple(boldsymboltheta) = frac1N sum_n=1^N leftbarboldsymbolepsilon_k_n n - boldsymbolepsilon_boldsymbolthetaleft(sqrtbaralpha_k_nmathbfx_0^n + sqrt1 - baralpha_k_nbarboldsymbolepsilon_k_n n k_nright) right^2","category":"page"},{"location":"generative/ddpm/#Connection-with-score-matching","page":"Denoising diffusion probabilistic models","title":"Connection with score matching","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Going back to","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbfx_k = sqrtbaralpha_kmathbfx_0 + sqrt1 - baralpha_kbarboldsymbolepsilon_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"we have ","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    beginalign*\n        barboldsymbolepsilon_k - boldsymbolepsilon_boldsymbolthetaleft(sqrtbaralpha_kmathbfx_0 + sqrt1 - baralpha_kbarboldsymbolepsilon_k kright)  = fracmathbfx_k - sqrtbaralpha_kmathbfx_0sqrt1 - baralpha_k - boldsymbolepsilon_boldsymbolthetaleft(mathbfx_k kright) \n         = sqrt1 - baralpha_k left(fracmathbfx_k - sqrtbaralpha_kmathbfx_01 - baralpha_k - fracboldsymbolepsilon_boldsymbolthetaleft(mathbfx_k kright)sqrt1 - baralpha_kright)\n    endalign*","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The first term in the parenthesis can be seen as the score function of the conditional distribution of mathbfX_k given mathbfX_0 = mathbfx_0, with density","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    p(mathbfx_kmathbfx_0) = mathcalN(mathbfx_k sqrtbaralpha_kmathbfx_0 1 - baralpha_k) = frac1(2pi (1 - baralpha_k))^d2 e^-frac12frac(mathbfx_k - sqrtbaralpha_kmathbfx_0)^21 - baralpha_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The score function of this distribution reads","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    boldsymbolnabla_mathbfx_klog p(mathbfx_kmathbfx_0) =  - fracmathbfx_k - sqrtbaralpha_kmathbfx_01 - baralpha_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Introducing","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    tildeboldsymbolepsilon_boldsymbolthetaleft(mathbfx_k kright) = -fracboldsymbolepsilon_boldsymbolthetaleft(mathbfx_k kright)sqrt1 - baralpha_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"we rewrite the loss term L_mathrmVLB k-1(boldsymboltheta) as","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    L_mathrmVLB k-1(boldsymboltheta) = frac12sigma_k^2frac(1-alpha_k)sqrt1 - baralpha_ksqrtalpha_kmathbbE_p_0(mathbfx_0)p(mathbfx_kmathbfx_0) leftleftboldsymbolnabla_mathbfx_klog p(mathbfx_kmathbfx_0) -  tildeboldsymbolepsilon_boldsymbolthetaleft(mathbfx_k kright)right^2right","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"for k=1 ldots K. ","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thus, boldsymbolepsilon_boldsymbolthetaleft(mathbfx_k kright) is actually learning a scaled version of the score function of the diffusion conditioned at each sample point. Notice the relation with denoising score matching.","category":"page"},{"location":"generative/ddpm/#More-improvements","page":"Denoising diffusion probabilistic models","title":"More improvements","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Nichol and Dhariwal (2021) modified a little more the simplifications in Ho, Jain, and Abbeel (2020) and improved even more some of the benchmark results for DDPM.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"While Ho, Jain, and Abbeel (2020) pre-determined the variance sigma_k^2 of the reverse model to either one of the extreme values beta_k and tildebeta_k, Nichol and Dhariwal (2021) found best to learn this variance, but in a very specific form, namely, as a combination","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    log sigma_k^2 = v logbeta_k + (1 - v)logtildebeta_k","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Another improvement was to use a nonlinear cosine variance schedule beta_k changing very little near the extremes k=1 and k=K and with a linear dropoff of tildealpha_k in the middle.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The motivation was that while DDPM had showed very good results with CIFAR-10 and LSUN datasets, it did not achieve log-likelihood competitiveness with other likelihood based models. This casted doubts whether DDPM would capture all the modes of a distribution and perform well on a more diverse datasets.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"With the improvements above, Nichol and Dhariwal (2021), showed that log-likelihood competitiveness could indeed be achieved with DDPM.","category":"page"},{"location":"generative/ddpm/#Numerical-example","page":"Denoising diffusion probabilistic models","title":"Numerical example","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We illustrate the method numerically, modeling a synthetic univariate Gaussian mixture distribution.","category":"page"},{"location":"generative/ddpm/#Julia-language-setup","page":"Denoising diffusion probabilistic models","title":"Julia language setup","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"As usual, we use the Julia programming language for the numerical simulations, with suitable packages and set the seed for reproducibility purposes.","category":"page"},{"location":"generative/ddpm/#Data","page":"Denoising diffusion probabilistic models","title":"Data","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We build the target model, draw samples from it, and prepare all the parameters for training and sampling.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"target_prob = MixtureModel([Normal(-3, 1), Normal(3, 1)], [0.1, 0.9])\n\nxrange = range(-10, 10, 200)\ndx = Float64(xrange.step)\nxx = permutedims(collect(xrange))\ntarget_pdf = pdf.(target_prob, xrange')\n\nsample_points = permutedims(rand(rng, target_prob, 1024))\nnothing # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"beta_init = 0.02\nbeta_final = 0.8\nbeta_len = 80\nbeta_schedule = range(beta_init, beta_final, beta_len)\nalpha_schedule = 1 .- beta_schedule\nalpha_tilde = cumprod(alpha_schedule)\nbeta_tilde = ( 1 .- [0; alpha_tilde[begin:end-1]]) ./ ( 1 .- alpha_tilde ) .* beta_schedule\ncoeffs_train = (\n    krange = 1:beta_len,\n    sqrtalphatilde = map(√, alpha_tilde),\n    sqrtoneminusalphatilde = map(x -> √(1 - x), alpha_tilde)\n)\ncoeffs_sample = (\n    sqrtalpha = map(√, alpha_schedule),\n    alpharatio = (1 .- alpha_schedule) ./ map(x -> √(1 - x), alpha_tilde),\n    sigmaschedule = copy(beta_schedule)\n)\ndata = (rng, sample_points, coeffs_train)\nnothing # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plt # hide","category":"page"},{"location":"generative/ddpm/#Markov-chain","page":"Denoising diffusion probabilistic models","title":"Markov chain","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Now we evolve the sample as the initial state of a Markov chain mathbfX_k_k=1 ldots K with","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbfX_k = sqrt1 - beta_k mathbfX_k-1 + beta_k mathbfZ_k quad mathbfZ_k sim mathcalN(mathbf0 mathbfI)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Markdown.parse(\"\"\"where \\$\\\\{\\\\beta_k\\\\}_{k=1}^{K}\\$ is a given schedule.We choose the schedule to be a linear schedule from ``\\\\beta_1 = $beta_init`` to ``\\\\beta_K = $beta_final`` in ``K = $beta_len`` steps.\"\"\") # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plot(xt, label=nothing, title=\"Sample paths of the Markov diffusion\", titlefont=10, color=1, alpha=0.2) # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The final histogram and the asymptotic standard normal distribution.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plt # hide","category":"page"},{"location":"generative/ddpm/#The-neural-network-model","page":"Denoising diffusion probabilistic models","title":"The neural network model","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"There are two natural ways to model boldsymbolepsilon_boldsymboltheta(mathbfx_k k), where mathbfx_kin mathbbR and kin 1 2 ldots K One is to embed it into a two-dimensional function","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbbR^2 ni (mathbfx_k k) mapsto boldsymbolepsilon_boldsymboltheta(mathbfx_k k) in mathbbR","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"and the other is as a vector-valued function","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"    mathbbR ni mathbfx_k mapsto left(boldsymbolepsilon_boldsymboltheta(mathbfx_k k)right)_k=1^K in mathbbR^K","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"The first one is in a framework compatible with the limit case of a stochastic differential equations, where k becomes a time variable tin 0 T, T  0. The second one is compatible with the fact that we do have a finite number K of steps and this also gives a more flexible network. In practice, though, the second case, even increasing the width and depth of the neural network, did not improve the results. So we decide to present here only the first option.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Thus, the neural network we consider is a two-dimensional feed-forward neural network with scalar values. Since we model the steps of the whole Markov chain, not only, a single random variable, we need to bump it up a little bit.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"model = Chain(Dense(2 => 64, relu), Dense(64 => 1))","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We initialize the parameters and the state of the model.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model","category":"page"},{"location":"generative/ddpm/#Loss-function","page":"Denoising diffusion probabilistic models","title":"Loss function","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Here it is how we implement the objective tilde L_mathrmVLB^mathrmsimple(boldsymboltheta)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"function loss_function_uniform_simple(model, ps, st, data)\n    rng, sample_points, coeffs_train = data\n    epsilons = randn(rng, size(sample_points))\n    ks = rand(rng, coeffs_train.krange, size(sample_points))\n    model_input = [coeffs_train.sqrtalphatilde[ks] .* sample_points .+ coeffs_train.sqrtoneminusalphatilde[ks] .* epsilons; ks]\n    epsilons_pred, st = Lux.apply(model, model_input, ps, st)\n    loss = mean(abs2, epsilons_pred .- epsilons)\n    return loss, st, ()\nend\nnothing # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"This is how the points used for training look like at a given epoch:","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"scatter(ks, xts, color=1, alpha=0.4, legend=false, title=\"points used for training\", titlefont=10) # hide","category":"page"},{"location":"generative/ddpm/#Optimization-setup","page":"Denoising diffusion probabilistic models","title":"Optimization setup","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We do the usual setup.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"opt = Adam(0.001)\n\ntstate_org = Lux.Training.TrainState(model, ps, st, opt)","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"vjp_rule = Lux.Training.AutoZygote()","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"dev_cpu = cpu_device()\n## dev_gpu = gpu_device()","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Lux.Training.compute_gradients(vjp_rule, loss_function_uniform_simple, data, tstate_org)","category":"page"},{"location":"generative/ddpm/#Training","page":"Denoising diffusion probabilistic models","title":"Training","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Now we train the model. Since this is stochastic and it is a Markov chain, it takes some more epochs than the previous ones.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_uniform_simple, 1000, 20, 25)\nnothing # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false) # hide","category":"page"},{"location":"generative/ddpm/#Results","page":"Denoising diffusion probabilistic models","title":"Results","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"For checking the results, we first need to implement the sampling backward chain.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"function ddpm_backward_chain!(rng, xbwt, xbwK, coeffs_sample, tstate, aux = xbwt[1:2, :])\n    @assert axes(xbwt, 1) == only(axes(alpha_schedule))\n    i1 = lastindex(axes(xbwt, 1))\n    randn!(rng, xbwt)\n    xbwt[i1, :] .= xbwK\n    for i in Iterators.drop(Iterators.reverse(axes(xbwt, 1)), 1)\n        aux[1, :] .= view(xbwt, i1, :)\n        aux[2, :] .= i1\n        xbwt[i:i, :] .= ( view(xbwt, i1:i1, :) .- coeffs_sample.alpharatio[i1] .* first(tstate.model(aux, tstate.parameters, tstate.states)) ) ./ coeffs_sample.sqrtalpha[i1] .+ coeffs_sample.sigmaschedule[i1] .* view(xbwt, i:i, :)\n        i1 = i\n    end\n    return xbwt\nend\n\nfunction ddpm_backward_chain(rng, xbwK, coeffs_sample, tstate)\n    xbwt = alpha_schedule .* xbwK'\n    ddpm_backward_chain!(rng, xbwt, xbwK, coeffs_sample, tstate)\n    return xbwt\nend\nnothing # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"With that implemented, we can generate some samples.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"xbwK = randn(rng, size(x0))\nxbwt = ddpm_backward_chain(rng, xbwK, coeffs_sample, tstate)\nnothing # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"Here is the resulting backward trajectories.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plot(xbwt, label=nothing, title=\"Sample paths of the reverse sampling process\", titlefont=10, color=1, alpha=0.2) # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"We then visualize the histogram of the generated samples and compare it with the pdf of the synthetic target distribution.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plt # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"As one can see, it did not generate spurious samples, but it was concentrated near the highest modal of the target distribution. Different linear variance schedules, more training, and different network architectures resulted in somewhat the same pattern. Maybe a nonlinear schedule improves the result? Let's try.","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plt # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plot(xt, label=nothing, title=\"Sample paths of the Markov diffusion\", titlefont=10, color=1, alpha=0.2) # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plt # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_uniform_simple, 5000, 20, 25)\nnothing # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false) # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"xbwK = randn(rng, size(x0))\nxbwt = ddpm_backward_chain(rng, xbwK, coeffs_sample, tstate)\nnothing # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plot(xbwt, label=nothing, title=\"Sample paths of the reverse sampling process\", titlefont=10, color=1, alpha=0.2) # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"plt # hide","category":"page"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"I guess not even that... We need to try harder.","category":"page"},{"location":"generative/ddpm/#References","page":"Denoising diffusion probabilistic models","title":"References","text":"","category":"section"},{"location":"generative/ddpm/","page":"Denoising diffusion probabilistic models","title":"Denoising diffusion probabilistic models","text":"J. Sohl-Dickstein, E. A. Weiss, N. Maheswaranathan, S. Ganguli (2015), \"Deep unsupervised learning using nonequilibrium thermodynamics\", ICML'15: Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, 2256-2265\nJ. Ho, A. Jain, P. Abbeel (2020), \"Denoising diffusion probabilistic models\", in Advances in Neural Information Processing Systems 33, NeurIPS2020\nL. Weng (2021), \"What are diffusion models?\" Lil’Log. lilianweng.github.io/posts/2021-07-11-diffusion-models/\nA. Q. Nichol and P. Dhariwal (2021), \"Improved denoising diffusion probabilistic models\", ICLR 2021 Conference\nJ. Song, C. Meng, S. Ermon (2021), \"Denoising diffusion implicit models\", ICLR 2021 Conference","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Score-matching-with-Parzen-estimation","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/#Introduction","page":"Score matching with Parzen estimation","title":"Introduction","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/#Aim","page":"Score matching with Parzen estimation","title":"Aim","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Explore the use of Parzen kernel estimation to approximate the explicit score matching, used as the basis for the implicit score matching objective proposed by Aapo Hyvärinen (2005) and discussed en passant by Pascal Vincent (2011) on their way to the denoising score matching objective. We illustrate the method by fiting a multi-layer perceptron to model the score function of a one-dimensional synthetic Gaussian-mixture distribution.","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Motivation","page":"Score matching with Parzen estimation","title":"Motivation","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"The motivation is to continue building a solid background on score-matching diffusion.","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Background","page":"Score matching with Parzen estimation","title":"Background","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Aapo Hyvärinen (2005) proposed fitting directly the score of a distribution. This is obtained, in theory, by minimizing an explicit score matching objective function (i.e. the Fisher divergence). However, this function requires knowing the supposedly unknown target score function. The trick used by Aapo Hyvärinen (2005) was then to do an integration by parts and rewrite the optimization problem in terms of an implicit score matching objective function, which yields the same minima and does not require further information from the target distribution other than some sample points. The implicit score matching method requires, however, the derivative of the  score function of the model, which is costly to compute in general.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Then, Pascal Vincent (2011) explored the idea of using non-parametric Parzen density estimation to directly approximate the explicit score matching objective, making a connection with denoising autoenconders, and proposing the denoising (explicit) score matching method.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"We will detail denoising score matching in a separate note. Here, we stop at the Parzen density estimation idea, which was used in Pascal Vincent (2011) only as a step towards the denoising score matching. We call this method the Parzen estimated (explicit) score matching method. We also model directly the score of the distribution, as proposed in 1. Song and Ermon (2019), instead of the pdf or an energy potential of the pdf, as done earlier.","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Objective-function-approximating-the-explicit-score-matching-objective","page":"Score matching with Parzen estimation","title":"Objective function approximating the explicit score matching objective","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"The score-matching method from Aapo Hyvärinen (2005) aims to fit the model score function psi(mathbfx boldsymboltheta) to the score function psi_X(mathbfx) of a random variable mathbfX by minimizing the  implicit score matching objective","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    J_mathrmISM(boldsymboltheta) = int_mathbbR^d p_mathbfX(mathbfx) left( frac12leftboldsymbolpsi(mathbfx boldsymboltheta)right^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx boldsymboltheta) right)mathrmdmathbfx","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"which is equivalent to minimizing the explicit score matching objective","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    J_mathrmESM(boldsymboltheta) = frac12int_mathbbR^d p_mathbfX(mathbfx) leftboldsymbolpsi(mathbfx boldsymboltheta) - boldsymbolpsi_mathbfX(mathbfx)right^2mathrmdmathbfx","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"due to the following identity obtained via integration by parts in the expectation","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    J_mathrmESM(boldsymboltheta) = tilde J_mathrmISM(boldsymboltheta) + C","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"where C is constant with respect to the parameters. The advantage of tilde J_mathrmISM(boldsymboltheta) is that it does not involve the unknown score function of X. It does, however, involve the gradient of the modeled score function, which is expensive to compute.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"In practice, this is further approximated by the empirical distribution tilde p_0(mathbfx) given by","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    tilde p_0(mathbfx) = frac1Nsum_n=1^N delta(mathbfx - mathbfx_n)","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"so the implemented objective is the empirical implicit score matching objective","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    tilde J_mathrmISMtilde p_0(boldsymboltheta) = frac1Nsum_n=1^N left( frac12leftboldsymbolpsi(mathbfx_n boldsymboltheta)right^2 + boldsymbolnabla_mathbfx cdot boldsymbolpsi(mathbfx_n boldsymboltheta) right)","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Aapo Hyvärinen (2005) briefly mentions that minimizing J_mathrmESM(boldsymboltheta) directly is \"basically a non-parametric estimation problem\", but dismisses it for the \"simple trick of partial integration to compute the objective function very easily\". As we have seen, the trick is fine for model functions for which we can compute the gradient without much trouble, but for modeling it with a neural network, for instance, it becomes computationally expensive.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"A few years later, Pascal Vincent (2011) considered the idea of using a Parzel kernel density estimation","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    tilde p_sigma(mathbfx) = frac1sigma^dint_mathbbR^d Kleft(fracmathbfx - mathbfx_nsigmaright) mathrmdtilde p_0(mathbfx) = frac1sigma^d Nsum_n=1^N Kleft(fracmathbfx - mathbfx_nsigmaright)","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"where sigma  0 is a kernel window parameter and K(mathbfx) is a kernel density (properly normalized to have mass one). In this way, the explicit score matching objective function is approximated by the Parzen-estimated explicit score matching objective","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    tilde J_mathrmP_sigma ESM(boldsymboltheta) = frac12int_mathbbR^d tilde p_sigma(mathbfx) leftboldsymbolpsi(mathbfx boldsymboltheta) - boldsymbolnabla_mathbfxlog tilde p_sigma(mathbfx)right^2mathrmdmathbfx","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"which is then further approximated with the empirical distribution, yielding the empirical Parzen-estimated explicit score matching","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    beginalign*\n        tilde J_mathrmP_sigma ESMtilde p_0(boldsymboltheta)  = frac12int_mathbbR^d tilde p_0(mathbfx) leftboldsymbolpsi(mathbfx boldsymboltheta) - boldsymbolnabla_mathbfxlog tilde p_sigma(mathbfx)right^2mathrmdmathbfx \n         = frac1N sum_n=1^N leftboldsymbolpsi(mathbfx_n boldsymboltheta) - boldsymbolnabla_mathbfx_nlog tilde p_sigma(mathbfx)right^2\n    endalign*","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"However, Pascal Vincent (2011) did not use this as a final objective function. Pascal further simplified the objective function tilde J_mathrmP_sigma ESM(boldsymboltheta) by expanding the gradient of the logpdf of the Parzen estimator, writing a double integral with a conditional probability, and switching the order of integration. We will do this in a follow up note, but for the moment we will stop at tilde J_mathrmP_sigma ESM(boldsymboltheta) and tilde J_mathrmP_sigma ESMtilde p_0(boldsymboltheta), use a Gaussian estimator, and see how this works.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Computing the score function with the Parzen estimation amounts to","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    beginalign*\n        boldsymbolnabla_mathbfxlog tilde p_sigma(mathbfx)  = boldsymbolnabla_mathbfxlogleft( frac1sigma^d Nsum_n=1^N Kleft(fracmathbfx - mathbfx_nsigmaright)right) \n         = frac1tilde p_sigma(mathbfx) frac1sigma^d Nsum_n=1^N boldsymbolnabla_mathbfx left(Kleft(fracmathbfx - mathbfx_nsigmaright)right) \n         = frac1tilde p_sigma(mathbfx) frac1sigma^d Nsum_n=1^N frac1sigmaleft(boldsymbolnabla_mathbfx Kright)left(fracmathbfx - mathbfx_nsigmaright)\n    endalign*","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"If we use the standard Gaussian kernel","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    G(mathbfx) = frac1sqrt2pi e^-frac12 mathbfx^2","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"then","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    left(boldsymbolnabla_mathbfx Gright)(mathbfx) = frac1sqrt2pie^-frac12 mathbfx^2 mathbfx = G(mathbfx)mathbfx","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"so that","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    boldsymbolnabla_mathbfxlog tilde p_sigma(mathbfx) = frac1tilde p_sigma(mathbfx) frac1sigma^d Nsum_n=1^N Gleft(fracmathbfx - mathbfx_nsigmaright)fracmathbfx - mathbfx_nsigma^2","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Notice that this can be computed beforehand at the sample points, just with the knowledge of the sample points themselves. Indeed, renaming the index above from n to j, and computing the approximate score function at each sample point mathbfx_n yield","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    boldsymbolnabla_mathbfxlog tilde p_sigma(mathbfx_n) = frac1tilde p_sigma(mathbfx_n) frac1sigma^d Nsum_n=1^N Gleft(fracmathbfx_n - mathbfx_jsigmaright)fracmathbfx_n - mathbfx_jsigma^2","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"where","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"tilde p_sigma(mathbfx_n) = frac1sigma^d Nsum_j=1^N Gleft(fracmathbfx - mathbfx_jsigmaright)","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Then, the explicit score matching objective approximated with the Parzen kernel estimator and with the empirical distribution yields the objective","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"    tilde J_mathrmP_sigma ESMtilde p_0(boldsymboltheta) = frac12frac1N sum_n=1^N leftboldsymbolpsi(mathbfx_n boldsymboltheta) - boldsymbolnabla_mathbfxlog tilde p_sigma(mathbfx_n)right^2","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Numerical-example","page":"Score matching with Parzen estimation","title":"Numerical example","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"We illustrate, numerically, the use of the empirical Parzen-estimated explicit score matching objective tilde J_mathrmP_sigma ESMtilde p_0 to model a synthetic univariate Gaussian mixture distribution.","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Julia-language-setup","page":"Score matching with Parzen estimation","title":"Julia language setup","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"We use the Julia programming language for the numerical simulations, with suitable packages.","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Packages","page":"Score matching with Parzen estimation","title":"Packages","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"using StatsPlots\nusing Random\nusing Distributions\nusing Lux # artificial neural networks explicitly parametrized\nusing Optimisers\nusing Zygote # automatic differentiation\nusing Markdown\n\nnothing # hide","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"There are several Julia libraries for artificial neural networks and for automatic differentiation (AD). As discussed in a previous note, we will use here the LuxDL/Lux.jl library, which is taylored to the differential equations SciML ecosystem.","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Reproducibility","page":"Score matching with Parzen estimation","title":"Reproducibility","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"We set the random seed for reproducibility purposes.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"rng = Xoshiro(12345)\nnothing # hide","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Data","page":"Score matching with Parzen estimation","title":"Data","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"We build the target model and draw samples from it.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"The target model is a univariate random variable denoted by X and defined by a probability distribution. Associated with that we consider its PDF and its score-function.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"target_prob = MixtureModel([Normal(-3, 1), Normal(3, 1)], [0.1, 0.9])\n\nxrange = range(-10, 10, 200)\ndx = Float64(xrange.step)\nxx = permutedims(collect(xrange))\ntarget_pdf = pdf.(target_prob, xrange')\ntarget_score = gradlogpdf.(target_prob, xrange')\n\nsample_points = permutedims(rand(rng, target_prob, 1024))","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Visualizing the sample data drawn from the distribution and the PDF.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"plt # hide","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Visualizing the score function.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"plt # hide","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"For the Parzen estimated score matching, we need to pre-compute the score function of the Parzen estimation.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"G(x) = exp(-x^2 / 2) / √(2π)\n\npsigma(x, sigma, sample_points) = mean(G( (x - xn) / sigma ) for xn in sample_points) / sigma\n\nscore_parzen(x, sigma, sample_points) = mean(G( (x - xn) / sigma ) * (xn - x) / sigma^2 for xn in sample_points) / psigma(x, sigma, sample_points) / sigma","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"The Parzen estimated score function is highly sensitive to the window parameter sigma:","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"plt # hide","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"sigma = 0.5\nscore_parzen_points = map(x -> score_parzen(x, sigma, sample_points), sample_points)\ndata = (sample_points, score_parzen_points)","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Markdown.parse(\"\"\"We choose the value ``\\\\sigma = $sigma``.\"\"\") # hide","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"plt # hide","category":"page"},{"location":"generative/parzen_estimation_score_matching/#The-neural-network-model","page":"Score matching with Parzen estimation","title":"The neural network model","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"The neural network we consider is a simple feed-forward neural network made of a single hidden layer, obtained as a chain of a couple of dense layers. This is implemented with the LuxDL/Lux.jl package.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"We will see that we don't need a big neural network in this simple example. We go as low as it works.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"model = Chain(Dense(1 => 8, relu), Dense(8 => 1))","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"The LuxDL/Lux.jl package uses explicit parameters, that are initialized (or obtained) with the Lux.setup function, giving us the parameters and the state of the model.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Loss-function","page":"Score matching with Parzen estimation","title":"Loss function","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Here it is how we implement the objective tilde J_mathrmP_sigma ESMtilde p_0(boldsymboltheta).","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"function loss_function_parzen(model, ps, st, data)\n    sample_points, score_parzen_points = data\n    y_score_pred, st = Lux.apply(model, sample_points, ps, st)\n    loss = mean(abs2, y_score_pred .- score_parzen_points)\n    return loss, st, ()\nend","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Optimization-setup","page":"Score matching with Parzen estimation","title":"Optimization setup","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/#Optimization-method","page":"Score matching with Parzen estimation","title":"Optimization method","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"We use the Adam optimiser.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"opt = Adam(0.01)\n\ntstate_org = Lux.Training.TrainState(model, ps, st, opt)","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Automatic-differentiation-in-the-optimization","page":"Score matching with Parzen estimation","title":"Automatic differentiation in the optimization","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"As mentioned, we setup differentiation in LuxDL/Lux.jl with the FluxML/Zygote.jl library.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"vjp_rule = Lux.Training.AutoZygote()","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Processor","page":"Score matching with Parzen estimation","title":"Processor","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"We use the CPU instead of the GPU.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"dev_cpu = cpu_device()\n## dev_gpu = gpu_device()","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Check-differentiation","page":"Score matching with Parzen estimation","title":"Check differentiation","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Check if Zygote via Lux is working fine to differentiate the loss functions for training.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Lux.Training.compute_gradients(vjp_rule, loss_function_parzen, data, tstate_org)","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Training-loop","page":"Score matching with Parzen estimation","title":"Training loop","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Here is the typical main training loop suggest in the LuxDL/Lux.jl tutorials, but sligthly modified to save the history of losses per iteration.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"function train(tstate, vjp, data, loss_function, epochs, numshowepochs=20, numsavestates=0)\n    losses = zeros(epochs)\n    tstates = [(0, tstate)]\n    for epoch in 1:epochs\n        grads, loss, stats, tstate = Lux.Training.compute_gradients(vjp,\n            loss_function, data, tstate)\n        if ( epochs ≥ numshowepochs > 0 ) && rem(epoch, div(epochs, numshowepochs)) == 0\n            println(\"Epoch: $(epoch) || Loss: $(loss)\")\n        end\n        if ( epochs ≥ numsavestates > 0 ) && rem(epoch, div(epochs, numsavestates)) == 0\n            push!(tstates, (epoch, tstate))\n        end\n        losses[epoch] = loss\n        tstate = Lux.Training.apply_gradients(tstate, grads)\n    end\n    return tstate, losses, tstates\nend","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Training","page":"Score matching with Parzen estimation","title":"Training","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Now we train the model with the objective function tilde J_mathrmP_sigma ESMtilde p_0(boldsymboltheta).","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_parzen, 500, 20, 125)\nnothing # hide","category":"page"},{"location":"generative/parzen_estimation_score_matching/#Results","page":"Score matching with Parzen estimation","title":"Results","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Testing out the trained model.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"y_pred = Lux.apply(tstate.model, xrange', tstate.parameters, tstate.states)[1]","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Visualizing the result.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"plot(title=\"Fitting\", titlefont=10)\n\nplot!(xrange, target_score', linewidth=4, label=\"score function\")\n\nscatter!(sample_points', s -> gradlogpdf(target_prob, s), label=\"data\", markersize=2)\n\nplot!(xx', y_pred', linewidth=2, label=\"predicted MLP\")","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Just for the fun of it, let us see an animation of the optimization process.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"gif(anim, fps = 20) # hide","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Recovering the PDF of the distribution from the trained score function.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"paux = exp.(accumulate(+, y_pred) .* dx)\npdf_pred = paux ./ sum(paux) ./ dx\nplot(title=\"Original PDF and PDF from predicted score function\", titlefont=10)\nplot!(xrange, target_pdf', label=\"original\")\nplot!(xrange, pdf_pred', label=\"recoverd\")","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"And the animation of the evolution of the PDF.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"gif(anim, fps = 10) # hide","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"We also visualize the evolution of the losses.","category":"page"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"plot(losses, title=\"Evolution of the loss\", titlefont=10, xlabel=\"iteration\", ylabel=\"error\", legend=false)","category":"page"},{"location":"generative/parzen_estimation_score_matching/#References","page":"Score matching with Parzen estimation","title":"References","text":"","category":"section"},{"location":"generative/parzen_estimation_score_matching/","page":"Score matching with Parzen estimation","title":"Score matching with Parzen estimation","text":"Pascal Vincent (2011), \"A connection between score matching and denoising autoencoders,\" Neural Computation, 23 (7), 1661-1674, doi:10.1162/NECOa00142\nAapo Hyvärinen (2005), \"Estimation of non-normalized statistical models by score matching\", Journal of Machine Learning Research 6, 695-709\nY. Song and S. Ermon (2019), \"Generative modeling by estimating gradients of the data distribution\", NIPS'19: Proceedings of the 33rd International Conference on Neural Information Processing Systems, no. 1067, 11918-11930","category":"page"}]
}
