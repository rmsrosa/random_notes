<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Denoising score matching of Pascal Vincent · Random notes</title><meta name="title" content="Denoising score matching of Pascal Vincent · Random notes"/><meta property="og:title" content="Denoising score matching of Pascal Vincent · Random notes"/><meta property="twitter:title" content="Denoising score matching of Pascal Vincent · Random notes"/><meta name="description" content="Documentation for Random notes."/><meta property="og:description" content="Documentation for Random notes."/><meta property="twitter:description" content="Documentation for Random notes."/><meta property="og:url" content="https://github.com/rmsrosa/random_notes/generative/denoising_score_matching/"/><meta property="twitter:url" content="https://github.com/rmsrosa/random_notes/generative/denoising_score_matching/"/><link rel="canonical" href="https://github.com/rmsrosa/random_notes/generative/denoising_score_matching/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Random notes logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Random notes</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Random Notes</a></li><li><span class="tocitem">Probability Essentials</span><ul><li><a class="tocitem" href="../../probability/kernel_density_estimation/">Kernel Density Estimation</a></li><li><a class="tocitem" href="../../probability/convergence_notions/">Convergence notions</a></li></ul></li><li><span class="tocitem">Discrete-time Markov chains</span><ul><li><a class="tocitem" href="../../markov_chains/mc_definitions/">Essential definitions</a></li><li><a class="tocitem" href="../../markov_chains/mc_invariance/">Invariant distributions</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Countable-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_countableX_recurrence/">Recurrence in the countable-space case</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_connections/">Connected states, irreducibility and uniqueness of invariant measures</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_convergencia/">Aperiodicidade e convergência para a distribuição estacionária</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Continuous-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_irreducibility_and_recurrence/">Irreducibility and recurrence in the continuous-space case</a></li></ul></li></ul></li><li><span class="tocitem">Sampling methods</span><ul><li><a class="tocitem" href="../../sampling/overview/">Overview</a></li><li><a class="tocitem" href="../../sampling/prng/">Random number generators</a></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Transform methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/invFtransform/">Probability integral transform</a></li><li><a class="tocitem" href="../../sampling/box_muller/">Box-Muller transform</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Accept-Reject methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/rejection_sampling/">Rejection sampling</a></li><li><a class="tocitem" href="../../sampling/empiricalsup_rejection/">Empirical supremum rejection sampling</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Markov Chain Monte Carlo (MCMC)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/mcmc/">Overview</a></li><li><a class="tocitem" href="../../sampling/metropolis/">Metropolis and Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/convergence_metropolis/">Convergence of Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/gibbs/">Gibbs sampling</a></li><li><a class="tocitem" href="../../sampling/hmc/">Hamiltonian Monte Carlo (HMC)</a></li></ul></li><li><a class="tocitem" href="../../sampling/langevin_sampling/">Langevin sampling</a></li></ul></li><li><span class="tocitem">Bayesian inference</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Bayes Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/bayes/">Bayes Theorem</a></li><li><a class="tocitem" href="../../bayesian/bayes_inference/">Bayesian inference</a></li><li><a class="tocitem" href="../../bayesian/bernstein_vonmises/">Bernstein–von Mises theorem</a></li></ul></li><li><a class="tocitem" href="../../bayesian/bayesian_probprog/">Bayesian probabilistic programming</a></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/find_pi/">Estimating π via frequentist and Bayesian methods</a></li><li><a class="tocitem" href="../../bayesian/linear_regression/">Many Ways to Linear Regression</a></li><li><a class="tocitem" href="../../bayesian/tilapia_alometry/">Alometry law for the Nile Tilapia</a></li><li><a class="tocitem" href="../../bayesian/mortality_tables/">Modeling mortality tables</a></li></ul></li></ul></li><li><span class="tocitem">Generative models</span><ul><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox" checked/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Score matching</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../stein_score/">Stein score function</a></li><li><a class="tocitem" href="../score_matching_aapo/">Score matching of Aapo Hyvärinen</a></li><li><a class="tocitem" href="../score_matching_neural_network/">Score matching a neural network</a></li><li><a class="tocitem" href="../parzen_estimation_score_matching/">Score matching with Parzen estimation</a></li><li class="is-active"><a class="tocitem" href>Denoising score matching of Pascal Vincent</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Objetive-function-for-denoising-score-matching"><span>Objetive function for denoising score matching</span></a></li><li><a class="tocitem" href="#Proof-that-{\\tilde-J}_{\\mathrm{ESM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-{\\tilde-J}_{\\mathrm{DSM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-C_\\sigma"><span>Proof that <span>${\tilde J}_{\mathrm{ESM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) = {\tilde J}_{\mathrm{DSM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) + C_\sigma$</span></span></a></li><li><a class="tocitem" href="#Numerical-example"><span>Numerical example</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../sliced_score_matching/">Sliced score matching</a></li><li><a class="tocitem" href="../1d_FD_score_matching/">1D finite-difference score matching</a></li><li><a class="tocitem" href="../2d_FD_score_matching/">2D finite-difference score matching</a></li><li><a class="tocitem" href="../ddpm/">Denoising diffusion probabilistic models</a></li><li><a class="tocitem" href="../mdsm/">Multiple denoising score matching</a></li><li><a class="tocitem" href="../probability_flow/">Probability flow</a></li><li><a class="tocitem" href="../reverse_flow/">Reverse probability flow</a></li><li><a class="tocitem" href="../score_based_sde/">Score-based SDE model</a></li></ul></li></ul></li><li><span class="tocitem">Sensitivity analysis</span><ul><li><a class="tocitem" href="../../sensitivity/overview/">Overview</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Generative models</a></li><li><a class="is-disabled">Score matching</a></li><li class="is-active"><a href>Denoising score matching of Pascal Vincent</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Denoising score matching of Pascal Vincent</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes/blob/main/docs/src/generative/denoising_score_matching.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Denoising-score-matching-of-Pascal-Vincent"><a class="docs-heading-anchor" href="#Denoising-score-matching-of-Pascal-Vincent">Denoising score matching of Pascal Vincent</a><a id="Denoising-score-matching-of-Pascal-Vincent-1"></a><a class="docs-heading-anchor-permalink" href="#Denoising-score-matching-of-Pascal-Vincent" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><h3 id="Aim"><a class="docs-heading-anchor" href="#Aim">Aim</a><a id="Aim-1"></a><a class="docs-heading-anchor-permalink" href="#Aim" title="Permalink"></a></h3><p>Explore the <strong>denoising score matching</strong> method proposed by <a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011)</a> and illustrate it by fiting a multi-layer perceptron to model the score function of a one-dimensional synthetic Gaussian-mixture distribution.</p><h3 id="Motivation"><a class="docs-heading-anchor" href="#Motivation">Motivation</a><a id="Motivation-1"></a><a class="docs-heading-anchor-permalink" href="#Motivation" title="Permalink"></a></h3><p>The motivation is to continue building a solid background on score-matching diffusion.</p><h3 id="Background"><a class="docs-heading-anchor" href="#Background">Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h3><p><a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005)</a> proposed fitting directly the score of a model distribution. This is obtained, in theory, by minimizing an <strong>explicit score matching</strong> objective function. However, this function requires knowing the supposedly unknown target score function. The trick used by <a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005)</a> was then to do an integration by parts and rewrite the optimization problem in terms of an <strong>implicit score matching</strong> objective function, which yields the same minima and does not require further information from the target distribution other than some sample points.</p><p>The <strong>implicit score matching</strong> method requires, however, the derivative of the score function of the model distribution, which is costly to compute in general.</p><p>Then, <a href="https://doi.org/10.1162/NECO_a_00142">Vincent (2011)</a> explored the idea of using <em>non-parametric Parzen density estimation</em> to directly approximate the explicit score matching objective, making a connection with denoising autoenconders (proposed earlir by Pascal himself, as a co-author in <a href="https://www.jmlr.org/papers/v11/vincent10a.html">Vincent, Larochelle, Lajoie, Bengio, and Manzagol(2010)</a>), and proposing the <strong>denoising score matching</strong> method.</p><h2 id="Objetive-function-for-denoising-score-matching"><a class="docs-heading-anchor" href="#Objetive-function-for-denoising-score-matching">Objetive function for denoising score matching</a><a id="Objetive-function-for-denoising-score-matching-1"></a><a class="docs-heading-anchor-permalink" href="#Objetive-function-for-denoising-score-matching" title="Permalink"></a></h2><h3 id="The-original-explicit-and-implicit-score-matching"><a class="docs-heading-anchor" href="#The-original-explicit-and-implicit-score-matching">The original explicit and implicit score matching</a><a id="The-original-explicit-and-implicit-score-matching-1"></a><a class="docs-heading-anchor-permalink" href="#The-original-explicit-and-implicit-score-matching" title="Permalink"></a></h3><p>The score-matching method from <a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005)</a> aims to fit the score function <span>$\psi(\mathbf{x}; {\boldsymbol{\theta}})$</span> of the model distribution to the score function <span>$\psi_X(\mathbf{x})$</span> of a random variable <span>$\mathbf{X}$</span> by minimizing the <strong>implicit score matching</strong> objective</p><p class="math-container">\[    J_{\mathrm{ISM}}({\boldsymbol{\theta}}) = \int_{\mathbb{R}} p_{\mathbf{X}}(\mathbf{x}) \left( \frac{1}{2}\left\|\boldsymbol{\psi}(\mathbf{x}; {\boldsymbol{\theta}})\right\|^2 + \boldsymbol{\nabla}_{\mathbf{x}} \cdot \boldsymbol{\psi}(\mathbf{x}; {\boldsymbol{\theta}}) \right)\;\mathrm{d}\mathbf{x},\]</p><p>which is equivalent to minimizing the <strong>explicit score matching</strong> objective</p><p class="math-container">\[    J_{\mathrm{ESM}}({\boldsymbol{\theta}}) = \frac{1}{2}\int_{\mathbb{R}^d} p_{\mathbf{X}}(\mathbf{x}) \left\|\boldsymbol{\psi}(\mathbf{x}; {\boldsymbol{\theta}}) - \boldsymbol{\psi}_{\mathbf{X}}(\mathbf{x})\right\|^2\;\mathrm{d}\mathbf{x},\]</p><p>due to the following identity obtained via integration by parts in the expectation</p><p class="math-container">\[    J_{\mathrm{ESM}}({\boldsymbol{\theta}}) = {\tilde J}_{\mathrm{ISM}}({\boldsymbol{\theta}}) + C_\sigma,\]</p><p>where <span>$C_\sigma$</span> is constant with respect to the parameters <span>$\boldsymbol{\theta}$</span>. The advantage of <span>${\tilde J}_{\mathrm{ISM}}({\boldsymbol{\theta}})$</span> is that it does not involve the unknown score function of <span>$X$</span>. It does, however, involve the gradient of the modeled score function, which is expensive to compute.</p><p>In practice, this is further approximated by the <strong>empirical distribution</strong> <span>${\tilde p}_0$</span> given by</p><p class="math-container">\[    {\tilde p}_0(\mathbf{x}) = \frac{1}{N}\sum_{n=1}^N \delta(\mathbf{x} - \mathbf{x}_n),\]</p><p>so the implemented implicit score matching objective is</p><p class="math-container">\[    {\tilde J}_{\mathrm{ISM{\tilde p}_0}}({\boldsymbol{\theta}}) = \frac{1}{N}\sum_{n=1}^N \left( \frac{1}{2}\left\|\boldsymbol{\psi}(\mathbf{x}_n; {\boldsymbol{\theta}})\right\|^2 + \boldsymbol{\nabla}_{\mathbf{x}} \cdot \boldsymbol{\psi}(\mathbf{x}_n; {\boldsymbol{\theta}}) \right).\]</p><h3 id="Using-Parzen-estimation"><a class="docs-heading-anchor" href="#Using-Parzen-estimation">Using Parzen estimation</a><a id="Using-Parzen-estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Using-Parzen-estimation" title="Permalink"></a></h3><p><a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005)</a> briefly mentions that minimizing <span>$J_{\mathrm{ESM}}({\boldsymbol{\theta}})$</span> directly is &quot;basically a non-parametric estimation problem&quot;, but dismisses it for the &quot;simple trick of partial integration to compute the objective function very easily&quot;. As we have seen, the trick is fine for model functions for which we can compute the gradient without much trouble, but for modeling it with a neural network, for instance, it becomes computationally expensive.</p><p>A few years later, <a href="https://doi.org/10.1162/NECO_a_00142">Vincent (2011)</a> considered the idea of using a Parzel kernel density estimation</p><p class="math-container">\[    {\tilde p}_\sigma(\mathbf{x}) = \frac{1}{\sigma^d}\int_{\mathbb{R}^d} K\left(\frac{\mathbf{x} - \tilde{\mathbf{x}}}{\sigma}\right) \;\mathrm{d}{\tilde p}_0(\tilde{\mathbf{x}}) = \frac{1}{\sigma^d N}\sum_{n=1}^N K\left(\frac{\mathbf{x} - \mathbf{x}_n}{\sigma}\right),\]</p><p>where <span>$\sigma &gt; 0$</span> is a kernel window parameter and <span>$K(\mathbf{x})$</span> is a kernel density properly normalized to have mass one. In this way, the explicit score matching objective function is approximated by</p><p class="math-container">\[    {\tilde J}_{\mathrm{ESM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) = \frac{1}{2}\int_{\mathbb{R}^d} {\tilde p}_\sigma(\mathbf{x}) \left\|\boldsymbol{\psi}(\mathbf{x}; {\boldsymbol{\theta}}) - \boldsymbol{\nabla}_{\mathbf{x}}\log {\tilde p}_\sigma(\mathbf{x})\right\|^2\;\mathrm{d}\mathbf{x}.\]</p><h3 id="Denoising-autoencoder"><a class="docs-heading-anchor" href="#Denoising-autoencoder">Denoising autoencoder</a><a id="Denoising-autoencoder-1"></a><a class="docs-heading-anchor-permalink" href="#Denoising-autoencoder" title="Permalink"></a></h3><p>However, <a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011)</a> did not use this as a final objective function. Pascal further simplified the objective function <span>${\tilde J}_{\mathrm{ESM{\tilde p}_\sigma}}({\boldsymbol{\theta}})$</span> by expanding the gradient of the logpdf of the Parzen estimator, writing a double integral with a conditional probability, simplifying the computation of the gradient of the logarithm of the Parzen estimation, which involves the log of a sum, to the gradient of the logarithm of the conditional probability, which involves the log of a single kernel.</p><p>In this way, Pascal arrived at the <strong>(Parzen) denoising score matching</strong> objective function</p><p class="math-container">\[    {\tilde J}_{\mathrm{DSM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) = \frac{1}{2}\int_{\mathbb{R}^d} \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x})\left\| \boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) - \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) \right\|^2 \mathrm{d}\mathbf{x}\,\mathrm{d}\tilde{\mathbf{x}}\]</p><p>where <span>${\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x})$</span> is the conditional density</p><p class="math-container">\[    {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) = \frac{1}{\sigma^d}K\left(\frac{\tilde{\mathbf{x}} - \mathbf{x}}{\sigma}\right).\]</p><p>Notice that the empirical distribution is not a further approximation to this objective function. It comes directly from the Parzen estimator. So, we can write</p><p class="math-container">\[    {\tilde J}_{\mathrm{DSM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) = \frac{1}{2}\frac{1}{N}\sum_{n=1}^N \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}_n) \left\| \boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) - \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}_n) \right\|^2 \mathrm{d}\tilde{\mathbf{x}}.\]</p><p>We do need, however, for the sake of implementation, to approximate the (inner) expectation with respect to the conditional distribution. This is achieved by drawing a certain number of sample points from the conditional distribution associated with <span>${\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}_n)$</span>.</p><h3 id="Denoising-autoencoder-with-the-standard-Gaussian-kernel"><a class="docs-heading-anchor" href="#Denoising-autoencoder-with-the-standard-Gaussian-kernel">Denoising autoencoder with the standard Gaussian kernel</a><a id="Denoising-autoencoder-with-the-standard-Gaussian-kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Denoising-autoencoder-with-the-standard-Gaussian-kernel" title="Permalink"></a></h3><p>At this point, choosing the kernel of the Parzen estimation to be the standard Gaussian kernel</p><p class="math-container">\[    G(\mathbf{x}) = \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2} \mathbf{x}^2},\]</p><p>the conditional distribution is a Normal distribution with mean <span>$\mathbf{x}_n$</span> and variance <span>$\sigma^2$</span>. Hence, for each <span>$n=1, \ldots, N$</span>, we draw <span>$M$</span> sample points <span>$\tilde{\mathbf{x}}_{n,m}$</span>, <span>$m=1, \ldots, M$</span>, according to</p><p class="math-container">\[    \tilde{\mathbf{x}}_{n,m} \sim \mathcal{N}(\mathbf{x}_n, \sigma^2), \quad m=1, \ldots, M.\]</p><p>Then, using the associated empirical distribution </p><p class="math-container">\[    {\tilde p}_{\sigma, 0}(\tilde{\mathbf{x}}|\mathbf{x}_n) = \frac{1}{M}\sum_{m=1}^M \delta(\tilde{\mathbf{x}} - \tilde{\mathbf{x}}_{n,m}),\]</p><p>we arrive at the <strong>empirical denoising score matching</strong> objective</p><p class="math-container">\[    {\tilde J}_{\mathrm{DSM{\tilde p}_{\sigma, 0}}}({\boldsymbol{\theta}}) = \frac{1}{2}\frac{1}{NM}\sum_{n=1}^N \sum_{m=1}^M \left\| \boldsymbol{\psi}(\mathbf{x}_{n, m}; {\boldsymbol{\theta}}) - \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}}_{n,m}|\mathbf{x}_n) \right\|^2 \mathrm{d}\tilde{\mathbf{x}}.\]</p><p>With the Gaussian kernel, we have</p><p class="math-container">\[    \begin{align*}
        \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}}_{n,m}|\mathbf{x}_n) &amp; = \boldsymbol{\nabla}_{\tilde{\mathbf{x}}} \log\left( \frac{1}{\sqrt{2\pi}\sigma^d} e^{-\frac{1}{2} \left(\frac{\tilde{\mathbf{x}} - \mathbf{x}_n}{\sigma}\right)^2} \right) \!\!\Bigg|_{\;\tilde{\mathbf{x}}=\tilde{\mathbf{x}}_{n, m}} \\
        &amp; = \boldsymbol{\nabla}_{\tilde{\mathbf{x}}} \left( -\frac{1}{2} \left(\frac{\tilde{\mathbf{x}} - \mathbf{x}_n}{\sigma}\right)^2 - \log(\sqrt{2\pi}\sigma^d) \right)\!\!\Bigg|_{\;\tilde{\mathbf{x}}=\tilde{\mathbf{x}}_{n, m}} \\
        &amp; = \left( - \frac{\tilde{\mathbf{x}} - \mathbf{x}_n}{\sigma^2} \right)\!\!\Bigg|_{\;\tilde{\mathbf{x}}=\tilde{\mathbf{x}}_{n, m}} \\
        &amp; = - \frac{\tilde{\mathbf{x}}_{n, m} - \mathbf{x}_n}{\sigma^2} \\
        &amp; = \frac{\mathbf{x}_n - \tilde{\mathbf{x}}_{n, m}}{\sigma^2}
    \end{align*}\]</p><p>Thus, in this case, the <strong>empirical denoising score matching</strong> objective reads</p><p class="math-container">\[    {\tilde J}_{\mathrm{DSM{\tilde p}_{\sigma, 0}}}({\boldsymbol{\theta}}) = \frac{1}{2}\frac{1}{NM}\sum_{n=1}^N \sum_{m=1}^M \left\| \boldsymbol{\psi}(\mathbf{x}_{n, m}; {\boldsymbol{\theta}}) - \frac{\mathbf{x}_n - \tilde{\mathbf{x}}_{n, m}}{\sigma^2} \right\|^2 \mathrm{d}\tilde{\mathbf{x}}.\]</p><p>Often, with <span>$N$</span> sufficiently large, it suffices to take <span>$M=1$</span>, i.e. a single &quot;corrupted&quot; sample <span>$\tilde{\mathbf{x}}_n$</span>, for each &quot;clean&quot; sample point <span>$\mathbf{x}_n$</span>. In this way, the double summation becomes a single summation and the computation is just as fast as the one with the score of the unconditional Parzen estimation, with the benefit similar to the denosing autoencoders.</p><h3 id="Energy-based-modeling"><a class="docs-heading-anchor" href="#Energy-based-modeling">Energy based modeling</a><a id="Energy-based-modeling-1"></a><a class="docs-heading-anchor-permalink" href="#Energy-based-modeling" title="Permalink"></a></h3><p>The model distribution is chosen by <a href="https://doi.org/10.1162/NECO_a_00142">Vincent (2011)</a> in the form</p><p class="math-container">\[    p_{\boldsymbol{\theta}}(\mathbf{x}) = \frac{1}{Z(\boldsymbol{\theta})} e^{-U(\mathbf{x}; \boldsymbol{\theta})},\]</p><p>for an energy potential <span>$U(\mathbf{x}; \boldsymbol{\theta})$</span> of the form</p><p class="math-container">\[    U(\mathbf{x}; \boldsymbol{\theta}) = - \frac{1}{\sigma^2}\left( \mathbf{c}\cdot \mathbf{x} - \frac{1}{2}\|\mathbf{x}\|^2 + \sum_{j=1}^d \operatorname{softplus}\left(\mathbf{W}_j\cdot \mathbf{x} + b_j\right)\right),\]</p><p>where</p><p class="math-container">\[    \boldsymbol{\theta} = (\mathbf{W}, \mathbf{b}, \mathbf{c}), \quad \mathbf{W}\in \mathbb{R}^{d\times d}, \;\mathbf{b}, \mathbf{c}\in\mathbf{R}^d,\]</p><p>with <span>$\mathbf{W}_j$</span> being the rows of the matrix <span>$\mathbf{W}$</span>, and <span>$\operatorname{sigmoid}()$</span> is an activation function. For this model, the score function can be computed explicitly <a href="https://doi.org/10.1162/NECO_a_00142">Vincent (2011)</a>, being</p><p class="math-container">\[    \boldsymbol{\nabla}_{\mathbf{x}} p(\mathbf{x}; \boldsymbol{\theta}) = \frac{1}{\sigma^2}\left( \mathbf{W}^{\mathrm{tr}}\operatorname{sigmoid}\left(\mathbf{W}\mathbf{x} + \mathbf{b}\right) + \mathbf{c} - \mathbf{x}\right).\]</p><p>When substitute for in the denoising score matching objective, we obtain a loss function directly in terms of the parameters <span>$\boldsymbol{\theta} = (\mathbf{W}, \mathbf{b}, \mathbf{c})$</span>.</p><h3 id="Connection-with-denoising-autoencoder"><a class="docs-heading-anchor" href="#Connection-with-denoising-autoencoder">Connection with denoising autoencoder</a><a id="Connection-with-denoising-autoencoder-1"></a><a class="docs-heading-anchor-permalink" href="#Connection-with-denoising-autoencoder" title="Permalink"></a></h3><p>This brings us to the connection, discussed by <a href="https://doi.org/10.1162/NECO_a_00142">Vincent (2011)</a>,  with denoising autoencoders, which were proposed a bit earlier by <a href="https://www.jmlr.org/papers/v11/vincent10a.html">Vincent, Larochelle, Lajoie, Bengio, and Manzagol(2010)</a>.</p><p>In an <strong>autoencoder</strong>, as introduced by <a href="https://doi.org/10.1002/AIC.690370209">Kramer (1991)</a>, one has two models, an <em>encoder</em> model <span>$\mathbf{y} = \mathbf{f}_{\boldsymbol{\xi}}(\mathbf{x})$</span> and a <em>decoder</em> <span>$\mathbf{x} = \mathbf{g}_{\boldsymbol{\eta}}(\mathbf{y})$</span>, and the objective is to be able to encode and decode the sample, and recover the original sample as close as possible, i.e.</p><p class="math-container">\[    J(\boldsymbol{\xi}, \boldsymbol{\eta}) = \frac{1}{N} \sum_{n=1}^N \left\|\mathbf{x}_n - \mathbf{g}_{\boldsymbol{\eta}}(\mathbf{f}_{\boldsymbol{\xi}}(\mathbf{x}_n))\right\|.\]</p><p>Of course, this is useful when the <em>latent</em> space of the encoded information <span>$\mathbf{y}$</span> is much smaller than the sample space, otherwise we just need to model the identity operator.</p><p>In a <strong>denoising autoencoder</strong>, proposed by <a href="https://www.jmlr.org/papers/v11/vincent10a.html">Vincent, Larochelle, Lajoie, Bengio, and Manzagol(2010)</a>, one first &quot;corrupts&quot; the sample points according to some distribution law, say</p><p class="math-container">\[    \tilde{\mathbf{x}}_n \sim \mathcal{P}(\tilde{\mathbf{x}}|\mathbf{x}_n),\]</p><p>and then use the corrupted sample to train the encoder/decoder pair with the objective function</p><p class="math-container">\[    J_{\mathcal{P}}(\boldsymbol{\xi}, \boldsymbol{\eta}) = \frac{1}{N} \sum_{n=1}^N \left\|\mathbf{x}_n - \mathbf{g}_{\boldsymbol{\eta}}(\mathbf{f}_{\boldsymbol{\xi}}(\tilde{\mathbf{x}}_n)) \right\|.\]</p><p>The idea is that the encoder/decoder model learns to better &quot;reconstruct&quot; the information even from &quot;imperfect&quot; information. Think about the case of encoding/decoding a handwritten message, where the letters are not &quot;perfect&quot; according to any font style.</p><p>In <a href="https://doi.org/10.1162/NECO_a_00142">Vincent (2011)</a>, by choosing the score model of the form</p><p class="math-container">\[    \boldsymbol{\psi}(\mathbf{x}, \boldsymbol{\theta}) = \frac{1}{\sigma^2}\left( \mathbf{W}^{\mathrm{tr}} \operatorname{sigmoid}\left(\mathbf{W}\mathbf{x} + \mathbf{b}\right) + \mathbf{c} - \mathbf{x}\right),\]</p><p>where <span>$\boldsymbol{\theta} = (\mathbf{W}, \mathbf{b}, \mathbf{c})$</span> are the parameters and <span>$\operatorname{sigmoid}()$</span> is an activation function, and choosing the noise according to</p><p class="math-container">\[    \mathcal{P}(\tilde{\mathbf{x}}|\mathbf{x}_n) = \mathcal{N}(\mathbf{x}_n, \sigma^2),\]</p><p>one obtains the connection</p><p class="math-container">\[    {\tilde J}_{\mathrm{DSM{\tilde p}_{\sigma, 0}}}({\boldsymbol{\theta}}) = \frac{1}{2\sigma^4} {\tilde J}_{\mathcal{P}}(\boldsymbol{\theta}),\]</p><p>where <span>${\tilde J}_{\mathcal{P}}(\boldsymbol{\theta})$</span> is similar to the denoising autoencoder objective <span>$J_{\mathcal{P}}(\boldsymbol{\xi}, \boldsymbol{\eta})$</span>, and is defined by</p><p class="math-container">\[    {\tilde J}_{\mathcal{P}}(\boldsymbol{\theta}) = \frac{1}{N} \sum_{n=1}^N \left\|\mathbf{x}_n - \mathbf{h}_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}_n) \right\|,\]</p><p>where <span>$\mathbf{h}_{\boldsymbol{\theta}}(\mathbf{x})$</span> is almost of the form of an encoder/decoder, namely</p><p class="math-container">\[    \mathbf{h}_{\boldsymbol{\theta}}(\mathbf{x}) = \mathbf{g}_{\boldsymbol{\theta}}(\mathbf{f}_{\boldsymbol{\theta}}(\mathbf{x})) - \mathbf{x},\]</p><p>with</p><p class="math-container">\[    {f}_{\boldsymbol{\theta}}(\mathbf{x}) = \mathrm{sigmoid}\left(\mathbf{W}\mathbf{x} + \mathbf{b}\right), \quad \mathbf{g}_{\boldsymbol{\theta}}(\mathbf{y}) = \mathbf{W}^{\mathrm{tr}}\mathbf{y} + \mathbf{c}.\]</p><p>Remember that here we are not trying to encode/decode the variate <span>$\mathbf{x}$</span> itself, but its score function, so the above structure is compatible with that.</p><p><a href="https://doi.org/10.1162/NECO_a_00142">Vincent (2011)</a> does not mention explicitly that what we denoted above by <span>$\mathbf{h}_{\boldsymbol{\theta}}(\mathbf{x})$</span> is not exactly of the form <span>$\mathbf{g}_{\boldsymbol{\theta}}(\mathbf{f}_{\boldsymbol{\theta}}(\mathbf{x}))$</span> and actually seems to suggest they are of the same form, for the sake of the connection with a denoising autoenconder. But we see here that it is not. Let us not freak out about that, though. This is good enough to draw some connection between denoising score matching and denoising autoencoder and to have this as an inspiration.</p><h2 id="Proof-that-{\\tilde-J}_{\\mathrm{ESM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-{\\tilde-J}_{\\mathrm{DSM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-C_\\sigma"><a class="docs-heading-anchor" href="#Proof-that-{\\tilde-J}_{\\mathrm{ESM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-{\\tilde-J}_{\\mathrm{DSM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-C_\\sigma">Proof that <span>${\tilde J}_{\mathrm{ESM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) = {\tilde J}_{\mathrm{DSM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) + C_\sigma$</span></a><a id="Proof-that-{\\tilde-J}_{\\mathrm{ESM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-{\\tilde-J}_{\\mathrm{DSM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-C_\\sigma-1"></a><a class="docs-heading-anchor-permalink" href="#Proof-that-{\\tilde-J}_{\\mathrm{ESM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-{\\tilde-J}_{\\mathrm{DSM{\\tilde-p}_\\sigma}}({\\boldsymbol{\\theta}})-C_\\sigma" title="Permalink"></a></h2><p>We start by renaming the dummy variable in the expression for <span>${\tilde J}_{\mathrm{ESM{\tilde p}_\sigma}}({\boldsymbol{\theta}})$</span>, writing</p><p class="math-container">\[    {\tilde J}_{\mathrm{ESM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) = \frac{1}{2}\int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}) \left\|\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) - \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}})\right\|^2\;\mathrm{d}\tilde{\mathbf{x}}.\]</p><p>Then, we expand the integrand of <span>${\tilde J}_{\mathrm{ESM{\tilde p}_\sigma}}({\boldsymbol{\theta}})$</span> and write</p><p class="math-container">\[    \begin{align*}
        {\tilde J}_{\mathrm{ESM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) &amp; = \frac{1}{2}\int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}) \left\|\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) - \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}})\right\|^2\;\mathrm{d}\tilde{\mathbf{x}} \\
        &amp; = \frac{1}{2}\int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}) \left( \left\|\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}})\right\|^2 - 2\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) \cdot \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}}) + \left\|\boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}})\right\|^2\right)\mathrm{d}\tilde{\mathbf{x}}.
    \end{align*}\]</p><p>The last term is constant with respect to the trainable parameters <span>$\boldsymbol{\theta}$</span>, so we just write</p><p class="math-container">\[    {\tilde J}_{\mathrm{ESM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) = \frac{1}{2}\int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}) \left( \left\|\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}})\right\|^2 - 2\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) \cdot \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}})\right)\mathrm{d}\tilde{\mathbf{x}} + C_{\sigma, 1},\]</p><p>where</p><p class="math-container">\[    C_{\sigma, 1} = \frac{1}{2}\int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}) \left\|\boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}})\right\|^2\mathrm{d}\tilde{\mathbf{x}}.\]</p><p>Now, notice we can write</p><p class="math-container">\[    {\tilde p}_\sigma(\tilde{\mathbf{x}}) = \frac{1}{\sigma^d}\int_{\mathbb{R}^d} K\left(\frac{\tilde{\mathbf{x}} - \mathbf{x}}{\sigma}\right) \;\mathrm{d}{\tilde p}_0(\mathbf{x}) = \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) \;\mathrm{d}{\tilde p}_0(\mathbf{x}) = \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x}) \;\mathrm{d}\mathbf{x},\]</p><p>where <span>${\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x})$</span> is the conditional density</p><p class="math-container">\[    {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) = \frac{1}{\sigma^d}K\left(\frac{\tilde{\mathbf{x}} - \mathbf{x}}{\sigma}\right).\]</p><p>Thus, the first term in the objective function becomes</p><p class="math-container">\[    \frac{1}{2}\int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}) \left\|\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}})\right\|^2\;\mathrm{d}\tilde{\mathbf{x}} = \frac{1}{2}\int_{\mathbb{R}^d} \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x}) \left\|\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}})\right\|^2\;\mathrm{d}\mathbf{x}\,\mathrm{d}\tilde{\mathbf{x}}.\]</p><p>It remains to treat the second term. For that, we use that</p><p class="math-container">\[    \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}}) = \frac{1}{{\tilde p}_\sigma(\tilde{\mathbf{x}})} \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}{\tilde p}_\sigma(\tilde{\mathbf{x}}).\]</p><p>Thus,</p><p class="math-container">\[    \begin{align*}
        \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}) \boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) \cdot \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}})\mathrm{d}\tilde{\mathbf{x}} &amp; = \int_{\mathbb{R}^d} \boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) \cdot \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}{\tilde p}_\sigma(\tilde{\mathbf{x}})\mathrm{d}\tilde{\mathbf{x}} \\
    \end{align*}\]</p><p>Now we write that</p><p class="math-container">\[    \begin{align*}
        \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}{\tilde p}_\sigma(\tilde{\mathbf{x}}) &amp; = \boldsymbol{\nabla}_{\tilde{\mathbf{x}}} \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x}) \;\mathrm{d}\mathbf{x} \\
        &amp; = \int_{\mathbb{R}^d} \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}{\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x}) \;\mathrm{d}\mathbf{x} \\
        &amp; = \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) \boldsymbol{\nabla}_{\tilde{\mathbf{x}}} \log {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x}) \;\mathrm{d}\mathbf{x}.
    \end{align*}\]</p><p>Hence,</p><p class="math-container">\[    \begin{align*}
        \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}) \boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) \cdot \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}})\mathrm{d}\tilde{\mathbf{x}} &amp; = \int_{\mathbb{R}^d} \boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) \cdot \left(\int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) \boldsymbol{\nabla}_{\tilde{\mathbf{x}}} \log {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x}) \;\mathrm{d}\mathbf{x}\right)\mathrm{d}\tilde{\mathbf{x}} \\
        &amp; = \int_{\mathbb{R}^d} \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x}) \boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) \cdot \boldsymbol{\nabla}_{\tilde{\mathbf{x}}} \log {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) \;\mathrm{d}\mathbf{x}\,\mathrm{d}\tilde{\mathbf{x}}
    \end{align*}\]</p><p>Putting the terms together, we find that</p><p class="math-container">\[    \begin{align*}
        {\tilde J}_{\mathrm{ESM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) &amp; = \frac{1}{2}\int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}) \left( \left\|\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}})\right\|^2 - 2\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) \cdot \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}})\right)\mathrm{d}\tilde{\mathbf{x}} + C_{\sigma, 1} \\
        &amp; = \frac{1}{2}\int_{\mathbb{R}^d} \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x}) \left( \left\|\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}})\right\|^2 - 2\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) \cdot \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x})\right)\;\mathrm{d}\mathbf{x}\,\mathrm{d}\tilde{\mathbf{x}} + C_{\sigma, 1}
    \end{align*}\]</p><p>Now we add and subtract the constant (with respect to the parameters <span>$\boldsymbol{\theta}$</span>)</p><p class="math-container">\[    C_{\sigma, 2} = \frac{1}{2}\int_{\mathbb{R}^d} \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x}) \left\|\boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x})\right\|^2 \;\mathrm{d}\mathbf{x}\,\mathrm{d}\tilde{\mathbf{x}}.\]</p><p>With that, we finally obtain the desired relation</p><p class="math-container">\[    \begin{align*}
        {\tilde J}_{\mathrm{ESM{\tilde p}_\sigma}}({\boldsymbol{\theta}})
        &amp; = \frac{1}{2}\int_{\mathbb{R}^d} \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x}) \Bigg( \left\|\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}})\right\|^2 \\
        &amp; \qquad\qquad - 2\boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) \cdot \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) + \left\|\boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x})\right\|^2\Bigg)\;\mathrm{d}\mathbf{x}\,\mathrm{d}\tilde{\mathbf{x}} + C_{\sigma, 1} - C_{\sigma, 2} \\
        &amp; = \frac{1}{2}\int_{\mathbb{R}^d} \int_{\mathbb{R}^d} {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) {\tilde p}_0(\mathbf{x})\left\| \boldsymbol{\psi}(\tilde{\mathbf{x}}; {\boldsymbol{\theta}}) - \boldsymbol{\nabla}_{\tilde{\mathbf{x}}}\log {\tilde p}_\sigma(\tilde{\mathbf{x}}|\mathbf{x}) \right\|^2 \mathrm{d}\mathbf{x}\,\mathrm{d}\tilde{\mathbf{x}} + C_{\sigma, 1} - C_{\sigma, 2} \\
        &amp; = {\tilde J}_{\mathrm{DSM{\tilde p}_\sigma}}({\boldsymbol{\theta}}) + C_\sigma,
    \end{align*}\]</p><p>where</p><p class="math-container">\[    C_\sigma = C_{\sigma, 1} - C_{\sigma, 2}.\]</p><h2 id="Numerical-example"><a class="docs-heading-anchor" href="#Numerical-example">Numerical example</a><a id="Numerical-example-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-example" title="Permalink"></a></h2><p>We illustrate, numerically, the use of the <strong>denoising (explicit) score matching</strong> objective <span>${\tilde J}_{\mathrm{DSM{\tilde p}_\sigma}}$</span> to model a synthetic univariate Gaussian mixture distribution. However, instead using an energy based method and model an energy potential of the density as done by <a href="https://doi.org/10.1162/NECO_a_00142">Vincent (2011)</a>, we model directly the score function.</p><h3 id="Julia-language-setup"><a class="docs-heading-anchor" href="#Julia-language-setup">Julia language setup</a><a id="Julia-language-setup-1"></a><a class="docs-heading-anchor-permalink" href="#Julia-language-setup" title="Permalink"></a></h3><p>We use the <a href="https://julialang.org">Julia programming language</a> for the numerical simulations, with suitable packages.</p><h4 id="Packages"><a class="docs-heading-anchor" href="#Packages">Packages</a><a id="Packages-1"></a><a class="docs-heading-anchor-permalink" href="#Packages" title="Permalink"></a></h4><pre><code class="language-julia hljs">using StatsPlots
using Random
using Distributions
using Lux # artificial neural networks explicitly parametrized
using Optimisers
using Zygote # automatic differentiation
using Markdown</code></pre><h4 id="Reproducibility"><a class="docs-heading-anchor" href="#Reproducibility">Reproducibility</a><a id="Reproducibility-1"></a><a class="docs-heading-anchor-permalink" href="#Reproducibility" title="Permalink"></a></h4><p>We set the random seed for reproducibility purposes.</p><pre><code class="language-julia hljs">rng = Xoshiro(12345)</code></pre><h3 id="Data"><a class="docs-heading-anchor" href="#Data">Data</a><a id="Data-1"></a><a class="docs-heading-anchor-permalink" href="#Data" title="Permalink"></a></h3><p>We build the usual target model and draw samples from it.</p><pre><code class="language-julia hljs">target_prob = MixtureModel([Normal(-3, 1), Normal(3, 1)], [0.1, 0.9])

xrange = range(-10, 10, 200)
dx = Float64(xrange.step)
xx = permutedims(collect(xrange))
target_pdf = pdf.(target_prob, xrange&#39;)
target_score = gradlogpdf.(target_prob, xrange&#39;)

sample_points = permutedims(rand(rng, target_prob, 1024))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1×1024 Matrix{Float64}:
 2.30308  2.84284  3.4103  3.68232  …  1.71428  2.75491  3.14101  2.48846</code></pre><p>Visualizing the sample data drawn from the distribution and the PDF.</p><img src="dabb289d.svg" alt="Example block output"/><p>Visualizing the score function.</p><img src="8ea41c5e.svg" alt="Example block output"/><h3 id="The-neural-network-model"><a class="docs-heading-anchor" href="#The-neural-network-model">The neural network model</a><a id="The-neural-network-model-1"></a><a class="docs-heading-anchor-permalink" href="#The-neural-network-model" title="Permalink"></a></h3><p>The neural network we consider is a simple feed-forward neural network made of a single hidden layer, obtained as a chain of a couple of dense layers. This is implemented with the <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> package.</p><p>We will see that we don&#39;t need a big neural network in this simple example. We go as low as it works.</p><pre><code class="language-julia hljs">model = Chain(Dense(1 =&gt; 8, relu), Dense(8 =&gt; 1))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(1 =&gt; 8, relu),      <span class="sgr90"># 16 parameters</span>
    layer_2 = Dense(8 =&gt; 1),            <span class="sgr90"># 9 parameters</span>
) <span class="sgr90">        # Total: </span>25 parameters,
<span class="sgr90">          #        plus </span>0 states.</code></pre><p>The <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> package uses explicit parameters, that are initialized (or obtained) with the <code>Lux.setup</code> function, giving us the <em>parameters</em> and the <em>state</em> of the model.</p><pre><code class="language-julia hljs">ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((layer_1 = (weight = Float32[-0.003556765; -1.8715183; … ; 0.66702616; -0.9373461;;], bias = Float32[0.18317068, 0.5787344, -0.18110967, 0.9307035, -0.43067825, -0.46645045, -0.8246051, -0.9340805]), layer_2 = (weight = Float32[0.27326134 -0.2086962 … 0.42855448 0.5658726], bias = Float32[0.09530755])), (layer_1 = NamedTuple(), layer_2 = NamedTuple()))</code></pre><h3 id="Loss-function"><a class="docs-heading-anchor" href="#Loss-function">Loss function</a><a id="Loss-function-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-function" title="Permalink"></a></h3><p>Here it is how we implement the <strong>empirical denoising score matching</strong> objective</p><p class="math-container">\[    {\tilde J}_{\mathrm{DSM{\tilde p}_{\sigma, 0}}}({\boldsymbol{\theta}}) = \frac{1}{2}\frac{1}{NM}\sum_{n=1}^N \sum_{m=1}^M \left\| \boldsymbol{\psi}(\mathbf{x}_{n, m}; {\boldsymbol{\theta}}) - \frac{\mathbf{x}_n - \tilde{\mathbf{x}}_{n, m}}{\sigma^2} \right\|^2 \mathrm{d}\tilde{\mathbf{x}}.\]</p><p>First we precompute the matrix <span>$(\mathbf{a}_{n,m})_{n,m}$</span> given by</p><p class="math-container">\[    \mathbf{a}_{n,m} = \frac{\mathbf{x}_n - \tilde{\mathbf{x}}_{n, m}}{\sigma^2}.\]</p><p>Then, at each iteration of the optimization process, we take the current parameters <span>$\boldsymbol{\theta}$</span> and apply the model to the perturbed points <span>$\tilde{\mathbf{x}}_{n, m}$</span> to obtain the predicted scores <span>$\{\boldsymbol{\psi}_{n,m}^{\boldsymbol{\theta}}\}$</span> with values</p><p class="math-container">\[    \boldsymbol{\psi}_{n,m}^{\boldsymbol{\theta}} = \boldsymbol{\psi}(\tilde{\mathbf{x}}_{n,m}, \boldsymbol{\theta}),\]</p><p>and then compute half the mean square distance between the two matrices:</p><p class="math-container">\[    \frac{1}{2}\sum_{m=1}^M \sum_{n=1}^N \left\| \boldsymbol{\psi}_{n,m}^{\boldsymbol{\theta}} - \mathbf{a}_{n,m}\right|^2.\]</p><p>In the implementation below, we just use <span>$M=1$</span>, so the matrices <span>$(\boldsymbol{\psi}_{n,m}^{\boldsymbol{\theta}})_{n,m}$</span> and <span>$(\mathbf{a}_{n,m})_{n,m}$</span> are actually just vectors. Besides, this is a scalar example, i.e. with <span>$d=1$</span>, so they are indeed plain real-valued vectors <span>$(\psi_{n,1})_n$</span> and <span>$(a_{n,1})_n$</span>.</p><p>In general, though, these objects <span>$(\boldsymbol{\psi}_{n,m}^{\boldsymbol{\theta}})_{n,m}$</span> and <span>$(\mathbf{a}_{n,m})_{n,m}$</span> are <span>$\mathbb{R}^d$</span>-vector-valued matrices.</p><p>So, here is how we prepare the data.</p><pre><code class="language-julia hljs">sigma = 0.3
noised_sample_points = sample_points .+ sigma .* randn(size(sample_points))
dsm_target = ( sample_points .- noised_sample_points ) ./ sigma ^ 2
data = (noised_sample_points, dsm_target)</code></pre><p>and here is the implementation of the loss function</p><pre><code class="language-julia hljs">function loss_function_dsm(model, ps, st, data)
    noised_sample_points, dsm_target = data
    y_score_pred, st = Lux.apply(model, noised_sample_points, ps, st)
    loss = mean(abs2, y_score_pred .- dsm_target) / 2
    return loss, st, ()
end</code></pre><h3 id="Optimization-setup"><a class="docs-heading-anchor" href="#Optimization-setup">Optimization setup</a><a id="Optimization-setup-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-setup" title="Permalink"></a></h3><h4 id="Optimization-method"><a class="docs-heading-anchor" href="#Optimization-method">Optimization method</a><a id="Optimization-method-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-method" title="Permalink"></a></h4><p>We use the Adam optimiser.</p><pre><code class="language-julia hljs">opt = Adam(0.01)

tstate_org = Lux.Training.TrainState(model, ps, st, opt)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">TrainState
    model: Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(1 =&gt; 8, relu), layer_2 = Dense(8 =&gt; 1)), nothing)
    # of parameters: 25
    # of states: 0
    optimizer: Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8)
    step: 0</code></pre><h4 id="Automatic-differentiation-in-the-optimization"><a class="docs-heading-anchor" href="#Automatic-differentiation-in-the-optimization">Automatic differentiation in the optimization</a><a id="Automatic-differentiation-in-the-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-differentiation-in-the-optimization" title="Permalink"></a></h4><p>As mentioned, we setup differentiation in <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> with the <a href="https://github.com/FluxML/Zygote.jl">FluxML/Zygote.jl</a> library.</p><pre><code class="language-julia hljs">vjp_rule = Lux.Training.AutoZygote()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ADTypes.AutoZygote()</code></pre><h4 id="Processor"><a class="docs-heading-anchor" href="#Processor">Processor</a><a id="Processor-1"></a><a class="docs-heading-anchor-permalink" href="#Processor" title="Permalink"></a></h4><p>We use the CPU instead of the GPU.</p><pre><code class="language-julia hljs">dev_cpu = cpu_device()
## dev_gpu = gpu_device()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(::MLDataDevices.CPUDevice) (generic function with 1 method)</code></pre><h4 id="Check-differentiation"><a class="docs-heading-anchor" href="#Check-differentiation">Check differentiation</a><a id="Check-differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Check-differentiation" title="Permalink"></a></h4><p>Check if Zygote via Lux is working fine to differentiate the loss functions for training.</p><pre><code class="language-julia hljs">Lux.Training.compute_gradients(vjp_rule, loss_function_dsm, data, tstate_org)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((layer_1 = (weight = Float32[-0.5267566; -0.016819999; … ; -0.8290766; 0.049060315;;], bias = Float32[-0.24741077, 0.002247631, -0.108209126, -0.22188646, 0.3179872, 0.07255608, -0.34661016, -0.00781215]), layer_2 = (weight = Float32[-0.15898645 -0.15706906 … -0.6234896 -0.06837107], bias = Float32[-0.90539986])), 5.925286824354095, (), Lux.Training.TrainState{Nothing, Nothing, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, @NamedTuple{layer_1::@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, layer_2::@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}}, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}}, Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, @NamedTuple{layer_1::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}}, layer_2::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}}}}(nothing, nothing, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(1 =&gt; 8, relu), layer_2 = Dense(8 =&gt; 1)), nothing), (layer_1 = (weight = Float32[-0.003556765; -1.8715183; … ; 0.66702616; -0.9373461;;], bias = Float32[0.18317068, 0.5787344, -0.18110967, 0.9307035, -0.43067825, -0.46645045, -0.8246051, -0.9340805]), layer_2 = (weight = Float32[0.27326134 -0.2086962 … 0.42855448 0.5658726], bias = Float32[0.09530755])), (layer_1 = NamedTuple(), layer_2 = NamedTuple()), Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), (layer_1 = (weight = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0; 0.0; … ; 0.0; 0.0;;], Float32[0.0; 0.0; … ; 0.0; 0.0;;], (0.9, 0.999))<span class="sgr32">)</span>, bias = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))<span class="sgr32">)</span>), layer_2 = (weight = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0], (0.9, 0.999))<span class="sgr32">)</span>, bias = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0], Float32[0.0], (0.9, 0.999))<span class="sgr32">)</span>)), 0))</code></pre><h4 id="Training-loop"><a class="docs-heading-anchor" href="#Training-loop">Training loop</a><a id="Training-loop-1"></a><a class="docs-heading-anchor-permalink" href="#Training-loop" title="Permalink"></a></h4><p>Here is the typical main training loop suggest in the <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> tutorials, but sligthly modified to save the history of losses per iteration.</p><pre><code class="language-julia hljs">function train(tstate, vjp, data, loss_function, epochs, numshowepochs=20, numsavestates=0)
    losses = zeros(epochs)
    tstates = [(0, tstate)]
    for epoch in 1:epochs
        grads, loss, stats, tstate = Lux.Training.compute_gradients(vjp,
            loss_function, data, tstate)
        if ( epochs ≥ numshowepochs &gt; 0 ) &amp;&amp; rem(epoch, div(epochs, numshowepochs)) == 0
            println(&quot;Epoch: $(epoch) || Loss: $(loss)&quot;)
        end
        if ( epochs ≥ numsavestates &gt; 0 ) &amp;&amp; rem(epoch, div(epochs, numsavestates)) == 0
            push!(tstates, (epoch, tstate))
        end
        losses[epoch] = loss
        tstate = Lux.Training.apply_gradients(tstate, grads)
    end
    return tstate, losses, tstates
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">train (generic function with 3 methods)</code></pre><h3 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h3><p>Now we train the model with the objective function <span>${\tilde J}_{\mathrm{ESM{\tilde p}_\sigma{\tilde p}_0}}({\boldsymbol{\theta}})$</span>.</p><pre><code class="language-julia hljs">@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_dsm, 500, 20, 125)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Warning: Mixed-Precision `matmul_cpu_fallback!` detected and Octavian.jl cannot be used for this set of inputs (C [Matrix{Float64}]: A [Matrix{Float32}] x B [Matrix{Float64}]). Falling back to generic implementation. This may be slow.
└ @ LuxLib.Impl ~/.julia/packages/LuxLib/1B1qw/src/impl/matmul.jl:190
Epoch: 25 || Loss: 5.546435361699053
Epoch: 50 || Loss: 5.3680215718276525
Epoch: 75 || Loss: 5.262723126341523
Epoch: 100 || Loss: 5.230705161220581
Epoch: 125 || Loss: 5.223518770380638
Epoch: 150 || Loss: 5.220228532655915
Epoch: 175 || Loss: 5.218587551060592
Epoch: 200 || Loss: 5.218006597414838
Epoch: 225 || Loss: 5.217707352026923
Epoch: 250 || Loss: 5.217567117701483
Epoch: 275 || Loss: 5.217469446710719
Epoch: 300 || Loss: 5.217402993962296
Epoch: 325 || Loss: 5.2173453286526295
Epoch: 350 || Loss: 5.21729438065879
Epoch: 375 || Loss: 5.217244098715848
Epoch: 400 || Loss: 5.217194924082553
Epoch: 425 || Loss: 5.217146425266852
Epoch: 450 || Loss: 5.217099852774568
Epoch: 475 || Loss: 5.2170483932369365
Epoch: 500 || Loss: 5.216998595316845
  0.144808 seconds (188.35 k allocations: 127.655 MiB, 23.48% gc time, 29.14% compilation time)</code></pre><h3 id="Results"><a class="docs-heading-anchor" href="#Results">Results</a><a id="Results-1"></a><a class="docs-heading-anchor-permalink" href="#Results" title="Permalink"></a></h3><p>Testing out the trained model.</p><pre><code class="language-julia hljs">y_pred = Lux.apply(tstate.model, xrange&#39;, tstate.parameters, tstate.states)[1]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1×200 Matrix{Float64}:
 5.22678  5.15083  5.07489  4.99894  4.923  …  -7.38612  -7.49651  -7.6069</code></pre><p>Visualizing the result.</p><pre><code class="language-julia hljs">plot(title=&quot;Fitting&quot;, titlefont=10)

plot!(xrange, target_score&#39;, linewidth=4, label=&quot;score function&quot;)

scatter!(sample_points&#39;, s -&gt; gradlogpdf(target_prob, s), label=&quot;data&quot;, markersize=2)

plot!(xx&#39;, y_pred&#39;, linewidth=2, label=&quot;predicted MLP&quot;)</code></pre><img src="a3057e7c.svg" alt="Example block output"/><p>Just for the fun of it, let us see an animation of the optimization process.</p><img src="49355741.gif" alt="Example block output"/><p>Recovering the PDF of the distribution from the trained score function.</p><pre><code class="language-julia hljs">paux = exp.(accumulate(+, y_pred) .* dx)
pdf_pred = paux ./ sum(paux) ./ dx
plot(title=&quot;Original PDF and PDF from predicted score function&quot;, titlefont=10)
plot!(xrange, target_pdf&#39;, label=&quot;original&quot;)
plot!(xrange, pdf_pred&#39;, label=&quot;recoverd&quot;)</code></pre><img src="804d9e39.svg" alt="Example block output"/><p>And the animation of the evolution of the PDF.</p><img src="35eaa45e.gif" alt="Example block output"/><p>We also visualize the evolution of the losses.</p><pre><code class="language-julia hljs">plot(losses, title=&quot;Evolution of the loss&quot;, titlefont=10, xlabel=&quot;iteration&quot;, ylabel=&quot;error&quot;, legend=false)</code></pre><img src="0ce96421.svg" alt="Example block output"/><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ol><li><a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011), &quot;A connection between score matching and denoising autoencoders,&quot; Neural Computation, 23 (7), 1661-1674, doi:10.1162/NECO<em>a</em>00142</a></li><li><a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005), &quot;Estimation of non-normalized statistical models by score matching&quot;, Journal of Machine Learning Research 6, 695-709</a></li><li><a href="https://www.jmlr.org/papers/v11/vincent10a.html">P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, and P.-A. Manzagol (2010), &quot;Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion&quot;. Journal of Machine Learning Research. 11 (110), 3371-3408</a></li><li><a href="https://doi.org/10.1002/AIC.690370209">M. A. Kramer (1991), &quot;Nonlinear principal component analysis using autoassociative neural networks&quot;, AIChE Journal. 37 (2), 233–243. doi:10.1002/aic.690370209.</a></li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../parzen_estimation_score_matching/">« Score matching with Parzen estimation</a><a class="docs-footer-nextpage" href="../sliced_score_matching/">Sliced score matching »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.13.0 on <span class="colophon-date" title="Thursday 26 June 2025 15:35">Thursday 26 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
