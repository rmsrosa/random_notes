<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Score-based SDE model · Random notes</title><meta name="title" content="Score-based SDE model · Random notes"/><meta property="og:title" content="Score-based SDE model · Random notes"/><meta property="twitter:title" content="Score-based SDE model · Random notes"/><meta name="description" content="Documentation for Random notes."/><meta property="og:description" content="Documentation for Random notes."/><meta property="twitter:description" content="Documentation for Random notes."/><meta property="og:url" content="https://github.com/rmsrosa/random_notes/generative/score_based_sde/"/><meta property="twitter:url" content="https://github.com/rmsrosa/random_notes/generative/score_based_sde/"/><link rel="canonical" href="https://github.com/rmsrosa/random_notes/generative/score_based_sde/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Random notes logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Random notes</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Random Notes</a></li><li><span class="tocitem">Probability Essentials</span><ul><li><a class="tocitem" href="../../probability/kernel_density_estimation/">Kernel Density Estimation</a></li><li><a class="tocitem" href="../../probability/convergence_notions/">Convergence notions</a></li></ul></li><li><span class="tocitem">Discrete-time Markov chains</span><ul><li><a class="tocitem" href="../../markov_chains/mc_definitions/">Essential definitions</a></li><li><a class="tocitem" href="../../markov_chains/mc_invariance/">Invariant distributions</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Countable-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_countableX_recurrence/">Recurrence in the countable-space case</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_connections/">Connected states, irreducibility and uniqueness of invariant measures</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_convergencia/">Aperiodicidade e convergência para a distribuição estacionária</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Continuous-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_irreducibility_and_recurrence/">Irreducibility and recurrence in the continuous-space case</a></li></ul></li></ul></li><li><span class="tocitem">Sampling methods</span><ul><li><a class="tocitem" href="../../sampling/overview/">Overview</a></li><li><a class="tocitem" href="../../sampling/prng/">Random number generators</a></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Transform methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/invFtransform/">Probability integral transform</a></li><li><a class="tocitem" href="../../sampling/box_muller/">Box-Muller transform</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Accept-Reject methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/rejection_sampling/">Rejection sampling</a></li><li><a class="tocitem" href="../../sampling/empiricalsup_rejection/">Empirical supremum rejection sampling</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Markov Chain Monte Carlo (MCMC)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/mcmc/">Overview</a></li><li><a class="tocitem" href="../../sampling/metropolis/">Metropolis and Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/convergence_metropolis/">Convergence of Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/gibbs/">Gibbs sampling</a></li><li><a class="tocitem" href="../../sampling/hmc/">Hamiltonian Monte Carlo (HMC)</a></li></ul></li><li><a class="tocitem" href="../../sampling/langevin_sampling/">Langevin sampling</a></li></ul></li><li><span class="tocitem">Bayesian inference</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Bayes Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/bayes/">Bayes Theorem</a></li><li><a class="tocitem" href="../../bayesian/bayes_inference/">Bayesian inference</a></li><li><a class="tocitem" href="../../bayesian/bernstein_vonmises/">Bernstein–von Mises theorem</a></li></ul></li><li><a class="tocitem" href="../../bayesian/bayesian_probprog/">Bayesian probabilistic programming</a></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/find_pi/">Estimating π via frequentist and Bayesian methods</a></li><li><a class="tocitem" href="../../bayesian/linear_regression/">Many Ways to Linear Regression</a></li><li><a class="tocitem" href="../../bayesian/tilapia_alometry/">Alometry law for the Nile Tilapia</a></li><li><a class="tocitem" href="../../bayesian/mortality_tables/">Modeling mortality tables</a></li></ul></li></ul></li><li><span class="tocitem">Generative models</span><ul><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox" checked/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Score matching</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../stein_score/">Stein score function</a></li><li><a class="tocitem" href="../score_matching_aapo/">Score matching of Aapo Hyvärinen</a></li><li><a class="tocitem" href="../score_matching_neural_network/">Score matching a neural network</a></li><li><a class="tocitem" href="../parzen_estimation_score_matching/">Score matching with Parzen estimation</a></li><li><a class="tocitem" href="../denoising_score_matching/">Denoising score matching of Pascal Vincent</a></li><li><a class="tocitem" href="../sliced_score_matching/">Sliced score matching</a></li><li><a class="tocitem" href="../1d_FD_score_matching/">1D finite-difference score matching</a></li><li><a class="tocitem" href="../2d_FD_score_matching/">2D finite-difference score matching</a></li><li><a class="tocitem" href="../ddpm/">Denoising diffusion probabilistic models</a></li><li><a class="tocitem" href="../mdsm/">Multiple denoising score matching</a></li><li><a class="tocitem" href="../probability_flow/">Probability flow</a></li><li><a class="tocitem" href="../reverse_flow/">Reverse probability flow</a></li><li class="is-active"><a class="tocitem" href>Score-based SDE model</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Forward-SDE"><span>Forward SDE</span></a></li><li><a class="tocitem" href="#Loss-function"><span>Loss function</span></a></li><li><a class="tocitem" href="#Numerical-example"><span>Numerical example</span></a></li><li><a class="tocitem" href="#Sampling-with-annealed-Langevin"><span>Sampling with annealed Langevin</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li></ul></li></ul></li><li><span class="tocitem">Sensitivity analysis</span><ul><li><a class="tocitem" href="../../sensitivity/overview/">Overview</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Generative models</a></li><li><a class="is-disabled">Score matching</a></li><li class="is-active"><a href>Score-based SDE model</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Score-based SDE model</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes/blob/main/docs/src/generative/score_based_sde.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Score-based-generative-modeling-through-stochastic-differential-equations"><a class="docs-heading-anchor" href="#Score-based-generative-modeling-through-stochastic-differential-equations">Score-based generative modeling through stochastic differential equations</a><a id="Score-based-generative-modeling-through-stochastic-differential-equations-1"></a><a class="docs-heading-anchor-permalink" href="#Score-based-generative-modeling-through-stochastic-differential-equations" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><h3 id="Aim"><a class="docs-heading-anchor" href="#Aim">Aim</a><a id="Aim-1"></a><a class="docs-heading-anchor-permalink" href="#Aim" title="Permalink"></a></h3><p>Review the work of <a href="https://arxiv.org/abs/2011.13456">Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020)</a> that takes a complex data distribution, adds noise to it via a stochastic differential equation and generates new samples by modeling the reverse process. It is a generalization to the continuous case of the previous discrete processes of <em>denoising diffusion probabilistic models</em> and <em>multiple denoising score matching.</em></p><h3 id="Background"><a class="docs-heading-anchor" href="#Background">Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h3><p>After <a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005)</a> proposed the <strong>implicit score matching</strong> to model a distribution by fitting its score function, several works followed it, including the <strong>denosing score matching</strong> of <a href="https://doi.org/10.1162/NECO_a_00142">Paul Vincent (2011)</a>, which perturbed the data so the analytic expression of the score function of the perturbation could be used. Then the <strong>denoising diffusion probabilistic models,</strong> of <a href="https://dl.acm.org/doi/10.5555/3045118.3045358">Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015)</a> and <a href="https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html">Ho, Jain, and Abbeel (2020)</a>, and the <strong>multiple denoising score matching,</strong> of <a href="https://dl.acm.org/doi/10.5555/3454287.3455354">Song and Ermon (2019)</a>, went one step further by adding several levels of noise, facilitating the generation process. The work of <a href="https://arxiv.org/abs/2011.13456">Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020)</a> extended that idea to the continuous case, adding noise via a stochastic differential equation.</p><h2 id="Forward-SDE"><a class="docs-heading-anchor" href="#Forward-SDE">Forward SDE</a><a id="Forward-SDE-1"></a><a class="docs-heading-anchor-permalink" href="#Forward-SDE" title="Permalink"></a></h2><p>A initial unknown probability distribution with density <span>$p_0=p_0(x),$</span> associated with a random variable <span>$X_0,$</span> is embedded into the distribution of an SDE of the form</p><p class="math-container">\[    \mathrm{d}X_t = f(t)X_t\;\mathrm{d}t + g(t)\;\mathrm{d}W_t,\]</p><p>with initial condition <span>$X_0.$</span> The solution can be obtained with the help of the integrating factor <span>$e^{-\int_0^t f(s)\;\mathrm{d}s}$</span> associated with the deterministic part of the equation. In this case,</p><p class="math-container">\[    \begin{aligned}
        \mathrm{d}\left(X_te^{-\int_0^t f(s)\;\mathrm{d}s}\right) &amp; = \mathrm{d}X_t e^{-\int_0^t f(s)\;\mathrm{d}s} - X_t f(t) e^{\int_0^t f(s)\;\mathrm{d}s} \;\mathrm{d}t \\
        &amp; = \left(f(t)X_t\;\mathrm{d}t + g(t)\;\mathrm{d}W_t\right)e^{-\int_0^t f(s)\;\mathrm{d}s} - X_t f(t) e^{-\int_0^t f(s)\;\mathrm{d}s} \;\mathrm{d}t \\
        &amp; = g(t)e^{-\int_0^t f(s)\;\mathrm{d}s}\;\mathrm{d}W_t.
    \end{aligned}\]</p><p>Integrating yields</p><p class="math-container">\[    X_te^{-\int_0^t f(s)\;\mathrm{d}s} - X_0 = \int_0^t g(s)e^{-\int_0^s f(\tau)\;\mathrm{d}\tau}\;\mathrm{d}W_s.\]</p><p>Moving the exponential term to the right hand side yields the solution</p><p class="math-container">\[    X_t = X_0 e^{\int_0^t f(s)\;\mathrm{d}s} + \int_0^t e^{\int_s^t f(\tau)\;\mathrm{d}\tau}g(s)\;\mathrm{d}W_s.\]</p><p>The mean value evolves according to</p><p class="math-container">\[    \mathbb{E}[X_t] = \mathbb{E}[X_0] e^{\int_0^t f(s)\;\mathrm{d}s}.\]</p><p>Using the Itô isometry, the second moment evolves with</p><p class="math-container">\[    \mathbb{E}[X_t^2] = \mathbb{E}[X_0^2]e^{2\int_0^t f(s)\;\mathrm{d}s} + \int_0^t e^{2\int_s^t f(\tau)\;\mathrm{d}\tau}g(s)^2\;\mathrm{d}s.\]</p><p>Hence, the variance is given by</p><p class="math-container">\[    \operatorname{Var}(X_t) = \operatorname{Var}(X_0)e^{2\int_0^t f(s)\;\mathrm{d}s} + \int_0^t e^{2\int_s^t f(\tau)\;\mathrm{d}\tau}g(s)^2\;\mathrm{d}s.\]</p><p>Thus, the probability density function <span>$p(t, x)$</span> can be obtained by conditioning it at each initial point, with</p><p class="math-container">\[    p(t, x) = \int_{\mathbb{R}} p(t, x | 0, x_0) p_0(x_0)\;\mathrm{d}x_0,\]</p><p>and</p><p class="math-container">\[    p(t, x | 0, x_0) = \mathcal{N}(x; \mu(t)x_0, \zeta(t)^2),\]</p><p>where</p><p class="math-container">\[    \mu(t) = e^{\int_0^t f(s)\;\mathrm{d}s}\]</p><p>and</p><p class="math-container">\[    \zeta(t)^2 = \int_0^t e^{2\int_s^t f(\tau)\;\mathrm{d}\tau}g(s)^2\;\mathrm{d}s.\]</p><p>The probability density function <span>$p(t, x)$</span> can also be obtained with the help of the Fokker-Planck equation</p><p class="math-container">\[    \frac{\partial p}{\partial t} + \nabla_x \cdot (f(t) p(t, x)) = \frac{1}{2}\Delta_x \left( g(t)^2 p(t, x) \right),\]</p><p>whose fundamental solutions are precisely <span>$p(t, x | 0, x_0) = \mathcal{N}(x; \mu(t)x_0, \zeta(t)^2).$</span></p><h3 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h3><h4 id="Variance-exploding-SDE"><a class="docs-heading-anchor" href="#Variance-exploding-SDE">Variance-exploding SDE</a><a id="Variance-exploding-SDE-1"></a><a class="docs-heading-anchor-permalink" href="#Variance-exploding-SDE" title="Permalink"></a></h4><p>For example, in the variance-exploding case (VE SDE), as discussed in <a href="https://arxiv.org/abs/2011.13456">Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020)</a>, as the continuous limit of the <em>Multiple Denoising Score Matching,</em> we have</p><p class="math-container">\[    f(t) = 0, \quad g(t) = \sqrt{\frac{\mathrm{d}(\sigma(t)^2)}{\mathrm{d}t}},\]</p><p>so that</p><p class="math-container">\[    \mu(t) = 1\]</p><p>and</p><p class="math-container">\[    \zeta(t)^2 = \int_0^t \frac{\mathrm{d}(\sigma(s)^2)}{\mathrm{d}s}\;\mathrm{d}s = \sigma(t)^2 - \sigma(0)^2.\]</p><p>Thus,</p><p class="math-container">\[    p(t, x | 0, x_0) = \mathcal{N}\left( x; 1, \sigma(t)^2 - \sigma(0)^2\right).\]</p><h4 id="Variance-preserving-SDE"><a class="docs-heading-anchor" href="#Variance-preserving-SDE">Variance-preserving SDE</a><a id="Variance-preserving-SDE-1"></a><a class="docs-heading-anchor-permalink" href="#Variance-preserving-SDE" title="Permalink"></a></h4><p>In the variance-preserving case (VP SDE), as discussed in <a href="https://arxiv.org/abs/2011.13456">Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020)</a>, as the continuous limit of the <em>Denoising Diffusion Probabilistic Model,</em></p><p class="math-container">\[    f(t) = -\frac{1}{2}\beta(t), \quad g(t) = \sqrt{\beta(t)},\]</p><p>so that</p><p class="math-container">\[    \mu(t) = e^{-\frac{1}{2}\int_0^t \beta(s)\;\mathrm{d}s}\]</p><p>and</p><p class="math-container">\[    \zeta(t)^2 = \int_0^t e^{-\int_s^t \beta(\tau)\;\mathrm{d}\tau}\beta(s)\;\mathrm{d}s = \left. -e^{-\int_s^t \beta(\tau)\;\mathrm{d}\tau} \right|_{s=0}^{s=t} = 1 - e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau}.\]</p><p>Thus,</p><p class="math-container">\[    p(t, x | 0, x_0) = \mathcal{N}\left( x; e^{-\frac{1}{2}\int_0^t \beta(s)\;\mathrm{d}s}, 1 - e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau}\right).\]</p><h4 id="Sub-variance-preserving-SDE"><a class="docs-heading-anchor" href="#Sub-variance-preserving-SDE">Sub-variance-preserving SDE</a><a id="Sub-variance-preserving-SDE-1"></a><a class="docs-heading-anchor-permalink" href="#Sub-variance-preserving-SDE" title="Permalink"></a></h4><p>In the sub-variance-preserving case (VP SDE), proposed in <a href="https://arxiv.org/abs/2011.13456">Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020)</a> as an alternative to the previous ones,</p><p class="math-container">\[    f(t) = -\frac{1}{2}\beta(t), \quad g(t) = \sqrt{\beta(t)(1 - e^{-2\int_0^t \beta(s)\;\mathrm{d}s})},\]</p><p>so that</p><p class="math-container">\[    \mu(t) = e^{-\frac{1}{2}\int_0^t \beta(s)\;\mathrm{d}s}\]</p><p>and</p><p class="math-container">\[    \begin{align*}
        \zeta(t)^2 &amp; = \int_0^t e^{-\int_s^t \beta(\tau)\;\mathrm{d}\tau}\beta(s)(1 - e^{-2\int_0^s \beta(\tau)\;\mathrm{d}\tau})\;\mathrm{d}s \\
        &amp; = \int_0^t e^{-\int_s^t \beta(\tau)\;\mathrm{d}\tau}\beta(s)\;\mathrm{d}s - \int_0^t e^{-\int_s^t \beta(\tau)\;\mathrm{d}\tau}e^{-2\int_0^s \beta(\tau)\;\mathrm{d}\tau}\beta(s)\;\mathrm{d}s \\
        &amp; = \int_0^t e^{-\int_s^t \beta(\tau)\;\mathrm{d}\tau}\beta(s)\;\mathrm{d}s - \int_0^t e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau}e^{-\int_0^s \beta(\tau)\;\mathrm{d}\tau}\beta(s)\;\mathrm{d}s \\
        &amp; = 1 - e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau} - e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau} \int_0^t e^{-\int_0^s \beta(\tau)\;\mathrm{d}\tau}\beta(s)\;\mathrm{d}s \\
        &amp; = 1 - e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau} + e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau} \left.e^{-\int_0^s \beta(\tau)\;\mathrm{d}\tau}\right|_{s=0}^t \\
        &amp; = 1 - e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau} + e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau} \left(e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau} - 1\right) \\
        &amp; = 1 - 2e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau} + e^{-2\int_0^t \beta(\tau)\;\mathrm{d}\tau} \\
        &amp; = \left(1 - e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau}\right)^2.
    \end{align*}\]</p><p>Thus,</p><p class="math-container">\[    p(t, x | 0, x_0) = \mathcal{N}\left( x; e^{-\frac{1}{2}\int_0^t \beta(s)\;\mathrm{d}s}, \left(1 - e^{-\int_0^t \beta(\tau)\;\mathrm{d}\tau}\right)^2\right).\]</p><h2 id="Loss-function"><a class="docs-heading-anchor" href="#Loss-function">Loss function</a><a id="Loss-function-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-function" title="Permalink"></a></h2><p>The loss function for training is a continuous version of the loss for the multiple denoising score-matching. In that case, we had</p><p class="math-container">\[    J_{\textrm{SMLD}}(\boldsymbol{\theta}) = \frac{1}{2L}\sum_{i=1}^L \lambda(\sigma_i) \mathbb{E}_{p(\mathbf{x})p_{\sigma_i}(\tilde{\mathbf{x}}|\mathbf{x})}\left[ \left\| s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}, \sigma_i) - \frac{\mathbf{x} - \tilde{\mathbf{x}}}{\sigma_i^2} \right\|^2 \right],\]</p><p>where <span>$\lambda = \lambda(\sigma_i)$</span> is a weighting factor. When too many levels are considered, one takes a stochastic approach and approximate the loss <span>$J_{\textrm{SMLD}}(\boldsymbol{\theta})$</span> by</p><p class="math-container">\[    J_{\textrm{SMLD}}^*(\boldsymbol{\theta}) = \frac{1}{2}\lambda(\sigma_i) \mathbb{E}_{p(\mathbf{x})p_{\sigma_i}(\tilde{\mathbf{x}}|\mathbf{x})}\left[ \left\| s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}, \sigma_i) - \frac{\mathbf{x} - \tilde{\mathbf{x}}}{\sigma_i^2} \right\|^2 \right],\]</p><p>with</p><p class="math-container">\[    \sigma_i \sim \operatorname{Uniform}[\{1, 2, \ldots, L\}].\]</p><p>The continuous version becomes</p><p class="math-container">\[    J_{\textrm{SDE}}^*(\boldsymbol{\theta}) = \frac{1}{2}\lambda(t) \mathbb{E}_{p_0(\mathbf{x}_0)p(t, \tilde{\mathbf{x}}|0, \mathbf{x}_0)}\left[ \left\| s_{\boldsymbol{\theta}}(t, \tilde{\mathbf{x}}) - \boldsymbol{\nabla}_{\tilde{\mathbf{x}}} p(t, \tilde{\mathbf{x}}|0, \mathbf{x}_0) \right\|^2 \right],\]</p><p>with</p><p class="math-container">\[    t \sim \operatorname{Uniform}[0, T].\]</p><p>In practice, the empirical distribution is considered for <span>$p_0(\mathbf{x}_0),$</span> and a stochastic approach is taken by sampling a single <span>$\tilde{\mathbf{x}}_n \sim p(t_n, \tilde{\mathbf{x}}|0, \mathbf{x}_n),$</span> besides <span>$t_n \sim \operatorname{Uniform}([0, T]).$</span> Thus, the loss takes the form</p><p class="math-container">\[    {\tilde J}_{\textrm{SDE}}^*(\boldsymbol{\theta}) = \frac{1}{2N}\sum_{n=1}^N \lambda(t_n) \left[ \left\| s_{\boldsymbol{\theta}}(t_n, \tilde{\mathbf{x}}_n) - \boldsymbol{\nabla}_{\tilde{\mathbf{x}}} p(t_n, \tilde{\mathbf{x}}_n|0, \mathbf{x}_n) \right\|^2 \right],\]</p><p>with</p><p class="math-container">\[    \mathbf{x}_n \sim p_0, \quad t_n \sim \operatorname{Uniform}[0, T], \quad \mathbf{x}_n \sim p(t_n, x | 0, \mathbf{x}_n).\]</p><p>The explicit form for the distribution <span>$p(t_n, x | 0, \mathbf{x}_n)$</span> and its score <span>$\boldsymbol{\nabla}_{\tilde{\mathbf{x}}} p(t_n, \tilde{\mathbf{x}}_n|0, \mathbf{x}_n)$</span> depends on the choice of the SDE.</p><h2 id="Numerical-example"><a class="docs-heading-anchor" href="#Numerical-example">Numerical example</a><a id="Numerical-example-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-example" title="Permalink"></a></h2><p>We illustrate, numerically, the use of the <strong>score-based SDE method</strong> to model a synthetic univariate Gaussian mixture distribution.</p><h3 id="Julia-language-setup"><a class="docs-heading-anchor" href="#Julia-language-setup">Julia language setup</a><a id="Julia-language-setup-1"></a><a class="docs-heading-anchor-permalink" href="#Julia-language-setup" title="Permalink"></a></h3><p>We use the <a href="https://julialang.org">Julia programming language</a> for the numerical simulations, with suitable packages.</p><h4 id="Packages"><a class="docs-heading-anchor" href="#Packages">Packages</a><a id="Packages-1"></a><a class="docs-heading-anchor-permalink" href="#Packages" title="Permalink"></a></h4><pre><code class="language-julia hljs">using StatsPlots
using Random
using Distributions
using Lux # artificial neural networks explicitly parametrized
using Optimisers
using Zygote # automatic differentiation
using Markdown</code></pre><h4 id="Reproducibility"><a class="docs-heading-anchor" href="#Reproducibility">Reproducibility</a><a id="Reproducibility-1"></a><a class="docs-heading-anchor-permalink" href="#Reproducibility" title="Permalink"></a></h4><p>We set the random seed for reproducibility purposes.</p><pre><code class="language-julia hljs">rng = Xoshiro(12345)</code></pre><h3 id="Data"><a class="docs-heading-anchor" href="#Data">Data</a><a id="Data-1"></a><a class="docs-heading-anchor-permalink" href="#Data" title="Permalink"></a></h3><p>We build the usual target model and draw samples from it.</p><p>Visualizing the sample data drawn from the distribution and the PDF.</p><img src="8c65a45b.svg" alt="Example block output"/><p>Visualizing the score function.</p><img src="6b5be90b.svg" alt="Example block output"/><h3 id="Parameters"><a class="docs-heading-anchor" href="#Parameters">Parameters</a><a id="Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Parameters" title="Permalink"></a></h3><p>Here we set some parameters for the model and prepare any necessary data.</p><pre><code class="language-julia hljs">trange = 0.0:0.01:1.0</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.0:0.01:1.0</code></pre><h4 id="Variance-exploding"><a class="docs-heading-anchor" href="#Variance-exploding">Variance exploding</a><a id="Variance-exploding-1"></a><a class="docs-heading-anchor-permalink" href="#Variance-exploding" title="Permalink"></a></h4><pre><code class="language-julia hljs">sigma_min = 0.01
sigma_max = 1.0

f_ve(t) = 0.0
g_ve(t; σₘᵢₙ = sigma_min, σₘₐₓ = sigma_max) = σₘᵢₙ * ( σₘₐₓ / σₘᵢₙ)^t * √(2 * log(σₘₐₓ/σₘᵢₙ))

prob_kernel_ve(t, x0; σₘᵢₙ = sigma_min, σₘₐₓ = sigma_max) = Normal( x0, σₘᵢₙ^2 * (σₘₐₓ/σₘᵢₙ)^(2t) )
p_kernel_ve(t, x, x0) = pdf(prob_kernel_ve(t, x0), x)
score_kernel_ve(t, x, x0) = gradlogpdf(prob_kernel_ve(t, x, x0), x)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">score_kernel_ve (generic function with 1 method)</code></pre><pre><code class="language-julia hljs">surface(trange, xrange, (t, x) -&gt; log(sum(x0 -&gt; pdf(prob_kernel_ve(t, x0), x) * pdf(target_prob, x0), xrange)))</code></pre><img src="28be7b58.svg" alt="Example block output"/><pre><code class="language-julia hljs">heatmap(trange, xrange, (t, x) -&gt; log(sum(x0 -&gt; pdf(prob_kernel_ve(t, x0), x) * pdf(target_prob, x0), xrange)))</code></pre><img src="45f66b58.svg" alt="Example block output"/><h4 id="Variance-preserving"><a class="docs-heading-anchor" href="#Variance-preserving">Variance preserving</a><a id="Variance-preserving-1"></a><a class="docs-heading-anchor-permalink" href="#Variance-preserving" title="Permalink"></a></h4><pre><code class="language-julia hljs">beta_min = 0.1
beta_max = 20.0

f_vp(t; βₘᵢₙ=beta_min, βₘₐₓ=beta_max) = ( βₘᵢₙ + t * ( βₘₐₓ - βₘᵢₙ ) ) / 2
g_vp(t; βₘᵢₙ=beta_min, βₘₐₓ=beta_max) = √( βₘᵢₙ + t * ( βₘₐₓ - βₘᵢₙ ) )

prob_kernel_vp(t, x0; βₘᵢₙ=beta_min, βₘₐₓ=beta_max) = Normal( x0 * exp( - t^4 * ( βₘₐₓ - βₘᵢₙ ) / 4 - t * βₘᵢₙ / 2 ), 1 - exp( - t^4 * ( βₘₐₓ - βₘᵢₙ ) / 2 - t * βₘᵢₙ ))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">prob_kernel_vp (generic function with 1 method)</code></pre><pre><code class="language-julia hljs">surface(trange, xrange, (t, x) -&gt; log(sum(x0 -&gt; pdf(prob_kernel_vp(t, x0), x) * pdf(target_prob, x0), xrange)))</code></pre><img src="3829d35e.svg" alt="Example block output"/><pre><code class="language-julia hljs">heatmap(trange, xrange, (t, x) -&gt; log(sum(x0 -&gt; pdf(prob_kernel_vp(t, x0), x) * pdf(target_prob, x0), xrange)))</code></pre><img src="68361933.svg" alt="Example block output"/><pre><code class="language-julia hljs">L = 6
sigma_1 = 2.0
sigma_L = 0.5
theta = ( sigma_L / sigma_1 )^(1/(L-1))
sigmas = [sigma_1 * theta ^ (i-1) for i in 1:L]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">6-element Vector{Float64}:
 2.0
 1.515716566510398
 1.1486983549970349
 0.870550563296124
 0.659753955386447
 0.49999999999999983</code></pre><pre><code class="language-julia hljs">data = (sample_points, sigmas)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([0.8606155918844086 -1.0314315213443432 … -0.9717983805592734 0.8976929261501944], [2.0, 1.515716566510398, 1.1486983549970349, 0.870550563296124, 0.659753955386447, 0.49999999999999983])</code></pre><h3 id="The-neural-network-model"><a class="docs-heading-anchor" href="#The-neural-network-model">The neural network model</a><a id="The-neural-network-model-1"></a><a class="docs-heading-anchor-permalink" href="#The-neural-network-model" title="Permalink"></a></h3><p>The neural network we consider is a simple feed-forward neural network made of a single hidden layer, obtained as a chain of a couple of dense layers. This is implemented with the <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> package.</p><p>We will see that we don&#39;t need a big neural network in this simple example. We go as low as it works.</p><pre><code class="language-julia hljs">model = Chain(Dense(2 =&gt; 64, relu), Dense(64 =&gt; 1))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(2 =&gt; 64, relu),     <span class="sgr90"># 192 parameters</span>
    layer_2 = Dense(64 =&gt; 1),           <span class="sgr90"># 65 parameters</span>
) <span class="sgr90">        # Total: </span>257 parameters,
<span class="sgr90">          #        plus </span>0 states.</code></pre><p>The <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> package uses explicit parameters, that are initialized (or obtained) with the <code>Lux.setup</code> function, giving us the <em>parameters</em> and the <em>state</em> of the model.</p><pre><code class="language-julia hljs">ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((layer_1 = (weight = Float32[0.96560603 -1.3963945; -0.864941 1.1274849; … ; 0.7158331 1.1567085; 2.3663533 1.2393725], bias = Float32[0.18311752, 0.4076413, 0.6408686, -0.013799805, 0.65769726, 0.27097112, -0.11596697, 0.48491788, -0.42007604, 0.118874006  …  0.1418748, -0.5943321, -0.60492563, 0.5363705, 0.31154066, -0.022509282, 0.3484151, 0.14444627, 0.36740452, -0.6803152]), layer_2 = (weight = Float32[0.09065902 0.13053486 … 0.042090528 0.21522477], bias = Float32[0.004801482])), (layer_1 = NamedTuple(), layer_2 = NamedTuple()))</code></pre><h3 id="Loss-function-2"><a class="docs-heading-anchor" href="#Loss-function-2">Loss function</a><a class="docs-heading-anchor-permalink" href="#Loss-function-2" title="Permalink"></a></h3><pre><code class="language-julia hljs">function loss_function_sde(model, ps, st, data)
    sample_points, sigmas = data

    noisy_sample_points = sample_points .+ sigmas .* randn(rng, size(sample_points))
    scores = ( sample_points .- noisy_sample_points ) ./ sigmas .^ 2

    flattened_noisy_sample_points = reshape(noisy_sample_points, 1, :)
    flattened_sigmas = repeat(sigmas&#39;, 1, length(sample_points))
    model_input = [flattened_noisy_sample_points; flattened_sigmas]

    y_score_pred, st = Lux.apply(model, model_input, ps, st)

    flattened_scores = reshape(scores, 1, :)

    loss = mean(abs2, flattened_sigmas .* (y_score_pred .- flattened_scores)) / 2

    return loss, st, ()
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">loss_function_sde (generic function with 1 method)</code></pre><h3 id="Optimization-setup"><a class="docs-heading-anchor" href="#Optimization-setup">Optimization setup</a><a id="Optimization-setup-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-setup" title="Permalink"></a></h3><h4 id="Optimization-method"><a class="docs-heading-anchor" href="#Optimization-method">Optimization method</a><a id="Optimization-method-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-method" title="Permalink"></a></h4><p>We use the Adam optimiser.</p><pre><code class="language-julia hljs">opt = Adam(0.01)

tstate_org = Lux.Training.TrainState(model, ps, st, opt)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">TrainState
    model: Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(2 =&gt; 64, relu), layer_2 = Dense(64 =&gt; 1)), nothing)
    # of parameters: 257
    # of states: 0
    optimizer: Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8)
    step: 0</code></pre><h4 id="Automatic-differentiation-in-the-optimization"><a class="docs-heading-anchor" href="#Automatic-differentiation-in-the-optimization">Automatic differentiation in the optimization</a><a id="Automatic-differentiation-in-the-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-differentiation-in-the-optimization" title="Permalink"></a></h4><p>As mentioned, we setup differentiation in <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> with the <a href="https://github.com/FluxML/Zygote.jl">FluxML/Zygote.jl</a> library.</p><pre><code class="language-julia hljs">vjp_rule = Lux.Training.AutoZygote()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ADTypes.AutoZygote()</code></pre><h4 id="Processor"><a class="docs-heading-anchor" href="#Processor">Processor</a><a id="Processor-1"></a><a class="docs-heading-anchor-permalink" href="#Processor" title="Permalink"></a></h4><p>We use the CPU instead of the GPU.</p><pre><code class="language-julia hljs">dev_cpu = cpu_device()
## dev_gpu = gpu_device()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(::MLDataDevices.CPUDevice) (generic function with 1 method)</code></pre><h4 id="Check-differentiation"><a class="docs-heading-anchor" href="#Check-differentiation">Check differentiation</a><a id="Check-differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Check-differentiation" title="Permalink"></a></h4><p>Check if Zygote via Lux is working fine to differentiate the loss functions for training.</p><pre><code class="language-julia hljs">Lux.Training.compute_gradients(vjp_rule, loss_function_sde, data, tstate_org)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((layer_1 = (weight = Float32[0.34248495 0.17144734; 0.3385421 0.43916073; … ; 0.23387475 0.2079672; 1.198205 1.0327464], bias = Float32[0.111951314, 0.255828, 0.05792513, -0.1414185, 0.011816772, -0.1453327, -0.040131677, 0.0, 0.17985131, 0.16945557  …  -0.20052071, -0.061180312, -0.339524, 0.113274135, -0.4008663, -0.14912026, 0.08600748, -0.020066934, 0.12535073, 0.6215555]), layer_2 = (weight = Float32[1.2331666 2.348907 … 10.78692 17.15639], bias = Float32[2.9029262])), 6.685081362917852, (), Lux.Training.TrainState{Nothing, Nothing, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, @NamedTuple{layer_1::@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, layer_2::@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}}, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}}, Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, @NamedTuple{layer_1::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}}, layer_2::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}}}}(nothing, nothing, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(2 =&gt; 64, relu), layer_2 = Dense(64 =&gt; 1)), nothing), (layer_1 = (weight = Float32[0.96560603 -1.3963945; -0.864941 1.1274849; … ; 0.7158331 1.1567085; 2.3663533 1.2393725], bias = Float32[0.18311752, 0.4076413, 0.6408686, -0.013799805, 0.65769726, 0.27097112, -0.11596697, 0.48491788, -0.42007604, 0.118874006  …  0.1418748, -0.5943321, -0.60492563, 0.5363705, 0.31154066, -0.022509282, 0.3484151, 0.14444627, 0.36740452, -0.6803152]), layer_2 = (weight = Float32[0.09065902 0.13053486 … 0.042090528 0.21522477], bias = Float32[0.004801482])), (layer_1 = NamedTuple(), layer_2 = NamedTuple()), Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), (layer_1 = (weight = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0 0.0; 0.0 0.0; … ; 0.0 0.0; 0.0 0.0], Float32[0.0 0.0; 0.0 0.0; … ; 0.0 0.0; 0.0 0.0], (0.9, 0.999))<span class="sgr32">)</span>, bias = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))<span class="sgr32">)</span>), layer_2 = (weight = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0], (0.9, 0.999))<span class="sgr32">)</span>, bias = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0], Float32[0.0], (0.9, 0.999))<span class="sgr32">)</span>)), 0))</code></pre><h4 id="Training-loop"><a class="docs-heading-anchor" href="#Training-loop">Training loop</a><a id="Training-loop-1"></a><a class="docs-heading-anchor-permalink" href="#Training-loop" title="Permalink"></a></h4><p>Here is the typical main training loop suggest in the <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> tutorials, but sligthly modified to save the history of losses per iteration.</p><pre><code class="language-julia hljs">function train(tstate, vjp, data, loss_function, epochs, numshowepochs=20, numsavestates=0)
    losses = zeros(epochs)
    tstates = [(0, tstate)]
    for epoch in 1:epochs
        grads, loss, stats, tstate = Lux.Training.compute_gradients(vjp,
            loss_function, data, tstate)
        if ( epochs ≥ numshowepochs &gt; 0 ) &amp;&amp; rem(epoch, div(epochs, numshowepochs)) == 0
            println(&quot;Epoch: $(epoch) || Loss: $(loss)&quot;)
        end
        if ( epochs ≥ numsavestates &gt; 0 ) &amp;&amp; rem(epoch, div(epochs, numsavestates)) == 0
            push!(tstates, (epoch, tstate))
        end
        losses[epoch] = loss
        tstate = Lux.Training.apply_gradients(tstate, grads)
    end
    return tstate, losses, tstates
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">train (generic function with 3 methods)</code></pre><h3 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h3><p>Now we train the model with the objective function <span>${\tilde J}_{\mathrm{ESM{\tilde p}_\sigma{\tilde p}_0}}({\boldsymbol{\theta}})$</span>.</p><pre><code class="language-julia hljs">@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_sde, 1000, 20, 125)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Warning: Mixed-Precision `matmul_cpu_fallback!` detected and Octavian.jl cannot be used for this set of inputs (C [Matrix{Float64}]: A [Matrix{Float32}] x B [Matrix{Float64}]). Falling back to generic implementation. This may be slow.
└ @ LuxLib.Impl ~/.julia/packages/LuxLib/1B1qw/src/impl/matmul.jl:190
Epoch: 50 || Loss: 0.2825422092260028
Epoch: 100 || Loss: 0.2664865870837632
Epoch: 150 || Loss: 0.27509917457510513
Epoch: 200 || Loss: 0.25550228691048
Epoch: 250 || Loss: 0.24452857389854796
Epoch: 300 || Loss: 0.23809200120701077
Epoch: 350 || Loss: 0.23584896317371198
Epoch: 400 || Loss: 0.2419833316277218
Epoch: 450 || Loss: 0.22898116619073225
Epoch: 500 || Loss: 0.23564025395575575
Epoch: 550 || Loss: 0.20653899841845824
Epoch: 600 || Loss: 0.20108098836715735
Epoch: 650 || Loss: 0.2252943786223162
Epoch: 700 || Loss: 0.21997904580626185
Epoch: 750 || Loss: 0.2125949631680312
Epoch: 800 || Loss: 0.20827904310322956
Epoch: 850 || Loss: 0.19328358064767995
Epoch: 900 || Loss: 0.20871206386816585
Epoch: 950 || Loss: 0.2064316094779668
Epoch: 1000 || Loss: 0.21487302803497235
  7.378145 seconds (511.96 k allocations: 10.010 GiB, 12.17% gc time, 0.66% compilation time)</code></pre><h3 id="Results"><a class="docs-heading-anchor" href="#Results">Results</a><a id="Results-1"></a><a class="docs-heading-anchor-permalink" href="#Results" title="Permalink"></a></h3><p>Checking out the trained model.</p><img src="3e5f84f9.svg" alt="Example block output"/><p>Visualizing the result with the smallest noise.</p><img src="bd435059.svg" alt="Example block output"/><p>Recovering the PDF of the distribution from the trained score function.</p><img src="667101b3.svg" alt="Example block output"/><p>With the smallest noise.</p><img src="33c3aaa2.svg" alt="Example block output"/><p>Just for the fun of it, let us see an animation of the optimization process.</p><img src="dae2e84a.gif" alt="Example block output"/><p>And the animation of the evolution of the PDF.</p><img src="a6b570f7.gif" alt="Example block output"/><p>We also visualize the evolution of the losses.</p><img src="5280b4d2.svg" alt="Example block output"/><h2 id="Sampling-with-annealed-Langevin"><a class="docs-heading-anchor" href="#Sampling-with-annealed-Langevin">Sampling with annealed Langevin</a><a id="Sampling-with-annealed-Langevin-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling-with-annealed-Langevin" title="Permalink"></a></h2><p>Now we sample the modeled distribution with the annealed Langevin method described earlier.</p><p>Here are the trajectories.</p><img src="ef494cc0.svg" alt="Example block output"/><p>The sample histogram obtained at the end of the trajectories.</p><img src="9b24732a.svg" alt="Example block output"/><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ol><li><a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005), &quot;Estimation of non-normalized statistical models by score matching&quot;, Journal of Machine Learning Research 6, 695-709</a></li><li><a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011), &quot;A connection between score matching and denoising autoencoders,&quot; Neural Computation, 23 (7), 1661-1674, doi:10.1162/NECO<em>a</em>00142</a></li><li><a href="https://dl.acm.org/doi/10.5555/3045118.3045358">J. Sohl-Dickstein, E. A. Weiss, N. Maheswaranathan, S. Ganguli (2015), &quot;Deep unsupervised learning using nonequilibrium thermodynamics&quot;, ICML&#39;15: Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, 2256-2265</a></li><li><a href="https://dl.acm.org/doi/10.5555/3454287.3455354">Y. Song and S. Ermon (2019), &quot;Generative modeling by estimating gradients of the data distribution&quot;, NIPS&#39;19: Proceedings of the 33rd International Conference on Neural Information Processing Systems, no. 1067, 11918-11930</a></li><li><a href="https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html">J. Ho, A. Jain, P. Abbeel (2020), &quot;Denoising diffusion probabilistic models&quot;, in Advances in Neural Information Processing Systems 33, NeurIPS2020</a></li><li><a href="https://arxiv.org/abs/2011.13456">Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, B. Poole (2020), &quot;Score-based generative modeling through stochastic differential equations&quot;, arXiv:2011.13456</a></li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../reverse_flow/">« Reverse probability flow</a><a class="docs-footer-nextpage" href="../../sensitivity/overview/">Overview »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.13.0 on <span class="colophon-date" title="Thursday 26 June 2025 15:36">Thursday 26 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
