<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Score matching with Parzen estimation · Random notes</title><meta name="title" content="Score matching with Parzen estimation · Random notes"/><meta property="og:title" content="Score matching with Parzen estimation · Random notes"/><meta property="twitter:title" content="Score matching with Parzen estimation · Random notes"/><meta name="description" content="Documentation for Random notes."/><meta property="og:description" content="Documentation for Random notes."/><meta property="twitter:description" content="Documentation for Random notes."/><meta property="og:url" content="https://github.com/rmsrosa/random_notes/generative/parzen_estimation_score_matching/"/><meta property="twitter:url" content="https://github.com/rmsrosa/random_notes/generative/parzen_estimation_score_matching/"/><link rel="canonical" href="https://github.com/rmsrosa/random_notes/generative/parzen_estimation_score_matching/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Random notes logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Random notes</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Random Notes</a></li><li><span class="tocitem">Probability Essentials</span><ul><li><a class="tocitem" href="../../probability/kernel_density_estimation/">Kernel Density Estimation</a></li><li><a class="tocitem" href="../../probability/convergence_notions/">Convergence notions</a></li></ul></li><li><span class="tocitem">Discrete-time Markov chains</span><ul><li><a class="tocitem" href="../../markov_chains/mc_definitions/">Essential definitions</a></li><li><a class="tocitem" href="../../markov_chains/mc_invariance/">Invariant distributions</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Countable-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_countableX_recurrence/">Recurrence in the countable-space case</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_connections/">Connected states, irreducibility and uniqueness of invariant measures</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_convergencia/">Aperiodicidade e convergência para a distribuição estacionária</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Continuous-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_irreducibility_and_recurrence/">Irreducibility and recurrence in the continuous-space case</a></li></ul></li></ul></li><li><span class="tocitem">Sampling methods</span><ul><li><a class="tocitem" href="../../sampling/overview/">Overview</a></li><li><a class="tocitem" href="../../sampling/prng/">Random number generators</a></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Transform methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/invFtransform/">Probability integral transform</a></li><li><a class="tocitem" href="../../sampling/box_muller/">Box-Muller transform</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Accept-Reject methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/rejection_sampling/">Rejection sampling</a></li><li><a class="tocitem" href="../../sampling/empiricalsup_rejection/">Empirical supremum rejection sampling</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Markov Chain Monte Carlo (MCMC)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/mcmc/">Overview</a></li><li><a class="tocitem" href="../../sampling/metropolis/">Metropolis and Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/convergence_metropolis/">Convergence of Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/gibbs/">Gibbs sampling</a></li><li><a class="tocitem" href="../../sampling/hmc/">Hamiltonian Monte Carlo (HMC)</a></li></ul></li><li><a class="tocitem" href="../../sampling/langevin_sampling/">Langevin sampling</a></li></ul></li><li><span class="tocitem">Bayesian inference</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Bayes Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/bayes/">Bayes Theorem</a></li><li><a class="tocitem" href="../../bayesian/bayes_inference/">Bayesian inference</a></li><li><a class="tocitem" href="../../bayesian/bernstein_vonmises/">Bernstein–von Mises theorem</a></li></ul></li><li><a class="tocitem" href="../../bayesian/bayesian_probprog/">Bayesian probabilistic programming</a></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/find_pi/">Estimating π via frequentist and Bayesian methods</a></li><li><a class="tocitem" href="../../bayesian/linear_regression/">Many Ways to Linear Regression</a></li><li><a class="tocitem" href="../../bayesian/tilapia_alometry/">Alometry law for the Nile Tilapia</a></li><li><a class="tocitem" href="../../bayesian/mortality_tables/">Modeling mortality tables</a></li></ul></li></ul></li><li><span class="tocitem">Generative models</span><ul><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox" checked/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Score matching</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../stein_score/">Stein score function</a></li><li><a class="tocitem" href="../score_matching_aapo/">Score matching of Aapo Hyvärinen</a></li><li><a class="tocitem" href="../score_matching_neural_network/">Score matching a neural network</a></li><li class="is-active"><a class="tocitem" href>Score matching with Parzen estimation</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Objective-function-approximating-the-explicit-score-matching-objective"><span>Objective function approximating the explicit score matching objective</span></a></li><li><a class="tocitem" href="#Numerical-example"><span>Numerical example</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../denoising_score_matching/">Denoising score matching of Pascal Vincent</a></li><li><a class="tocitem" href="../sliced_score_matching/">Sliced score matching</a></li><li><a class="tocitem" href="../1d_FD_score_matching/">1D finite-difference score matching</a></li><li><a class="tocitem" href="../2d_FD_score_matching/">2D finite-difference score matching</a></li><li><a class="tocitem" href="../ddpm/">Denoising diffusion probabilistic models</a></li><li><a class="tocitem" href="../mdsm/">Multiple denoising score matching</a></li><li><a class="tocitem" href="../probability_flow/">Probability flow</a></li><li><a class="tocitem" href="../reverse_flow/">Reverse probability flow</a></li><li><a class="tocitem" href="../score_based_sde/">Score-based SDE model</a></li></ul></li></ul></li><li><span class="tocitem">Sensitivity analysis</span><ul><li><a class="tocitem" href="../../sensitivity/overview/">Overview</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Generative models</a></li><li><a class="is-disabled">Score matching</a></li><li class="is-active"><a href>Score matching with Parzen estimation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Score matching with Parzen estimation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes/blob/main/docs/src/generative/parzen_estimation_score_matching.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Score-matching-with-Parzen-estimation"><a class="docs-heading-anchor" href="#Score-matching-with-Parzen-estimation">Score matching with Parzen estimation</a><a id="Score-matching-with-Parzen-estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Score-matching-with-Parzen-estimation" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><h3 id="Aim"><a class="docs-heading-anchor" href="#Aim">Aim</a><a id="Aim-1"></a><a class="docs-heading-anchor-permalink" href="#Aim" title="Permalink"></a></h3><p>Explore the use of <em>Parzen kernel estimation</em> to approximate the <strong>explicit score matching</strong>, used as the basis for the <strong>implicit score matching</strong> objective proposed by <a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005)</a> and discussed <em>en passant</em> by <a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011)</a> on their way to the <strong>denoising score matching</strong> objective. We illustrate the method by fiting a multi-layer perceptron to model the score function of a one-dimensional synthetic Gaussian-mixture distribution.</p><h3 id="Motivation"><a class="docs-heading-anchor" href="#Motivation">Motivation</a><a id="Motivation-1"></a><a class="docs-heading-anchor-permalink" href="#Motivation" title="Permalink"></a></h3><p>The motivation is to continue building a solid background on score-matching diffusion.</p><h3 id="Background"><a class="docs-heading-anchor" href="#Background">Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h3><p><a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005)</a> proposed fitting directly the score of a distribution. This is obtained, in theory, by minimizing an <strong>explicit score matching</strong> objective function (i.e. the Fisher divergence). However, this function requires knowing the supposedly unknown target score function. The trick used by <a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005)</a> was then to do an integration by parts and rewrite the optimization problem in terms of an <strong>implicit score matching</strong> objective function, which yields the same minima and does not require further information from the target distribution other than some sample points. The <strong>implicit score matching</strong> method requires, however, the derivative of the  score function of the model, which is costly to compute in general.</p><p>Then, <a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011)</a> explored the idea of using <em>non-parametric Parzen density estimation</em> to directly approximate the explicit score matching objective, making a connection with denoising autoenconders, and proposing the <strong>denoising (explicit) score matching</strong> method.</p><p>We will detail denoising score matching in a separate note. Here, we stop at the Parzen density estimation idea, which was used in <a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011)</a> only as a step towards the denoising score matching. We call this method the <strong>Parzen estimated (explicit) score matching</strong> method. We also model directly the score of the distribution, as proposed in 1. <a href="https://dl.acm.org/doi/10.5555/3454287.3455354">Song and Ermon (2019)</a>, instead of the pdf or an energy potential of the pdf, as done earlier.</p><h2 id="Objective-function-approximating-the-explicit-score-matching-objective"><a class="docs-heading-anchor" href="#Objective-function-approximating-the-explicit-score-matching-objective">Objective function approximating the explicit score matching objective</a><a id="Objective-function-approximating-the-explicit-score-matching-objective-1"></a><a class="docs-heading-anchor-permalink" href="#Objective-function-approximating-the-explicit-score-matching-objective" title="Permalink"></a></h2><p>The score-matching method from <a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005)</a> aims to fit the model score function <span>$\psi(\mathbf{x}; {\boldsymbol{\theta}})$</span> to the score function <span>$\psi_X(\mathbf{x})$</span> of a random variable <span>$\mathbf{X}$</span> by minimizing the  <strong>implicit score matching</strong> objective</p><p class="math-container">\[    J_{\mathrm{ISM}}({\boldsymbol{\theta}}) = \int_{\mathbb{R}^d} p_{\mathbf{X}}(\mathbf{x}) \left( \frac{1}{2}\left\|\boldsymbol{\psi}(\mathbf{x}; {\boldsymbol{\theta}})\right\|^2 + \boldsymbol{\nabla}_{\mathbf{x}} \cdot \boldsymbol{\psi}(\mathbf{x}; {\boldsymbol{\theta}}) \right)\;\mathrm{d}\mathbf{x},\]</p><p>which is equivalent to minimizing the <strong>explicit score matching</strong> objective</p><p class="math-container">\[    J_{\mathrm{ESM}}({\boldsymbol{\theta}}) = \frac{1}{2}\int_{\mathbb{R}^d} p_{\mathbf{X}}(\mathbf{x}) \left\|\boldsymbol{\psi}(\mathbf{x}; {\boldsymbol{\theta}}) - \boldsymbol{\psi}_{\mathbf{X}}(\mathbf{x})\right\|^2\;\mathrm{d}\mathbf{x},\]</p><p>due to the following identity obtained via integration by parts in the expectation</p><p class="math-container">\[    J_{\mathrm{ESM}}({\boldsymbol{\theta}}) = {\tilde J}_{\mathrm{ISM}}({\boldsymbol{\theta}}) + C,\]</p><p>where <span>$C$</span> is constant with respect to the parameters. The advantage of <span>${\tilde J}_{\mathrm{ISM}}({\boldsymbol{\theta}})$</span> is that it does not involve the unknown score function of <span>$X$</span>. It does, however, involve the gradient of the modeled score function, which is expensive to compute.</p><p>In practice, this is further approximated by the <strong>empirical distribution</strong> <span>${\tilde p}_0(\mathbf{x})$</span> given by</p><p class="math-container">\[    {\tilde p}_0(\mathbf{x}) = \frac{1}{N}\sum_{n=1}^N \delta(\mathbf{x} - \mathbf{x}_n),\]</p><p>so the implemented objective is the <strong>empirical implicit score matching</strong> objective</p><p class="math-container">\[    {\tilde J}_{\mathrm{ISM}{\tilde p}_0}({\boldsymbol{\theta}}) = \frac{1}{N}\sum_{n=1}^N \left( \frac{1}{2}\left\|\boldsymbol{\psi}(\mathbf{x}_n; {\boldsymbol{\theta}})\right\|^2 + \boldsymbol{\nabla}_{\mathbf{x}} \cdot \boldsymbol{\psi}(\mathbf{x}_n; {\boldsymbol{\theta}}) \right).\]</p><p><a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005)</a> briefly mentions that minimizing <span>$J_{\mathrm{ESM}}({\boldsymbol{\theta}})$</span> directly is &quot;basically a non-parametric estimation problem&quot;, but dismisses it for the &quot;simple trick of partial integration to compute the objective function very easily&quot;. As we have seen, the trick is fine for model functions for which we can compute the gradient without much trouble, but for modeling it with a neural network, for instance, it becomes computationally expensive.</p><p>A few years later, <a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011)</a> considered the idea of using a Parzel kernel density estimation</p><p class="math-container">\[    {\tilde p}_\sigma(\mathbf{x}) = \frac{1}{\sigma^d}\int_{\mathbb{R}^d} K\left(\frac{\mathbf{x} - \mathbf{x}_n}{\sigma}\right) \;\mathrm{d}{\tilde p}_0(\mathbf{x}) = \frac{1}{\sigma^d N}\sum_{n=1}^N K\left(\frac{\mathbf{x} - \mathbf{x}_n}{\sigma}\right),\]</p><p>where <span>$\sigma &gt; 0$</span> is a kernel window parameter and <span>$K(\mathbf{x})$</span> is a kernel density (properly normalized to have mass one). In this way, the explicit score matching objective function is approximated by the <strong>Parzen-estimated explicit score matching</strong> objective</p><p class="math-container">\[    {\tilde J}_{\mathrm{P_\sigma ESM}}({\boldsymbol{\theta}}) = \frac{1}{2}\int_{\mathbb{R}^d} {\tilde p}_\sigma(\mathbf{x}) \left\|\boldsymbol{\psi}(\mathbf{x}; {\boldsymbol{\theta}}) - \boldsymbol{\nabla}_{\mathbf{x}}\log {\tilde p}_\sigma(\mathbf{x})\right\|^2\;\mathrm{d}\mathbf{x},\]</p><p>which is then further approximated with the empirical distribution, yielding the <strong>empirical Parzen-estimated explicit score matching</strong></p><p class="math-container">\[    \begin{align*}
        {\tilde J}_{\mathrm{P_\sigma ESM{\tilde p}_0}}({\boldsymbol{\theta}}) &amp; = \frac{1}{2}\int_{\mathbb{R}^d} {\tilde p}_0(\mathbf{x}) \left\|\boldsymbol{\psi}(\mathbf{x}; {\boldsymbol{\theta}}) - \boldsymbol{\nabla}_{\mathbf{x}}\log {\tilde p}_\sigma(\mathbf{x})\right\|^2\;\mathrm{d}\mathbf{x} \\
        &amp; = \frac{1}{N} \sum_{n=1}^N \left\|\boldsymbol{\psi}(\mathbf{x}_n; {\boldsymbol{\theta}}) - \boldsymbol{\nabla}_{\mathbf{x}_n}\log {\tilde p}_\sigma(\mathbf{x})\right\|^2.
    \end{align*}\]</p><p>However, <a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011)</a> did not use this as a final objective function. Pascal further simplified the objective function <span>${\tilde J}_{\mathrm{P_\sigma ESM}}({\boldsymbol{\theta}})$</span> by expanding the gradient of the logpdf of the Parzen estimator, writing a double integral with a conditional probability, and switching the order of integration. We will do this in a follow up note, but for the moment we will stop at <span>${\tilde J}_{\mathrm{P_\sigma ESM}}({\boldsymbol{\theta}})$</span> and <span>${\tilde J}_{\mathrm{P_\sigma ESM{\tilde p}_0}}({\boldsymbol{\theta}})$</span>, use a Gaussian estimator, and see how this works.</p><p>Computing the score function with the Parzen estimation amounts to</p><p class="math-container">\[    \begin{align*}
        \boldsymbol{\nabla}_{\mathbf{x}}\log {\tilde p}_\sigma(\mathbf{x}) &amp; = \boldsymbol{\nabla}_{\mathbf{x}}\log\left( \frac{1}{\sigma^d N}\sum_{n=1}^N K\left(\frac{\mathbf{x} - \mathbf{x}_n}{\sigma}\right)\right) \\
        &amp; = \frac{1}{{\tilde p}_\sigma(\mathbf{x})} \frac{1}{\sigma^d N}\sum_{n=1}^N \boldsymbol{\nabla}_{\mathbf{x}} \left(K\left(\frac{\mathbf{x} - \mathbf{x}_n}{\sigma}\right)\right) \\
        &amp; = \frac{1}{{\tilde p}_\sigma(\mathbf{x})} \frac{1}{\sigma^d N}\sum_{n=1}^N \frac{1}{\sigma}\left(\boldsymbol{\nabla}_{\mathbf{x}} K\right)\left(\frac{\mathbf{x} - \mathbf{x}_n}{\sigma}\right).
    \end{align*}\]</p><p>If we use the standard Gaussian kernel</p><p class="math-container">\[    G(\mathbf{x}) = \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2} \mathbf{x}^2},\]</p><p>then</p><p class="math-container">\[    \left(\boldsymbol{\nabla}_{\mathbf{x}} G\right)(\mathbf{x}) = \frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2} \mathbf{x}^2} \mathbf{x} = G(\mathbf{x})\mathbf{x},\]</p><p>so that</p><p class="math-container">\[    \boldsymbol{\nabla}_{\mathbf{x}}\log {\tilde p}_\sigma(\mathbf{x}) = \frac{1}{{\tilde p}_\sigma(\mathbf{x})} \frac{1}{\sigma^d N}\sum_{n=1}^N G\left(\frac{\mathbf{x} - \mathbf{x}_n}{\sigma}\right)\frac{\mathbf{x} - \mathbf{x}_n}{\sigma^2}.\]</p><p>Notice that this can be computed beforehand at the sample points, just with the knowledge of the sample points themselves. Indeed, renaming the index above from <span>$n$</span> to <span>$j$</span>, and computing the approximate score function at each sample point <span>$\mathbf{x}_n$</span> yield</p><p class="math-container">\[    \boldsymbol{\nabla}_{\mathbf{x}}\log {\tilde p}_\sigma(\mathbf{x}_n) = \frac{1}{{\tilde p}_\sigma(\mathbf{x}_n)} \frac{1}{\sigma^d N}\sum_{n=1}^N G\left(\frac{\mathbf{x}_n - \mathbf{x}_j}{\sigma}\right)\frac{\mathbf{x}_n - \mathbf{x}_j}{\sigma^2},\]</p><p>where</p><p class="math-container">\[{\tilde p}_\sigma(\mathbf{x}_n) = \frac{1}{\sigma^d N}\sum_{j=1}^N G\left(\frac{\mathbf{x} - \mathbf{x}_j}{\sigma}\right).\]</p><p>Then, the explicit score matching objective approximated with the Parzen kernel estimator and with the empirical distribution yields the objective</p><p class="math-container">\[    {\tilde J}_{\mathrm{P_\sigma ESM{\tilde p}_0}}({\boldsymbol{\theta}}) = \frac{1}{2}\frac{1}{N} \sum_{n=1}^N \left\|\boldsymbol{\psi}(\mathbf{x}_n; {\boldsymbol{\theta}}) - \boldsymbol{\nabla}_{\mathbf{x}}\log {\tilde p}_\sigma(\mathbf{x}_n)\right\|^2.\]</p><h2 id="Numerical-example"><a class="docs-heading-anchor" href="#Numerical-example">Numerical example</a><a id="Numerical-example-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-example" title="Permalink"></a></h2><p>We illustrate, numerically, the use of the <strong>empirical Parzen-estimated explicit score matching</strong> objective <span>${\tilde J}_{\mathrm{P_\sigma ESM{\tilde p}_0}}$</span> to model a synthetic univariate Gaussian mixture distribution.</p><h3 id="Julia-language-setup"><a class="docs-heading-anchor" href="#Julia-language-setup">Julia language setup</a><a id="Julia-language-setup-1"></a><a class="docs-heading-anchor-permalink" href="#Julia-language-setup" title="Permalink"></a></h3><p>We use the <a href="https://julialang.org">Julia programming language</a> for the numerical simulations, with suitable packages.</p><h4 id="Packages"><a class="docs-heading-anchor" href="#Packages">Packages</a><a id="Packages-1"></a><a class="docs-heading-anchor-permalink" href="#Packages" title="Permalink"></a></h4><pre><code class="language-julia hljs">using StatsPlots
using Random
using Distributions
using Lux # artificial neural networks explicitly parametrized
using Optimisers
using Zygote # automatic differentiation
using Markdown</code></pre><p>There are several Julia libraries for artificial neural networks and for automatic differentiation (AD). As discussed in a previous note, we will use here the <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> library, which is taylored to the differential equations <a href="https://sciml.ai">SciML</a> ecosystem.</p><h4 id="Reproducibility"><a class="docs-heading-anchor" href="#Reproducibility">Reproducibility</a><a id="Reproducibility-1"></a><a class="docs-heading-anchor-permalink" href="#Reproducibility" title="Permalink"></a></h4><p>We set the random seed for reproducibility purposes.</p><pre><code class="language-julia hljs">rng = Xoshiro(12345)</code></pre><h3 id="Data"><a class="docs-heading-anchor" href="#Data">Data</a><a id="Data-1"></a><a class="docs-heading-anchor-permalink" href="#Data" title="Permalink"></a></h3><p>We build the target model and draw samples from it.</p><p>The target model is a univariate random variable denoted by <span>$X$</span> and defined by a probability distribution. Associated with that we consider its PDF and its score-function.</p><pre><code class="language-julia hljs">target_prob = MixtureModel([Normal(-3, 1), Normal(3, 1)], [0.1, 0.9])

xrange = range(-10, 10, 200)
dx = Float64(xrange.step)
xx = permutedims(collect(xrange))
target_pdf = pdf.(target_prob, xrange&#39;)
target_score = gradlogpdf.(target_prob, xrange&#39;)

sample_points = permutedims(rand(rng, target_prob, 1024))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1×1024 Matrix{Float64}:
 2.30308  2.84284  3.4103  3.68232  …  1.71428  2.75491  3.14101  2.48846</code></pre><p>Visualizing the sample data drawn from the distribution and the PDF.</p><img src="e4b2e544.svg" alt="Example block output"/><p>Visualizing the score function.</p><img src="883ad87c.svg" alt="Example block output"/><p>For the Parzen estimated score matching, we need to pre-compute the score function of the Parzen estimation.</p><pre><code class="language-julia hljs">G(x) = exp(-x^2 / 2) / √(2π)

psigma(x, sigma, sample_points) = mean(G( (x - xn) / sigma ) for xn in sample_points) / sigma

score_parzen(x, sigma, sample_points) = mean(G( (x - xn) / sigma ) * (xn - x) / sigma^2 for xn in sample_points) / psigma(x, sigma, sample_points) / sigma</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">score_parzen (generic function with 1 method)</code></pre><p>The Parzen estimated score function is highly sensitive to the window parameter <span>$\sigma$</span>:</p><img src="ce2d6232.svg" alt="Example block output"/><pre><code class="language-julia hljs">sigma = 0.5
score_parzen_points = map(x -&gt; score_parzen(x, sigma, sample_points), sample_points)
data = (sample_points, score_parzen_points)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([2.303077959422043 2.8428423932782843 … 3.1410080972036334 2.488464630750972], [0.5909442505839475 0.15076935144375442 … -0.10704209580452212 0.4520888778084795])</code></pre><div class="markdown"><p>We choose the value &#36;\sigma &#61; 0.5&#36;.</p>
</div><img src="22ef1ae8.svg" alt="Example block output"/><h3 id="The-neural-network-model"><a class="docs-heading-anchor" href="#The-neural-network-model">The neural network model</a><a id="The-neural-network-model-1"></a><a class="docs-heading-anchor-permalink" href="#The-neural-network-model" title="Permalink"></a></h3><p>The neural network we consider is a simple feed-forward neural network made of a single hidden layer, obtained as a chain of a couple of dense layers. This is implemented with the <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> package.</p><p>We will see that we don&#39;t need a big neural network in this simple example. We go as low as it works.</p><pre><code class="language-julia hljs">model = Chain(Dense(1 =&gt; 8, relu), Dense(8 =&gt; 1))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(1 =&gt; 8, relu),      <span class="sgr90"># 16 parameters</span>
    layer_2 = Dense(8 =&gt; 1),            <span class="sgr90"># 9 parameters</span>
) <span class="sgr90">        # Total: </span>25 parameters,
<span class="sgr90">          #        plus </span>0 states.</code></pre><p>The <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> package uses explicit parameters, that are initialized (or obtained) with the <code>Lux.setup</code> function, giving us the <em>parameters</em> and the <em>state</em> of the model.</p><pre><code class="language-julia hljs">ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((layer_1 = (weight = Float32[-0.003556765; -1.8715183; … ; 0.66702616; -0.9373461;;], bias = Float32[0.18317068, 0.5787344, -0.18110967, 0.9307035, -0.43067825, -0.46645045, -0.8246051, -0.9340805]), layer_2 = (weight = Float32[0.27326134 -0.2086962 … 0.42855448 0.5658726], bias = Float32[0.09530755])), (layer_1 = NamedTuple(), layer_2 = NamedTuple()))</code></pre><h3 id="Loss-function"><a class="docs-heading-anchor" href="#Loss-function">Loss function</a><a id="Loss-function-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-function" title="Permalink"></a></h3><p>Here it is how we implement the objective <span>${\tilde J}_{\mathrm{P_\sigma ESM{\tilde p}_0}}({\boldsymbol{\theta}})$</span>.</p><pre><code class="language-julia hljs">function loss_function_parzen(model, ps, st, data)
    sample_points, score_parzen_points = data
    y_score_pred, st = Lux.apply(model, sample_points, ps, st)
    loss = mean(abs2, y_score_pred .- score_parzen_points)
    return loss, st, ()
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">loss_function_parzen (generic function with 1 method)</code></pre><h3 id="Optimization-setup"><a class="docs-heading-anchor" href="#Optimization-setup">Optimization setup</a><a id="Optimization-setup-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-setup" title="Permalink"></a></h3><h4 id="Optimization-method"><a class="docs-heading-anchor" href="#Optimization-method">Optimization method</a><a id="Optimization-method-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-method" title="Permalink"></a></h4><p>We use the Adam optimiser.</p><pre><code class="language-julia hljs">opt = Adam(0.01)

tstate_org = Lux.Training.TrainState(model, ps, st, opt)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">TrainState
    model: Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(1 =&gt; 8, relu), layer_2 = Dense(8 =&gt; 1)), nothing)
    # of parameters: 25
    # of states: 0
    optimizer: Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8)
    step: 0</code></pre><h4 id="Automatic-differentiation-in-the-optimization"><a class="docs-heading-anchor" href="#Automatic-differentiation-in-the-optimization">Automatic differentiation in the optimization</a><a id="Automatic-differentiation-in-the-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-differentiation-in-the-optimization" title="Permalink"></a></h4><p>As mentioned, we setup differentiation in <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> with the <a href="https://github.com/FluxML/Zygote.jl">FluxML/Zygote.jl</a> library.</p><pre><code class="language-julia hljs">vjp_rule = Lux.Training.AutoZygote()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ADTypes.AutoZygote()</code></pre><h4 id="Processor"><a class="docs-heading-anchor" href="#Processor">Processor</a><a id="Processor-1"></a><a class="docs-heading-anchor-permalink" href="#Processor" title="Permalink"></a></h4><p>We use the CPU instead of the GPU.</p><pre><code class="language-julia hljs">dev_cpu = cpu_device()
## dev_gpu = gpu_device()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(::MLDataDevices.CPUDevice) (generic function with 1 method)</code></pre><h4 id="Check-differentiation"><a class="docs-heading-anchor" href="#Check-differentiation">Check differentiation</a><a id="Check-differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Check-differentiation" title="Permalink"></a></h4><p>Check if Zygote via Lux is working fine to differentiate the loss functions for training.</p><pre><code class="language-julia hljs">Lux.Training.compute_gradients(vjp_rule, loss_function_parzen, data, tstate_org)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((layer_1 = (weight = Float32[-1.1681719; -0.031349946; … ; -1.8529496; 0.085765265;;], bias = Float32[-0.4716841, 0.0065649897, -0.20609447, -0.421418, 0.60616744, 0.13954438, -0.6792602, -0.01314271]), layer_2 = (weight = Float32[-0.30097115 -0.29934126 … -1.5770327 -0.1203723], bias = Float32[-1.7261282])), 0.9676230699994186, (), Lux.Training.TrainState{Nothing, Nothing, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, @NamedTuple{layer_1::@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, layer_2::@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}}, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}}, Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, @NamedTuple{layer_1::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}}, layer_2::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}}}}(nothing, nothing, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(1 =&gt; 8, relu), layer_2 = Dense(8 =&gt; 1)), nothing), (layer_1 = (weight = Float32[-0.003556765; -1.8715183; … ; 0.66702616; -0.9373461;;], bias = Float32[0.18317068, 0.5787344, -0.18110967, 0.9307035, -0.43067825, -0.46645045, -0.8246051, -0.9340805]), layer_2 = (weight = Float32[0.27326134 -0.2086962 … 0.42855448 0.5658726], bias = Float32[0.09530755])), (layer_1 = NamedTuple(), layer_2 = NamedTuple()), Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), (layer_1 = (weight = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0; 0.0; … ; 0.0; 0.0;;], Float32[0.0; 0.0; … ; 0.0; 0.0;;], (0.9, 0.999))<span class="sgr32">)</span>, bias = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))<span class="sgr32">)</span>), layer_2 = (weight = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0], (0.9, 0.999))<span class="sgr32">)</span>, bias = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0], Float32[0.0], (0.9, 0.999))<span class="sgr32">)</span>)), 0))</code></pre><h4 id="Training-loop"><a class="docs-heading-anchor" href="#Training-loop">Training loop</a><a id="Training-loop-1"></a><a class="docs-heading-anchor-permalink" href="#Training-loop" title="Permalink"></a></h4><p>Here is the typical main training loop suggest in the <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> tutorials, but sligthly modified to save the history of losses per iteration.</p><pre><code class="language-julia hljs">function train(tstate, vjp, data, loss_function, epochs, numshowepochs=20, numsavestates=0)
    losses = zeros(epochs)
    tstates = [(0, tstate)]
    for epoch in 1:epochs
        grads, loss, stats, tstate = Lux.Training.compute_gradients(vjp,
            loss_function, data, tstate)
        if ( epochs ≥ numshowepochs &gt; 0 ) &amp;&amp; rem(epoch, div(epochs, numshowepochs)) == 0
            println(&quot;Epoch: $(epoch) || Loss: $(loss)&quot;)
        end
        if ( epochs ≥ numsavestates &gt; 0 ) &amp;&amp; rem(epoch, div(epochs, numsavestates)) == 0
            push!(tstates, (epoch, tstate))
        end
        losses[epoch] = loss
        tstate = Lux.Training.apply_gradients(tstate, grads)
    end
    return tstate, losses, tstates
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">train (generic function with 3 methods)</code></pre><h3 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h3><p>Now we train the model with the objective function <span>${\tilde J}_{\mathrm{P_\sigma ESM{\tilde p}_0}}({\boldsymbol{\theta}})$</span>.</p><pre><code class="language-julia hljs">@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_parzen, 500, 20, 125)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Warning: Mixed-Precision `matmul_cpu_fallback!` detected and Octavian.jl cannot be used for this set of inputs (C [Matrix{Float64}]: A [Matrix{Float32}] x B [Matrix{Float64}]). Falling back to generic implementation. This may be slow.
└ @ LuxLib.Impl ~/.julia/packages/LuxLib/1B1qw/src/impl/matmul.jl:190
Epoch: 25 || Loss: 0.3146751538692399
Epoch: 50 || Loss: 0.14475783539036852
Epoch: 75 || Loss: 0.04822871096088892
Epoch: 100 || Loss: 0.01422081589813772
Epoch: 125 || Loss: 0.007780503754661453
Epoch: 150 || Loss: 0.005983948559172082
Epoch: 175 || Loss: 0.005365842308950139
Epoch: 200 || Loss: 0.005176360564815512
Epoch: 225 || Loss: 0.005055584121408747
Epoch: 250 || Loss: 0.004969020452845882
Epoch: 275 || Loss: 0.004903591148776164
Epoch: 300 || Loss: 0.004846139113962426
Epoch: 325 || Loss: 0.004793438006817945
Epoch: 350 || Loss: 0.004743980275946228
Epoch: 375 || Loss: 0.004696628294573014
Epoch: 400 || Loss: 0.004651043999609307
Epoch: 425 || Loss: 0.004606712599424626
Epoch: 450 || Loss: 0.004563380058778279
Epoch: 475 || Loss: 0.004520931298427852
Epoch: 500 || Loss: 0.004482978076567467
  0.217206 seconds (188.35 k allocations: 127.579 MiB, 31.06% gc time, 24.23% compilation time)</code></pre><h3 id="Results"><a class="docs-heading-anchor" href="#Results">Results</a><a id="Results-1"></a><a class="docs-heading-anchor-permalink" href="#Results" title="Permalink"></a></h3><p>Testing out the trained model.</p><pre><code class="language-julia hljs">y_pred = Lux.apply(tstate.model, xrange&#39;, tstate.parameters, tstate.states)[1]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1×200 Matrix{Float64}:
 5.97032  5.88188  5.79343  5.70499  5.61655  …  -5.29022  -5.36861  -5.44701</code></pre><p>Visualizing the result.</p><pre><code class="language-julia hljs">plot(title=&quot;Fitting&quot;, titlefont=10)

plot!(xrange, target_score&#39;, linewidth=4, label=&quot;score function&quot;)

scatter!(sample_points&#39;, s -&gt; gradlogpdf(target_prob, s), label=&quot;data&quot;, markersize=2)

plot!(xx&#39;, y_pred&#39;, linewidth=2, label=&quot;predicted MLP&quot;)</code></pre><img src="f36bca8f.svg" alt="Example block output"/><p>Just for the fun of it, let us see an animation of the optimization process.</p><img src="b39f94a3.gif" alt="Example block output"/><p>Recovering the PDF of the distribution from the trained score function.</p><pre><code class="language-julia hljs">paux = exp.(accumulate(+, y_pred) .* dx)
pdf_pred = paux ./ sum(paux) ./ dx
plot(title=&quot;Original PDF and PDF from predicted score function&quot;, titlefont=10)
plot!(xrange, target_pdf&#39;, label=&quot;original&quot;)
plot!(xrange, pdf_pred&#39;, label=&quot;recoverd&quot;)</code></pre><img src="b9c1599a.svg" alt="Example block output"/><p>And the animation of the evolution of the PDF.</p><img src="352a0958.gif" alt="Example block output"/><p>We also visualize the evolution of the losses.</p><pre><code class="language-julia hljs">plot(losses, title=&quot;Evolution of the loss&quot;, titlefont=10, xlabel=&quot;iteration&quot;, ylabel=&quot;error&quot;, legend=false)</code></pre><img src="2dca3ca1.svg" alt="Example block output"/><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ol><li><a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011), &quot;A connection between score matching and denoising autoencoders,&quot; Neural Computation, 23 (7), 1661-1674, doi:10.1162/NECO<em>a</em>00142</a></li><li><a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005), &quot;Estimation of non-normalized statistical models by score matching&quot;, Journal of Machine Learning Research 6, 695-709</a></li><li><a href="https://dl.acm.org/doi/10.5555/3454287.3455354">Y. Song and S. Ermon (2019), &quot;Generative modeling by estimating gradients of the data distribution&quot;, NIPS&#39;19: Proceedings of the 33rd International Conference on Neural Information Processing Systems, no. 1067, 11918-11930</a></li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../score_matching_neural_network/">« Score matching a neural network</a><a class="docs-footer-nextpage" href="../denoising_score_matching/">Denoising score matching of Pascal Vincent »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.13.0 on <span class="colophon-date" title="Thursday 26 June 2025 15:37">Thursday 26 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
