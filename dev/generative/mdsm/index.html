<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Multiple denoising score matching · Random notes</title><meta name="title" content="Multiple denoising score matching · Random notes"/><meta property="og:title" content="Multiple denoising score matching · Random notes"/><meta property="twitter:title" content="Multiple denoising score matching · Random notes"/><meta name="description" content="Documentation for Random notes."/><meta property="og:description" content="Documentation for Random notes."/><meta property="twitter:description" content="Documentation for Random notes."/><meta property="og:url" content="https://github.com/rmsrosa/random_notes/generative/mdsm/"/><meta property="twitter:url" content="https://github.com/rmsrosa/random_notes/generative/mdsm/"/><link rel="canonical" href="https://github.com/rmsrosa/random_notes/generative/mdsm/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Random notes logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Random notes</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Random Notes</a></li><li><span class="tocitem">Probability Essentials</span><ul><li><a class="tocitem" href="../../probability/kernel_density_estimation/">Kernel Density Estimation</a></li><li><a class="tocitem" href="../../probability/convergence_notions/">Convergence notions</a></li></ul></li><li><span class="tocitem">Discrete-time Markov chains</span><ul><li><a class="tocitem" href="../../markov_chains/mc_definitions/">Essential definitions</a></li><li><a class="tocitem" href="../../markov_chains/mc_invariance/">Invariant distributions</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Countable-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_countableX_recurrence/">Recurrence in the countable-space case</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_connections/">Connected states, irreducibility and uniqueness of invariant measures</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_convergencia/">Aperiodicidade e convergência para a distribuição estacionária</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Continuous-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_irreducibility_and_recurrence/">Irreducibility and recurrence in the continuous-space case</a></li></ul></li></ul></li><li><span class="tocitem">Sampling methods</span><ul><li><a class="tocitem" href="../../sampling/overview/">Overview</a></li><li><a class="tocitem" href="../../sampling/prng/">Random number generators</a></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Transform methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/invFtransform/">Probability integral transform</a></li><li><a class="tocitem" href="../../sampling/box_muller/">Box-Muller transform</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Accept-Reject methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/rejection_sampling/">Rejection sampling</a></li><li><a class="tocitem" href="../../sampling/empiricalsup_rejection/">Empirical supremum rejection sampling</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Markov Chain Monte Carlo (MCMC)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../sampling/mcmc/">Overview</a></li><li><a class="tocitem" href="../../sampling/metropolis/">Metropolis and Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/convergence_metropolis/">Convergence of Metropolis-Hastings</a></li><li><a class="tocitem" href="../../sampling/gibbs/">Gibbs sampling</a></li><li><a class="tocitem" href="../../sampling/hmc/">Hamiltonian Monte Carlo (HMC)</a></li></ul></li><li><a class="tocitem" href="../../sampling/langevin_sampling/">Langevin sampling</a></li></ul></li><li><span class="tocitem">Bayesian inference</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Bayes Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/bayes/">Bayes Theorem</a></li><li><a class="tocitem" href="../../bayesian/bayes_inference/">Bayesian inference</a></li><li><a class="tocitem" href="../../bayesian/bernstein_vonmises/">Bernstein–von Mises theorem</a></li></ul></li><li><a class="tocitem" href="../../bayesian/bayesian_probprog/">Bayesian probabilistic programming</a></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/find_pi/">Estimating π via frequentist and Bayesian methods</a></li><li><a class="tocitem" href="../../bayesian/linear_regression/">Many Ways to Linear Regression</a></li><li><a class="tocitem" href="../../bayesian/tilapia_alometry/">Alometry law for the Nile Tilapia</a></li><li><a class="tocitem" href="../../bayesian/mortality_tables/">Modeling mortality tables</a></li></ul></li></ul></li><li><span class="tocitem">Generative models</span><ul><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox" checked/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Score matching</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../stein_score/">Stein score function</a></li><li><a class="tocitem" href="../score_matching_aapo/">Score matching of Aapo Hyvärinen</a></li><li><a class="tocitem" href="../score_matching_neural_network/">Score matching a neural network</a></li><li><a class="tocitem" href="../parzen_estimation_score_matching/">Score matching with Parzen estimation</a></li><li><a class="tocitem" href="../denoising_score_matching/">Denoising score matching of Pascal Vincent</a></li><li><a class="tocitem" href="../sliced_score_matching/">Sliced score matching</a></li><li><a class="tocitem" href="../1d_FD_score_matching/">1D finite-difference score matching</a></li><li><a class="tocitem" href="../2d_FD_score_matching/">2D finite-difference score matching</a></li><li><a class="tocitem" href="../ddpm/">Denoising diffusion probabilistic models</a></li><li class="is-active"><a class="tocitem" href>Multiple denoising score matching</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Multiple-denoising-score-matching"><span>Multiple denoising score matching</span></a></li><li><a class="tocitem" href="#Numerical-example"><span>Numerical example</span></a></li><li><a class="tocitem" href="#Sampling-with-annealed-Langevin"><span>Sampling with annealed Langevin</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../probability_flow/">Probability flow</a></li><li><a class="tocitem" href="../reverse_flow/">Reverse probability flow</a></li><li><a class="tocitem" href="../score_based_sde/">Score-based SDE model</a></li></ul></li></ul></li><li><span class="tocitem">Sensitivity analysis</span><ul><li><a class="tocitem" href="../../sensitivity/overview/">Overview</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Generative models</a></li><li><a class="is-disabled">Score matching</a></li><li class="is-active"><a href>Multiple denoising score matching</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Multiple denoising score matching</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes/blob/main/docs/src/generative/mdsm.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Multiple-denoising-score-matching-with-annealed-Langevin-dynamics"><a class="docs-heading-anchor" href="#Multiple-denoising-score-matching-with-annealed-Langevin-dynamics">Multiple denoising score matching with annealed Langevin dynamics</a><a id="Multiple-denoising-score-matching-with-annealed-Langevin-dynamics-1"></a><a class="docs-heading-anchor-permalink" href="#Multiple-denoising-score-matching-with-annealed-Langevin-dynamics" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><h3 id="Aim"><a class="docs-heading-anchor" href="#Aim">Aim</a><a id="Aim-1"></a><a class="docs-heading-anchor-permalink" href="#Aim" title="Permalink"></a></h3><p>Review the <strong>(multiple denoising) score matching with Langevin dynamics (SMLD),</strong> which fits a <strong>noise conditional score network (NCSN),</strong> as introduced by <a href="https://dl.acm.org/doi/10.5555/3454287.3455354">Song and Ermon (2019)</a>, which together with DDPM was one step closer to the score-based SDE model.</p><h3 id="Background"><a class="docs-heading-anchor" href="#Background">Background</a><a id="Background-1"></a><a class="docs-heading-anchor-permalink" href="#Background" title="Permalink"></a></h3><p>After <a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005)</a> suggested fitting the score function of a distribution, several directions were undertaken to improve the quality of the method and make it more practical.</p><p>One of the approaches was the <em>denoising score matching</em> of <a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011)</a>, in which the data is corrupted by a Gaussian noise and the model was trained to correctly denoise the corrupted data. The model itself would either be of the pdf itself or of an energy potential for the pdf. In any case, one would have a model for the pdf and could draw samples directly using that.</p><p><a href="https://dl.acm.org/doi/10.5555/3454287.3455354">Song and Ermon (2019)</a> came with two ideas tied together. The first idea was to model directly the score function and use the Langevin equation to draw samples from it. One difficulty with Langevin sampling, however, is in correctly estimating the weights of multimodal distributions, either superestimating or subestimating some modal regions, depending on where the initial distribution of points is located relative to the model regions. It may take a long time to reach the desired distribution.</p><p>In order to overcome that, <a href="https://dl.acm.org/doi/10.5555/3454287.3455354">Song and Ermon (2019)</a> also proposed using an annealed version of Langevin dynamics, based on a scale of <em>denoising score matching</em> models, with different levels of noise, instead of a single denoising. Lower noises are closer to the target distribution but are challenging to the Langevin sampling, while higher noises are better for Langevin sampling but depart from the target distributions. Combining different levels of noise and gradually sampling between different denoising models improve the modeling and sampling of a distribution. That is the idea of their proposed <strong>noise conditional score network (NCSN)</strong> framework, in a method that was later denominated <strong>denosing score matching with Langevin dynamics (SMLD),</strong> and for which a more precise description would be <strong>(multiple denosing) score matching with (annealed) Langevin dynamics.</strong></p><h2 id="Multiple-denoising-score-matching"><a class="docs-heading-anchor" href="#Multiple-denoising-score-matching">Multiple denoising score matching</a><a id="Multiple-denoising-score-matching-1"></a><a class="docs-heading-anchor-permalink" href="#Multiple-denoising-score-matching" title="Permalink"></a></h2><p>The idea is to consider a sequence of denoising score matching models, starting with a relatively large noise level <span>$\sigma_1$</span>, to avoid the difficulties with Langevin sampling described earlier, and end up with a relatively small noise level <span>$\sigma_L$</span>, to minimize the noisy effect on the data.</p><p>For training, one trains directly a score model according to a weighted loss involving all noise levels.</p><p>Then, for sampling, a corresponding sequence of Langevin dynamics, with decreasing levels of noise, driving new samples closer and closer to the target distribution.</p><h3 id="The-model"><a class="docs-heading-anchor" href="#The-model">The model</a><a id="The-model-1"></a><a class="docs-heading-anchor-permalink" href="#The-model" title="Permalink"></a></h3><p>More precisely, one starts with a positive geometric sequence of noise levels <span>$\sigma_1, \ldots, \sigma_L$</span> satisfying</p><p class="math-container">\[    \frac{\sigma_1}{\sigma_2} = \cdots = \frac{\sigma_{L-1}}{\sigma_L} &gt; 1,\]</p><p>which is the same as</p><p class="math-container">\[    \sigma_i = \theta^{i-1} \sigma_1, \quad i = 1, \ldots, L,\]</p><p>for a starting <span>$\sigma_1 &gt; 0$</span> and a rate <span>$0 &lt; \theta &lt; 1$</span> given by <span>$\theta = \sigma_2/\sigma_1 = \ldots = \sigma_L/\sigma_{L-1}$</span>.</p><p>For each <span>$\sigma=\sigma_i$</span>, <span>$i=1, \ldots, L$</span>, one considers the perturbed distribution</p><p class="math-container">\[    p_{\sigma}(\tilde{\mathbf{x}}) = \int_{\mathbb{R}^d} p(\mathbf{x})p_{\sigma}(\tilde{\mathbf{x}}|\mathbf{x})\;\mathrm{d}\mathbf{x},\]</p><p>with a perturbation kernel</p><p class="math-container">\[    p_{\sigma}(\tilde{\mathbf{x}}|\mathbf{x}) = \mathcal{N}\left(\tilde{\mathbf{x}}; \mathbf{x}, \sigma^2 \mathbf{I}\right).\]</p><p>This yields a sequence of perturbed distributions</p><p class="math-container">\[    \{p_{\sigma_i}\}_{i=1}^L.\]</p><p>We model the corresponding family of score functions <span>$\{s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}, \sigma_i)\}$</span>, i.e. such that <span>$s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}, \sigma_i)$</span> approximates the score function of <span>$p_{\sigma_i}$</span>, i.e.</p><p class="math-container">\[    s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}, \sigma_i) \approx \boldsymbol{\nabla}_{\tilde{\mathbf{x}}} \log p_{\sigma_i}(\tilde{\mathbf{x}}).\]</p><p>The <strong>noise conditional score network (NCSN)</strong> is precisely </p><p class="math-container">\[    s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}, \sigma).\]</p><h3 id="The-loss-function"><a class="docs-heading-anchor" href="#The-loss-function">The loss function</a><a id="The-loss-function-1"></a><a class="docs-heading-anchor-permalink" href="#The-loss-function" title="Permalink"></a></h3><p>One wants to train the noise conditional score network <span>$s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}, \sigma)$</span> by weighting together the denosing loss function of each perturbation, i.e.</p><p class="math-container">\[    J_{\textrm{SMLD}}(\boldsymbol{\theta}) = \frac{1}{2L}\sum_{i=1}^L \lambda(\sigma_i) \mathbb{E}_{p(\mathbf{x})p_{\sigma_i}(\tilde{\mathbf{x}}|\mathbf{x})}\left[ \left\| s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}, \sigma_i) - \frac{\mathbf{x} - \tilde{\mathbf{x}}}{\sigma_i^2} \right\|^2 \right],\]</p><p>where <span>$\lambda = \lambda(\sigma_i)$</span> is a weighting factor.</p><p>In practice, we use the empirical distribution and a single corrupted data for each sample data, i.e.</p><p class="math-container">\[    {\tilde J}_{\textrm{SMLD}}(\boldsymbol{\theta}) = \frac{1}{2LN} \sum_{n=1}^N \sum_{i=1}^L \lambda(\sigma_i)\left\| s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}_{n, i}, \sigma_i) - \frac{\mathbf{x}_n - \tilde{\mathbf{x}}_{n, i}}{\sigma_i^2} \right\|^2, \quad \tilde{\mathbf{x}}_{n, i} \sim \mathcal{N}\left(\mathbf{x}_n, \sigma^2 \mathbf{I}\right).\]</p><p>This can also be written with a reparametrization,</p><p class="math-container">\[    {\tilde J}_{\textrm{SMLD}}(\boldsymbol{\theta}) = \frac{1}{2LN} \sum_{n=1}^N \sum_{i=1}^L \lambda(\sigma_i) \left\| s_{\boldsymbol{\theta}}(\mathbf{x}_n + \boldsymbol{\epsilon}_{n, i}, \sigma_i) + \frac{\boldsymbol{\epsilon}_{n, i}}{\sigma_i} \right\|^2, \quad \boldsymbol{\epsilon}_{n, i} \sim \mathcal{N}\left(\mathbf{0}_n, \mathbf{I}\right).\]</p><p>As for the choice of <span>$\lambda(\sigma)$</span>, <a href="https://dl.acm.org/doi/10.5555/3454287.3455354">Song and Ermon (2019)</a> suggested choosing</p><p class="math-container">\[    \lambda(\sigma) = \sigma^2.\]</p><p>This comes from the observation that,</p><p class="math-container">\[    \|s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}_n, \sigma_i)\|^2 \sim \frac{1}{\sigma_i},\]</p><p>hence</p><p class="math-container">\[    \lambda(\sigma_i)\left\| s_{\boldsymbol{\theta}}(\mathbf{x}_n + \boldsymbol{\epsilon}_{n, i}, \sigma_i) + \frac{\boldsymbol{\epsilon}_{n, i}}{\sigma_i} \right\|^2 \sim 1\]</p><p>is independent of <span>$i=1, \ldots, L$</span>. Choosing such weighting, the loss function becomes</p><p class="math-container">\[    {\tilde J}_{\textrm{SMLD}}(\boldsymbol{\theta}) = \frac{1}{2LN} \sum_{n=1}^N \sum_{i=1}^L \left\| \sigma_i s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}_{n, i}, \sigma_i) - (\mathbf{x}_n - \tilde{\mathbf{x}}_{n, i})\right\|^2, \quad \tilde{\mathbf{x}}_{n, i} \sim \mathcal{N}\left(\mathbf{x}_n, \sigma^2 \mathbf{I}\right).\]</p><h3 id="Sampling"><a class="docs-heading-anchor" href="#Sampling">Sampling</a><a id="Sampling-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling" title="Permalink"></a></h3><p>For each <span>$i=1, \ldots, L$</span>, the dynamics of the overdamped Langevin equation</p><p class="math-container">\[    \mathrm{d}X_t = \boldsymbol{\nabla}_{\tilde{\mathbf{x}}} \log p_{\sigma_i}(\tilde{\mathbf{X}}_t)\;\mathrm{d}t + \sqrt{2}\;\mathrm{d}W_t\]</p><p>drives any initial sample towards the distribution defined by <span>$p_{\sigma_i}$</span>. With <span>$s_{\boldsymbol{\theta}}(\tilde{\mathbf{x}}, \sigma_i)$</span> being an approximation of <span>$\boldsymbol{\nabla}_{\tilde{\mathbf{x}}} \log p_{\sigma_i}(\tilde{\mathbf{x}})$</span> and with <span>$p_{\sigma_i}(\tilde{\mathbf{x}})$</span> being closer to the target <span>$p(\mathbf{x})$</span> the smaller the <span>$\sigma_i$</span>, the idea is to run batches of Langevin dynamics for decreasing values of noise, i.e. for <span>$\sigma_1$</span> down to <span>$\sigma_L$</span>.</p><p>More precisely, given <span>$K\in\mathbb{N}$</span>, we run the Langevin equation for <span>$K$</span> steps, for each <span>$i=1, \ldots, L$</span>:</p><p><strong>1.</strong> Start with a <span>$M$</span> sample points <span>$\mathbf{y}_m$</span>, <span>$m=1, \ldots, M$</span>, <span>$M\in\mathbb{N}$</span>, of a multivariate Normal distribution, or a uniform distribution, or any other known distribution.</p><p><strong>2.</strong> Then for each <span>$i=1, \ldots, L$</span>, run the discretized overdamped Langevin equation for <span>$K$</span> steps</p><p class="math-container">\[    \mathbf{y}^i_{m, k} = \mathbf{y}^i_{m, k-1} + s_{\boldsymbol{\theta}}(\tilde{\mathbf{y}}^{i-1}_{m, k-1}, \sigma_i) \tau_i + \sqrt{2\tau_i}\mathbf{z}^i_{m, k},\]</p><p>where <span>$\tau_i &gt; 0$</span> is a given time step (which may or may not vary with <span>$i$</span>); the <span>$\mathbf{z}^i_{m, k} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$</span> are independent; and the initial conditions are given by</p><p class="math-container">\[    \mathbf{y}^1_{m, 0} = \mathbf{y}_m,\]</p><p>for <span>$i=1$</span>, and</p><p class="math-container">\[    \mathbf{y}^i_{m, 0} = \mathbf{y}^{i-1}_{m, K},\]</p><p>for <span>$i = 2, \ldots, L$</span>, i.e. the final <span>$K$</span>th-step of the solution of the Langevin equation with a given <span>$i = 1, \ldots, K-1$</span> is the initial step of the Langevin equation for <span>$i+1$</span>.</p><p><strong>3.</strong> The final points <span>$\mathbf{y}^L_{m, K}$</span>, <span>$m=1, \ldots, M$</span>, are the <span>$M$</span> desired new generated samples of the distribution approximating the data distribution.</p><h2 id="Numerical-example"><a class="docs-heading-anchor" href="#Numerical-example">Numerical example</a><a id="Numerical-example-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-example" title="Permalink"></a></h2><p>We illustrate, numerically, the use of <strong>multiple denoising score matching</strong> to model a synthetic univariate Gaussian mixture distribution.</p><h3 id="Julia-language-setup"><a class="docs-heading-anchor" href="#Julia-language-setup">Julia language setup</a><a id="Julia-language-setup-1"></a><a class="docs-heading-anchor-permalink" href="#Julia-language-setup" title="Permalink"></a></h3><p>We use the <a href="https://julialang.org">Julia programming language</a> for the numerical simulations, with suitable packages.</p><h4 id="Packages"><a class="docs-heading-anchor" href="#Packages">Packages</a><a id="Packages-1"></a><a class="docs-heading-anchor-permalink" href="#Packages" title="Permalink"></a></h4><pre><code class="language-julia hljs">using StatsPlots
using Random
using Distributions
using Lux # artificial neural networks explicitly parametrized
using Optimisers
using Zygote # automatic differentiation
using Markdown</code></pre><h4 id="Reproducibility"><a class="docs-heading-anchor" href="#Reproducibility">Reproducibility</a><a id="Reproducibility-1"></a><a class="docs-heading-anchor-permalink" href="#Reproducibility" title="Permalink"></a></h4><p>We set the random seed for reproducibility purposes.</p><pre><code class="language-julia hljs">rng = Xoshiro(12345)</code></pre><h3 id="Data"><a class="docs-heading-anchor" href="#Data">Data</a><a id="Data-1"></a><a class="docs-heading-anchor-permalink" href="#Data" title="Permalink"></a></h3><p>We build the usual target model and draw samples from it.</p><p>Visualizing the sample data drawn from the distribution and the PDF.</p><img src="401a2b83.svg" alt="Example block output"/><p>Visualizing the score function.</p><img src="d1835947.svg" alt="Example block output"/><h3 id="Parameters"><a class="docs-heading-anchor" href="#Parameters">Parameters</a><a id="Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Parameters" title="Permalink"></a></h3><p>Here we set some parameters for the model and prepare any necessary data.</p><pre><code class="language-julia hljs">L = 16
sigma_1 = 2.0
sigma_L = 0.5
theta = ( sigma_L / sigma_1 )^(1/(L-1))
sigmas = [sigma_1 * theta ^ (i-1) for i in 1:L]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">16-element Vector{Float64}:
 2.0
 1.8234449771164336
 1.6624757922855755
 1.515716566510398
 1.381912879967776
 1.2599210498948732
 1.1486983549970349
 1.0472941228206267
 0.9548416039104165
 0.8705505632961241
 0.7937005259840997
 0.723634618720189
 0.6597539553864471
 0.6015125180410583
 0.548412489847313
 0.49999999999999994</code></pre><pre><code class="language-julia hljs">data = (sample_points, sigmas)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">([2.303077959422043 2.8428423932782843 … 3.1410080972036334 2.488464630750972], [2.0, 1.8234449771164336, 1.6624757922855755, 1.515716566510398, 1.381912879967776, 1.2599210498948732, 1.1486983549970349, 1.0472941228206267, 0.9548416039104165, 0.8705505632961241, 0.7937005259840997, 0.723634618720189, 0.6597539553864471, 0.6015125180410583, 0.548412489847313, 0.49999999999999994])</code></pre><h3 id="The-neural-network-model"><a class="docs-heading-anchor" href="#The-neural-network-model">The neural network model</a><a id="The-neural-network-model-1"></a><a class="docs-heading-anchor-permalink" href="#The-neural-network-model" title="Permalink"></a></h3><p>The neural network we consider is a simple feed-forward neural network made of a single hidden layer, obtained as a chain of a couple of dense layers. This is implemented with the <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> package.</p><p>We will see that we don&#39;t need a big neural network in this simple example. We go as low as it works.</p><pre><code class="language-julia hljs">model = Chain(Dense(2 =&gt; 64, relu), Dense(64 =&gt; 1))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(2 =&gt; 64, relu),     <span class="sgr90"># 192 parameters</span>
    layer_2 = Dense(64 =&gt; 1),           <span class="sgr90"># 65 parameters</span>
) <span class="sgr90">        # Total: </span>257 parameters,
<span class="sgr90">          #        plus </span>0 states.</code></pre><p>The <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> package uses explicit parameters, that are initialized (or obtained) with the <code>Lux.setup</code> function, giving us the <em>parameters</em> and the <em>state</em> of the model.</p><pre><code class="language-julia hljs">ps, st = Lux.setup(rng, model) # initialize and get the parameters and states of the model</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((layer_1 = (weight = Float32[0.96560603 -1.3963945; -0.864941 1.1274849; … ; 0.7158331 1.1567085; 2.3663533 1.2393725], bias = Float32[0.18311752, 0.4076413, 0.6408686, -0.013799805, 0.65769726, 0.27097112, -0.11596697, 0.48491788, -0.42007604, 0.118874006  …  0.1418748, -0.5943321, -0.60492563, 0.5363705, 0.31154066, -0.022509282, 0.3484151, 0.14444627, 0.36740452, -0.6803152]), layer_2 = (weight = Float32[0.09065902 0.13053486 … 0.042090528 0.21522477], bias = Float32[0.004801482])), (layer_1 = NamedTuple(), layer_2 = NamedTuple()))</code></pre><h3 id="Loss-function"><a class="docs-heading-anchor" href="#Loss-function">Loss function</a><a id="Loss-function-1"></a><a class="docs-heading-anchor-permalink" href="#Loss-function" title="Permalink"></a></h3><pre><code class="language-julia hljs">function loss_function_mdsm(model, ps, st, data)
        sample_points, sigmas = data

    noisy_sample_points = sample_points .+ sigmas .* randn(rng, size(sample_points))
    scores = ( sample_points .- noisy_sample_points ) ./ sigmas .^ 2

    flattened_noisy_sample_points = reshape(noisy_sample_points, 1, :)
    flattened_sigmas = repeat(sigmas&#39;, 1, length(sample_points))
    model_input = [flattened_noisy_sample_points; flattened_sigmas]

    y_score_pred, st = Lux.apply(model, model_input, ps, st)

    flattened_scores = reshape(scores, 1, :)

    loss = mean(abs2, flattened_sigmas .* (y_score_pred .- flattened_scores)) / 2

    return loss, st, ()
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">loss_function_mdsm (generic function with 1 method)</code></pre><h3 id="Optimization-setup"><a class="docs-heading-anchor" href="#Optimization-setup">Optimization setup</a><a id="Optimization-setup-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-setup" title="Permalink"></a></h3><h4 id="Optimization-method"><a class="docs-heading-anchor" href="#Optimization-method">Optimization method</a><a id="Optimization-method-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-method" title="Permalink"></a></h4><p>We use the Adam optimiser.</p><pre><code class="language-julia hljs">opt = Adam(0.01)

tstate_org = Lux.Training.TrainState(model, ps, st, opt)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">TrainState
    model: Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(2 =&gt; 64, relu), layer_2 = Dense(64 =&gt; 1)), nothing)
    # of parameters: 257
    # of states: 0
    optimizer: Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8)
    step: 0</code></pre><h4 id="Automatic-differentiation-in-the-optimization"><a class="docs-heading-anchor" href="#Automatic-differentiation-in-the-optimization">Automatic differentiation in the optimization</a><a id="Automatic-differentiation-in-the-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-differentiation-in-the-optimization" title="Permalink"></a></h4><p>As mentioned, we setup differentiation in <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> with the <a href="https://github.com/FluxML/Zygote.jl">FluxML/Zygote.jl</a> library.</p><pre><code class="language-julia hljs">vjp_rule = Lux.Training.AutoZygote()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ADTypes.AutoZygote()</code></pre><h4 id="Processor"><a class="docs-heading-anchor" href="#Processor">Processor</a><a id="Processor-1"></a><a class="docs-heading-anchor-permalink" href="#Processor" title="Permalink"></a></h4><p>We use the CPU instead of the GPU.</p><pre><code class="language-julia hljs">dev_cpu = cpu_device()
## dev_gpu = gpu_device()</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(::MLDataDevices.CPUDevice) (generic function with 1 method)</code></pre><h4 id="Check-differentiation"><a class="docs-heading-anchor" href="#Check-differentiation">Check differentiation</a><a id="Check-differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Check-differentiation" title="Permalink"></a></h4><p>Check if Zygote via Lux is working fine to differentiate the loss functions for training.</p><pre><code class="language-julia hljs">Lux.Training.compute_gradients(vjp_rule, loss_function_mdsm, data, tstate_org)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((layer_1 = (weight = Float32[2.24268 0.7496106; 0.2701228 0.27481318; … ; 1.0937802 0.41069224; 5.6002707 2.0936315], bias = Float32[0.5180968, 0.16000718, 0.026133753, -0.32105532, 0.01996234, -0.53315395, -0.13178797, 0.0014373355, 0.058482938, 0.36684003  …  -0.6349388, -0.015089363, -0.7687205, 0.025982726, -0.8973341, -0.035599682, 0.022229744, -0.0066108867, 0.27588746, 1.4066838]), layer_2 = (weight = Float32[13.387149 1.0834881 … 32.29652 69.18358], bias = Float32[6.572551])), 22.073953377107767, (), Lux.Training.TrainState{Nothing, Nothing, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}, @NamedTuple{layer_1::@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}, layer_2::@NamedTuple{weight::Matrix{Float32}, bias::Vector{Float32}}}, @NamedTuple{layer_1::@NamedTuple{}, layer_2::@NamedTuple{}}, Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, @NamedTuple{layer_1::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}}, layer_2::@NamedTuple{weight::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Matrix{Float32}, Matrix{Float32}, Tuple{Float32, Float32}}}, bias::Optimisers.Leaf{Optimisers.Adam{Float64, Tuple{Float64, Float64}, Float64}, Tuple{Vector{Float32}, Vector{Float32}, Tuple{Float32, Float32}}}}}}(nothing, nothing, Lux.Chain{@NamedTuple{layer_1::Lux.Dense{typeof(NNlib.relu), Int64, Int64, Nothing, Nothing, Static.True}, layer_2::Lux.Dense{typeof(identity), Int64, Int64, Nothing, Nothing, Static.True}}, Nothing}((layer_1 = Dense(2 =&gt; 64, relu), layer_2 = Dense(64 =&gt; 1)), nothing), (layer_1 = (weight = Float32[0.96560603 -1.3963945; -0.864941 1.1274849; … ; 0.7158331 1.1567085; 2.3663533 1.2393725], bias = Float32[0.18311752, 0.4076413, 0.6408686, -0.013799805, 0.65769726, 0.27097112, -0.11596697, 0.48491788, -0.42007604, 0.118874006  …  0.1418748, -0.5943321, -0.60492563, 0.5363705, 0.31154066, -0.022509282, 0.3484151, 0.14444627, 0.36740452, -0.6803152]), layer_2 = (weight = Float32[0.09065902 0.13053486 … 0.042090528 0.21522477], bias = Float32[0.004801482])), (layer_1 = NamedTuple(), layer_2 = NamedTuple()), Optimisers.Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), (layer_1 = (weight = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0 0.0; 0.0 0.0; … ; 0.0 0.0; 0.0 0.0], Float32[0.0 0.0; 0.0 0.0; … ; 0.0 0.0; 0.0 0.0], (0.9, 0.999))<span class="sgr32">)</span>, bias = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], (0.9, 0.999))<span class="sgr32">)</span>), layer_2 = (weight = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0 0.0 … 0.0 0.0], Float32[0.0 0.0 … 0.0 0.0], (0.9, 0.999))<span class="sgr32">)</span>, bias = <span class="sgr32">Leaf(Adam(eta=0.01, beta=(0.9, 0.999), epsilon=1.0e-8), </span>(Float32[0.0], Float32[0.0], (0.9, 0.999))<span class="sgr32">)</span>)), 0))</code></pre><h4 id="Training-loop"><a class="docs-heading-anchor" href="#Training-loop">Training loop</a><a id="Training-loop-1"></a><a class="docs-heading-anchor-permalink" href="#Training-loop" title="Permalink"></a></h4><p>Here is the typical main training loop suggest in the <a href="https://github.com/LuxDL/Lux.jl">LuxDL/Lux.jl</a> tutorials, but sligthly modified to save the history of losses per iteration.</p><pre><code class="language-julia hljs">function train(tstate, vjp, data, loss_function, epochs, numshowepochs=20, numsavestates=0)
    losses = zeros(epochs)
    tstates = [(0, tstate)]
    for epoch in 1:epochs
        grads, loss, stats, tstate = Lux.Training.compute_gradients(vjp,
            loss_function, data, tstate)
        if ( epochs ≥ numshowepochs &gt; 0 ) &amp;&amp; rem(epoch, div(epochs, numshowepochs)) == 0
            println(&quot;Epoch: $(epoch) || Loss: $(loss)&quot;)
        end
        if ( epochs ≥ numsavestates &gt; 0 ) &amp;&amp; rem(epoch, div(epochs, numsavestates)) == 0
            push!(tstates, (epoch, tstate))
        end
        losses[epoch] = loss
        tstate = Lux.Training.apply_gradients(tstate, grads)
    end
    return tstate, losses, tstates
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">train (generic function with 3 methods)</code></pre><h3 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h3><p>Now we train the model with the objective function <span>${\tilde J}_{\mathrm{ESM{\tilde p}_\sigma{\tilde p}_0}}({\boldsymbol{\theta}})$</span>.</p><pre><code class="language-julia hljs">@time tstate, losses, tstates = train(tstate_org, vjp_rule, data, loss_function_mdsm, 1000, 20, 125)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Warning: Mixed-Precision `matmul_cpu_fallback!` detected and Octavian.jl cannot be used for this set of inputs (C [Matrix{Float64}]: A [Matrix{Float32}] x B [Matrix{Float64}]). Falling back to generic implementation. This may be slow.
└ @ LuxLib.Impl ~/.julia/packages/LuxLib/1B1qw/src/impl/matmul.jl:190
Epoch: 50 || Loss: 0.421606670713073
Epoch: 100 || Loss: 0.37060237037864924
Epoch: 150 || Loss: 0.3510065271952815
Epoch: 200 || Loss: 0.32678324360457717
Epoch: 250 || Loss: 0.31034354146437804
Epoch: 300 || Loss: 0.33423218941198585
Epoch: 350 || Loss: 0.31526974973273664
Epoch: 400 || Loss: 0.3188117558846085
Epoch: 450 || Loss: 0.2975144744482348
Epoch: 500 || Loss: 0.30187425098577436
Epoch: 550 || Loss: 0.29523852672237094
Epoch: 600 || Loss: 0.30701505890355335
Epoch: 650 || Loss: 0.31595139324544913
Epoch: 700 || Loss: 0.2944143912928159
Epoch: 750 || Loss: 0.3077361268326157
Epoch: 800 || Loss: 0.2953219121051579
Epoch: 850 || Loss: 0.2717302253257928
Epoch: 900 || Loss: 0.30380289547379313
Epoch: 950 || Loss: 0.3155977911880601
Epoch: 1000 || Loss: 0.3002877469733034
 16.752575 seconds (531.83 k allocations: 26.567 GiB, 11.88% gc time, 0.32% compilation time)</code></pre><h3 id="Results"><a class="docs-heading-anchor" href="#Results">Results</a><a id="Results-1"></a><a class="docs-heading-anchor-permalink" href="#Results" title="Permalink"></a></h3><p>Checking out the trained model.</p><img src="1f962148.svg" alt="Example block output"/><p>Visualizing the result with the smallest noise.</p><img src="f1e606d0.svg" alt="Example block output"/><p>Recovering the PDF of the distribution from the trained score function.</p><img src="50cedf23.svg" alt="Example block output"/><p>With the smallest noise.</p><img src="c5e4504d.svg" alt="Example block output"/><p>Just for the fun of it, let us see an animation of the optimization process.</p><img src="0eb48605.gif" alt="Example block output"/><p>And the animation of the evolution of the PDF.</p><img src="54534bc0.gif" alt="Example block output"/><p>We also visualize the evolution of the losses.</p><img src="541edb6b.svg" alt="Example block output"/><h2 id="Sampling-with-annealed-Langevin"><a class="docs-heading-anchor" href="#Sampling-with-annealed-Langevin">Sampling with annealed Langevin</a><a id="Sampling-with-annealed-Langevin-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling-with-annealed-Langevin" title="Permalink"></a></h2><p>Now we sample the modeled distribution with the annealed Langevin method described earlier.</p><p>Here are the trajectories.</p><img src="9b74cfbb.svg" alt="Example block output"/><p>The sample histogram obtained at the end of the trajectories.</p><img src="ee0a4bda.svg" alt="Example block output"/><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ol><li><a href="https://jmlr.org/papers/v6/hyvarinen05a.html">Aapo Hyvärinen (2005), &quot;Estimation of non-normalized statistical models by score matching&quot;, Journal of Machine Learning Research 6, 695-709</a></li><li><a href="https://doi.org/10.1162/NECO_a_00142">Pascal Vincent (2011), &quot;A connection between score matching and denoising autoencoders,&quot; Neural Computation, 23 (7), 1661-1674, doi:10.1162/NECO<em>a</em>00142</a></li><li><a href="https://dl.acm.org/doi/10.5555/3454287.3455354">Y. Song and S. Ermon (2019), &quot;Generative modeling by estimating gradients of the data distribution&quot;, NIPS&#39;19: Proceedings of the 33rd International Conference on Neural Information Processing Systems, no. 1067, 11918-11930</a></li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../ddpm/">« Denoising diffusion probabilistic models</a><a class="docs-footer-nextpage" href="../probability_flow/">Probability flow »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.13.0 on <span class="colophon-date" title="Thursday 26 June 2025 15:35">Thursday 26 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
