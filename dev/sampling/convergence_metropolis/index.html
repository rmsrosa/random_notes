<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Convergence of Metropolis-Hastings · Random notes</title><meta name="title" content="Convergence of Metropolis-Hastings · Random notes"/><meta property="og:title" content="Convergence of Metropolis-Hastings · Random notes"/><meta property="twitter:title" content="Convergence of Metropolis-Hastings · Random notes"/><meta name="description" content="Documentation for Random notes."/><meta property="og:description" content="Documentation for Random notes."/><meta property="twitter:description" content="Documentation for Random notes."/><meta property="og:url" content="https://github.com/rmsrosa/random_notes/sampling/convergence_metropolis/"/><meta property="twitter:url" content="https://github.com/rmsrosa/random_notes/sampling/convergence_metropolis/"/><link rel="canonical" href="https://github.com/rmsrosa/random_notes/sampling/convergence_metropolis/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Random notes logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Random notes</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Random Notes</a></li><li><span class="tocitem">Probability Essentials</span><ul><li><a class="tocitem" href="../../probability/kernel_density_estimation/">Kernel Density Estimation</a></li><li><a class="tocitem" href="../../probability/convergence_notions/">Convergence notions</a></li></ul></li><li><span class="tocitem">Discrete-time Markov chains</span><ul><li><a class="tocitem" href="../../markov_chains/mc_definitions/">Essential definitions</a></li><li><a class="tocitem" href="../../markov_chains/mc_invariance/">Invariant distributions</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Countable-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_countableX_recurrence/">Recurrence in the countable-space case</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_connections/">Connected states, irreducibility and uniqueness of invariant measures</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_convergencia/">Aperiodicidade e convergência para a distribuição estacionária</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Continuous-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_irreducibility_and_recurrence/">Irreducibility and recurrence in the continuous-space case</a></li></ul></li></ul></li><li><span class="tocitem">Sampling methods</span><ul><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../prng/">Random number generators</a></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Transform methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../invFtransform/">Probability integral transform</a></li><li><a class="tocitem" href="../box_muller/">Box-Muller transform</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Accept-Reject methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../rejection_sampling/">Rejection sampling</a></li><li><a class="tocitem" href="../empiricalsup_rejection/">Empirical supremum rejection sampling</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox" checked/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Markov Chain Monte Carlo (MCMC)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../mcmc/">Overview</a></li><li><a class="tocitem" href="../metropolis/">Metropolis and Metropolis-Hastings</a></li><li class="is-active"><a class="tocitem" href>Convergence of Metropolis-Hastings</a><ul class="internal"><li><a class="tocitem" href="#Fundamental-Markov-chain-concepts"><span>Fundamental Markov chain concepts</span></a></li><li><a class="tocitem" href="#Metropolis-Hastings-properties"><span>Metropolis-Hastings properties</span></a></li><li><a class="tocitem" href="#Further-concepts-and-properties"><span>Further concepts and properties</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../gibbs/">Gibbs sampling</a></li><li><a class="tocitem" href="../hmc/">Hamiltonian Monte Carlo (HMC)</a></li></ul></li><li><a class="tocitem" href="../langevin_sampling/">Langevin sampling</a></li></ul></li><li><span class="tocitem">Bayesian inference</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Bayes Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/bayes/">Bayes Theorem</a></li><li><a class="tocitem" href="../../bayesian/bayes_inference/">Bayesian inference</a></li><li><a class="tocitem" href="../../bayesian/bernstein_vonmises/">Bernstein–von Mises theorem</a></li></ul></li><li><a class="tocitem" href="../../bayesian/bayesian_probprog/">Bayesian probabilistic programming</a></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/find_pi/">Estimating π via frequentist and Bayesian methods</a></li><li><a class="tocitem" href="../../bayesian/linear_regression/">Many Ways to Linear Regression</a></li><li><a class="tocitem" href="../../bayesian/tilapia_alometry/">Alometry law for the Nile Tilapia</a></li><li><a class="tocitem" href="../../bayesian/mortality_tables/">Modeling mortality tables</a></li></ul></li></ul></li><li><span class="tocitem">Generative models</span><ul><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox"/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Score matching</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../generative/overview/">Overview</a></li><li><a class="tocitem" href="../../generative/stein_score/">Stein score function</a></li><li><a class="tocitem" href="../../generative/score_matching_aapo/">Score matching of Aapo Hyvärinen</a></li><li><a class="tocitem" href="../../generative/score_matching_neural_network/">Score matching a neural network</a></li><li><a class="tocitem" href="../../generative/parzen_estimation_score_matching/">Score matching with Parzen estimation</a></li><li><a class="tocitem" href="../../generative/denoising_score_matching/">Denoising score matching of Pascal Vincent</a></li><li><a class="tocitem" href="../../generative/sliced_score_matching/">Sliced score matching</a></li><li><a class="tocitem" href="../../generative/1d_FD_score_matching/">1D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/2d_FD_score_matching/">2D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/ddpm/">Denoising diffusion probabilistic models</a></li><li><a class="tocitem" href="../../generative/mdsm/">Multiple denoising score matching</a></li><li><a class="tocitem" href="../../generative/probability_flow/">Probability flow</a></li><li><a class="tocitem" href="../../generative/reverse_flow/">Reverse probability flow</a></li><li><a class="tocitem" href="../../generative/score_based_sde/">Score-based SDE model</a></li></ul></li></ul></li><li><span class="tocitem">Sensitivity analysis</span><ul><li><a class="tocitem" href="../../sensitivity/overview/">Overview</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Sampling methods</a></li><li><a class="is-disabled">Markov Chain Monte Carlo (MCMC)</a></li><li class="is-active"><a href>Convergence of Metropolis-Hastings</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Convergence of Metropolis-Hastings</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes/blob/main/docs/src/sampling/convergence_metropolis.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Convergence-of-the-Metropolis-Hastings-method"><a class="docs-heading-anchor" href="#Convergence-of-the-Metropolis-Hastings-method">Convergence of the Metropolis-Hastings method</a><a id="Convergence-of-the-Metropolis-Hastings-method-1"></a><a class="docs-heading-anchor-permalink" href="#Convergence-of-the-Metropolis-Hastings-method" title="Permalink"></a></h1><p>The convergences of the Metropolis-Hastings and Gibbs MCMC methods were proved in the early 1990&#39;s, in a number of articles, under reasonable assumptions. The rate of convergence, however, can be either sub-geometric or geometric, depending on the assumptions. These convergences are based on classical conditions of stability of Markov Chains. We will follow here the paper <a href="https://doi.org/10.1214/aos/1033066201">Mengersen &amp; Tweedie (1996)</a> and the second edition of the classic book <a href="https://doi.org/10.1017/CBO9780511626630">Meyn &amp; Tweeedie (2009)</a> (the first edition <a href="https://doi.org/10.1007/978-1-4471-3267-7">Meyn &amp; Tweeedie (1993)</a> was published a few years before the article).</p><h2 id="Fundamental-Markov-chain-concepts"><a class="docs-heading-anchor" href="#Fundamental-Markov-chain-concepts">Fundamental Markov chain concepts</a><a id="Fundamental-Markov-chain-concepts-1"></a><a class="docs-heading-anchor-permalink" href="#Fundamental-Markov-chain-concepts" title="Permalink"></a></h2><p>The fundamental result, for Markov chains, that we use here is the following</p><div class="admonition is-info" id="Theorem-(Convergence-for-a-Markov-chain)-6b5ff184b2b8a63d"><header class="admonition-header">Theorem (Convergence for a Markov chain)<a class="admonition-anchor" href="#Theorem-(Convergence-for-a-Markov-chain)-6b5ff184b2b8a63d" title="Permalink"></a></header><div class="admonition-body"><p>Let <span>$(X_n)_n$</span> be a Markov chain with transition probability <span>$A_n(x, E) = \mathbb{P}(X_n\in E | X_0 = x),$</span> where <span>$E\subset \mathcal{X}$</span> is a Borel measurable set, on the event space <span>$\mathcal{X}=\mathbb{R}^d,$</span> for some <span>$d\in\mathbb{N}.$</span> Let <span>$p=p(x)$</span> be a probability density function, with respect to the Lebesgue measure on <span>$\mathcal{X},$</span> and suppose the Markov chain is <span>$p$</span>-irreducible and aperiodic. Then, for <span>$p$</span>-almost every initial condition <span>$x\in \mathcal{X},$</span></p><p class="math-container">\[    \|A_n(x, \cdot) - p\|_{\mathrm{TV}} \rightarrow 0, \quad n\rightarrow \infty,\]</p><p>where <span>$\|\mu\|_{\mathrm{TV}} = \sup_{A\in\mathcal{B}(\mathcal{X})}|\mu(A)|$</span> is the total variation norm.</p></div></div><p>We need to clarify some terminology first.</p><h3 id="Irreducibility"><a class="docs-heading-anchor" href="#Irreducibility">Irreducibility</a><a id="Irreducibility-1"></a><a class="docs-heading-anchor-permalink" href="#Irreducibility" title="Permalink"></a></h3><p>We start with the notion of <span>${\tilde P}$</span>-irreducibility (see Section 4.2, page 82, of <a href="https://doi.org/10.1017/CBO9780511626630">Meyn &amp; Tweeedie (2009)</a>).</p><div class="admonition is-info" id="Definition-(irreducible-chain)-9b00648bb646ca22"><header class="admonition-header">Definition (irreducible chain)<a class="admonition-anchor" href="#Definition-(irreducible-chain)-9b00648bb646ca22" title="Permalink"></a></header><div class="admonition-body"><p>A Markov chain <span>$(X_n)_n$</span> with transition probability <span>$A_n(x, \cdot)$</span> is called <strong><span>${\tilde P}$</span>-irreducible,</strong> with respect to a probability distribution <span>${\tilde P},$</span> if</p><p class="math-container">\[    {\tilde P}(E) &gt; 0 \Longrightarrow \sum_{n\in \mathbb{N}} A_n(x, E) &gt; 0, \quad \forall x\in \mathcal{X}.\]</p><p>This is equivalent to assuming that, for all <span>$x\in\mathcal{X}$</span> and all measurable set <span>$E$</span> with <span>${\tilde P}(E) &gt; 0,$</span> there exists <span>$n(x, E)$</span> such that <span>$A_n(x, E) &gt; 0.$</span> The Markov chain is called <strong>strongly <span>${\tilde P}$</span>-irreducible</strong> when <span>$n(x, E) = 1$</span> for all such <span>$x$</span> and <span>$E.$</span></p></div></div><p>Irreducibility means that any measurable set with positive measure is eventually reached by the chain, with positive probability, starting from any point in <span>$\mathcal{X}.$</span></p><p>The definition of irreversibility can be also be made with the notion of stopping time at a set.</p><div class="admonition is-info" id="Definition-(stopping-time)-808dee8f01349f9e"><header class="admonition-header">Definition (stopping time)<a class="admonition-anchor" href="#Definition-(stopping-time)-808dee8f01349f9e" title="Permalink"></a></header><div class="admonition-body"><p>Let <span>$(X_n)_n$</span> be a Markov chain with transition probability <span>$A_n(x, \cdot).$</span> Given a measurable set <span>$E\subset \mathcal{X},$</span> the <strong>stopping time</strong> <span>$\tau_E$</span> at <span>$E$</span> of the Markov chain is defined as <span>$\tau_E = \infty,$</span> if <span>$\tau_E\notin E,$</span> for all <span>$n\in\mathbb{N},$</span> or</p><p class="math-container">\[    \tau_E = \inf\{n\in\mathbb{N}; \; X_n\in E\},\]</p><p>otherwise.</p></div></div><p>Thus, the chain is <span>${\tilde P}$</span>-irreducible when <span>${\tilde P}(\tau_E &lt; 0 | X_0 = x) &gt; 0,$</span> for every <span>$x$</span> and every <span>${\tilde P}(E) &gt; 0.$</span></p><h3 id="Recurrence"><a class="docs-heading-anchor" href="#Recurrence">Recurrence</a><a id="Recurrence-1"></a><a class="docs-heading-anchor-permalink" href="#Recurrence" title="Permalink"></a></h3><p class="math-container">\[{\tilde P}\]</p><p>-Irreducibility implies that any set <span>$E$</span> of positive <span>${\tilde P}$</span>-measure is reached, at some step <span>$n(x, E),$</span> from any point <span>$x$</span> in space. A stronger property is that of <em>recurrence,</em> when the set is visited infinitely often.</p><div class="admonition is-info" id="Recurrence-366fbe11ce6bc7a9"><header class="admonition-header">Recurrence<a class="admonition-anchor" href="#Recurrence-366fbe11ce6bc7a9" title="Permalink"></a></header><div class="admonition-body"><p>A Markov chain <span>$(X_n)_n$</span> with transition probability <span>$A_n(x, \cdot)$</span> is called <strong><span>${\tilde P}$</span>-irreducible,</strong> with respect to a probability distribution <span>${\tilde P},$</span> if</p><p class="math-container">\[    {\tilde P}(E) &gt; 0 \Longrightarrow \sum_{n\in \mathbb{N}} A_n(x, E) &gt; 0, \quad \forall x\in \mathcal{X}.\]</p></div></div><h3 id="Small-sets"><a class="docs-heading-anchor" href="#Small-sets">Small sets</a><a id="Small-sets-1"></a><a class="docs-heading-anchor-permalink" href="#Small-sets" title="Permalink"></a></h3><p>For the aperiodicity, we need the concept of <em>small set.</em> (see Section 5.2, page 102, of <a href="https://doi.org/10.1017/CBO9780511626630">Meyn &amp; Tweeedie (2009)</a>).</p><div class="admonition is-info" id="Definition-(small-set)-f43b2d3cc4452de3"><header class="admonition-header">Definition (small set)<a class="admonition-anchor" href="#Definition-(small-set)-f43b2d3cc4452de3" title="Permalink"></a></header><div class="admonition-body"><p>Let <span>$(X_n)_n$</span> be a Markov chain with <span>$n$</span>-transition probability <span>$A_n(x, \cdot).$</span> A set <span>$C$</span> is called a <strong>small set</strong> if there exist <span>$n\in\mathbb{N},$</span> <span>$\delta &gt; 0,$</span> and a probability measure <span>$\nu$</span> such that</p><p class="math-container">\[    A_n(x, E) \geq \delta\nu(E), \quad \forall x\in C, \;\forall E\in\mathcal{B}(E).\]</p></div></div><p>Equivalently, some authors take <span>$\delta = 1$</span> and ask <span>$\nu$</span> to be a nontrivial measure, without necessarily being normalized to a probability measure.</p><p>One motivation behind this notion is that, when <span>$0&lt;\delta &lt; 1,$</span> we can write</p><p class="math-container">\[    A_n(x, E) = \delta\nu(E) + (1-\delta)K_n(x, E), \quad \forall E\in\mathcal{B}(\mathcal{X}),\]</p><p>where <span>$K_n(x, E) = (A_n(x, E) - \nu(E))/(1-\delta)$</span> is itself a probability distribution, and notice that the <span>$n$</span>-transition probability has a nontrivial portion <span>$\nu$</span> that does not depend on the initial point <span>$x.$</span> This allows us to get some uniform bounds.</p><p>The case <span>$\delta &gt; 1$</span> is not possible. Indeed, notice that the condition for being a small set means that</p><p class="math-container">\[    \mu_n(x, E) = A_n(x, E) - \delta\nu(E) \geq 0, \]</p><p>which implies that the signed measure <span>$\mu_n(x, \cdot)$</span> is nonnegative and, hence, is actually a measure. Notice then that</p><p class="math-container">\[    0 \leq \mu_n(x, E) \leq \mu_n(x, \mathbb{R}) = A_n(x, \mathbb{R}) - \delta\nu(\mathbb{R}) = 1 - \delta.\]</p><p>This means not only that <span>$\delta \leq 1$</span> but also that, if <span>$\delta = 1,$</span> then <span>$\mu_n(x, E) = 0,$</span> for all <span>$E,$</span> and hence <span>$A_n(x, \cdot) = \delta\nu(\cdot).$</span></p><p>In summary, we must have <span>$0 &lt; \delta \leq 1.$</span> If <span>$\delta = 1,$</span> then <span>$A(x, E) = \delta \nu(E)$</span> is independent of <span>$x$</span> on <span>$C$</span>. And if <span>$0 &lt; \delta &lt; 1,$</span> <span>$A(x, E) = \delta \nu(E) + (1-\delta)K_n(x, \cdot),$</span> so that there is at least a nontrivial part of <span>$A(x,\cdot)$</span> that is independent of <span>$x$</span> on <span>$C.$</span> In any case, this allows us to obtain uniform lower bounds for the transition distribution.</p><p>But that does not give us much intuition to why it is called a small set, or in what sense that would be small. This can be illustrated with a few random walk examples.</p><h4 id="A-fair-random-walk"><a class="docs-heading-anchor" href="#A-fair-random-walk">A fair random walk</a><a id="A-fair-random-walk-1"></a><a class="docs-heading-anchor-permalink" href="#A-fair-random-walk" title="Permalink"></a></h4><p>Consider the random walk (see e.g. Section 1.2.3 of <a href="https://doi.org/10.1017/CBO9780511626630">Meyn &amp; Tweeedie (2009)</a>)</p><p class="math-container">\[    X_{n+1} = X_n + W_n, \qquad W_n \sim \mathcal{N}(0, 1),\]</p><p>on <span>$\mathcal{X} = \mathbb{R}.$</span> If we take a set <span>$C_r=[-r, r],$</span> where <span>$r &gt; 0,$</span> then, for each <span>$x\in C,$</span> the PDF <span>$\mathcal{N}(y; x, 1) = e^{-(x - y)^2/2}/\sqrt{2\pi},$</span> <span>$y\in\mathbb{R},$</span> of the normal distribution <span>$\mathcal{N}(x, 1)$</span> with mean <span>$x$</span> and variance <span>$1$</span> is such that</p><p class="math-container">\[    \mathcal{N}(y; x, 1) \geq \mathcal{N}(2r; 0, 1) = \frac{1}{\sqrt{2\pi}}e^{-2r^2}, \quad \forall x\in C_r = [-r, r].\]</p><p>Thus, if we take <span>$\nu_r$</span> to be the uniform distribution over <span>$C_r,$</span> and noticing that the Lebesgue measure of <span>$C_r$</span> is <span>$2r$</span> and that <span>$A(x, \cdot) = \mathcal{N}(x, 1)$</span> is the transition probability of this random walk, we have</p><p class="math-container">\[    A(x, \cdot) \geq \delta_r \nu_r(\cdot), \quad \delta_r = \frac{2r}{\sqrt{2\pi}}e^{-r^2}.\]</p><p>More explicitly, we have, for any Borel set <span>$E,$</span> and any <span>$x\in C_r,$</span></p><p class="math-container">\[    \begin{align*}
        A(x, E) &amp; = \frac{1}{\sqrt{2\pi}}\int_{E} e^{-(x - y)^2/2} \;\mathrm{d}y \\
        &amp; \geq \frac{1}{\sqrt{2\pi}}\int_{E \cap C_r} e^{-(x - y)^2/2} \;\mathrm{d}y \\
        &amp; \geq \frac{1}{\sqrt{2\pi}}\int_{E \cap C_r} e^{-(2r)^2/2} \;\mathrm{d}y \\
        &amp; = \frac{1}{\sqrt{2\pi}} e^{-2r^2} \int_{E\cap C_r} \;\mathrm{d}y \\
        &amp; = \frac{2r}{\sqrt{2\pi}} e^{-2r^2} \frac{1}{2r}\int_{E\cap C_r} \;\mathrm{d}y \\
        &amp; = \delta_r \nu_r(E).
    \end{align*}\]</p><p>The value of <span>$\delta_r$</span> has its maximum at <span>$r = 1/2,$</span> with value <span>$e^{-1/2}/\sqrt{2\pi} \approx 0.24,$</span> decreasing to zero either as we increase <span>$r$</span> towards <span>$\infty$</span> or decrease it towards zero. In a sense, <span>$\delta_r\nu_r(\cdot)$</span> is small, regardless of <span>$r &gt; 0.$</span></p><img src="2347ac08.svg" alt="Example block output"/><h4 id="Random-walk-on-a-half-line"><a class="docs-heading-anchor" href="#Random-walk-on-a-half-line">Random walk on a half line</a><a id="Random-walk-on-a-half-line-1"></a><a class="docs-heading-anchor-permalink" href="#Random-walk-on-a-half-line" title="Permalink"></a></h4><p>Now we consider the following random walk on the nonnegative half line.</p><p class="math-container">\[    X_{n+1} = [X_n + W_n]^+, \qquad W_n \sim \mathcal{N}(0, 1),\]</p><p>where <span>$[s]^+ = \max\{0, s\},$</span> for any real <span>$s.$</span></p><p>Note that <span>$X_n,$</span> <span>$n=0, 1, 2, \ldot,$</span> can only assume nonnegative values, and that for any <span>$x\geq 0,$</span></p><p class="math-container">\[    \mathbb{P}(X_{n+1} = 0|X_n = x) = \int_{-\infty}^0 \frac{1}{\sqrt{2\pi}} e^{\frac{1}{2}|y - x|^2} = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{-x} e^{\frac{1}{2}s^2} \;\mathrm{d}s = F_{\mathcal{N}}(-x) &gt; 0,\]</p><p>where <span>$F_{\mathcal{N}}$</span> denotes the cumulative distribution function of the standard normal distribution.</p><p>Thus, if we take <span>$\nu=\nu_0$</span> to be the delta distribution at <span>$x=0,$</span> we see that the singleton <span>$C=\{0\}$</span> and any interval <span>$C=[0, r],$</span> <span>$r &gt; 0,$</span> is a small set for this random walk, since</p><p class="math-container">\[    A(x, E) \geq F_{\mathcal{N}}(-x)\delta_0(E) \geq \delta\nu_0(E), \qquad \forall E\in\mathcal{B}(\mathbb{R}),\]</p><p>with <span>$\delta = F_{\mathcal{N}}(-r).$</span></p><h3 id="Aperiodicity"><a class="docs-heading-anchor" href="#Aperiodicity">Aperiodicity</a><a id="Aperiodicity-1"></a><a class="docs-heading-anchor-permalink" href="#Aperiodicity" title="Permalink"></a></h3><p>With the notion of small set, we have the definition of aperiodicity.</p><div class="admonition is-info" id="Definition-(aperiodic-chain)-d0554e66bbede6ef"><header class="admonition-header">Definition (aperiodic chain)<a class="admonition-anchor" href="#Definition-(aperiodic-chain)-d0554e66bbede6ef" title="Permalink"></a></header><div class="admonition-body"><p>Let <span>$(X_n)_n$</span> be a Markov chain with transition probability <span>$A_n(x, \cdot).$</span> Then, the chain is called <strong>aperiodic</strong> when, for some small set <span>$C$</span> with <span>${\tilde p}(C) &gt; 0,$</span> the greatest common divisor of all the integers <span>$n\in\mathbb{N}$</span> such that</p><p class="math-container">\[    A_n(x, E) \geq \nu(E), \quad \forall x\in E, \;\forall E\in\mathcal{B}(E),\]</p><p>is <span>$1.$</span></p></div></div><h2 id="Metropolis-Hastings-properties"><a class="docs-heading-anchor" href="#Metropolis-Hastings-properties">Metropolis-Hastings properties</a><a id="Metropolis-Hastings-properties-1"></a><a class="docs-heading-anchor-permalink" href="#Metropolis-Hastings-properties" title="Permalink"></a></h2><p>With these definitions in mind and with the results above, we check that the Metropolis-Hastings chain is <span>$p$</span>-irreducible and aperiodic and, thus, it convergences, in total variation, to the desired distribution <span>$p,$</span> when <span>$n\rightarrow \infty.$</span></p><h2 id="Further-concepts-and-properties"><a class="docs-heading-anchor" href="#Further-concepts-and-properties">Further concepts and properties</a><a id="Further-concepts-and-properties-1"></a><a class="docs-heading-anchor-permalink" href="#Further-concepts-and-properties" title="Permalink"></a></h2><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ol><li><a href="https://doi.org/10.1214/aos/1033066201">K. L. Mengersen, R. L. Tweedie (1996), &quot;Rates of convergence of the Hastings and Metropolis algorithms,&quot; The Annals of Statistics, 24, no. 1, 101-121</a></li><li><a href="https://doi.org/10.1007/978-1-4471-3267-7">S. P. Meyn, R. L. Tweeedie (1993), &quot;Markov Chains and Stochastic Stability,&quot; vol. 1, Springer-Verlag</a></li><li><a href="https://doi.org/10.1017/CBO9780511626630">S. P. Meyn, R. L. Tweeedie (2009), &quot;Markov Chains and Stochastic Stability,&quot; vol. 2, Cambridge University Press</a></li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../metropolis/">« Metropolis and Metropolis-Hastings</a><a class="docs-footer-nextpage" href="../gibbs/">Gibbs sampling »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.13.0 on <span class="colophon-date" title="Thursday 26 June 2025 15:36">Thursday 26 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
