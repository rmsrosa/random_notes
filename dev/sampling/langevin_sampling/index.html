<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Langevin sampling · Random notes</title><meta name="title" content="Langevin sampling · Random notes"/><meta property="og:title" content="Langevin sampling · Random notes"/><meta property="twitter:title" content="Langevin sampling · Random notes"/><meta name="description" content="Documentation for Random notes."/><meta property="og:description" content="Documentation for Random notes."/><meta property="twitter:description" content="Documentation for Random notes."/><meta property="og:url" content="https://github.com/rmsrosa/random_notes/sampling/langevin_sampling/"/><meta property="twitter:url" content="https://github.com/rmsrosa/random_notes/sampling/langevin_sampling/"/><link rel="canonical" href="https://github.com/rmsrosa/random_notes/sampling/langevin_sampling/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Random notes logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Random notes</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Random Notes</a></li><li><span class="tocitem">Probability Essentials</span><ul><li><a class="tocitem" href="../../probability/kernel_density_estimation/">Kernel Density Estimation</a></li><li><a class="tocitem" href="../../probability/convergence_notions/">Convergence notions</a></li></ul></li><li><span class="tocitem">Discrete-time Markov chains</span><ul><li><a class="tocitem" href="../../markov_chains/mc_definitions/">Essential definitions</a></li><li><a class="tocitem" href="../../markov_chains/mc_invariance/">Invariant distributions</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Countable-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_countableX_recurrence/">Recurrence in the countable-space case</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_connections/">Connected states, irreducibility and uniqueness of invariant measures</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_convergencia/">Aperiodicidade e convergência para a distribuição estacionária</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Continuous-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_irreducibility_and_recurrence/">Irreducibility and recurrence in the continuous-space case</a></li></ul></li></ul></li><li><span class="tocitem">Sampling methods</span><ul><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../prng/">Random number generators</a></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Transform methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../invFtransform/">Probability integral transform</a></li><li><a class="tocitem" href="../box_muller/">Box-Muller transform</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Accept-Reject methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../rejection_sampling/">Rejection sampling</a></li><li><a class="tocitem" href="../empiricalsup_rejection/">Empirical supremum rejection sampling</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Markov Chain Monte Carlo (MCMC)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../mcmc/">Overview</a></li><li><a class="tocitem" href="../metropolis/">Metropolis and Metropolis-Hastings</a></li><li><a class="tocitem" href="../convergence_metropolis/">Convergence of Metropolis-Hastings</a></li><li><a class="tocitem" href="../gibbs/">Gibbs sampling</a></li><li><a class="tocitem" href="../hmc/">Hamiltonian Monte Carlo (HMC)</a></li></ul></li><li class="is-active"><a class="tocitem" href>Langevin sampling</a><ul class="internal"><li><a class="tocitem" href="#Introduction"><span>Introduction</span></a></li><li><a class="tocitem" href="#Langevin-dynamics"><span>Langevin dynamics</span></a></li><li><a class="tocitem" href="#Sampling-from-the-score-function-via-Langevin-dynamics"><span>Sampling from the score function via Langevin dynamics</span></a></li><li><a class="tocitem" href="#Numerical-example"><span>Numerical example</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li></ul></li><li><span class="tocitem">Bayesian inference</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Bayes Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/bayes/">Bayes Theorem</a></li><li><a class="tocitem" href="../../bayesian/bayes_inference/">Bayesian inference</a></li><li><a class="tocitem" href="../../bayesian/bernstein_vonmises/">Bernstein–von Mises theorem</a></li></ul></li><li><a class="tocitem" href="../../bayesian/bayesian_probprog/">Bayesian probabilistic programming</a></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/find_pi/">Estimating π via frequentist and Bayesian methods</a></li><li><a class="tocitem" href="../../bayesian/linear_regression/">Many Ways to Linear Regression</a></li><li><a class="tocitem" href="../../bayesian/tilapia_alometry/">Alometry law for the Nile Tilapia</a></li><li><a class="tocitem" href="../../bayesian/mortality_tables/">Modeling mortality tables</a></li></ul></li></ul></li><li><span class="tocitem">Generative models</span><ul><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox"/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Score matching</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../generative/overview/">Overview</a></li><li><a class="tocitem" href="../../generative/stein_score/">Stein score function</a></li><li><a class="tocitem" href="../../generative/score_matching_aapo/">Score matching of Aapo Hyvärinen</a></li><li><a class="tocitem" href="../../generative/score_matching_neural_network/">Score matching a neural network</a></li><li><a class="tocitem" href="../../generative/parzen_estimation_score_matching/">Score matching with Parzen estimation</a></li><li><a class="tocitem" href="../../generative/denoising_score_matching/">Denoising score matching of Pascal Vincent</a></li><li><a class="tocitem" href="../../generative/sliced_score_matching/">Sliced score matching</a></li><li><a class="tocitem" href="../../generative/1d_FD_score_matching/">1D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/2d_FD_score_matching/">2D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/ddpm/">Denoising diffusion probabilistic models</a></li><li><a class="tocitem" href="../../generative/mdsm/">Multiple denoising score matching</a></li><li><a class="tocitem" href="../../generative/probability_flow/">Probability flow</a></li><li><a class="tocitem" href="../../generative/reverse_flow/">Reverse probability flow</a></li><li><a class="tocitem" href="../../generative/score_based_sde/">Score-based SDE model</a></li></ul></li></ul></li><li><span class="tocitem">Sensitivity analysis</span><ul><li><a class="tocitem" href="../../sensitivity/overview/">Overview</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Sampling methods</a></li><li class="is-active"><a href>Langevin sampling</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Langevin sampling</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes/blob/main/docs/src/sampling/langevin_sampling.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Langevin-sampling"><a class="docs-heading-anchor" href="#Langevin-sampling">Langevin sampling</a><a id="Langevin-sampling-1"></a><a class="docs-heading-anchor-permalink" href="#Langevin-sampling" title="Permalink"></a></h1><h2 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h2><p>One of the cornerstones of score-based generative models is the method of sampling from the score function of a distribution via Langevin dynamics. Our aim here is to review the method of sampling via Langevin dynamics based on the score function.</p><h2 id="Langevin-dynamics"><a class="docs-heading-anchor" href="#Langevin-dynamics">Langevin dynamics</a><a id="Langevin-dynamics-1"></a><a class="docs-heading-anchor-permalink" href="#Langevin-dynamics" title="Permalink"></a></h2><p>The velocity of a particle moving in a fluid has long been known to be reduced by friction forces with the surrounding fluid particles. For relatively slowly moving particles, when the surrouding fluid flow is essentially laminar, this friction force is regarded to be proportional to the velocity, in what is known as the <em>Stokes law.</em> When the motion is relatively fast and the flow around the particle is turbulent, this friction tends to be proportional to the square of the velocity.</p><p>If this were the only force, though, a particle initially at rest on a still fluid would remain forever at rest. That is not the case, as observed by the botanist <a href="https://doi.org/10.1080%2F14786442808674769">Robert Brown (1828)</a>. His observations led to what is now known as <em>Brownian motion,</em> and which is formally modeled as a Wiener process (see e.g. <a href="https://doi.org/10.1002/andp.19053220806">Einstein (1905)</a> and <a href="https://www.cambridge.org/il/academic/subjects/statistics-probability/probability-theory-and-stochastic-processes/brownian-motion?format=HB&amp;isbn=9780521760188">Mörters and Peres (2010)</a>). A Wiener process describes the (random) position of a particle which is initially at rest and is put into motion by the erratic collisions with the nearby fluid particles.</p><p>When in motion, both forces are actually in effect, a deterministic one dependent on the velocity and a random one due to irregular collisions. In a short time scale, the inertia forces are negligible and we recover the Brownian motion. For larger times scales, the Langevin is more appropriate since it takes both forces into account.</p><h3 id="Langevin-equation"><a class="docs-heading-anchor" href="#Langevin-equation">Langevin equation</a><a id="Langevin-equation-1"></a><a class="docs-heading-anchor-permalink" href="#Langevin-equation" title="Permalink"></a></h3><p>We start with the Langevin equation for a free particle and then introduce the equation with a potential field.</p><h4 id="Langevin-equation-for-a-free-particle"><a class="docs-heading-anchor" href="#Langevin-equation-for-a-free-particle">Langevin equation for a free particle</a><a id="Langevin-equation-for-a-free-particle-1"></a><a class="docs-heading-anchor-permalink" href="#Langevin-equation-for-a-free-particle" title="Permalink"></a></h4><p>In the Langevin model, both viscous and random collision forces affect the momentum of the particle (<a href="https://gallica.bnf.fr/ark:/12148/bpt6k3100t/f530.item">Paul Langevin (1908)</a>). In this model, the position <span>$x_t$</span> of a particle of mass <span>$m$</span> at time <span>$t$</span> is given by</p><p class="math-container">\[    m \ddot x_t = - a \mu \dot x_t + \alpha \xi_t,\]</p><p>where <span>$a$</span> is a caractheristic length of the particle; <span>$\mu$</span> is the molecular viscosity, associated with the frictional drag force assumed proportional to the velocity; and <span>$\alpha$</span> is a proportionality coefficient associated with a <em>white noise</em> term <span>$\xi_t$</span> modeling the random collisions with the fluid particles, i.e. <span>$\xi_t$</span> is a Gaussian (distribution) process with zero mean, <span>$\mathbb{E}[\xi_t] = 0,$</span> and delta correlated, <span>$\mathbb{E}[\xi_t\xi_s] = \delta_0(t - s).$</span> The two coefficients are connected by</p><p class="math-container">\[    \alpha = \sqrt{2a\mu k_B T},\]</p><p>where <span>$k_B$</span> is the Boltzmann constant and <span>$T$</span> is the temperature of the fluid.</p><p>The white noise is highly irregular, so the equation above is made rigorous with the theory of stochastic differential equations when casted in the form</p><p class="math-container">\[    \mathrm{d}Y_t = -\nu Y_t \;\mathrm{d}t + \sigma \;\mathrm{d}W_t,\]</p><p>where <span>$\{Y_t\}_t$</span> is a stochastic processes representing the evolution of the velocity in time; <span>$\nu = a\mu / m$</span> is a kinematic damping factor (with dimension <span>$1/\texttt{time}$</span>); <span>$\sigma=\alpha/m$</span> is called the <em>diffusion</em> parameter; and <span>$\{W_t\}_t$</span> is a Wiener process, whose formal derivative represents the white noise. The solution <span>$\{Y_t\}_t$</span> of the equation above is known as the <strong>Ornstein-Uhlenbeck</strong> stochastic process. The relation between <span>$\sigma$</span> and <span>$\nu$</span> becomes</p><p class="math-container">\[    \sigma = \sqrt{\frac{2\nu k_B T}{m}}.\]</p><h4 id="Langevin-equation-with-an-energy-potential"><a class="docs-heading-anchor" href="#Langevin-equation-with-an-energy-potential">Langevin equation with an energy potential</a><a id="Langevin-equation-with-an-energy-potential-1"></a><a class="docs-heading-anchor-permalink" href="#Langevin-equation-with-an-energy-potential" title="Permalink"></a></h4><p>This is all fine for a nearly free particle, affected only by friction and by smaller nearby particles. More generally, one may also consider a particle under an extra force field with potential <span>$U=U(x)$</span>. In this case, the equation is modified to</p><p class="math-container">\[    m \ddot x_t = - a\mu \dot x_t - m\nabla U(x_t) + \alpha \xi_t,\]</p><h4 id="Rigorous-stochastic-formulation"><a class="docs-heading-anchor" href="#Rigorous-stochastic-formulation">Rigorous stochastic formulation</a><a id="Rigorous-stochastic-formulation-1"></a><a class="docs-heading-anchor-permalink" href="#Rigorous-stochastic-formulation" title="Permalink"></a></h4><p>The rigorous stochastic formulation takes the form of a system,</p><p class="math-container">\[    \begin{cases}
        \mathrm{d}X_t = Y_t\;\mathrm{d}t, \\
        \mathrm{d}Y_t = (-\nu Y_t - \nabla U(X_t))\;\mathrm{d}t + \sigma \;\mathrm{d}W_t.
    \end{cases}\]</p><p>These are called the <strong>Langevin equation</strong> or <strong>Langevin system.</strong></p><h3 id="Physical-dimensions"><a class="docs-heading-anchor" href="#Physical-dimensions">Physical dimensions</a><a id="Physical-dimensions-1"></a><a class="docs-heading-anchor-permalink" href="#Physical-dimensions" title="Permalink"></a></h3><p>We want to check the physical dimensions of the terms in the Langevin equation</p><p class="math-container">\[    m \ddot x_t = - a \mu \dot x_t - m\nabla U(x_t) + \alpha \xi_t,\]</p><p>where</p><p class="math-container">\[    \alpha = \sqrt{2a\mu k_B T}.\]</p><h4 id="Basic-physical-dimensions"><a class="docs-heading-anchor" href="#Basic-physical-dimensions">Basic physical dimensions</a><a id="Basic-physical-dimensions-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-physical-dimensions" title="Permalink"></a></h4><p>We denote the physical dimensions by</p><p class="math-container">\[    \quad M = \texttt{ mass,} \quad L = \texttt{ length,} \quad T = \texttt{ time,} \quad \Theta = \texttt{ temperature.} \]</p><h4 id="Physical-dimension-of-variables-and-parameters"><a class="docs-heading-anchor" href="#Physical-dimension-of-variables-and-parameters">Physical dimension of variables and parameters</a><a id="Physical-dimension-of-variables-and-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Physical-dimension-of-variables-and-parameters" title="Permalink"></a></h4><p>The variable <span>$x_t$</span> denotes position at time <span>$t,$</span> hence its physical dimension, <span>$[x_t],$</span> is length,</p><p class="math-container">\[    [x_t] = L.\]</p><p>The time derivative has dimension of one over time, i.e.</p><p class="math-container">\[    \left[\frac{\mathrm{d}}{\mathrm{d} t}\right] = \frac{1}{T}.\]</p><p>The Dirac delta <span>$\delta_0(\cdot)$</span> in the definition of white noise is the (time) derivative of the Heaviside function <span>$H(t) = \chi_{[0, \infty)}(t).$</span> The Heaviside is adimensional, so</p><p class="math-container">\[    [\delta_0] = \frac{1}{T}.\]</p><p>Since the dimension of the correlation is</p><p class="math-container">\[    \left[\mathbb{E}[\xi_t\xi_s]\right] = [\xi_t]^2\]</p><p>and</p><p class="math-container">\[    [\xi_t]^2 = \left[\mathbb{E}[\xi_t\xi_s]\right] = \left[\delta_0\right] = \frac{1}{T},\]</p><p>we find that</p><p class="math-container">\[    [\xi_t] = \frac{1}{\sqrt{T}}.\]</p><p>For consistency reasons, the dimension of <span>$\mu$</span> has to be</p><p class="math-container">\[    [\mu] = \frac{M}{LT}.\]</p><p>The potential field is the potential energy over the mass of the particle under the potential field, thus</p><p class="math-container">\[    [U(x)] = \frac{L^2}{T^2}.\]</p><p>The dimension of the Boltzmann constant is that of energy over temperature, i.e.</p><p class="math-container">\[    [k_B] = \frac{ML^2}{T^2\Theta}.\]</p><p>With that, the dimension of <span>$\alpha$</span> becomes</p><p class="math-container">\[    [\alpha] = \sqrt{[a][\mu] [k_B] [T]} = \sqrt{L \frac{M}{LT} \frac{ML^2}{T^2\Theta} \Theta} = \sqrt{\frac{M^2L^2}{T^3}} = \frac{ML}{T^{3/2}}.\]</p><h4 id="Physical-dimensions-of-the-Langevin-equation"><a class="docs-heading-anchor" href="#Physical-dimensions-of-the-Langevin-equation">Physical dimensions of the Langevin equation</a><a id="Physical-dimensions-of-the-Langevin-equation-1"></a><a class="docs-heading-anchor-permalink" href="#Physical-dimensions-of-the-Langevin-equation" title="Permalink"></a></h4><p>Now we check that all the terms in the Langevin equation have the same physical dimension of force, since it is an expression of Newton&#39;s second law of motion. Indeed, the first term has dimension</p><p class="math-container">\[    [m\ddot x_t] = [m] \left[\frac{\mathrm{d}^2}{\mathrm{d}t^2}\right] [x_t] = M \frac{1}{T^2} L = \frac{ML}{T^2}.\]</p><p>The second term has dimension</p><p class="math-container">\[    [a\mu \dot x_t] = [a] [\mu] \left[\frac{\mathrm{d}}{\mathrm{d}t}\right] [x_t] = L \frac{M}{LT} \frac{1}{T} L = \frac{ML}{T^2}.\]</p><p>The potential term has dimension</p><p class="math-container">\[    [m\nabla U(x_t)] = M \frac{1}{L} \frac{L^2}{T^2} = \frac{ML}{T^2}.\]</p><p>The last term has dimension</p><p class="math-container">\[    [\alpha \xi_t] = [\alpha] [\xi_t] = \frac{ML}{T^{3/2}}\frac{1}{T^{1/2}} = \frac{ML}{T^2}.\]</p><h4 id="Physical-dimension-of-the-stochastic-equation-for-the-random-velocity"><a class="docs-heading-anchor" href="#Physical-dimension-of-the-stochastic-equation-for-the-random-velocity">Physical dimension of the stochastic equation for the random velocity</a><a id="Physical-dimension-of-the-stochastic-equation-for-the-random-velocity-1"></a><a class="docs-heading-anchor-permalink" href="#Physical-dimension-of-the-stochastic-equation-for-the-random-velocity" title="Permalink"></a></h4><p>Looking now at the equation</p><p class="math-container">\[    \mathrm{d}Y_t = -\nu Y_t \;\mathrm{d}t + \sigma \;\mathrm{d}W_t,\]</p><p>we first observe that</p><p class="math-container">\[    [\nu] = \left[\frac{a\mu}{m}\right] = L \frac{M}{LT} \frac{1}{M} = \frac{L}{T}\]</p><p>and</p><p class="math-container">\[    [\sigma] = \left[\frac{\alpha}{m}\right] = \frac{ML}{T^{3/2}} \frac{1}{M} = \frac{L}{T^{3/2}}.\]</p><p>Since the <span>$W_t \sim \mathcal{N}(0, t) = \sqrt{t}\mathcal{N}(0, 1),$</span> we see that</p><p class="math-container">\[    [\mathrm{d}W_t] = [W_t] = \sqrt{T}.\]</p><p>This is consistent with the idea that the white noise <span>$\{\xi_t\}_t$</span> is formally the time derivative of the Wiener process <span>$\{W_t\}_t.$</span> </p><p>Now, we see that</p><p class="math-container">\[    [\mathrm{d}Y_t] = [Y_t] = \frac{L}{T},\]</p><p>while</p><p class="math-container">\[    [\nu Y_t \;\mathrm{d}t] = \frac{1}{T} \frac{L}{T} T = \frac{L}{T},\]</p><p>and</p><p class="math-container">\[    [\sigma \;\mathrm{d}W_t] = \frac{L}{T^{3/2}} T^{1/2} = \frac{L}{T},\]</p><p>establishing the consistency of the equation in terms of physical dimension.</p><h3 id="The-overdamped-limit"><a class="docs-heading-anchor" href="#The-overdamped-limit">The overdamped limit</a><a id="The-overdamped-limit-1"></a><a class="docs-heading-anchor-permalink" href="#The-overdamped-limit" title="Permalink"></a></h3><p>In the Langevin equation</p><p class="math-container">\[    m \ddot x_t = - a \mu \dot x_t - m\nabla U(x_t) + \alpha \xi_t, \qquad \alpha = \sqrt{2a\mu k_B T},\]</p><p>the term <span>$m \ddot x_t$</span> represents the inertial force. When the motion is relatively slow, this inertia might be negligible when compared with the drag force. Dropping this term yields the equation</p><p class="math-container">\[    0 = - \nu \dot x_t - \nabla U(x_t) + \alpha \xi_t,\]</p><p>which we can write in the usual form of the <em>overdamped Langevin equation</em></p><p class="math-container">\[    \mu \dot x_t = - \nabla U(x_t) + \alpha \xi_t.\]</p><p>The corresponding stochastic system reduces to a single equation</p><p class="math-container">\[    \nu \mathrm{d}X_t = - \nabla U(X_t)\;\mathrm{d}t + \sigma \;\mathrm{d}W_t.\]</p><p>For this approximation to be valid, we look at the ratio between the inertial force <span>$m\ddot x_t$</span> and the damping force <span>$-a\mu \dot x_t.$</span> We have</p><p class="math-container">\[    \frac{m\ddot x_t}{a\mu \dot x_t} \sim \frac{1}{\nu}\frac{\Delta Y_t}{Y_t\Delta t}.\]</p><p>The inertial force is negligible when</p><p class="math-container">\[    \frac{\Delta Y_t}{Y_t} \ll \nu \Delta t,\]</p><p>which can be interpreted as when the relative variations <span>$\Delta Y_t/Y_t$</span> in velocity are relatively small or when the damping is relatively large. This is consistent with saying that we obtain the first order equation in the overdamped regime.</p><p>In the absence of a force field <span>$U=U(x)$</span>, we are left with</p><p class="math-container">\[    \nu \mathrm{d}X_t = \sigma \;\mathrm{d}W_t.\]</p><p>which is the Brownian motion equation, with the solution</p><p class="math-container">\[    X_t = \frac{\sigma}{\nu} = \sqrt{\frac{2k_B T}{a\mu}} W_t.\]</p><p>In this way, we recover the Brownian motion from the Langevin equation as the overdamped limit without a force field.</p><p>Notice the right hand side above has indeed the dimension of length,</p><p class="math-container">\[    \left[\sqrt{\frac{2k_B T}{a\mu}} W_t \right] = \sqrt{\frac{ML^2}{\Theta T^2}\Theta \frac{1}{L}\frac{LT}{M}} \sqrt{T} = \sqrt{\frac{L^2}{T}} \sqrt{T} = L.\]</p><h3 id="Adimensionalization"><a class="docs-heading-anchor" href="#Adimensionalization">Adimensionalization</a><a id="Adimensionalization-1"></a><a class="docs-heading-anchor-permalink" href="#Adimensionalization" title="Permalink"></a></h3><p>With a proper rescaling, we obtain the <em>adimensional overdamped Langevin equation</em></p><p class="math-container">\[    \mathrm{d}\tilde X_t = - \nabla_{\tilde x}{\tilde U}({\tilde X}_{\tilde t})\;\mathrm{d}\tilde t + \sqrt{2}\;\mathrm{d}{\tilde W}_{\tilde t}.\]</p><p>We do the details of this change of variables below. See also <a href="https://doi.org/10.1007/978-1-4939-1323-7_6">Section 6.5</a> of <a href="https://doi.org/10.1007/978-1-4939-1323-7">Grigorios Pavliotis (2014)</a>.</p><p>We start with the equation</p><p class="math-container">\[    \nu \mathrm{d}X_t = - \nabla U(X_t)\;\mathrm{d}t + \sigma \;\mathrm{d}W_t,\]</p><p>and divide it by <span>$a\nu,$</span> so that</p><p class="math-container">\[    \frac{1}{a}\mathrm{d}X_t = - \frac{1}{a\nu}\nabla U(X_t)\;\mathrm{d}t + \frac{\sigma}{a\nu} \;\mathrm{d}W_t.\]</p><p>Since <span>$\sigma = \sqrt{2\nu k_B T / m}$</span> and <span>$\nu = a\mu / m,$</span> we write</p><p class="math-container">\[    \frac{\sigma}{a\nu} = \frac{\sqrt{2\nu k_B T / m}}{a\nu} = \sqrt{\frac{2\nu k_B T}{a^2 m \nu^2}} = \sqrt{\frac{2 k_B T}{a^2 m \nu}} = \sqrt{\frac{2k_B T}{a^3\mu}}.\]</p><p>Thus,</p><p class="math-container">\[    \frac{1}{a}\mathrm{d}X_t = - \frac{1}{a\nu}\nabla U(X_t)\;\mathrm{d}t + \sqrt{\frac{2k_B T}{a^3\mu}}\;\mathrm{d}W_t.\]</p><p>The time and length scales are changed to</p><p class="math-container">\[    \tilde t = \nu t, \quad \tilde x = \frac{x}{a}.\]</p><p>Accordingly, we set</p><p class="math-container">\[    \tilde X_{\tilde t} = \frac{1}{a} \tilde X_{\tilde t / \nu} = \frac{1}{a} X_t.\]</p><p>Thus,</p><p class="math-container">\[    \frac{1}{a} \mathrm{d}X_t = \mathrm{d}{\tilde X}_{\tilde t}.\]</p><p>We also define the adimensional potential</p><p class="math-container">\[    \tilde U(\tilde x) = \frac{1}{a^2\nu^2}U(a\tilde x) = \frac{1}{a^2\nu^2} U(x).\]</p><p>Thus,</p><p class="math-container">\[    - \frac{1}{a\nu}\nabla_x U(X_t)\;\mathrm{d}t = - \frac{1}{a\nu} \nabla_x \left(a^2\nu^2 {\tilde U}\left(\frac{X_t}{a}\right) \right)\;\frac{\mathrm{d}\tilde t}{\nu} = - a\nabla_x \left( {\tilde U}\left(\frac{X_t}{a}\right)\right)\;\mathrm{d}\tilde t = - a\nabla_{\tilde x} {\tilde U}({\tilde X}_{\tilde t})\frac{1}{a}\;\mathrm{d}\tilde t,\]</p><p>so that</p><p class="math-container">\[    - \frac{1}{a\nu}\nabla_x U(X_t)\;\mathrm{d}t = - \nabla_{\tilde x} {\tilde U}({\tilde X}_{\tilde t})\;\mathrm{d}\tilde t.\]</p><p>Finally we set</p><p class="math-container">\[    {\tilde W}_{\tilde t} = \sqrt{\frac{k_B T}{a^3\mu}} W_{\tilde t / \nu} = \sqrt{\frac{k_B T}{a^3\mu}} W_t,\]</p><p>so that</p><p class="math-container">\[    \sqrt{\frac{2k_B T}{a^3\mu}} \;\mathrm{d}W_t = \sqrt{2}\mathrm{d}{\tilde W}_{\tilde t}. \]</p><p>Notice that</p><p class="math-container">\[    \left[ \sqrt{\frac{2k_B T}{a^3\mu}} \right] = \sqrt{\frac{ML^2}{\Theta T^2} \Theta\frac{LT}{L^3 M}} = \sqrt{\frac{1}{T}}, \qquad \left[\mathrm{d}W_t\right] = \sqrt{T},\]</p><p>so <span>${\tilde W}_{\tilde t}$</span> is indeed adimensional.</p><p>Combining the terms, we obtain the adimensional equation</p><p class="math-container">\[    \mathrm{d}{\tilde X}_{\tilde t} = - \nabla_{\tilde x} {\tilde U}({\tilde X}_{\tilde t})\;\mathrm{d}\tilde t + \sqrt{2}\;\mathrm{d}{\tilde W}_{\tilde t}.\]</p><p>The factor <span>$\sqrt{2}$</span> could have been included in the definition of <span>${\tilde W}_{\tilde t},$</span> but it was left out because it will compensate the one-half term coming from the Itô formula and both eventually cancel out when computing the invariant distribution.</p><h4 id="The-limit-as-\\nu-\\rightarrow-\\infty."><a class="docs-heading-anchor" href="#The-limit-as-\\nu-\\rightarrow-\\infty.">The limit as <span>$\nu \rightarrow \infty.$</span></a><a id="The-limit-as-\\nu-\\rightarrow-\\infty.-1"></a><a class="docs-heading-anchor-permalink" href="#The-limit-as-\\nu-\\rightarrow-\\infty." title="Permalink"></a></h4><p>If one does the rescaling above in the full equation</p><p class="math-container">\[    m \ddot x_t = - a\mu \dot x_t - m\nabla U(x_t) + \alpha \xi_t,\]</p><p>one obtains the overdamped limit exactly when taking the limit <span>$\nu \rightarrow \infty.$</span> We leave this as an exercise.</p><h3 id="The-asymptotic-distribution"><a class="docs-heading-anchor" href="#The-asymptotic-distribution">The asymptotic distribution</a><a id="The-asymptotic-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#The-asymptotic-distribution" title="Permalink"></a></h3><p>In the inviscid deterministic case, the Langevin equation reads</p><p class="math-container">\[    m \ddot x_t = - m \nabla U(x_t),\]</p><p>and the level sets</p><p class="math-container">\[    \left\{(x, v); \frac{1}{2}v^2 + U(x) = c\right\}\]</p><p>of the <em>total energy</em> are invariant by the solution group. In the viscous deterministic case</p><p class="math-container">\[    m \ddot x_t = - a\mu \dot x_t - m\nabla U(x_t),\]</p><p>the solutions tend to the equilibria states <span>$\min_x U(x)$</span>, or more precisely to the variety</p><p class="math-container">\[    \{(x, v); v = \nabla U(x) = 0\}.\]</p><p>In the full viscous, stochastic equation, the tendency to go to the equilibria is balanced by the diffusion, and the system tends to a <em>stochastic</em> equilibrium represented by a distribution with probability density function</p><p class="math-container">\[    p_U(x, v) = \frac{1}{Z} e^{-\frac{m}{k_B T}\left( \frac{v^2}{2} + U(x)\right)},\]</p><p>where <span>$Z$</span> is a normalization constant to have <span>$p_U(x, v)$</span> integrate to <span>$1$</span>.</p><p>A similar behavior occurs in the overdamped Langevin equation, for which the equilibrium distribution is given by</p><p class="math-container">\[    p_U(x) = \frac{1}{Z_0} e^{-\frac{m}{k_B T} U(x)},\]</p><p>where <span>$Z_0$</span> is another normalization constant.</p><p>We now discuss in more details the equilibrium distribution in the overdamped equation. For that, we look at the Fokker-Plank equation for</p><p class="math-container">\[    \nu\mathrm{d} X_t = - \nabla U(X_t)\;\mathrm{d}t + \sqrt{\frac{2\nu k_B T}{m}}\;\mathrm{d}W_{t},\]</p><p>In general, a stochastic differential equation of the form</p><p class="math-container">\[    \mathrm{d} X_t = \mu(t, X_t) \;\mathrm{d}t + \sigma(t, X_t)\;\mathrm{d}W_{t}\]</p><p>is associated with the Fokker-Planck equation</p><p class="math-container">\[    \frac{\partial}{\partial t} p(t, x) = - \nabla_x \cdot \left(\mu(t, x) p(t, x)\right) + \frac{1}{2} \Delta_x \left( \sigma(t, x)^2 p(t, x) \right),\]</p><p>where <span>$p(t, x)$</span> is such that <span>$x \mapsto p(t, x)$</span> is the probability density function of the solution <span>$X_t$</span>, i.e. the marginal distribution at time <span>$t$</span> of the process <span>$\{X_t\}_t$</span>. For the overdamped Langevin equation above, the Fokker-Planck equation takes the form</p><p class="math-container">\[    \frac{\partial}{\partial t} p(t, x) = \frac{1}{\nu}\nabla_x \cdot \left(\nabla U(x) p(t, x)\right) + \frac{k_B T}{\nu m}\Delta_x p(t, x),\]</p><p>which can also be written as</p><p class="math-container">\[    \frac{\partial}{\partial t} p(t, x) = \frac{1}{\nu}\nabla_x \cdot \left(\nabla U(x) p(t, x) + \frac{k_B T}{m}\nabla_x p(t, x) \right),\]</p><p>At the equilibrium, the probability density function <span>$p(t, x) = p_\infty(x)$</span> is independent of time and satisfies</p><p class="math-container">\[    \nabla_x \cdot \left(\nabla U(x) p_\infty(x) + \frac{k_B T}{m}\nabla_x p_\infty(x) \right) = 0.\]</p><p>In the one-dimensional case, this means that</p><p class="math-container">\[    \frac{\partial U(x)}{\partial x} p_\infty(x) + \frac{k_B T}{m}\frac{\partial p_\infty(x)}{\partial t} = C,\]</p><p>for some constant <span>$C$</span>. This can be written in the form of the first order differential equation</p><p class="math-container">\[    \frac{\partial p_\infty(x)}{\partial t} + \frac{m}{k_B T}\frac{\partial U(x)}{\partial x} p_\infty(x) = \frac{m}{k_B T} C.\]</p><p>This equation can be solved using the integrating factor</p><p class="math-container">\[    e^{\frac{m}{k_B T} U(x)}.\]</p><p>But assuming that the terms on the left hand side of the first order differential equation vanish when <span>$|x| \rightarrow \infty$</span>, the constant <span>$C$</span> must be zero. In this case, the solution simplifies to</p><p class="math-container">\[    p_\infty(x) = C_0 e^{-\frac{m}{k_B T} U(x)},\]</p><p>for some other constant <span>$C_0$</span>, which we may write as <span>$C_0 = 1/Z_0$</span> and obtain the expression</p><p class="math-container">\[    p_\infty(x) = \frac{1}{Z_0} e^{-\frac{m}{k_B T} U(x)}.\]</p><p>The constant <span>$Z_0$</span> is a normalization factor to yield that <span>$p(x)$</span> is a proper probability density function, with total mass <span>$1$</span>, i.e.</p><p class="math-container">\[    Z_0 = \int_{-\infty}^\infty e^{-\frac{m}{k_B T} U(x)}\;\mathrm{d}x.\]</p><p>One can check that the PDF above is also a solution in the multi-dimensional case.</p><p>When the potential <span>$U=U(x)$</span> grows sufficiently rapidly as <span>$|x|\rightarrow \infty$</span>, this distribution is the unique equilibrium. In the case of thermodynamics, this corresponds to thermodynamic equilibrium and this is known as the <em>Boltzmann distribution.</em> The condition that the potential grows sufficiently rapidly at infinite means that the potential well is deep enough to confine the particle.</p><p>Abstracting away from the physical model and considering the overdamped Langevin equation in the form</p><p class="math-container">\[    \mathrm{d} X_t = - \nabla U(X_t)\;\mathrm{d}t + \sqrt{2\gamma}\;\mathrm{d}W_{t},\]</p><p>for some constant <span>$\gamma &gt; 0$</span>, then the Fokker-Planck equation reads</p><p class="math-container">\[    \frac{\partial}{\partial t} p(t, x) = \nabla_x \cdot \left(\nabla U(x) p(t, x)\right) + \gamma\Delta_x p(t, x),\]</p><p>and the stationary distribution takes the form</p><p class="math-container">\[    p_\infty(x) = \frac{1}{Z_0} e^{-\frac{U(x)}{\gamma}}.\]</p><h3 id="Convergence-to-the-asymptotic-distribution"><a class="docs-heading-anchor" href="#Convergence-to-the-asymptotic-distribution">Convergence to the asymptotic distribution</a><a id="Convergence-to-the-asymptotic-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#Convergence-to-the-asymptotic-distribution" title="Permalink"></a></h3><p>There are many rigorous results concerning the convergence to the equilibrium distribution, discussing conditions for the convergence, metrics, and rate of convergence. We will discuss them in more details in due course.</p><h2 id="Sampling-from-the-score-function-via-Langevin-dynamics"><a class="docs-heading-anchor" href="#Sampling-from-the-score-function-via-Langevin-dynamics">Sampling from the score function via Langevin dynamics</a><a id="Sampling-from-the-score-function-via-Langevin-dynamics-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling-from-the-score-function-via-Langevin-dynamics" title="Permalink"></a></h2><p>Now, suppose we take for the potential <span>$U=U(x)$</span> minus a multiple of the logpdf of a random variable <span>$X$</span> with probability density function <span>$p_X(x)$</span> up to an arbitrary constant, i.e.</p><p class="math-container">\[    U(x) = - \gamma \log p_X(x) + C,\]</p><p>for some constants <span>$\gamma$</span> and <span>$C$</span>. The score function is connected to the gradient of the potential by</p><p class="math-container">\[    \psi_X(x) = \nabla_x \log p_X(x) = - \frac{1}{\gamma} \nabla_x U(x).\]</p><p>In this case, we can write the PDF as</p><p class="math-container">\[    p_X(x) = e^{\log p_X(x)} = e^{-U(x)/\gamma + C/\gamma} = \frac{1}{Z} e^{-U(x)/\gamma},\]</p><p>for a (normalizing) constant <span>$Z = e^{-C/\gamma}$</span>. Then we see that the PDF <span>$p_X(x)$</span> is exactly the equilibrium of the Langevin equation</p><p class="math-container">\[    \mathrm{d}X_t = -\nabla U(X_t)\;\mathrm{d}t + \sqrt{2\gamma}\mathrm{d}W_t.\]</p><p>which can be written as</p><p class="math-container">\[    \mathrm{d}X_t = \gamma\psi_X(X_t)\;\mathrm{d}t + \sqrt{2\gamma}\mathrm{d}W_t.\]</p><p>This lead to a sampling method to draw samples from a distribution using its score function, as introduced by <a href="https://doi.org/10.2307/3318418">Gareth Roberts and Richard Tweedie (1996)</a>.</p><p>As mentioned above, questions about the conditions for the convergence, rate of converge and convergence metric are of great importance, and they are also important for sampling purposes. Other relevant question concern the stability of the equilibrium solution, when for instance an approximate score function is used. This is also relevant when the modeled score function (say via a neural network) might even not be exactly the gradient of a potential. We will leave these questions to another opportunity.</p><h2 id="Numerical-example"><a class="docs-heading-anchor" href="#Numerical-example">Numerical example</a><a id="Numerical-example-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-example" title="Permalink"></a></h2><h3 id="One-dimensional-numerical-example"><a class="docs-heading-anchor" href="#One-dimensional-numerical-example">One-dimensional numerical example</a><a id="One-dimensional-numerical-example-1"></a><a class="docs-heading-anchor-permalink" href="#One-dimensional-numerical-example" title="Permalink"></a></h3><p>We first illustrate the Langevin sampling by drawing samples for a univariate Gaussian mixture distribution.</p><img src="75fecf9b.svg" alt="Example block output"/><div class="markdown"><p>Now we draw samples from it using the overdamped Langevin equation with &#36;\gamma &#61; 0.5&#36;. We start with samples from a normal distribution &#36;\mathcal&#123;N&#125;&#40;5, 1^2&#41;&#36; and evolve them according to the equation, from the initial time &#36;t_0 &#61; 0&#36; up to time &#36;t_f &#61; 10&#36;.</p>
</div><p>Here is <span>$tx$</span> plot of the ensemble of solutions of the stochastic overdamped Langevin equation.</p><img src="46f712f1.svg" alt="Example block output"/><p>We obtain the following histogram at the final time:</p><img src="8ff0ced1.svg" alt="Example block output"/><p>We may also visualize a surface plot and a heatmap of the evolution of the Fokker-Planck equation for the density.</p><img src="eda4e414.svg" alt="Example block output"/><img src="0757c0ae.svg" alt="Example block output"/><p>With an animation just for fun.</p><img src="1e709fa4.gif" alt="Example block output"/><h3 id="Two-dimensional-numerical-example"><a class="docs-heading-anchor" href="#Two-dimensional-numerical-example">Two-dimensional numerical example</a><a id="Two-dimensional-numerical-example-1"></a><a class="docs-heading-anchor-permalink" href="#Two-dimensional-numerical-example" title="Permalink"></a></h3><p>Let&#39;s do a two-dimensional example, now. We consider a trimodal bivariate normal distribution and use the two-dimensional overdamped Langevin equations to obtain samples from the score function of the distribution.</p><p>Here is a visualization of the distribution and its score vector field.</p><img src="c3799505.svg" alt="Example block output"/><div class="markdown"><p>Now we draw samples from it using the overdamped Langevin equation with &#36;\gamma &#61; 0.5&#36;, and starting with samples from a standard normal distribution, evolving the particles from the initial time &#36;t_0 &#61; 0&#36; up to time &#36;t_f &#61; 10&#36;.</p>
</div><p>Let us see the location of the generated sample points and their histogram.</p><pre><code class="language-julia hljs">scatter!(xt[1, :, end], xt[2, :, end], markersize=2, markercolor=:white, label=false) # hid2</code></pre><img src="30cae5b9.svg" alt="Example block output"/><p>Observe how many more particles are trapped near the modal point in the middle. In the target distribution, this is the smallest nodal point, but it seems the highest. Given enough time, though, the particles do tend to the proper distribution.</p><p>Let us see an animation for fun.</p><img src="6ff19c8d.gif" alt="Example block output"/><p>Now we draw samples starting from a uniform distribution of points on the square <span>$[-6, 6]^2$</span>, which encompasses all three modal regions.</p><p>Here is what we get.</p><pre><code class="language-julia hljs">scatter!(xt[1, :, end], xt[2, :, end], markersize=2, markercolor=:white, label=false) # hid2</code></pre><img src="451b7924.svg" alt="Example block output"/><p>Notice this is closer to the desired distribution. With the initial points spread out over the modal regions, the particles have less trouble moving to the asymptotic distribution.</p><p>Again, let us see an animation.</p><img src="0d4db1bb.gif" alt="Example block output"/><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ol><li><a href="https://doi.org/10.1080%2F14786442808674769">R. Brown (1828), &quot;A brief account of microscopical observations made in the months of June, July and August, 1827, on the particles contained in the pollen of plants; and on the general existence of active molecules in organic and inorganic bodies&quot;. Philosophical Magazine. 4 (21), 161-173. doi:10.1080/14786442808674769</a></li><li><a href="https://doi.org/10.1002/andp.19053220806">A. Einstein (1905), &quot;Über die von der molekularkinetischen Theorie der Wärme geforderte Bewegung von in ruhenden Flüssigkeiten suspendierten Teilchen&quot; [On the Movement of Small Particles Suspended in Stationary Liquids Required by the Molecular-Kinetic Theory of Heat], Annalen der Physik, 322 (8), 549-560, doi:10.1002/andp.19053220806</a></li><li><a href="https://www.cambridge.org/il/academic/subjects/statistics-probability/probability-theory-and-stochastic-processes/brownian-motion?format=HB&amp;isbn=9780521760188">P. Mörters and Y. Peres (2010), &quot;Brownian motion&quot;, Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, Cambridge. With an appendix by Oded Schramm and Wendelin Werner</a></li><li><a href="https://gallica.bnf.fr/ark:/12148/bpt6k3100t/f530.item">P. Langevin (1908), &quot;Sur la théorie du mouvement brownien [On the Theory of Brownian Motion]&quot;. C. R. Acad. Sci. Paris. 146: 530–533</a> </li><li><a href="https://doi.org/10.1007/978-1-4939-1323-7">G. A. Pavliotis (2014), &quot;The Langevin Equation. In: Stochastic Processes and Applications&quot;. Texts in Applied Mathematics, vol 60. Springer, New York, NY, doi:10.1007/978-1-4939-1323-7_6</a></li><li><a href="https://doi.org/10.2307/3318418">G. O. Roberts, R. L. Tweedie (1996), &quot;Exponential Convergence of Langevin Distributions and Their Discrete Approximations&quot;, Bernoulli, Vol. 2, No. 4, 341-363, doi:10.2307/3318418</a></li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../hmc/">« Hamiltonian Monte Carlo (HMC)</a><a class="docs-footer-nextpage" href="../../bayesian/bayes/">Bayes Theorem »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.15.0 on <span class="colophon-date" title="Thursday 6 November 2025 15:39">Thursday 6 November 2025</span>. Using Julia version 1.12.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
