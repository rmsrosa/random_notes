<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Metropolis and Metropolis-Hastings · Random notes</title><meta name="title" content="Metropolis and Metropolis-Hastings · Random notes"/><meta property="og:title" content="Metropolis and Metropolis-Hastings · Random notes"/><meta property="twitter:title" content="Metropolis and Metropolis-Hastings · Random notes"/><meta name="description" content="Documentation for Random notes."/><meta property="og:description" content="Documentation for Random notes."/><meta property="twitter:description" content="Documentation for Random notes."/><meta property="og:url" content="https://github.com/rmsrosa/random_notes/sampling/metropolis/"/><meta property="twitter:url" content="https://github.com/rmsrosa/random_notes/sampling/metropolis/"/><link rel="canonical" href="https://github.com/rmsrosa/random_notes/sampling/metropolis/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/style.css" rel="stylesheet" type="text/css"/><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Random notes logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Random notes</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Random Notes</a></li><li><span class="tocitem">Probability Essentials</span><ul><li><a class="tocitem" href="../../probability/kernel_density_estimation/">Kernel Density Estimation</a></li><li><a class="tocitem" href="../../probability/convergence_notions/">Convergence notions</a></li></ul></li><li><span class="tocitem">Discrete-time Markov chains</span><ul><li><a class="tocitem" href="../../markov_chains/mc_definitions/">Essential definitions</a></li><li><a class="tocitem" href="../../markov_chains/mc_invariance/">Invariant distributions</a></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Countable-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_countableX_recurrence/">Recurrence in the countable-space case</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_connections/">Connected states, irreducibility and uniqueness of invariant measures</a></li><li><a class="tocitem" href="../../markov_chains/mc_countableX_convergencia/">Aperiodicidade e convergência para a distribuição estacionária</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Continuous-space Markov chains</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../markov_chains/mc_irreducibility_and_recurrence/">Irreducibility and recurrence in the continuous-space case</a></li></ul></li></ul></li><li><span class="tocitem">Sampling methods</span><ul><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../prng/">Random number generators</a></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Transform methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../invFtransform/">Probability integral transform</a></li><li><a class="tocitem" href="../box_muller/">Box-Muller transform</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Accept-Reject methods</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../rejection_sampling/">Rejection sampling</a></li><li><a class="tocitem" href="../empiricalsup_rejection/">Empirical supremum rejection sampling</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox" checked/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Markov Chain Monte Carlo (MCMC)</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../mcmc/">Overview</a></li><li class="is-active"><a class="tocitem" href>Metropolis and Metropolis-Hastings</a><ul class="internal"><li><a class="tocitem" href="#The-Metropolis-algorithm"><span>The Metropolis algorithm</span></a></li><li><a class="tocitem" href="#The-Metropolis-Hastings-algorithm"><span>The Metropolis-Hastings algorithm</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../convergence_metropolis/">Convergence of Metropolis-Hastings</a></li><li><a class="tocitem" href="../gibbs/">Gibbs sampling</a></li><li><a class="tocitem" href="../hmc/">Hamiltonian Monte Carlo (HMC)</a></li></ul></li><li><a class="tocitem" href="../langevin_sampling/">Langevin sampling</a></li></ul></li><li><span class="tocitem">Bayesian inference</span><ul><li><input class="collapse-toggle" id="menuitem-5-1" type="checkbox"/><label class="tocitem" for="menuitem-5-1"><span class="docs-label">Bayes Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/bayes/">Bayes Theorem</a></li><li><a class="tocitem" href="../../bayesian/bayes_inference/">Bayesian inference</a></li><li><a class="tocitem" href="../../bayesian/bernstein_vonmises/">Bernstein–von Mises theorem</a></li></ul></li><li><a class="tocitem" href="../../bayesian/bayesian_probprog/">Bayesian probabilistic programming</a></li><li><input class="collapse-toggle" id="menuitem-5-3" type="checkbox"/><label class="tocitem" for="menuitem-5-3"><span class="docs-label">Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../bayesian/find_pi/">Estimating π via frequentist and Bayesian methods</a></li><li><a class="tocitem" href="../../bayesian/linear_regression/">Many Ways to Linear Regression</a></li><li><a class="tocitem" href="../../bayesian/tilapia_alometry/">Alometry law for the Nile Tilapia</a></li><li><a class="tocitem" href="../../bayesian/mortality_tables/">Modeling mortality tables</a></li></ul></li></ul></li><li><span class="tocitem">Generative models</span><ul><li><input class="collapse-toggle" id="menuitem-6-1" type="checkbox"/><label class="tocitem" for="menuitem-6-1"><span class="docs-label">Score matching</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../generative/overview/">Overview</a></li><li><a class="tocitem" href="../../generative/stein_score/">Stein score function</a></li><li><a class="tocitem" href="../../generative/score_matching_aapo/">Score matching of Aapo Hyvärinen</a></li><li><a class="tocitem" href="../../generative/score_matching_neural_network/">Score matching a neural network</a></li><li><a class="tocitem" href="../../generative/parzen_estimation_score_matching/">Score matching with Parzen estimation</a></li><li><a class="tocitem" href="../../generative/denoising_score_matching/">Denoising score matching of Pascal Vincent</a></li><li><a class="tocitem" href="../../generative/sliced_score_matching/">Sliced score matching</a></li><li><a class="tocitem" href="../../generative/1d_FD_score_matching/">1D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/2d_FD_score_matching/">2D finite-difference score matching</a></li><li><a class="tocitem" href="../../generative/ddpm/">Denoising diffusion probabilistic models</a></li><li><a class="tocitem" href="../../generative/mdsm/">Multiple denoising score matching</a></li><li><a class="tocitem" href="../../generative/probability_flow/">Probability flow</a></li><li><a class="tocitem" href="../../generative/reverse_flow/">Reverse probability flow</a></li><li><a class="tocitem" href="../../generative/score_based_sde/">Score-based SDE model</a></li></ul></li></ul></li><li><span class="tocitem">Sensitivity analysis</span><ul><li><a class="tocitem" href="../../sensitivity/overview/">Overview</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Sampling methods</a></li><li><a class="is-disabled">Markov Chain Monte Carlo (MCMC)</a></li><li class="is-active"><a href>Metropolis and Metropolis-Hastings</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Metropolis and Metropolis-Hastings</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/rmsrosa/random_notes/blob/main/docs/src/sampling/metropolis.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Metropolis-and-Metropolis-Hastings-methods"><a class="docs-heading-anchor" href="#Metropolis-and-Metropolis-Hastings-methods">Metropolis and Metropolis-Hastings methods</a><a id="Metropolis-and-Metropolis-Hastings-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Metropolis-and-Metropolis-Hastings-methods" title="Permalink"></a></h1><p>The Metropolis algorithm was proposed by <a href="http://dx.doi.org/10.1063/1.1699114">N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, E. Teller (1953)</a> as a means to compute the equilibrium state of a many-particle system. The actual computations were done in the <a href="https://en.wikipedia.org/wiki/MANIAC_I">MANIAC I (Mathematical Analyzer Numerical Integrator and Automatic Computer Model I)</a>, an early computer developed under the direction of Nicholas Metropolis, at the Los Alamos Scientific Laboratory, and used, in particular, for the development of the hydrogen bomb, which most of the authors of this paper were involved with.</p><p>In the application, one aims to compute mean quantities of interest with respect to a statistical equilibrium state <span>$P$</span> of a many-particle system with potential energy <span>$U(x),$</span> which amounts to computing integrals with the probability density function of the form</p><p class="math-container">\[    p(x) = \frac{e^{-U(x)}}{Z}.\]</p><p>More generally, one considers <span>$f(x)$</span> such that</p><p class="math-container">\[    p(x) = \frac{f(x)}{Z},\]</p><p>for a possibly unknown normalizing constant <span>$Z.$</span> In the setting above, <span>$f(x) = e^{-U(x)}.$</span> The aim, then, is to draw samples of a distribution knowning the PDF only up to a multiplicative constant.</p><h2 id="The-Metropolis-algorithm"><a class="docs-heading-anchor" href="#The-Metropolis-algorithm">The Metropolis algorithm</a><a id="The-Metropolis-algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#The-Metropolis-algorithm" title="Permalink"></a></h2><p>Let us consider the case in which the event space is a finite dimensional space <span>$\mathcal{X} = \mathbb{R}^d,$</span> <span>$d\in\mathbb{E}$</span>, and the desired probability distribution <span>$P$</span> is absolutely continuous with respect to the Lebesgue measure <span>$\mathrm{d}x,$</span> with density <span>$p(x) = f(x)/Z,$</span> for a known function <span>$f=f(x)$</span> and a possibly unkown normalization factor <span>$Z.$</span></p><p>The algorithm is built upon the idea of designing a Markov chain <span>$(X_n)_{n=0, 1, \ldots}$</span> and drawing a (single) sample path <span>$(x_n)_{n=0, 1, \ldots}$</span> as a representative of the distribution, as follows</p><ol><li>Choose a <em>symmetric</em> (and stationary) proposal transition probability <span>$Q = Q(x, \cdot)$</span> with kernel density <span>$q(x, y),$</span> of going from state <span>$X_n = x$</span> to state <span>$X_{n+1} = y;$</span></li><li>Choose a initial state <span>$x_0;$</span></li><li>Proceed by induction to define the state <span>$x_{n+1}$</span> from a given state <span>$x_n$</span> as follows<ol><li>Choose a <em>candidate</em> <span>$x&#39; \sim Q(x_n, \cdot);$</span></li><li>Compute the acceptance ratio <span>$r(x_n, x&#39;),$</span> where <span>$r(x, y) = \frac{f(y)}{f(x)} = \frac{p(y)}{p(x)}.$</span></li><li>Draw a sample <span>$u$</span> from a standard uniform distribution, <span>$u \sim \operatorname{Uniform}[0, 1];$</span></li><li>Accept/reject step:<ol><li>if <span>$u \leq r(x_n, x&#39;),$</span> accept the state <span>$x&#39;$</span> and set <span>$x_{n+1} = x;$</span></li><li>if <span>$u &gt; r(x_n, x&#39;),$</span> reject the state <span>$x&#39;$</span> and repeat the previous state, <span>$x_{n+1} = x_n.$</span></li></ol></li></ol></li><li>Discard a initial transient time <span>$N$</span> called the <em>burn-in</em> time and consider the states <span>$x_{N+1}, x_{N+2}, \ldots,$</span> as a sample of the desired distribution.</li></ol><h3 id="The-transition-kernel-of-the-Metropolis-algorithm"><a class="docs-heading-anchor" href="#The-transition-kernel-of-the-Metropolis-algorithm">The transition kernel of the Metropolis algorithm</a><a id="The-transition-kernel-of-the-Metropolis-algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#The-transition-kernel-of-the-Metropolis-algorithm" title="Permalink"></a></h3><p>The density <span>$q(x, y)$</span> is the kernel density of a <em>proposal distribution</em> <span>$Q(x, \cdot).$</span> The actual kernel of the Markov chain <span>$(X_n)_{n=0, 1, \ldots}$</span>  is affected by the acceptance/rejection step. When going from state <span>$x$</span> to state <span>$y \neq x,$</span> assuming <span>$f(x) &gt; 0,$</span> the chances of the proposed state of being accepted has probability density</p><p class="math-container">\[    \min\left\{1, \frac{f(y)}{f(x)}\right\}.\]</p><p>When <span>$f(x) = 0,$</span> one should definitely accept any <span>$y$</span>, thus we consider the acceptance factor</p><p class="math-container">\[    \alpha(x, y) = \begin{cases}
        \min\left\{1, \frac{f(y)}{f(x)}\right\}, &amp; f(x) &gt; 0, \\
        1, &amp; f(x) = 0.
    \end{cases}\]</p><p>Then, the actual transition probability <span>$A(x, E) = \mathbb{P}(X_{n+1} \in E | X_n = x)$</span> of going from state <span>$X_n = x$</span> to a state <span>$X_{n+1}$</span> in a measurable set <span>$E$</span> has density</p><p class="math-container">\[    a(x, y) = q(x, y)\alpha(x, y).\]</p><p>Thus, if <span>$p_{X_n}(x)$</span> is the density of the <span>$X_n$</span> state, then the density <span>$p_{X_{n+1}}(x)$</span> of the next state <span>$X_{n+1}$</span> is given by</p><p class="math-container">\[    p_{X_{n+1}}(x) = \int_{\mathcal{X}} a(x, y) p_{X_n}(x)\;\mathrm{d}x.\]</p><h3 id="The-equilibrium-distribution"><a class="docs-heading-anchor" href="#The-equilibrium-distribution">The equilibrium distribution</a><a id="The-equilibrium-distribution-1"></a><a class="docs-heading-anchor-permalink" href="#The-equilibrium-distribution" title="Permalink"></a></h3><p>Any equilibrium distribution <span>${\tilde p}(x)$</span> must, then, satisfy the equation</p><p class="math-container">\[    {\tilde p}(x) = \int_{\mathcal{X}} a(x, y) {\tilde p}(x)\;\mathrm{d}x, \quad x\in\mathcal{X}.\]</p><p>In particular, we must check whether the density <span>$p=p(x)$</span> of the desired distribution is an equilibrium distribution. This is obtained by checking a stronger condition known as the detailed balance equation.</p><h3 id="Detailed-balance-equation"><a class="docs-heading-anchor" href="#Detailed-balance-equation">Detailed balance equation</a><a id="Detailed-balance-equation-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-balance-equation" title="Permalink"></a></h3><p>A distribution, with density <span>${\tilde p}(x),$</span> is said to satisfy the <strong>detailed balance equation</strong> of a Markov chain with transition kernel <span>$a(x, y)$</span> when</p><p class="math-container">\[    a(x, y){\tilde p}(x) = a(y, x){\tilde p}(y), \quad \text{a.s. } x, y\in \mathcal{X}.\]</p><p>This says that, under a given probability state with density <span>${\tilde p},$</span> the chances of going from a measurable set <span>$B$</span> to a measurable set <span>$C$</span> are the same as those of going from <span>$C$</span> back to <span>$B.$</span> It is a <em>reversibility</em> condition. This implies the stationarity of the distribution, as follows.</p><h3 id="Stationarity-of-a-distribution-satisfying-the-detailed-balance-equation"><a class="docs-heading-anchor" href="#Stationarity-of-a-distribution-satisfying-the-detailed-balance-equation">Stationarity of a distribution satisfying the detailed balance equation</a><a id="Stationarity-of-a-distribution-satisfying-the-detailed-balance-equation-1"></a><a class="docs-heading-anchor-permalink" href="#Stationarity-of-a-distribution-satisfying-the-detailed-balance-equation" title="Permalink"></a></h3><p>Given a state <span>$X_n$</span> with density <span>${\tilde p}={\tilde p}(x),$</span> the density of the next state <span>$X_{n+1} = y$</span> is given by</p><p class="math-container">\[    y \mapsto \int_{\mathcal{X}} q(x, y){\tilde p}(x)\;\mathrm{d}x.\]</p><p>Assuming the detailed balance equation, we have</p><p class="math-container">\[    \int_{\mathcal{X}} q(x, y){\tilde p}(x)\;\mathrm{d}x = \int_{\mathcal{X}} q(y, x){\tilde p}(y)\;\mathrm{d}x.\]</p><p>Since this is a transition kernel, it should satisfy the condition</p><p class="math-container">\[    \int_{\mathcal{X}} q(x, y) \;\mathrm{d}y = 1,\]</p><p>which essentially says that if we start at <span>$x$</span> we should go <em>somewhere</em> with probability one. Switching the variables <span>$x$</span> and <span>$y$</span> we find that</p><p class="math-container">\[    \int_{\mathcal{X}} q(x, y){\tilde p}(x)\;\mathrm{d}x = \int_{\mathcal{X}} q(y, x){\tilde p}(y)\;\mathrm{d}x = {\tilde p}(y)\int_{\mathcal{X}} q(y, x)\;\mathrm{d}x = {\tilde p}(y).\]</p><p>This shows that <span>${\tilde p}$</span> is a stationary density distribution.</p><h3 id="Detailed-balance-equation-and-stationarity-of-the-Metropolis-algorithm"><a class="docs-heading-anchor" href="#Detailed-balance-equation-and-stationarity-of-the-Metropolis-algorithm">Detailed balance equation and stationarity of the Metropolis algorithm</a><a id="Detailed-balance-equation-and-stationarity-of-the-Metropolis-algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Detailed-balance-equation-and-stationarity-of-the-Metropolis-algorithm" title="Permalink"></a></h3><p>We have seen that the transition density of the Metropolis algorithm is</p><p class="math-container">\[    a(x, y) = q(x, y)\alpha(x, y).\]</p><p>where</p><p class="math-container">\[    \alpha(x, y) = \begin{cases}
        \min\left\{1, \frac{f(y)}{f(x)}\right\}, &amp; f(x) &gt; 0, \\
        1, &amp; f(x) = 0.
    \end{cases}\]</p><p>Now we check the detailed balance equation for the distribution density <span>$p(x) = f(x)/Z.$</span></p><p>We only need to check the condition almost surely on <span>$x, y\in\mathcal{X},$</span> so it suffices to consider <span>$x, y$</span> such that <span>$f(x), f(y) &gt; 0.$</span> When <span>$0 &lt; f(x) \leq f(y),$</span> we have</p><p class="math-container">\[    \alpha(x, y) = \min\left\{1, \frac{f(y)}{f(x)}\right\} =  \frac{f(y)}{f(x)} = \frac{p(y)}{p(x)}\]</p><p>and</p><p class="math-container">\[    \alpha(y, x) = \min\left\{1, \frac{f(x)}{f(y)}\right\} = 1.\]</p><p>Thus,</p><p class="math-container">\[    a(x, y) p(x) = q(x, y)\alpha(x, y) p(x) = q(x, y)\frac{p(y)}{p(x)}p(x) = q(x, y) p(y).\]</p><p>Since the proposal distribution is assumed to be symmetric, we have <span>$q(x, y) = q(y, x),$</span> and hence</p><p class="math-container">\[    a(x, y) p(x) = q(y, x)p(y) = q(y, x)p(y).\]</p><p>Using that <span>$\alpha(y, x) = 1,$</span> we obtain</p><p class="math-container">\[    a(x, y) p(x) = q(y, x)\alpha(y, x)p(y) = a(y, x)p(y).\]</p><p>Similarly, when <span>$0 &lt; f(y) \leq f(x),$</span> we find that</p><p class="math-container">\[    \alpha(x, y) = 1, \quad \alpha(y, x) = \frac{p(x)}{p(y)},\]</p><p>and the result follows in the same way,</p><p class="math-container">\[    a(x, y)p(x) = q(x, y)p(x) = q(y, x)\frac{p(x)}{p(y)}p(y) = q(y, x)\alpha(y, x)p(y) = a(y, x)p(y).\]</p><h2 id="The-Metropolis-Hastings-algorithm"><a class="docs-heading-anchor" href="#The-Metropolis-Hastings-algorithm">The Metropolis-Hastings algorithm</a><a id="The-Metropolis-Hastings-algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#The-Metropolis-Hastings-algorithm" title="Permalink"></a></h2><p><a href="https://doi.org/10.1093/biomet/57.1.97">Hastings (1970)</a> extended the idea of the Metropolis algorithm to non-symmetric kernels. This is useful, for instance, when the possible events are restricted to a region of the phase space and we don&#39;t want to waste computational time generating proposal steps away of this region. For instance, if we want to generate samples of a distribution which we known to only accept non-negative coordinate values, we can use a truncated normal proposal distribution, centered on <span>$X_n = x,$</span> and truncated to <span>$x&#39; \geq 0,$</span> which leads to an assymetric density.</p><p>The modification is simple. We only need to modify the acceptance ratio to</p><p class="math-container">\[    r(x, y) = \frac{f(y)q(y, x)}{f(x)q(x, y)},\]</p><p>when <span>$f(x)q(x, y) &gt; 0,$</span> otherwise <span>$r(x, y) = 1.$</span></p><h3 id="Transition-kernel"><a class="docs-heading-anchor" href="#Transition-kernel">Transition kernel</a><a id="Transition-kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Transition-kernel" title="Permalink"></a></h3><p>In the Metropolis-Hastings method, the transition density is still of the form</p><p class="math-container">\[    a(x, y) = q(x, y)\alpha(x, y),\]</p><p>but now</p><p class="math-container">\[    \alpha(x, y) = \begin{cases}
        \min\left\{1, \frac{f(y)q(y, x)}{f(x)q(x, y)}\right\}, &amp; f(x)q(x, y) &gt; 0, \\
        1, &amp; f(x)q(x, y) = 0.
    \end{cases}\]</p><h3 id="The-detailed-balance-equation"><a class="docs-heading-anchor" href="#The-detailed-balance-equation">The detailed balance equation</a><a id="The-detailed-balance-equation-1"></a><a class="docs-heading-anchor-permalink" href="#The-detailed-balance-equation" title="Permalink"></a></h3><p>The proof is similar. But we assume that <span>$q(x, y) &gt; 0,$</span> when <span>$f(x), f(y) &gt; 0 (and consequently $q(y, x) &gt; 0$</span>). </p><p>For the detailed balance equation, we only need to consider  <span>$x, y$</span> such that <span>$f(x), f(y) &gt; 0.$</span> Thus, <span>$q(x, y), q(y, x) &gt; 0.$</span></p><p>When <span>$0 &lt; f(y)q(y, x) \geq f(x)q(x, y),$</span> we have</p><p class="math-container">\[    \alpha(x, y) = \frac{f(y)q(y, x)}{f(x)q(x, y)}, \quad \alpha(y, x) = 1,\]</p><p>so that</p><p class="math-container">\[    a(x, y) = q(x, y) \frac{f(y)q(y, x)}{f(x)q(x, y)} = \frac{p(y)q(y, x)}{p(x)}, \qquad a(y, x) = q(y, x).\]</p><p>Thus,</p><p class="math-container">\[    a(x, y) p(x) = p(y)q(y, x) = p(y)a(y, x).\]</p><p>By symmetry in <span>$x$</span> and <span>$y,$</span> the same follows if <span>$0 &lt; f(x)q(x, y) \geq f(y)q(y, x),$</span> i.e.</p><p class="math-container">\[    p(y)a(y, x) = a(y, x) p(y).\]</p><p>This proves the detailed balance equation, for the density <span>$p=p(x),$</span> with respect to the transition density of the Metropolis-Hasting Markov chain.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><ol><li><a href="http://dx.doi.org/10.1063/1.1699114">Nicholas Metropolis,  Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, and Edward Teller (1953), &quot;Equation of State Calculations by Fast Computing Machines,&quot; J. Chem. Phys. 21, 1087–1092</a></li><li><a href="https://doi.org/10.1093/biomet/57.1.97">W. K. Hastings (1970), &quot;Monte Carlo sampling methods using Markov chains and their applications,&quot; Biometrika 57 (1), 97-109</a></li><li><a href="https://doi.org/10.1007/978-0-387-76371-2">Jun S. Liu, &quot;Monte Carlo Strategies in Scientific Computing,&quot; Springer Series in Statistics, Springer-Verlag New York 2004</a></li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../mcmc/">« Overview</a><a class="docs-footer-nextpage" href="../convergence_metropolis/">Convergence of Metropolis-Hastings »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.13.0 on <span class="colophon-date" title="Thursday 26 June 2025 15:36">Thursday 26 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
