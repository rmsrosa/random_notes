# Overview of the main results pertaining to score-based generative methods

Here we review the main results associated with score-based generative methods.

## Main results

The Langevin equation dates back to the beginning of the 20th Century, as proposed by [Langevin (1908)](https://gallica.bnf.fr/ark:/12148/bpt6k3100t/f530.item), in relation to the Brownian motion.

The use of the Langevin equation (and especially of the overdamped Langevin equation) to draw samples of a *known* distribution from its score function was proposed by [Roberts and Tweedie (1996)](https://doi.org/10.2307/3318418). Rates of convergence were also given and are still an important area of research.

The idea of *modeling* the score function from samples of a distribution was then proposed by [Hyvärinen (2005)](https://jmlr.org/papers/v6/hyvarinen05a.html), via **implicit score matching**. The implicit score matching is obtained via integration by parts of the **explicit score matching** objective, which requires the unknown target score function. The implicit score function, however, requires computing the gradient of the model score function, which works fine for some specific models for which the derivatives can be readily computed, as considered by [Hyvärinen (2005)](https://jmlr.org/papers/v6/hyvarinen05a.html) (and subsequently by [Köster and Hyvärinen (2010)](https://doi.org/10.1162/neco_a_00010)), but which otherwise might be computationally intensive.

[Kingma and LeCun (2010)](https://papers.nips.cc/paper_files/paper/2010/hash/6f3e29a35278d71c7f65495871231324-Abstract.html) used automatic differentiation of certain neural network topologies to compute the gradient of the model score function and proposed a **regularized implicit score matching** objective for stability purposes, by adding a penalization on the gradient of the model score function. This penalization does not add much to the complexity of the method, but it is nevertheless a computationally demanding method, since it is based on the implicit score matching and needs the gradient of the score function. This computational cost also increases dramatically with the dimension of the problem.

[Vincent (2011)](https://doi.org/10.1162/NECO_a_00142) proposed the **denoising score matching** method, by working with the explicit score matching and using Parzen kernel density estimation to approximate the gradient of the desired score function, avoiding the need to differentiate the model score function. One can directly compute the score of the Parzen estimation, which involves computing the logarithm of a sum of kernels, and this can be computed explicitly beforehand, so the optimization process is relatively straightforward. Pascal went further, though, writing the objective function as a double integral with a conditional distribution, so the score that needs to be computed is that of a single kernel, simplifying the computation. This is also interpreted in connection with the denoising auto-encoder methods, where one uses the original sample and a corrupted sample, associated with the conditional distribution over a single kernel of the Parzen estimation. The double integral is not a burden in computations since it turns out a single corrupted sample for each clean sample is sufficient, rendering it effectively as a single integral.

[Song, Garg, Shi, and Ermon (2020)](https://proceedings.mlr.press/v115/song20a.html) addressed again the implicit score matching approach and proposed a **sliced (implicit) score matching** method to reduce the computational cost of the implicit score matching for high-dimensional problems. The trick is to take derivatives only at certain random directions, at each sample point.

A few months later, [Pang, Xu, Li, Song, Ermon, and Zhu (2020)](https://openreview.net/forum?id=LVRoKppWczk) proposed the **finite-difference (implicit) score matching** method, using finite differences to approximate the gradient of the model score function of the implicit score matching objective, greatly reducing the computational cost of the optimization process.

A few years earlier, [Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015)](https://dl.acm.org/doi/10.5555/3045118.3045358) introduced **denoising diffusion probabilistic models (DDPM)**, which was further improved in [Ho, Jain, and Abbeel (2020)](https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html). The idea is to embed the target distribution into a Markov chain and model the reverse process of the Markov chain. The Markov chain gradually adds noise to the process and drives it to a tractable noisy distribution. The model then starts from the tractable distribution and reverts back to an approximation of the target distribution. In other words, the model *denoises* a noisy sample towards a sample of the desired distribution. This is a much more complex task which greatly increases the dimension of the problem, but which yields more stability to both training and generative processes. The original work of [Sohl-Dickstein, Weiss, Maheswaranathan, Ganguli (2015)](https://dl.acm.org/doi/10.5555/3045118.3045358) had a more complex model and an expensive loss function. [Ho, Jain, and Abbeel (2020)](https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html) simplified the model and the loss function, turning it into a practical and efficient model. Further on, [Nichol and Dhariwal (2021)](https://openreview.net/forum?id=-NEXDKk8gZ) showed improvements with a nonlinear variance schedule for the forward process and a partial training of the variance of the model reverse process.

In a subsequent work, [Song, Meng, Ermon (2021)](https://openreview.net/forum?id=St1giarCHLP) improved the DDPM model and introduced **denoising diffusion implicit models (DDIM)**, which is based on non-Markovian processes but amounts to the same training strategy and model. The advantage, then, is that sampling is greatly expedited with a non-Markovian reverse process that can sample directly from the tractable distribution. We do not detail this method here, though.

Then came [Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole (2020)](https://arxiv.org/abs/2011.13456), with the **score-based denoising diffusion SDE models**.

## References

1. [P. Langevin (1908), "Sur la théorie du mouvement brownien [On the Theory of Brownian Motion]". C. R. Acad. Sci. Paris. 146: 530–533](https://gallica.bnf.fr/ark:/12148/bpt6k3100t/f530.item)
1. [G. O. Roberts, R. L. Tweedie (1996), "Exponential Convergence of Langevin Distributions and Their Discrete Approximations", Bernoulli, Vol. 2, No. 4, 341-363, doi:10.2307/3318418](https://doi.org/10.2307/3318418)
1. [Aapo Hyvärinen (2005), "Estimation of non-normalized statistical models by score matching", Journal of Machine Learning Research 6, 695-709](https://jmlr.org/papers/v6/hyvarinen05a.html)
1. [U. Köster, A. Hyvärinen (2010), "A two-layer model of natural stimuli estimated with score matching", Neural. Comput. 22 (no. 9), 2308-33, doi: 10.1162/NECO_a_00010](https://doi.org/10.1162/neco_a_00010)
1. [Durk P. Kingma, Yann Cun (2010), "Regularized estimation of image statistics by Score Matching", Advances in Neural Information Processing Systems 23 (NIPS 2010)](https://papers.nips.cc/paper_files/paper/2010/hash/6f3e29a35278d71c7f65495871231324-Abstract.html)
1. [Pascal Vincent (2011), "A connection between score matching and denoising autoencoders," Neural Computation, 23 (7), 1661-1674, doi:10.1162/NECO_a_00142](https://doi.org/10.1162/NECO_a_00142)
1. [Y. Song, S. Garg, J. Shi, S. Ermon (2020), Sliced Score Matching: A Scalable Approach to Density and Score Estimation, Proceedings of The 35th Uncertainty in Artificial Intelligence Conference, PMLR 115:574-584](https://proceedings.mlr.press/v115/song20a.html) -- see also the [arxiv version](https://arxiv.org/abs/1905.07088)
1. [T. Pang, K. Xu, C. Li, Y. Song, S. Ermon, J. Zhu (2020), Efficient Learning of Generative Models via Finite-Difference Score Matching, NeurIPS](https://openreview.net/forum?id=LVRoKppWczk) - see also the [arxiv version](https://arxiv.org/abs/2007.03317)
1. [J. Sohl-Dickstein, E. A. Weiss, N. Maheswaranathan, S. Ganguli (2015), "Deep unsupervised learning using nonequilibrium thermodynamics", ICML'15: Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37, 2256-2265](https://dl.acm.org/doi/10.5555/3045118.3045358)
1. [J. Ho, A. Jain, P. Abbeel (2020), "Denoising diffusion probabilistic models", in Advances in Neural Information Processing Systems 33, NeurIPS2020](https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html)
1. [A. Q. Nichol and P. Dhariwal (2021), "Improved denoising diffusion probabilistic models", ICLR 2021 Conference](https://openreview.net/forum?id=-NEXDKk8gZ)
1. [J. Song, C. Meng, S. Ermon (2021), "Denoising diffusion implicit models", ICLR 2021 Conference](https://openreview.net/forum?id=St1giarCHLP)
1. [Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, B. Poole (2020), "Score-based generative modeling through stochastic differential equations", arXiv:2011.13456](https://arxiv.org/abs/2011.13456)